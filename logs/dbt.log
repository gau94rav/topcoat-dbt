2021-02-24 16:29:32.999625 (MainThread): Running with dbt=0.17.2
2021-02-24 16:29:33.150464 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-02-24 16:29:33.171380 (MainThread): Tracking: tracking
2021-02-24 16:29:33.179658 (Thread-1): Parsing macros/core.sql
2021-02-24 16:29:33.185084 (Thread-1): Parsing macros/materializations/helpers.sql
2021-02-24 16:29:33.193342 (Thread-1): Parsing macros/materializations/common/merge.sql
2021-02-24 16:29:33.207640 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-24 16:29:33.209702 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2021-02-24 16:29:33.229358 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-24 16:29:33.257784 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-24 16:29:33.262949 (Thread-1): Parsing macros/materializations/view/view.sql
2021-02-24 16:29:33.269346 (Thread-1): Parsing macros/materializations/seed/seed.sql
2021-02-24 16:29:33.291414 (Thread-1): Parsing macros/materializations/table/table.sql
2021-02-24 16:29:33.298332 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2021-02-24 16:29:33.300400 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2021-02-24 16:29:33.306647 (Thread-1): Parsing macros/etc/is_incremental.sql
2021-02-24 16:29:33.308409 (Thread-1): Parsing macros/etc/query.sql
2021-02-24 16:29:33.309673 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc5bff40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc3591c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc359bb0>]}
2021-02-24 16:29:33.310068 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=15
2021-02-24 16:29:33.310471 (Thread-1): Parsing macros/etc/datetime.sql
2021-02-24 16:29:33.310662 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-02-24 16:29:33.319662 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-02-24 16:29:33.320063 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2021-02-24 16:29:33.321332 (Thread-1): Parsing macros/etc/get_custom_database.sql
2021-02-24 16:29:33.323181 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2021-02-24 16:29:33.325156 (Thread-1): Parsing macros/schema_tests/not_null.sql
2021-02-24 16:29:33.326077 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2021-02-24 16:29:33.328004 (Thread-1): Parsing macros/schema_tests/relationships.sql
2021-02-24 16:29:33.329144 (Thread-1): Parsing macros/schema_tests/unique.sql
2021-02-24 16:29:33.330271 (Thread-1): Parsing macros/adapters/common.sql
2021-02-24 16:29:33.380998 (Thread-1): Parsing macros/adapters.sql
2021-02-24 16:29:33.397298 (Thread-1): Parsing macros/etc.sql
2021-02-24 16:29:33.398073 (Thread-1): Parsing macros/catalog.sql
2021-02-24 16:29:33.404027 (Thread-1): Parsing macros/materializations/table.sql
2021-02-24 16:29:33.413708 (Thread-1): Parsing macros/materializations/incremental.sql
2021-02-24 16:29:33.426133 (Thread-1): Parsing macros/materializations/seed.sql
2021-02-24 16:29:33.428851 (Thread-1): Parsing macros/materializations/snapshot.sql
2021-02-24 16:29:33.430641 (Thread-1): Parsing macros/materializations/view.sql
2021-02-24 16:29:33.499155 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-24 16:29:33.499355 (Thread-1): Opening a new connection, currently in state init
2021-02-24 16:29:33.529643 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-24 16:29:33.529805 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 16:29:33.546147 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-24 16:29:33.546311 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 16:29:33.558919 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-24 16:29:33.559074 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 16:29:33.570645 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-24 16:29:33.570800 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 16:29:33.585265 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-24 16:29:33.585419 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 16:29:33.599423 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-24 16:29:33.599600 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 16:29:34.085473 (Thread-2): handling status request
2021-02-24 16:29:34.085931 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc5b2190>]}
2021-02-24 16:29:34.090901 (Thread-2): sending response (<Response 12402 bytes [200 OK]>) to 10.0.38.142
2021-02-24 16:29:59.580018 (Thread-3): handling status request
2021-02-24 16:29:59.582778 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc6050d0>]}
2021-02-24 16:29:59.586725 (Thread-3): sending response (<Response 12402 bytes [200 OK]>) to 10.0.2.80
2021-02-24 16:29:59.872057 (Thread-4): handling run_sql request
2021-02-24 16:29:59.872485 (Thread-4): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc605b50>]}
2021-02-24 16:29:59.875113 (Thread-4): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-24 16:30:00.687120 (Thread-4): sending response (<Response 136 bytes [200 OK]>) to 10.0.46.68
2021-02-24 16:30:00.702603 (MainThread): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-02-24 16:30:00.702949 (MainThread): Opening a new connection, currently in state init
2021-02-24 16:30:00.737877 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 147 macros, 0 operations, 0 seed files, 0 sources
2021-02-24 16:30:00.738726 (Thread-1): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-02-24 16:30:00.738820 (Thread-1): Opening a new connection, currently in state init
2021-02-24 16:30:00.738886 (Thread-1): Compiling rpc.hashpath_demo.request
2021-02-24 16:30:00.754129 (Thread-1): finished collecting timing info
2021-02-24 16:30:00.754743 (Thread-1): On rpc.hashpath_demo.request: 

SELECT s.* FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
limit 500
/* limit added automatically by dbt cloud */
2021-02-24 16:30:00.966428 (Thread-5): handling poll request
2021-02-24 16:30:00.966894 (Thread-5): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc2d8dc0>]}
2021-02-24 16:30:00.970182 (Thread-5): sending response (<Response 3013 bytes [200 OK]>) to 10.0.13.171
2021-02-24 16:30:02.292337 (Thread-6): handling poll request
2021-02-24 16:30:02.292771 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc308df0>]}
2021-02-24 16:30:02.293674 (Thread-6): sending response (<Response 402 bytes [200 OK]>) to 10.0.13.171
2021-02-24 16:30:03.595789 (Thread-7): handling poll request
2021-02-24 16:30:03.596217 (Thread-7): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc3081f0>]}
2021-02-24 16:30:03.597073 (Thread-7): sending response (<Response 402 bytes [200 OK]>) to 10.0.1.18
2021-02-24 16:30:03.963131 (Thread-1): finished collecting timing info
2021-02-24 16:30:04.911909 (Thread-8): handling poll request
2021-02-24 16:30:04.912430 (Thread-8): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc1a5e50>]}
2021-02-24 16:30:04.931743 (Thread-8): sending response (<Response 1097703 bytes [200 OK]>) to 10.0.40.10
2021-02-24 18:59:20.631533 (Thread-9): handling status request
2021-02-24 18:59:20.632208 (Thread-10): handling ps request
2021-02-24 18:59:20.633752 (Thread-9): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc154430>]}
2021-02-24 18:59:20.634119 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc25dca0>]}
2021-02-24 18:59:20.638179 (Thread-9): sending response (<Response 12402 bytes [200 OK]>) to 10.0.44.85
2021-02-24 18:59:20.640253 (Thread-10): sending response (<Response 617 bytes [200 OK]>) to 10.0.38.103
2021-02-24 21:21:07.812058 (Thread-11): handling status request
2021-02-24 21:21:07.812572 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc1aad60>]}
2021-02-24 21:21:07.816746 (Thread-11): sending response (<Response 12402 bytes [200 OK]>) to 10.0.13.120
2021-02-24 21:21:07.898753 (Thread-12): handling ps request
2021-02-24 21:21:07.899165 (Thread-12): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc154ac0>]}
2021-02-24 21:21:07.900113 (Thread-12): sending response (<Response 617 bytes [200 OK]>) to 10.0.39.131
2021-02-24 21:22:24.765166 (Thread-13): handling status request
2021-02-24 21:22:24.767839 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc5aadf0>]}
2021-02-24 21:22:24.771845 (Thread-13): sending response (<Response 12402 bytes [200 OK]>) to 10.0.20.25
2021-02-24 21:22:24.840921 (Thread-14): handling status request
2021-02-24 21:22:24.841330 (Thread-14): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc25da60>]}
2021-02-24 21:22:24.845397 (Thread-14): sending response (<Response 12402 bytes [200 OK]>) to 10.0.38.248
2021-02-24 21:22:25.140828 (Thread-15): handling cli_args request
2021-02-24 21:22:25.141245 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0d18a37c0>]}
2021-02-24 21:22:25.153457 (Thread-15): sending response (<Response 561 bytes [200 OK]>) to 10.0.38.248
2021-02-24 21:22:27.745643 (Thread-16): handling status request
2021-02-24 21:22:27.746063 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc1d43a0>]}
2021-02-24 21:22:27.751140 (Thread-16): sending response (<Response 12402 bytes [200 OK]>) to 10.0.20.37
2021-02-24 21:22:37.209193 (Thread-17): handling status request
2021-02-24 21:22:37.209652 (Thread-17): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc1ecd90>]}
2021-02-24 21:22:37.213752 (Thread-17): sending response (<Response 12402 bytes [200 OK]>) to 10.0.8.202
2021-02-24 21:22:37.215096 (Thread-18): handling status request
2021-02-24 21:22:37.215424 (Thread-18): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc30ffd0>]}
2021-02-24 21:22:37.219364 (Thread-18): sending response (<Response 12402 bytes [200 OK]>) to 10.0.39.131
2021-02-24 21:22:37.489826 (Thread-19): handling docs.generate request
2021-02-24 21:22:37.490252 (Thread-19): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc34e850>]}
2021-02-24 21:22:38.287403 (Thread-19): sending response (<Response 136 bytes [200 OK]>) to 10.0.13.0
2021-02-24 21:22:38.313810 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 147 macros, 0 operations, 0 seed files, 0 sources
2021-02-24 21:22:38.315038 (MainThread): 
2021-02-24 21:22:38.315328 (MainThread): Acquiring new bigquery connection "master".
2021-02-24 21:22:38.315387 (MainThread): Opening a new connection, currently in state init
2021-02-24 21:22:38.331652 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-24 21:22:38.331753 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-24 21:22:38.560662 (MainThread): 21:22:38 | Concurrency: 1 threads (target='default')
2021-02-24 21:22:38.560795 (MainThread): 21:22:38 | 
2021-02-24 21:22:38.562910 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-24 21:22:38.574124 (Thread-20): handling poll request
2021-02-24 21:22:38.563120 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-24 21:22:38.575001 (Thread-20): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc30ffd0>]}
2021-02-24 21:22:38.577273 (Thread-20): sending response (<Response 3603 bytes [200 OK]>) to 10.0.3.189
2021-02-24 21:22:38.563188 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.563252 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-24 21:22:38.580258 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-24 21:22:38.621575 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.621932 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.622157 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-24 21:22:38.622258 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-24 21:22:38.622349 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-24 21:22:38.622405 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.622455 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-24 21:22:38.630580 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-24 21:22:38.652069 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.652387 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.652586 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-24 21:22:38.652683 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-24 21:22:38.652779 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-24 21:22:38.652834 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.652884 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-24 21:22:38.696581 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-24 21:22:38.708555 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.708834 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.709034 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-24 21:22:38.709129 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-24 21:22:38.709217 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-24 21:22:38.709271 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.709322 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-24 21:22:38.718341 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-24 21:22:38.746952 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.747248 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.747450 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-24 21:22:38.747572 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-24 21:22:38.747666 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-24 21:22:38.747723 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.747775 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-24 21:22:38.754416 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-24 21:22:38.766073 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.766351 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.766552 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-24 21:22:38.766648 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-24 21:22:38.766738 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-24 21:22:38.766794 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.766845 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-24 21:22:38.774254 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-24 21:22:38.786117 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.786402 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.786608 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-24 21:22:38.786703 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-24 21:22:38.786796 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-24 21:22:38.786851 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.786902 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-24 21:22:38.794640 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-24 21:22:38.810684 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.810966 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.811170 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-24 21:22:38.811265 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-24 21:22:38.811361 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-24 21:22:38.811417 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.811494 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-24 21:22:38.832931 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-24 21:22:38.858701 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.859063 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.859274 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-24 21:22:38.859379 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-24 21:22:38.859509 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-24 21:22:38.859573 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.859628 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-24 21:22:38.870043 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-24 21:22:38.883657 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.883970 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.884183 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-24 21:22:38.884284 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-24 21:22:38.884389 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-24 21:22:38.884445 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.884497 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-24 21:22:38.893249 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-24 21:22:38.905119 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.905386 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.905588 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-24 21:22:38.905682 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-24 21:22:38.905773 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-24 21:22:38.905827 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:22:38.905877 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-24 21:22:38.913655 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-24 21:22:38.926151 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.926414 (Thread-1): finished collecting timing info
2021-02-24 21:22:38.926613 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-24 21:22:38.927831 (MainThread): Connection 'master' was properly closed.
2021-02-24 21:22:38.927973 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-24 21:22:39.001817 (MainThread): 21:22:38 | Done.
2021-02-24 21:22:39.047273 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-02-24 21:22:39.047463 (MainThread): Opening a new connection, currently in state init
2021-02-24 21:22:39.047596 (MainThread): 21:22:39 | Building catalog
2021-02-24 21:22:39.270507 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-02-24 21:22:39.270648 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-02-24 21:22:39.292955 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: 
    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_jrosen`.__TABLES__
        where (upper(dataset_id) = upper('dbt_jrosen'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-02-24 21:22:39.871016 (Thread-21): handling poll request
2021-02-24 21:22:39.871450 (Thread-21): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc270e20>]}
2021-02-24 21:22:39.879715 (Thread-21): sending response (<Response 47347 bytes [200 OK]>) to 10.0.20.25
2021-02-24 21:22:41.142686 (Thread-22): handling poll request
2021-02-24 21:22:41.143106 (Thread-22): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc251460>]}
2021-02-24 21:22:41.144020 (Thread-22): sending response (<Response 293 bytes [200 OK]>) to 10.0.24.132
2021-02-24 21:22:42.221736 (MainThread): 21:22:42 | Catalog written to /usr/src/develop/user-7994/environment-9499/repository-16870/target/catalog.json
2021-02-24 21:22:42.478730 (Thread-23): handling poll request
2021-02-24 21:22:42.479163 (Thread-23): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc251c10>]}
2021-02-24 21:22:42.484747 (Thread-23): sending response (<Response 12079 bytes [200 OK]>) to 10.0.38.248
2021-02-24 21:22:42.753179 (Thread-24): handling status request
2021-02-24 21:22:42.753601 (Thread-24): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc2e8a30>]}
2021-02-24 21:22:42.757664 (Thread-24): sending response (<Response 12402 bytes [200 OK]>) to 10.0.17.9
2021-02-24 21:23:01.287311 (Thread-25): handling status request
2021-02-24 21:23:01.287792 (Thread-25): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc2b6430>]}
2021-02-24 21:23:01.291718 (Thread-25): sending response (<Response 12402 bytes [200 OK]>) to 10.0.13.0
2021-02-24 21:23:10.844525 (Thread-26): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-24 21:23:10.844705 (Thread-26): Opening a new connection, currently in state init
2021-02-24 21:23:10.859816 (Thread-26): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-24 21:23:10.859985 (Thread-26): Opening a new connection, currently in state closed
2021-02-24 21:23:10.876142 (Thread-26): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-24 21:23:10.876307 (Thread-26): Opening a new connection, currently in state closed
2021-02-24 21:23:10.889326 (Thread-26): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-24 21:23:10.889494 (Thread-26): Opening a new connection, currently in state closed
2021-02-24 21:23:10.900744 (Thread-26): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-24 21:23:10.900904 (Thread-26): Opening a new connection, currently in state closed
2021-02-24 21:23:10.915456 (Thread-26): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-24 21:23:10.915642 (Thread-26): Opening a new connection, currently in state closed
2021-02-24 21:23:10.929358 (Thread-26): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-24 21:23:10.929518 (Thread-26): Opening a new connection, currently in state closed
2021-02-24 21:23:11.038439 (Thread-27): handling status request
2021-02-24 21:23:11.038876 (Thread-27): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6d65d60>]}
2021-02-24 21:23:11.039613 (Thread-27): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.202
2021-02-24 21:23:12.893611 (Thread-28): handling status request
2021-02-24 21:23:12.894147 (Thread-28): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6d75ca0>]}
2021-02-24 21:23:12.896139 (Thread-28): sending response (<Response 4277 bytes [200 OK]>) to 10.0.12.219
2021-02-24 21:51:33.307264 (Thread-29): handling status request
2021-02-24 21:51:33.308029 (Thread-30): handling status request
2021-02-24 21:51:33.309430 (Thread-29): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc16c940>]}
2021-02-24 21:51:33.309830 (Thread-30): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc383b50>]}
2021-02-24 21:51:33.311678 (Thread-29): sending response (<Response 4277 bytes [200 OK]>) to 10.0.38.248
2021-02-24 21:51:33.314367 (Thread-30): sending response (<Response 4277 bytes [200 OK]>) to 10.0.32.159
2021-02-24 21:51:33.586816 (Thread-31): handling docs.generate request
2021-02-24 21:51:33.587233 (Thread-31): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0bc2d4910>]}
2021-02-24 21:51:33.614710 (Thread-31): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-24 21:51:34.430440 (Thread-31): sending response (<Response 136 bytes [200 OK]>) to 10.0.8.202
2021-02-24 21:51:34.481879 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 147 macros, 0 operations, 0 seed files, 0 sources
2021-02-24 21:51:34.483152 (MainThread): 
2021-02-24 21:51:34.483479 (MainThread): Acquiring new bigquery connection "master".
2021-02-24 21:51:34.483548 (MainThread): Opening a new connection, currently in state init
2021-02-24 21:51:34.499859 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-24 21:51:34.499988 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-24 21:51:34.700473 (MainThread): 21:51:34 | Concurrency: 1 threads (target='default')
2021-02-24 21:51:34.700602 (MainThread): 21:51:34 | 
2021-02-24 21:51:34.702880 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-24 21:51:34.712694 (Thread-32): handling poll request
2021-02-24 21:51:34.713082 (Thread-32): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e3b280>]}
2021-02-24 21:51:34.715155 (Thread-32): sending response (<Response 3272 bytes [200 OK]>) to 10.0.32.159
2021-02-24 21:51:34.703054 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-24 21:51:34.703119 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.703182 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-24 21:51:34.719121 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-24 21:51:34.745014 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.745339 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.745557 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-24 21:51:34.745657 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-24 21:51:34.745748 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-24 21:51:34.745802 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.745852 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-24 21:51:34.754269 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-24 21:51:34.772930 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.773223 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.773422 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-24 21:51:34.773516 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-24 21:51:34.773604 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-24 21:51:34.773657 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.773707 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-24 21:51:34.785152 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-24 21:51:34.801904 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.802160 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.802359 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-24 21:51:34.802454 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-24 21:51:34.802543 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-24 21:51:34.802597 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.802646 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-24 21:51:34.847429 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-24 21:51:34.864322 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.864639 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.864843 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-24 21:51:34.864941 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-24 21:51:34.865032 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-24 21:51:34.865087 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.865137 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-24 21:51:34.872047 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-24 21:51:34.889933 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.890210 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.890408 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-24 21:51:34.890507 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-24 21:51:34.890595 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-24 21:51:34.890650 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.890700 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-24 21:51:34.898092 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-24 21:51:34.915900 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.916181 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.916380 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-24 21:51:34.916475 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-24 21:51:34.916562 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-24 21:51:34.916614 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.916664 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-24 21:51:34.924459 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-24 21:51:34.943013 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.943298 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.943527 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-24 21:51:34.943626 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-24 21:51:34.943721 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-24 21:51:34.943777 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.943829 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-24 21:51:34.965298 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-24 21:51:34.987495 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.987792 (Thread-1): finished collecting timing info
2021-02-24 21:51:34.987997 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-24 21:51:34.988101 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-24 21:51:34.988194 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-24 21:51:34.988251 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:34.988302 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-24 21:51:34.998127 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-24 21:51:35.017031 (Thread-1): finished collecting timing info
2021-02-24 21:51:35.017283 (Thread-1): finished collecting timing info
2021-02-24 21:51:35.017477 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-24 21:51:35.017567 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-24 21:51:35.017656 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-24 21:51:35.017710 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:35.017760 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-24 21:51:35.026167 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-24 21:51:35.044491 (Thread-1): finished collecting timing info
2021-02-24 21:51:35.044720 (Thread-1): finished collecting timing info
2021-02-24 21:51:35.044927 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-24 21:51:35.045018 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-24 21:51:35.045101 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-24 21:51:35.045153 (Thread-1): Opening a new connection, currently in state closed
2021-02-24 21:51:35.045200 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-24 21:51:35.052810 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-24 21:51:35.069776 (Thread-1): finished collecting timing info
2021-02-24 21:51:35.070046 (Thread-1): finished collecting timing info
2021-02-24 21:51:35.070241 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-24 21:51:35.071311 (MainThread): Connection 'master' was properly closed.
2021-02-24 21:51:35.071404 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-24 21:51:35.133031 (MainThread): 21:51:35 | Done.
2021-02-24 21:51:35.205688 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-02-24 21:51:35.205832 (MainThread): Opening a new connection, currently in state init
2021-02-24 21:51:35.205889 (MainThread): 21:51:35 | Building catalog
2021-02-24 21:51:35.405124 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-02-24 21:51:35.405263 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-02-24 21:51:35.434039 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: 
    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_jrosen`.__TABLES__
        where (upper(dataset_id) = upper('dbt_jrosen'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-02-24 21:51:36.028774 (Thread-33): handling poll request
2021-02-24 21:51:36.029256 (Thread-33): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e3bbb0>]}
2021-02-24 21:51:36.038032 (Thread-33): sending response (<Response 47706 bytes [200 OK]>) to 10.0.38.248
2021-02-24 21:51:37.341766 (Thread-34): handling poll request
2021-02-24 21:51:37.342188 (Thread-34): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6d1cb80>]}
2021-02-24 21:51:37.343053 (Thread-34): sending response (<Response 308 bytes [200 OK]>) to 10.0.32.32
2021-02-24 21:51:38.203707 (MainThread): 21:51:38 | Catalog written to /usr/src/develop/user-7994/environment-9499/repository-16870/target/catalog.json
2021-02-24 21:51:38.634917 (Thread-35): handling poll request
2021-02-24 21:51:38.635337 (Thread-35): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e08460>]}
2021-02-24 21:51:38.640839 (Thread-35): sending response (<Response 12093 bytes [200 OK]>) to 10.0.32.159
2021-02-24 21:51:38.939338 (Thread-36): handling status request
2021-02-24 21:51:38.939790 (Thread-36): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e14f40>]}
2021-02-24 21:51:38.941567 (Thread-36): sending response (<Response 4277 bytes [200 OK]>) to 10.0.32.32
2021-02-25 00:33:54.255038 (Thread-37): handling status request
2021-02-25 00:33:54.255505 (Thread-37): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e14640>]}
2021-02-25 00:33:54.257241 (Thread-37): sending response (<Response 4277 bytes [200 OK]>) to 10.0.12.44
2021-02-25 00:33:54.281074 (Thread-38): handling ps request
2021-02-25 00:33:54.281565 (Thread-38): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e16cd0>]}
2021-02-25 00:33:54.283614 (Thread-38): sending response (<Response 1866 bytes [200 OK]>) to 10.0.12.44
2021-02-25 00:33:54.662031 (Thread-39): handling poll request
2021-02-25 00:33:54.662448 (Thread-39): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e16670>]}
2021-02-25 00:33:54.676030 (Thread-39): sending response (<Response 62459 bytes [200 OK]>) to 10.0.12.26
2021-02-25 00:33:54.948331 (Thread-40): handling status request
2021-02-25 00:33:54.948800 (Thread-40): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e168e0>]}
2021-02-25 00:33:54.950566 (Thread-40): sending response (<Response 4277 bytes [200 OK]>) to 10.0.28.107
2021-02-25 01:24:15.909194 (Thread-41): handling ps request
2021-02-25 01:24:15.909624 (Thread-41): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e168b0>]}
2021-02-25 01:24:15.911006 (Thread-41): sending response (<Response 1866 bytes [200 OK]>) to 10.0.26.158
2021-02-25 01:24:16.045656 (Thread-42): handling status request
2021-02-25 01:24:16.046073 (Thread-42): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e16ac0>]}
2021-02-25 01:24:16.047845 (Thread-42): sending response (<Response 4277 bytes [200 OK]>) to 10.0.32.171
2021-02-25 01:24:16.278294 (Thread-43): handling poll request
2021-02-25 01:24:16.278727 (Thread-43): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e14340>]}
2021-02-25 01:24:16.292723 (Thread-43): sending response (<Response 62459 bytes [200 OK]>) to 10.0.40.10
2021-02-25 01:24:16.645327 (Thread-44): handling status request
2021-02-25 01:24:16.645785 (Thread-44): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6e30f10>]}
2021-02-25 01:24:16.647597 (Thread-44): sending response (<Response 4277 bytes [200 OK]>) to 10.0.32.171
2021-02-25 01:26:59.651378 (Thread-45): Got an acceptable cached parse result
2021-02-25 01:26:59.939282 (Thread-46): handling status request
2021-02-25 01:26:59.939714 (Thread-46): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6d47820>]}
2021-02-25 01:26:59.940473 (Thread-46): sending response (<Response 445 bytes [200 OK]>) to 10.0.15.163
2021-02-25 01:27:04.742326 (Thread-47): Got an acceptable cached parse result
2021-02-25 01:27:04.963093 (Thread-48): handling status request
2021-02-25 01:27:04.963551 (Thread-48): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6c3fe20>]}
2021-02-25 01:27:04.964364 (Thread-48): sending response (<Response 445 bytes [200 OK]>) to 10.0.31.134
2021-02-25 01:27:35.879078 (Thread-49): handling ps request
2021-02-25 01:27:35.879538 (Thread-49): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6c3fee0>]}
2021-02-25 01:27:35.880988 (Thread-49): sending response (<Response 1866 bytes [200 OK]>) to 10.0.19.152
2021-02-25 01:27:35.930372 (Thread-50): handling status request
2021-02-25 01:27:35.930910 (Thread-50): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6c30970>]}
2021-02-25 01:27:35.931876 (Thread-50): sending response (<Response 445 bytes [200 OK]>) to 10.0.32.171
2021-02-25 01:27:36.293009 (Thread-51): handling poll request
2021-02-25 01:27:36.293492 (Thread-51): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfaa00>]}
2021-02-25 01:27:36.307301 (Thread-51): sending response (<Response 62459 bytes [200 OK]>) to 10.0.28.107
2021-02-25 01:27:36.681266 (Thread-52): handling status request
2021-02-25 01:27:36.681685 (Thread-52): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfa7f0>]}
2021-02-25 01:27:36.682449 (Thread-52): sending response (<Response 445 bytes [200 OK]>) to 10.0.15.163
2021-02-25 01:29:38.545987 (Thread-53): handling status request
2021-02-25 01:29:38.548369 (Thread-53): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfa610>]}
2021-02-25 01:29:38.549490 (Thread-53): sending response (<Response 445 bytes [200 OK]>) to 10.0.26.158
2021-02-25 01:29:38.565766 (Thread-54): handling status request
2021-02-25 01:29:38.566103 (Thread-54): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfa430>]}
2021-02-25 01:29:38.566823 (Thread-54): sending response (<Response 445 bytes [200 OK]>) to 10.0.5.107
2021-02-25 01:29:38.900737 (Thread-55): handling deps request
2021-02-25 01:29:38.901175 (Thread-55): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfa1f0>]}
2021-02-25 01:29:38.964551 (Thread-55): sending response (<Response 136 bytes [200 OK]>) to 10.0.10.7
2021-02-25 01:29:39.242622 (Thread-56): handling poll request
2021-02-25 01:29:39.243125 (Thread-56): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bf1250>]}
2021-02-25 01:29:39.244508 (Thread-56): sending response (<Response 285 bytes [200 OK]>) to 10.0.12.26
2021-02-25 01:29:39.755236 (MainThread): Set downloads directory='/tmp/dbt-downloads-qagjg3i6'
2021-02-25 01:29:39.756561 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2021-02-25 01:29:39.806127 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2021-02-25 01:29:39.806596 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/github_source.json
2021-02-25 01:29:39.852020 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/github_source.json 200
2021-02-25 01:29:39.853988 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/github_source/0.2.2.json
2021-02-25 01:29:39.895957 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/github_source/0.2.2.json 200
2021-02-25 01:29:39.909562 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2021-02-25 01:29:39.952012 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2021-02-25 01:29:39.965915 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.4.json
2021-02-25 01:29:40.010866 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.4.json 200
2021-02-25 01:29:40.011801 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2021-02-25 01:29:40.261013 (MainThread): STDOUT: "b''"
2021-02-25 01:29:40.261253 (MainThread): STDERR: "b"Cloning into '2570ae56bf9cb34e49fe01aa3bc99195'...\n""
2021-02-25 01:29:40.261626 (MainThread): Pulling new dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2021-02-25 01:29:40.261695 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:29:40.266286 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:29:40.266456 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.266527 (MainThread):   Checking out branch master.
2021-02-25 01:29:40.266570 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 01:29:40.271040 (MainThread): STDOUT: "b''"
2021-02-25 01:29:40.271243 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.271303 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 01:29:40.473610 (MainThread): STDOUT: "b''"
2021-02-25 01:29:40.473855 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 01:29:40.473926 (MainThread): Executing "git tag --list"
2021-02-25 01:29:40.478540 (MainThread): STDOUT: "b''"
2021-02-25 01:29:40.478754 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.478828 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 01:29:40.484762 (MainThread): STDOUT: "b'HEAD is now at f85759f Merge pull request #13 from fivetran/enabled_vars_one_true\n'"
2021-02-25 01:29:40.484969 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.485043 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:29:40.488469 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:29:40.488663 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.488731 (MainThread):   Checked out at f85759f.
2021-02-25 01:29:40.510693 (Thread-57): handling poll request
2021-02-25 01:29:40.511155 (Thread-57): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6c3f640>]}
2021-02-25 01:29:40.514590 (Thread-57): sending response (<Response 10459 bytes [200 OK]>) to 10.0.10.7
2021-02-25 01:29:40.512606 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/github_source.json
2021-02-25 01:29:40.556419 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/github_source.json 200
2021-02-25 01:29:40.558458 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2021-02-25 01:29:40.600500 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2021-02-25 01:29:40.613162 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/github_source/0.2.2.json
2021-02-25 01:29:40.660262 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/github_source/0.2.2.json 200
2021-02-25 01:29:40.666066 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.4.json
2021-02-25 01:29:40.707681 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.4.json 200
2021-02-25 01:29:40.708443 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2021-02-25 01:29:40.712867 (MainThread): STDOUT: "b''"
2021-02-25 01:29:40.713058 (MainThread): STDERR: "b"fatal: destination path '2570ae56bf9cb34e49fe01aa3bc99195' already exists and is not an empty directory.\n""
2021-02-25 01:29:40.713104 (MainThread): command return code=128
2021-02-25 01:29:40.713523 (MainThread): Updating existing dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2021-02-25 01:29:40.713588 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:29:40.717342 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:29:40.717530 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.717607 (MainThread):   Checking out branch master.
2021-02-25 01:29:40.717650 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 01:29:40.722158 (MainThread): STDOUT: "b''"
2021-02-25 01:29:40.722358 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.722419 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 01:29:40.947861 (MainThread): STDOUT: "b''"
2021-02-25 01:29:40.948112 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 01:29:40.948184 (MainThread): Executing "git tag --list"
2021-02-25 01:29:40.952952 (MainThread): STDOUT: "b''"
2021-02-25 01:29:40.953127 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.953200 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 01:29:40.958968 (MainThread): STDOUT: "b'HEAD is now at f85759f Merge pull request #13 from fivetran/enabled_vars_one_true\n'"
2021-02-25 01:29:40.959167 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.959242 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:29:40.962707 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:29:40.962863 (MainThread): STDERR: "b''"
2021-02-25 01:29:40.962928 (MainThread):   Already at f85759f, nothing to do.
2021-02-25 01:29:40.973060 (MainThread): Installing fivetran/github_source@0.2.2
2021-02-25 01:29:41.784377 (Thread-58): handling poll request
2021-02-25 01:29:41.784813 (Thread-58): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bea340>]}
2021-02-25 01:29:41.788107 (Thread-58): sending response (<Response 10156 bytes [200 OK]>) to 10.0.12.26
2021-02-25 01:29:43.066479 (MainThread):   Installed from version 0.2.2

2021-02-25 01:29:43.066726 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ca8bfdd4-ee1d-4afe-9300-49fcfe9edaa0', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea035a9e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea035af2b0>]}
2021-02-25 01:29:43.067017 (MainThread): Installing fishtown-analytics/dbt_utils@0.6.4
2021-02-25 01:29:43.169853 (Thread-59): handling poll request
2021-02-25 01:29:43.170288 (Thread-59): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b759d0>]}
2021-02-25 01:29:43.171357 (Thread-59): sending response (<Response 1371 bytes [200 OK]>) to 10.0.5.107
2021-02-25 01:29:44.447639 (Thread-60): handling poll request
2021-02-25 01:29:44.448068 (Thread-60): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b759a0>]}
2021-02-25 01:29:44.448933 (Thread-60): sending response (<Response 285 bytes [200 OK]>) to 10.0.19.152
2021-02-25 01:29:45.713959 (Thread-61): handling poll request
2021-02-25 01:29:45.714527 (Thread-61): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfd250>]}
2021-02-25 01:29:45.715753 (Thread-61): sending response (<Response 285 bytes [200 OK]>) to 10.0.15.163
2021-02-25 01:29:46.994460 (Thread-62): handling poll request
2021-02-25 01:29:46.994906 (Thread-62): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfdb20>]}
2021-02-25 01:29:46.995796 (Thread-62): sending response (<Response 285 bytes [200 OK]>) to 10.0.8.47
2021-02-25 01:29:48.230118 (Thread-63): handling poll request
2021-02-25 01:29:48.230557 (Thread-63): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfdb80>]}
2021-02-25 01:29:48.255340 (Thread-63): sending response (<Response 285 bytes [200 OK]>) to 10.0.19.152
2021-02-25 01:29:48.773950 (MainThread):   Installed from version 0.6.4

2021-02-25 01:29:48.774146 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ca8bfdd4-ee1d-4afe-9300-49fcfe9edaa0', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea036337c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea035a9460>]}
2021-02-25 01:29:48.774454 (MainThread): Installing https://github.com/fivetran/dbt_fivetran_utils.git@master
2021-02-25 01:29:48.776525 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2021-02-25 01:29:48.780897 (MainThread): STDOUT: "b''"
2021-02-25 01:29:48.781097 (MainThread): STDERR: "b"fatal: destination path '2570ae56bf9cb34e49fe01aa3bc99195' already exists and is not an empty directory.\n""
2021-02-25 01:29:48.781142 (MainThread): command return code=128
2021-02-25 01:29:48.781277 (MainThread): Updating existing dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2021-02-25 01:29:48.781331 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:29:48.785117 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:29:48.785306 (MainThread): STDERR: "b''"
2021-02-25 01:29:48.785380 (MainThread):   Checking out branch master.
2021-02-25 01:29:48.785423 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 01:29:48.790053 (MainThread): STDOUT: "b''"
2021-02-25 01:29:48.790246 (MainThread): STDERR: "b''"
2021-02-25 01:29:48.790308 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 01:29:48.996008 (MainThread): STDOUT: "b''"
2021-02-25 01:29:48.996260 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 01:29:48.996336 (MainThread): Executing "git tag --list"
2021-02-25 01:29:49.000941 (MainThread): STDOUT: "b''"
2021-02-25 01:29:49.001149 (MainThread): STDERR: "b''"
2021-02-25 01:29:49.001222 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 01:29:49.007073 (MainThread): STDOUT: "b'HEAD is now at f85759f Merge pull request #13 from fivetran/enabled_vars_one_true\n'"
2021-02-25 01:29:49.007238 (MainThread): STDERR: "b''"
2021-02-25 01:29:49.007308 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:29:49.010712 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:29:49.010903 (MainThread): STDERR: "b''"
2021-02-25 01:29:49.010972 (MainThread):   Already at f85759f, nothing to do.
2021-02-25 01:29:49.517868 (Thread-64): handling poll request
2021-02-25 01:29:49.518278 (Thread-64): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfac40>]}
2021-02-25 01:29:49.521145 (Thread-64): sending response (<Response 8344 bytes [200 OK]>) to 10.0.12.44
2021-02-25 01:29:50.776554 (Thread-65): handling poll request
2021-02-25 01:29:50.777023 (Thread-65): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6c3f820>]}
2021-02-25 01:29:50.777893 (Thread-65): sending response (<Response 286 bytes [200 OK]>) to 10.0.12.44
2021-02-25 01:29:51.935078 (MainThread):   Installed from revision master

2021-02-25 01:29:51.935409 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ca8bfdd4-ee1d-4afe-9300-49fcfe9edaa0', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea048ad1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fea035d7be0>]}
2021-02-25 01:29:52.089012 (Thread-66): handling poll request
2021-02-25 01:29:52.090358 (Thread-66): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b8f370>]}
2021-02-25 01:29:52.096433 (Thread-66): sending response (<Response 1096 bytes [200 OK]>) to 10.0.40.10
2021-02-25 01:29:53.396645 (Thread-67): handling poll request
2021-02-25 01:29:53.398321 (Thread-67): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6c3faf0>]}
2021-02-25 01:29:53.399137 (Thread-67): sending response (<Response 626 bytes [200 OK]>) to 10.0.45.17
2021-02-25 01:29:53.660576 (Thread-68): handling status request
2021-02-25 01:29:53.661027 (Thread-68): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfa940>]}
2021-02-25 01:29:53.669124 (Thread-68): sending response (<Response 30627 bytes [200 OK]>) to 10.0.28.107
2021-02-25 01:30:43.700271 (Thread-69): handling status request
2021-02-25 01:30:43.700806 (Thread-69): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfa1c0>]}
2021-02-25 01:30:43.712397 (Thread-69): sending response (<Response 30627 bytes [200 OK]>) to 10.0.8.47
2021-02-25 01:30:43.759578 (Thread-70): handling status request
2021-02-25 01:30:43.760227 (Thread-70): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfd790>]}
2021-02-25 01:30:43.774298 (Thread-70): sending response (<Response 30627 bytes [200 OK]>) to 10.0.15.163
2021-02-25 01:30:44.008845 (Thread-71): handling deps request
2021-02-25 01:30:44.009273 (Thread-71): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b858e0>]}
2021-02-25 01:30:44.103842 (Thread-71): sending response (<Response 136 bytes [200 OK]>) to 10.0.8.47
2021-02-25 01:30:44.399723 (Thread-72): handling poll request
2021-02-25 01:30:44.400234 (Thread-72): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b85f40>]}
2021-02-25 01:30:44.401680 (Thread-72): sending response (<Response 304 bytes [200 OK]>) to 10.0.15.163
2021-02-25 01:30:45.725254 (Thread-73): handling poll request
2021-02-25 01:30:45.725745 (Thread-73): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6c3f880>]}
2021-02-25 01:30:45.726880 (Thread-73): sending response (<Response 304 bytes [200 OK]>) to 10.0.40.10
2021-02-25 01:30:47.039059 (Thread-74): handling poll request
2021-02-25 01:30:47.039560 (Thread-74): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfdd60>]}
2021-02-25 01:30:47.040456 (Thread-74): sending response (<Response 303 bytes [200 OK]>) to 10.0.36.20
2021-02-25 01:30:47.451429 (MainThread): Set downloads directory='/tmp/dbt-downloads-zorh4esa'
2021-02-25 01:30:47.452896 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2021-02-25 01:30:47.508575 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2021-02-25 01:30:47.509009 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/github_source.json
2021-02-25 01:30:47.530470 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/github_source.json 200
2021-02-25 01:30:47.533440 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/github_source/0.2.2.json
2021-02-25 01:30:47.582826 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/github_source/0.2.2.json 200
2021-02-25 01:30:47.596109 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2021-02-25 01:30:47.645036 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2021-02-25 01:30:47.658887 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.4.json
2021-02-25 01:30:47.705837 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.4.json 200
2021-02-25 01:30:47.706894 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2021-02-25 01:30:47.962651 (MainThread): STDOUT: "b''"
2021-02-25 01:30:47.962936 (MainThread): STDERR: "b"Cloning into '2570ae56bf9cb34e49fe01aa3bc99195'...\n""
2021-02-25 01:30:47.963438 (MainThread): Pulling new dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2021-02-25 01:30:47.963602 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:30:47.971155 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:30:47.971485 (MainThread): STDERR: "b''"
2021-02-25 01:30:47.971621 (MainThread):   Checking out branch master.
2021-02-25 01:30:47.971699 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 01:30:47.978334 (MainThread): STDOUT: "b''"
2021-02-25 01:30:47.978624 (MainThread): STDERR: "b''"
2021-02-25 01:30:47.978731 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 01:30:48.192991 (MainThread): STDOUT: "b''"
2021-02-25 01:30:48.193318 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 01:30:48.193426 (MainThread): Executing "git tag --list"
2021-02-25 01:30:48.200542 (MainThread): STDOUT: "b''"
2021-02-25 01:30:48.200837 (MainThread): STDERR: "b''"
2021-02-25 01:30:48.200952 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 01:30:48.208123 (MainThread): STDOUT: "b'HEAD is now at f85759f Merge pull request #13 from fivetran/enabled_vars_one_true\n'"
2021-02-25 01:30:48.208430 (MainThread): STDERR: "b''"
2021-02-25 01:30:48.208544 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:30:48.214054 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:30:48.214314 (MainThread): STDERR: "b''"
2021-02-25 01:30:48.214438 (MainThread):   Checked out at f85759f.
2021-02-25 01:30:48.252553 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/github_source.json
2021-02-25 01:30:48.318399 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/github_source.json 200
2021-02-25 01:30:48.321851 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2021-02-25 01:30:48.324962 (Thread-75): handling poll request
2021-02-25 01:30:48.325419 (Thread-75): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b85250>]}
2021-02-25 01:30:48.329131 (Thread-75): sending response (<Response 11464 bytes [200 OK]>) to 10.0.36.20
2021-02-25 01:30:48.374190 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2021-02-25 01:30:48.387346 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fivetran/github_source/0.2.2.json
2021-02-25 01:30:48.406971 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fivetran/github_source/0.2.2.json 200
2021-02-25 01:30:48.417360 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.4.json
2021-02-25 01:30:48.472452 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.4.json 200
2021-02-25 01:30:48.473318 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2021-02-25 01:30:48.479292 (MainThread): STDOUT: "b''"
2021-02-25 01:30:48.479547 (MainThread): STDERR: "b"fatal: destination path '2570ae56bf9cb34e49fe01aa3bc99195' already exists and is not an empty directory.\n""
2021-02-25 01:30:48.479599 (MainThread): command return code=128
2021-02-25 01:30:48.480060 (MainThread): Updating existing dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2021-02-25 01:30:48.480129 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:30:48.485288 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:30:48.485466 (MainThread): STDERR: "b''"
2021-02-25 01:30:48.485540 (MainThread):   Checking out branch master.
2021-02-25 01:30:48.485582 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 01:30:48.491081 (MainThread): STDOUT: "b''"
2021-02-25 01:30:48.491370 (MainThread): STDERR: "b''"
2021-02-25 01:30:48.491498 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 01:30:48.708324 (MainThread): STDOUT: "b''"
2021-02-25 01:30:48.708589 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 01:30:48.708665 (MainThread): Executing "git tag --list"
2021-02-25 01:30:48.714714 (MainThread): STDOUT: "b''"
2021-02-25 01:30:48.714949 (MainThread): STDERR: "b''"
2021-02-25 01:30:48.715028 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 01:30:48.722571 (MainThread): STDOUT: "b'HEAD is now at f85759f Merge pull request #13 from fivetran/enabled_vars_one_true\n'"
2021-02-25 01:30:48.722809 (MainThread): STDERR: "b''"
2021-02-25 01:30:48.722893 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:30:48.728226 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:30:48.728540 (MainThread): STDERR: "b''"
2021-02-25 01:30:48.728667 (MainThread):   Already at f85759f, nothing to do.
2021-02-25 01:30:48.743818 (MainThread): Installing fivetran/github_source@0.2.2
2021-02-25 01:30:49.617910 (Thread-76): handling poll request
2021-02-25 01:30:49.618539 (Thread-76): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bf27f0>]}
2021-02-25 01:30:49.622201 (Thread-76): sending response (<Response 9190 bytes [200 OK]>) to 10.0.45.17
2021-02-25 01:30:50.865725 (MainThread):   Installed from version 0.2.2

2021-02-25 01:30:50.865970 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '27d1133e-0e83-4906-9816-91fe5283fb53', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cf4eb8e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cf4e8d100>]}
2021-02-25 01:30:50.866236 (MainThread): Installing fishtown-analytics/dbt_utils@0.6.4
2021-02-25 01:30:50.902704 (Thread-77): handling poll request
2021-02-25 01:30:50.903537 (Thread-77): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bf24c0>]}
2021-02-25 01:30:50.905333 (Thread-77): sending response (<Response 1390 bytes [200 OK]>) to 10.0.19.152
2021-02-25 01:30:52.153399 (Thread-78): handling poll request
2021-02-25 01:30:52.153813 (Thread-78): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b8f160>]}
2021-02-25 01:30:52.154690 (Thread-78): sending response (<Response 304 bytes [200 OK]>) to 10.0.31.134
2021-02-25 01:30:53.422770 (Thread-79): handling poll request
2021-02-25 01:30:53.423221 (Thread-79): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b8f340>]}
2021-02-25 01:30:53.424301 (Thread-79): sending response (<Response 304 bytes [200 OK]>) to 10.0.15.163
2021-02-25 01:30:54.675359 (Thread-80): handling poll request
2021-02-25 01:30:54.675845 (Thread-80): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b75dc0>]}
2021-02-25 01:30:54.676766 (Thread-80): sending response (<Response 305 bytes [200 OK]>) to 10.0.31.134
2021-02-25 01:30:55.989762 (Thread-81): handling poll request
2021-02-25 01:30:55.990274 (Thread-81): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bfa940>]}
2021-02-25 01:30:55.991198 (Thread-81): sending response (<Response 305 bytes [200 OK]>) to 10.0.26.158
2021-02-25 01:30:56.559293 (MainThread):   Installed from version 0.6.4

2021-02-25 01:30:56.559609 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '27d1133e-0e83-4906-9816-91fe5283fb53', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cf4e519a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cf4e515b0>]}
2021-02-25 01:30:56.559913 (MainThread): Installing https://github.com/fivetran/dbt_fivetran_utils.git@master
2021-02-25 01:30:56.561628 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2021-02-25 01:30:56.566506 (MainThread): STDOUT: "b''"
2021-02-25 01:30:56.566767 (MainThread): STDERR: "b"fatal: destination path '2570ae56bf9cb34e49fe01aa3bc99195' already exists and is not an empty directory.\n""
2021-02-25 01:30:56.566838 (MainThread): command return code=128
2021-02-25 01:30:56.567048 (MainThread): Updating existing dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2021-02-25 01:30:56.567134 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:30:56.572466 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:30:56.572703 (MainThread): STDERR: "b''"
2021-02-25 01:30:56.572800 (MainThread):   Checking out branch master.
2021-02-25 01:30:56.572846 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 01:30:56.578883 (MainThread): STDOUT: "b''"
2021-02-25 01:30:56.579182 (MainThread): STDERR: "b''"
2021-02-25 01:30:56.579280 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 01:30:56.855666 (MainThread): STDOUT: "b''"
2021-02-25 01:30:56.856018 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 01:30:56.856139 (MainThread): Executing "git tag --list"
2021-02-25 01:30:56.863578 (MainThread): STDOUT: "b''"
2021-02-25 01:30:56.863880 (MainThread): STDERR: "b''"
2021-02-25 01:30:56.864002 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 01:30:56.871848 (MainThread): STDOUT: "b'HEAD is now at f85759f Merge pull request #13 from fivetran/enabled_vars_one_true\n'"
2021-02-25 01:30:56.872082 (MainThread): STDERR: "b''"
2021-02-25 01:30:56.872166 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 01:30:56.877286 (MainThread): STDOUT: "b'f85759fc38a78d269262f14e778c93ab4f3d7fd1\n'"
2021-02-25 01:30:56.877511 (MainThread): STDERR: "b''"
2021-02-25 01:30:56.877585 (MainThread):   Already at f85759f, nothing to do.
2021-02-25 01:30:57.321011 (Thread-82): handling poll request
2021-02-25 01:30:57.321531 (Thread-82): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6be0220>]}
2021-02-25 01:30:57.324845 (Thread-82): sending response (<Response 8363 bytes [200 OK]>) to 10.0.45.17
2021-02-25 01:30:58.608468 (Thread-83): handling poll request
2021-02-25 01:30:58.608886 (Thread-83): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bdf910>]}
2021-02-25 01:30:58.609738 (Thread-83): sending response (<Response 305 bytes [200 OK]>) to 10.0.36.20
2021-02-25 01:30:59.989383 (MainThread):   Installed from revision master

2021-02-25 01:30:59.989755 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '27d1133e-0e83-4906-9816-91fe5283fb53', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cf4ed31c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cf4f0eb50>]}
2021-02-25 01:31:00.067064 (Thread-84): handling poll request
2021-02-25 01:31:00.067519 (Thread-84): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bdf640>]}
2021-02-25 01:31:00.068886 (Thread-84): sending response (<Response 1115 bytes [200 OK]>) to 10.0.40.10
2021-02-25 01:31:01.383783 (Thread-85): handling poll request
2021-02-25 01:31:01.384228 (Thread-85): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6bdf910>]}
2021-02-25 01:31:01.384953 (Thread-85): sending response (<Response 626 bytes [200 OK]>) to 10.0.36.20
2021-02-25 01:31:01.676111 (Thread-86): handling status request
2021-02-25 01:31:01.676549 (Thread-86): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b857f0>]}
2021-02-25 01:31:01.684828 (Thread-86): sending response (<Response 30627 bytes [200 OK]>) to 10.0.33.218
2021-02-25 01:32:44.053197 (Thread-87): handling status request
2021-02-25 01:32:44.053613 (Thread-87): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b85ac0>]}
2021-02-25 01:32:44.062257 (Thread-87): sending response (<Response 30627 bytes [200 OK]>) to 10.0.5.107
2021-02-25 01:32:44.065382 (Thread-88): handling ps request
2021-02-25 01:32:44.065690 (Thread-88): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6b85af0>]}
2021-02-25 01:32:44.067386 (Thread-88): sending response (<Response 2673 bytes [200 OK]>) to 10.0.36.20
2021-02-25 01:32:44.363544 (Thread-89): handling poll request
2021-02-25 01:32:44.363984 (Thread-89): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'e20d5b78-710c-4296-a941-9857ed68bbc4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0b6be04c0>]}
2021-02-25 01:32:44.378928 (Thread-89): sending response (<Response 62459 bytes [200 OK]>) to 10.0.19.152
2021-02-25 01:36:14.395150 (MainThread): Running with dbt=0.19.0
2021-02-25 01:36:14.550881 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-02-25 01:36:14.564056 (MainThread): Tracking: tracking
2021-02-25 01:36:14.585355 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5625ed60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50d31dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50d31fa0>]}
2021-02-25 01:36:14.585797 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=15
2021-02-25 01:36:14.586167 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-02-25 01:36:14.586400 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-02-25 01:36:14.602501 (Thread-2): handling status request
2021-02-25 01:36:14.604384 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50d47eb0>]}
2021-02-25 01:36:14.606049 (Thread-2): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.44
2021-02-25 01:36:14.670866 (Thread-1): Parsing macros/adapters.sql
2021-02-25 01:36:14.691288 (Thread-1): Parsing macros/etc.sql
2021-02-25 01:36:14.693493 (Thread-1): Parsing macros/catalog.sql
2021-02-25 01:36:14.700584 (Thread-1): Parsing macros/materializations/copy.sql
2021-02-25 01:36:14.705014 (Thread-1): Parsing macros/materializations/table.sql
2021-02-25 01:36:14.715031 (Thread-1): Parsing macros/materializations/incremental.sql
2021-02-25 01:36:14.733872 (Thread-1): Parsing macros/materializations/seed.sql
2021-02-25 01:36:14.738855 (Thread-1): Parsing macros/materializations/snapshot.sql
2021-02-25 01:36:14.742168 (Thread-1): Parsing macros/materializations/view.sql
2021-02-25 01:36:14.748554 (Thread-1): Parsing macros/core.sql
2021-02-25 01:36:14.755620 (Thread-1): Parsing macros/materializations/helpers.sql
2021-02-25 01:36:14.772075 (Thread-1): Parsing macros/materializations/common/merge.sql
2021-02-25 01:36:14.786766 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-25 01:36:14.788694 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2021-02-25 01:36:14.806519 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-25 01:36:14.838191 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-25 01:36:14.843267 (Thread-1): Parsing macros/materializations/view/view.sql
2021-02-25 01:36:14.849683 (Thread-1): Parsing macros/materializations/seed/seed.sql
2021-02-25 01:36:14.870679 (Thread-1): Parsing macros/materializations/table/table.sql
2021-02-25 01:36:14.877563 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2021-02-25 01:36:14.879531 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2021-02-25 01:36:14.885744 (Thread-1): Parsing macros/etc/is_incremental.sql
2021-02-25 01:36:14.887483 (Thread-1): Parsing macros/etc/query.sql
2021-02-25 01:36:14.888584 (Thread-1): Parsing macros/etc/datetime.sql
2021-02-25 01:36:14.897614 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2021-02-25 01:36:14.898602 (Thread-1): Parsing macros/etc/get_custom_database.sql
2021-02-25 01:36:14.900291 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2021-02-25 01:36:14.902341 (Thread-1): Parsing macros/schema_tests/not_null.sql
2021-02-25 01:36:14.903915 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2021-02-25 01:36:14.906659 (Thread-1): Parsing macros/schema_tests/relationships.sql
2021-02-25 01:36:14.908597 (Thread-1): Parsing macros/schema_tests/unique.sql
2021-02-25 01:36:14.910462 (Thread-1): Parsing macros/adapters/common.sql
2021-02-25 01:36:14.971695 (Thread-1): Parsing macros/logger/pretty_time.sql
2021-02-25 01:36:14.977012 (Thread-1): Parsing macros/logger/log_info.sql
2021-02-25 01:36:14.982440 (Thread-1): Parsing macros/logger/pretty_log_format.sql
2021-02-25 01:36:14.987974 (Thread-1): Parsing macros/sql/pivot.sql
2021-02-25 01:36:14.996170 (Thread-1): Parsing macros/sql/star.sql
2021-02-25 01:36:15.003746 (Thread-1): Parsing macros/sql/surrogate_key.sql
2021-02-25 01:36:15.012365 (Thread-1): Parsing macros/sql/get_query_results_as_dict.sql
2021-02-25 01:36:15.026719 (Thread-1): Parsing macros/sql/get_column_values.sql
2021-02-25 01:36:15.036225 (Thread-1): Parsing macros/sql/groupby.sql
2021-02-25 01:36:15.042641 (Thread-1): Parsing macros/sql/get_tables_by_pattern_sql.sql
2021-02-25 01:36:15.053600 (Thread-1): Parsing macros/sql/nullcheck_table.sql
2021-02-25 01:36:15.059568 (Thread-1): Parsing macros/sql/get_tables_by_prefix_sql.sql
2021-02-25 01:36:15.065886 (Thread-1): Parsing macros/sql/get_relations_by_pattern.sql
2021-02-25 01:36:15.077732 (Thread-1): Parsing macros/sql/get_relations_by_prefix.sql
2021-02-25 01:36:15.085207 (Thread-1): Parsing macros/sql/safe_add.sql
2021-02-25 01:36:15.091263 (Thread-1): Parsing macros/sql/unpivot.sql
2021-02-25 01:36:15.102733 (Thread-1): Parsing macros/sql/generate_series.sql
2021-02-25 01:36:15.111756 (Thread-1): Parsing macros/sql/nullcheck.sql
2021-02-25 01:36:15.117911 (Thread-1): Parsing macros/sql/union.sql
2021-02-25 01:36:15.131235 (Thread-1): Parsing macros/materializations/insert_by_period_materialization.sql
2021-02-25 01:36:15.162530 (Thread-1): Parsing macros/web/get_url_parameter.sql
2021-02-25 01:36:15.168312 (Thread-1): Parsing macros/web/get_url_path.sql
2021-02-25 01:36:15.175240 (Thread-1): Parsing macros/web/get_url_host.sql
2021-02-25 01:36:15.181577 (Thread-1): Parsing macros/datetime/date_spine.sql
2021-02-25 01:36:15.190791 (Thread-1): Parsing macros/schema_tests/expression_is_true.sql
2021-02-25 01:36:15.196677 (Thread-1): Parsing macros/schema_tests/not_constant.sql
2021-02-25 01:36:15.202868 (Thread-1): Parsing macros/schema_tests/at_least_one.sql
2021-02-25 01:36:15.208884 (Thread-1): Parsing macros/schema_tests/equality.sql
2021-02-25 01:36:15.218284 (Thread-1): Parsing macros/schema_tests/test_not_null_where.sql
2021-02-25 01:36:15.224688 (Thread-1): Parsing macros/schema_tests/equal_rowcount.sql
2021-02-25 01:36:15.231320 (Thread-1): Parsing macros/schema_tests/test_unique_where.sql
2021-02-25 01:36:15.237844 (Thread-1): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2021-02-25 01:36:15.248525 (Thread-1): Parsing macros/schema_tests/relationships_where.sql
2021-02-25 01:36:15.255608 (Thread-1): Parsing macros/schema_tests/unique_combination_of_columns.sql
2021-02-25 01:36:15.263856 (Thread-1): Parsing macros/schema_tests/recency.sql
2021-02-25 01:36:15.270023 (Thread-1): Parsing macros/schema_tests/cardinality_equality.sql
2021-02-25 01:36:15.276674 (Thread-1): Parsing macros/geo/haversine_distance.sql
2021-02-25 01:36:15.283593 (Thread-1): Parsing macros/cross_db_utils/split_part.sql
2021-02-25 01:36:15.290335 (Thread-1): Parsing macros/cross_db_utils/length.sql
2021-02-25 01:36:15.296376 (Thread-1): Parsing macros/cross_db_utils/current_timestamp.sql
2021-02-25 01:36:15.303686 (Thread-1): Parsing macros/cross_db_utils/_get_utils_namespaces.sql
2021-02-25 01:36:15.308470 (Thread-1): Parsing macros/cross_db_utils/right.sql
2021-02-25 01:36:15.314589 (Thread-1): Parsing macros/cross_db_utils/hash.sql
2021-02-25 01:36:15.320657 (Thread-1): Parsing macros/cross_db_utils/replace.sql
2021-02-25 01:36:15.326599 (Thread-1): Parsing macros/cross_db_utils/concat.sql
2021-02-25 01:36:15.334241 (Thread-1): Parsing macros/cross_db_utils/_is_relation.sql
2021-02-25 01:36:15.339347 (Thread-1): Parsing macros/cross_db_utils/identifier.sql
2021-02-25 01:36:15.345479 (Thread-1): Parsing macros/cross_db_utils/datediff.sql
2021-02-25 01:36:15.359076 (Thread-1): Parsing macros/cross_db_utils/dateadd.sql
2021-02-25 01:36:15.365596 (Thread-1): Parsing macros/cross_db_utils/datatypes.sql
2021-02-25 01:36:15.376604 (Thread-1): Parsing macros/cross_db_utils/position.sql
2021-02-25 01:36:15.383017 (Thread-1): Parsing macros/cross_db_utils/literal.sql
2021-02-25 01:36:15.388563 (Thread-1): Parsing macros/cross_db_utils/_is_ephemeral.sql
2021-02-25 01:36:15.395294 (Thread-1): Parsing macros/cross_db_utils/width_bucket.sql
2021-02-25 01:36:15.404665 (Thread-1): Parsing macros/cross_db_utils/date_trunc.sql
2021-02-25 01:36:15.410723 (Thread-1): Parsing macros/cross_db_utils/except.sql
2021-02-25 01:36:15.415843 (Thread-1): Parsing macros/cross_db_utils/safe_cast.sql
2021-02-25 01:36:15.422060 (Thread-1): Parsing macros/cross_db_utils/last_day.sql
2021-02-25 01:36:15.429833 (Thread-1): Parsing macros/cross_db_utils/intersect.sql
2021-02-25 01:36:15.436398 (Thread-1): Parsing macros/get_issue_closed_history_columns.sql
2021-02-25 01:36:15.442707 (Thread-1): Parsing macros/get_issue_comment_columns.sql
2021-02-25 01:36:15.448673 (Thread-1): Parsing macros/get_requested_reviewer_history_columns.sql
2021-02-25 01:36:15.454676 (Thread-1): Parsing macros/get_team_columns.sql
2021-02-25 01:36:15.460695 (Thread-1): Parsing macros/get_issue_assignee_columns.sql
2021-02-25 01:36:15.465735 (Thread-1): Parsing macros/get_user_columns.sql
2021-02-25 01:36:15.471190 (Thread-1): Parsing macros/get_pull_request_columns.sql
2021-02-25 01:36:15.479323 (Thread-1): Parsing macros/get_issue_columns.sql
2021-02-25 01:36:15.487053 (Thread-1): Parsing macros/get_repo_team_columns.sql
2021-02-25 01:36:15.492620 (Thread-1): Parsing macros/get_issue_merged_columns.sql
2021-02-25 01:36:15.498966 (Thread-1): Parsing macros/get_issue_label_columns.sql
2021-02-25 01:36:15.504753 (Thread-1): Parsing macros/get_repository_columns.sql
2021-02-25 01:36:15.512373 (Thread-1): Parsing macros/get_pull_request_review_columns.sql
2021-02-25 01:36:15.519764 (Thread-1): Parsing macros/enabled_vars_one_true.sql
2021-02-25 01:36:15.525157 (Thread-1): Parsing macros/dummy_coalesce_value.sql
2021-02-25 01:36:15.532428 (Thread-1): Parsing macros/enabled_vars.sql
2021-02-25 01:36:15.537264 (Thread-1): Parsing macros/_get_utils_namespaces.sql
2021-02-25 01:36:15.541872 (Thread-1): Parsing macros/remove_prefix_from_columns.sql
2021-02-25 01:36:15.547444 (Thread-1): Parsing macros/first_value.sql
2021-02-25 01:36:15.554204 (Thread-1): Parsing macros/generate_columns_macro.sql
2021-02-25 01:36:15.562789 (Thread-1): Parsing macros/timestamp_add.sql
2021-02-25 01:36:15.569314 (Thread-1): Parsing macros/snowflake_seed_data.sql
2021-02-25 01:36:15.574597 (Thread-1): Parsing macros/fill_staging_columns.sql
2021-02-25 01:36:15.583197 (Thread-1): Parsing macros/percentile.sql
2021-02-25 01:36:15.589428 (Thread-1): Parsing macros/get_columns_for_macro.sql
2021-02-25 01:36:15.597350 (Thread-1): Parsing macros/string_agg.sql
2021-02-25 01:36:15.603516 (Thread-1): Parsing macros/array_agg.sql
2021-02-25 01:36:15.609834 (Thread-1): Parsing macros/union_relations.sql
2021-02-25 01:36:15.791856 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 01:36:15.819396 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 01:36:15.837769 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 01:36:15.853194 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 01:36:15.867656 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 01:36:15.878155 (Thread-3): handling status request
2021-02-25 01:36:15.878527 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501e90d0>]}
2021-02-25 01:36:15.879175 (Thread-3): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 01:36:15.886127 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 01:36:15.904153 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 01:36:16.324002 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_merged".
2021-02-25 01:36:16.356908 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repo_team".
2021-02-25 01:36:16.376152 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_label".
2021-02-25 01:36:16.394422 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repository".
2021-02-25 01:36:16.418683 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_review".
2021-02-25 01:36:16.440050 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request".
2021-02-25 01:36:16.465597 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue".
2021-02-25 01:36:16.489746 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__team".
2021-02-25 01:36:16.512068 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_assignee".
2021-02-25 01:36:16.530877 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__user".
2021-02-25 01:36:16.550233 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__requested_reviewer_history".
2021-02-25 01:36:16.571310 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_comment".
2021-02-25 01:36:16.593107 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_closed_history".
2021-02-25 01:36:16.620896 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_merged_tmp".
2021-02-25 01:36:16.642792 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repo_team_tmp".
2021-02-25 01:36:16.664766 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_label_tmp".
2021-02-25 01:36:16.686523 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repository_tmp".
2021-02-25 01:36:16.707098 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_review_tmp".
2021-02-25 01:36:16.723264 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_tmp".
2021-02-25 01:36:16.741618 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_tmp".
2021-02-25 01:36:16.757850 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_assignee_tmp".
2021-02-25 01:36:16.773851 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__team_tmp".
2021-02-25 01:36:16.790354 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__user_tmp".
2021-02-25 01:36:16.806926 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_comment_tmp".
2021-02-25 01:36:16.823330 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__requested_reviewer_history_tmp".
2021-02-25 01:36:16.839042 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_closed_history_tmp".
2021-02-25 01:36:17.274291 (Thread-4): handling status request
2021-02-25 01:36:17.295244 (Thread-4): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50150be0>]}
2021-02-25 01:36:17.311481 (Thread-4): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 01:36:17.626523 (Thread-1): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43f2a2b0>]}
2021-02-25 01:36:18.585313 (Thread-5): handling status request
2021-02-25 01:36:18.585817 (Thread-5): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43ebd0d0>]}
2021-02-25 01:36:18.597905 (Thread-5): sending response (<Response 43242 bytes [200 OK]>) to 10.0.19.152
2021-02-25 01:36:29.128370 (Thread-6): handling status request
2021-02-25 01:36:29.130264 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d502f4eb0>]}
2021-02-25 01:36:29.142623 (Thread-6): sending response (<Response 43242 bytes [200 OK]>) to 10.0.31.134
2021-02-25 01:36:29.145866 (Thread-7): handling status request
2021-02-25 01:36:29.146232 (Thread-7): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504005b0>]}
2021-02-25 01:36:29.158591 (Thread-7): sending response (<Response 43242 bytes [200 OK]>) to 10.0.28.107
2021-02-25 01:36:29.409435 (Thread-8): handling docs.generate request
2021-02-25 01:36:29.409875 (Thread-8): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d502f4250>]}
2021-02-25 01:36:29.412237 (Thread-8): Connection 'model.github_source.stg_github__issue_closed_history_tmp' was properly closed.
2021-02-25 01:36:30.306805 (Thread-8): sending response (<Response 136 bytes [200 OK]>) to 10.0.28.107
2021-02-25 01:36:30.379113 (MainThread): Found 33 models, 22 tests, 0 snapshots, 0 analyses, 372 macros, 0 operations, 0 seed files, 13 sources, 0 exposures
2021-02-25 01:36:30.382562 (MainThread): 
2021-02-25 01:36:30.382912 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 01:36:30.448415 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 01:36:30.448558 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 01:36:30.586894 (Thread-9): handling poll request
2021-02-25 01:36:30.587397 (Thread-9): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50082dc0>]}
2021-02-25 01:36:30.591132 (Thread-9): sending response (<Response 1794 bytes [200 OK]>) to 10.0.5.107
2021-02-25 01:36:30.718698 (MainThread): 01:36:30 | Concurrency: 1 threads (target='default')
2021-02-25 01:36:30.718824 (MainThread): 01:36:30 | 
2021-02-25 01:36:30.721138 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 01:36:30.721314 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 01:36:30.721420 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 01:36:30.741769 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 01:36:30.758681 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.758978 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.759193 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 01:36:30.759293 (Thread-1): Began running node model.github_source.stg_github__issue_assignee_tmp
2021-02-25 01:36:30.759382 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_assignee_tmp".
2021-02-25 01:36:30.759441 (Thread-1): Compiling model.github_source.stg_github__issue_assignee_tmp
2021-02-25 01:36:30.770768 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_assignee_tmp"
2021-02-25 01:36:30.800220 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.800558 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.800776 (Thread-1): Finished running node model.github_source.stg_github__issue_assignee_tmp
2021-02-25 01:36:30.800879 (Thread-1): Began running node model.github_source.stg_github__issue_closed_history_tmp
2021-02-25 01:36:30.800971 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_closed_history_tmp".
2021-02-25 01:36:30.801034 (Thread-1): Compiling model.github_source.stg_github__issue_closed_history_tmp
2021-02-25 01:36:30.810017 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_closed_history_tmp"
2021-02-25 01:36:30.823903 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.824253 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.824470 (Thread-1): Finished running node model.github_source.stg_github__issue_closed_history_tmp
2021-02-25 01:36:30.824574 (Thread-1): Began running node model.github_source.stg_github__issue_comment_tmp
2021-02-25 01:36:30.824668 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_comment_tmp".
2021-02-25 01:36:30.824731 (Thread-1): Compiling model.github_source.stg_github__issue_comment_tmp
2021-02-25 01:36:30.833233 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_comment_tmp"
2021-02-25 01:36:30.846072 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.846367 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.846570 (Thread-1): Finished running node model.github_source.stg_github__issue_comment_tmp
2021-02-25 01:36:30.846668 (Thread-1): Began running node model.github_source.stg_github__issue_label_tmp
2021-02-25 01:36:30.846758 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_label_tmp".
2021-02-25 01:36:30.846819 (Thread-1): Compiling model.github_source.stg_github__issue_label_tmp
2021-02-25 01:36:30.855330 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_label_tmp"
2021-02-25 01:36:30.867558 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.867853 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.868057 (Thread-1): Finished running node model.github_source.stg_github__issue_label_tmp
2021-02-25 01:36:30.868154 (Thread-1): Began running node model.github_source.stg_github__issue_merged_tmp
2021-02-25 01:36:30.868241 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_merged_tmp".
2021-02-25 01:36:30.868301 (Thread-1): Compiling model.github_source.stg_github__issue_merged_tmp
2021-02-25 01:36:30.876589 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_merged_tmp"
2021-02-25 01:36:30.888254 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.888543 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.888869 (Thread-1): Finished running node model.github_source.stg_github__issue_merged_tmp
2021-02-25 01:36:30.889089 (Thread-1): Began running node model.github_source.stg_github__issue_tmp
2021-02-25 01:36:30.889273 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_tmp".
2021-02-25 01:36:30.889516 (Thread-1): Compiling model.github_source.stg_github__issue_tmp
2021-02-25 01:36:30.900082 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_tmp"
2021-02-25 01:36:30.911878 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.912174 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.912380 (Thread-1): Finished running node model.github_source.stg_github__issue_tmp
2021-02-25 01:36:30.912479 (Thread-1): Began running node model.github_source.stg_github__pull_request_review_tmp
2021-02-25 01:36:30.912569 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_review_tmp".
2021-02-25 01:36:30.912630 (Thread-1): Compiling model.github_source.stg_github__pull_request_review_tmp
2021-02-25 01:36:30.921098 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__pull_request_review_tmp"
2021-02-25 01:36:30.931912 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.932171 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.932374 (Thread-1): Finished running node model.github_source.stg_github__pull_request_review_tmp
2021-02-25 01:36:30.932471 (Thread-1): Began running node model.github_source.stg_github__pull_request_tmp
2021-02-25 01:36:30.932559 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_tmp".
2021-02-25 01:36:30.932702 (Thread-1): Compiling model.github_source.stg_github__pull_request_tmp
2021-02-25 01:36:30.942050 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__pull_request_tmp"
2021-02-25 01:36:30.952502 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.952743 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.952936 (Thread-1): Finished running node model.github_source.stg_github__pull_request_tmp
2021-02-25 01:36:30.953026 (Thread-1): Began running node model.github_source.stg_github__repo_team_tmp
2021-02-25 01:36:30.953111 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repo_team_tmp".
2021-02-25 01:36:30.953169 (Thread-1): Compiling model.github_source.stg_github__repo_team_tmp
2021-02-25 01:36:30.960886 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__repo_team_tmp"
2021-02-25 01:36:30.976936 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.977201 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.977422 (Thread-1): Finished running node model.github_source.stg_github__repo_team_tmp
2021-02-25 01:36:30.977522 (Thread-1): Began running node model.github_source.stg_github__repository_tmp
2021-02-25 01:36:30.977612 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repository_tmp".
2021-02-25 01:36:30.977672 (Thread-1): Compiling model.github_source.stg_github__repository_tmp
2021-02-25 01:36:30.985466 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__repository_tmp"
2021-02-25 01:36:30.998074 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.998355 (Thread-1): finished collecting timing info
2021-02-25 01:36:30.998562 (Thread-1): Finished running node model.github_source.stg_github__repository_tmp
2021-02-25 01:36:30.998658 (Thread-1): Began running node model.github_source.stg_github__requested_reviewer_history_tmp
2021-02-25 01:36:30.998747 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__requested_reviewer_history_tmp".
2021-02-25 01:36:30.998808 (Thread-1): Compiling model.github_source.stg_github__requested_reviewer_history_tmp
2021-02-25 01:36:31.006962 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__requested_reviewer_history_tmp"
2021-02-25 01:36:31.019137 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.019398 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.019598 (Thread-1): Finished running node model.github_source.stg_github__requested_reviewer_history_tmp
2021-02-25 01:36:31.019692 (Thread-1): Began running node model.github_source.stg_github__team_tmp
2021-02-25 01:36:31.019780 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__team_tmp".
2021-02-25 01:36:31.019841 (Thread-1): Compiling model.github_source.stg_github__team_tmp
2021-02-25 01:36:31.028147 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__team_tmp"
2021-02-25 01:36:31.039215 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.039461 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.039671 (Thread-1): Finished running node model.github_source.stg_github__team_tmp
2021-02-25 01:36:31.039763 (Thread-1): Began running node model.github_source.stg_github__user_tmp
2021-02-25 01:36:31.039849 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__user_tmp".
2021-02-25 01:36:31.039907 (Thread-1): Compiling model.github_source.stg_github__user_tmp
2021-02-25 01:36:31.047592 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__user_tmp"
2021-02-25 01:36:31.059348 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.059594 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.059794 (Thread-1): Finished running node model.github_source.stg_github__user_tmp
2021-02-25 01:36:31.059891 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 01:36:31.059981 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 01:36:31.060042 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 01:36:31.066531 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 01:36:31.087928 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.088190 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.088390 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 01:36:31.088481 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 01:36:31.088566 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 01:36:31.088625 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 01:36:31.099111 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 01:36:31.115984 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.116259 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.116461 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 01:36:31.116558 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 01:36:31.116647 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 01:36:31.116708 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 01:36:31.128168 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 01:36:31.145518 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.145811 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.146026 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 01:36:31.146126 (Thread-1): Began running node model.github_source.stg_github__issue_assignee
2021-02-25 01:36:31.146216 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_assignee".
2021-02-25 01:36:31.146277 (Thread-1): Compiling model.github_source.stg_github__issue_assignee
2021-02-25 01:36:31.155568 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:31.364183 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_assignee_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_assignee_tmp
2021-02-25 01:36:31.379102 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_assignee"
2021-02-25 01:36:31.391529 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.391849 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.392055 (Thread-1): Finished running node model.github_source.stg_github__issue_assignee
2021-02-25 01:36:31.392155 (Thread-1): Began running node model.github_source.stg_github__issue_closed_history
2021-02-25 01:36:31.392245 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_closed_history".
2021-02-25 01:36:31.392306 (Thread-1): Compiling model.github_source.stg_github__issue_closed_history
2021-02-25 01:36:31.404795 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:31.585550 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_closed_history_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_closed_history_tmp
2021-02-25 01:36:31.594107 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_closed_history"
2021-02-25 01:36:31.609135 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.609473 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.609693 (Thread-1): Finished running node model.github_source.stg_github__issue_closed_history
2021-02-25 01:36:31.609795 (Thread-1): Began running node model.github_source.stg_github__issue_comment
2021-02-25 01:36:31.609884 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_comment".
2021-02-25 01:36:31.609946 (Thread-1): Compiling model.github_source.stg_github__issue_comment
2021-02-25 01:36:31.619414 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:31.804062 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_comment_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_comment_tmp
2021-02-25 01:36:31.810743 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_comment"
2021-02-25 01:36:31.822469 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.822755 (Thread-1): finished collecting timing info
2021-02-25 01:36:31.822962 (Thread-1): Finished running node model.github_source.stg_github__issue_comment
2021-02-25 01:36:31.823062 (Thread-1): Began running node model.github_source.stg_github__issue_label
2021-02-25 01:36:31.823153 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_label".
2021-02-25 01:36:31.823214 (Thread-1): Compiling model.github_source.stg_github__issue_label
2021-02-25 01:36:31.832456 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:31.846654 (Thread-10): handling poll request
2021-02-25 01:36:31.847058 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43e4cc70>]}
2021-02-25 01:36:31.860016 (Thread-10): sending response (<Response 69862 bytes [200 OK]>) to 10.0.26.158
2021-02-25 01:36:32.039516 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_label_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_label_tmp
2021-02-25 01:36:32.046707 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_label"
2021-02-25 01:36:32.059445 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.059726 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.059929 (Thread-1): Finished running node model.github_source.stg_github__issue_label
2021-02-25 01:36:32.060029 (Thread-1): Began running node model.github_source.stg_github__issue_merged
2021-02-25 01:36:32.060120 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_merged".
2021-02-25 01:36:32.060181 (Thread-1): Compiling model.github_source.stg_github__issue_merged
2021-02-25 01:36:32.069319 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:32.255848 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_merged_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_merged_tmp
2021-02-25 01:36:32.261848 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_merged"
2021-02-25 01:36:32.273040 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.273375 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.273625 (Thread-1): Finished running node model.github_source.stg_github__issue_merged
2021-02-25 01:36:32.273730 (Thread-1): Began running node model.github_source.stg_github__issue
2021-02-25 01:36:32.273835 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue".
2021-02-25 01:36:32.273900 (Thread-1): Compiling model.github_source.stg_github__issue
2021-02-25 01:36:32.287257 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:32.494900 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_tmp
2021-02-25 01:36:32.504748 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue"
2021-02-25 01:36:32.517845 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.518185 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.518403 (Thread-1): Finished running node model.github_source.stg_github__issue
2021-02-25 01:36:32.518506 (Thread-1): Began running node model.github_source.stg_github__pull_request_review
2021-02-25 01:36:32.518597 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_review".
2021-02-25 01:36:32.518657 (Thread-1): Compiling model.github_source.stg_github__pull_request_review
2021-02-25 01:36:32.529088 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:32.710824 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__pull_request_review_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__pull_request_review_tmp
2021-02-25 01:36:32.718198 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__pull_request_review"
2021-02-25 01:36:32.731437 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.731756 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.731969 (Thread-1): Finished running node model.github_source.stg_github__pull_request_review
2021-02-25 01:36:32.732075 (Thread-1): Began running node model.github_source.stg_github__pull_request
2021-02-25 01:36:32.732169 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request".
2021-02-25 01:36:32.732232 (Thread-1): Compiling model.github_source.stg_github__pull_request
2021-02-25 01:36:32.742381 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:32.957960 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__pull_request_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__pull_request_tmp
2021-02-25 01:36:32.968996 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__pull_request"
2021-02-25 01:36:32.981294 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.981641 (Thread-1): finished collecting timing info
2021-02-25 01:36:32.981859 (Thread-1): Finished running node model.github_source.stg_github__pull_request
2021-02-25 01:36:32.981963 (Thread-1): Began running node model.github_source.stg_github__repo_team
2021-02-25 01:36:32.982054 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repo_team".
2021-02-25 01:36:32.982114 (Thread-1): Compiling model.github_source.stg_github__repo_team
2021-02-25 01:36:32.994088 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:33.174281 (Thread-11): handling poll request
2021-02-25 01:36:33.174713 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5007bb80>]}
2021-02-25 01:36:33.179036 (Thread-11): sending response (<Response 21021 bytes [200 OK]>) to 10.0.5.107
2021-02-25 01:36:33.186623 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__repo_team_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__repo_team_tmp
2021-02-25 01:36:33.195650 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__repo_team"
2021-02-25 01:36:33.207467 (Thread-1): finished collecting timing info
2021-02-25 01:36:33.207795 (Thread-1): finished collecting timing info
2021-02-25 01:36:33.208009 (Thread-1): Finished running node model.github_source.stg_github__repo_team
2021-02-25 01:36:33.208116 (Thread-1): Began running node model.github_source.stg_github__repository
2021-02-25 01:36:33.208209 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repository".
2021-02-25 01:36:33.208271 (Thread-1): Compiling model.github_source.stg_github__repository
2021-02-25 01:36:33.218011 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:33.401838 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__repository_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__repository_tmp
2021-02-25 01:36:33.411086 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__repository"
2021-02-25 01:36:33.423161 (Thread-1): finished collecting timing info
2021-02-25 01:36:33.423482 (Thread-1): finished collecting timing info
2021-02-25 01:36:33.423697 (Thread-1): Finished running node model.github_source.stg_github__repository
2021-02-25 01:36:33.423801 (Thread-1): Began running node model.github_source.stg_github__requested_reviewer_history
2021-02-25 01:36:33.423892 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__requested_reviewer_history".
2021-02-25 01:36:33.423953 (Thread-1): Compiling model.github_source.stg_github__requested_reviewer_history
2021-02-25 01:36:33.433793 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:33.630340 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__requested_reviewer_history_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__requested_reviewer_history_tmp
2021-02-25 01:36:33.636322 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__requested_reviewer_history"
2021-02-25 01:36:33.648209 (Thread-1): finished collecting timing info
2021-02-25 01:36:33.648520 (Thread-1): finished collecting timing info
2021-02-25 01:36:33.648731 (Thread-1): Finished running node model.github_source.stg_github__requested_reviewer_history
2021-02-25 01:36:33.648831 (Thread-1): Began running node model.github_source.stg_github__team
2021-02-25 01:36:33.648922 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__team".
2021-02-25 01:36:33.648984 (Thread-1): Compiling model.github_source.stg_github__team
2021-02-25 01:36:33.659386 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:33.825261 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__team_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__team_tmp
2021-02-25 01:36:33.832499 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__team"
2021-02-25 01:36:33.845321 (Thread-1): finished collecting timing info
2021-02-25 01:36:33.845597 (Thread-1): finished collecting timing info
2021-02-25 01:36:33.845799 (Thread-1): Finished running node model.github_source.stg_github__team
2021-02-25 01:36:33.845897 (Thread-1): Began running node model.github_source.stg_github__user
2021-02-25 01:36:33.845995 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__user".
2021-02-25 01:36:33.846058 (Thread-1): Compiling model.github_source.stg_github__user
2021-02-25 01:36:33.858117 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 01:36:34.034745 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__user_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__user_tmp
2021-02-25 01:36:34.039941 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__user"
2021-02-25 01:36:34.053682 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.054002 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.054216 (Thread-1): Finished running node model.github_source.stg_github__user
2021-02-25 01:36:34.054321 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 01:36:34.054422 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 01:36:34.054500 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 01:36:34.062421 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 01:36:34.078845 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.079084 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.079278 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 01:36:34.079388 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 01:36:34.079480 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 01:36:34.079539 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 01:36:34.087801 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 01:36:34.104821 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.105091 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.105292 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 01:36:34.105404 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 01:36:34.105493 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 01:36:34.105565 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 01:36:34.114493 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 01:36:34.131877 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.132168 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.132374 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 01:36:34.132478 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 01:36:34.132573 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 01:36:34.132634 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 01:36:34.157095 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 01:36:34.172994 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.173260 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.173492 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 01:36:34.173599 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 01:36:34.173689 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 01:36:34.173750 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 01:36:34.184574 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 01:36:34.202606 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.202898 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.203108 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 01:36:34.203216 (Thread-1): Began running node test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id
2021-02-25 01:36:34.203310 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id".
2021-02-25 01:36:34.203372 (Thread-1): Compiling test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id
2021-02-25 01:36:34.220611 (Thread-1): Writing injected SQL for node "test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id"
2021-02-25 01:36:34.244643 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.244902 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.245103 (Thread-1): Finished running node test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id
2021-02-25 01:36:34.245206 (Thread-1): Began running node test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at
2021-02-25 01:36:34.245295 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at".
2021-02-25 01:36:34.245356 (Thread-1): Compiling test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at
2021-02-25 01:36:34.253861 (Thread-1): Writing injected SQL for node "test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at"
2021-02-25 01:36:34.265836 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.266084 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.266283 (Thread-1): Finished running node test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at
2021-02-25 01:36:34.266386 (Thread-1): Began running node test.github_source.not_null_stg_github__issue_comment_issue_comment_id
2021-02-25 01:36:34.266475 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__issue_comment_issue_comment_id".
2021-02-25 01:36:34.266534 (Thread-1): Compiling test.github_source.not_null_stg_github__issue_comment_issue_comment_id
2021-02-25 01:36:34.274375 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__issue_comment_issue_comment_id"
2021-02-25 01:36:34.285340 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.285612 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.285810 (Thread-1): Finished running node test.github_source.not_null_stg_github__issue_comment_issue_comment_id
2021-02-25 01:36:34.285912 (Thread-1): Began running node test.github_source.unique_stg_github__issue_comment_issue_comment_id
2021-02-25 01:36:34.286011 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__issue_comment_issue_comment_id".
2021-02-25 01:36:34.286071 (Thread-1): Compiling test.github_source.unique_stg_github__issue_comment_issue_comment_id
2021-02-25 01:36:34.293849 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__issue_comment_issue_comment_id"
2021-02-25 01:36:34.305211 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.305478 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.305685 (Thread-1): Finished running node test.github_source.unique_stg_github__issue_comment_issue_comment_id
2021-02-25 01:36:34.305787 (Thread-1): Began running node test.github_source.not_null_stg_github__issue_issue_id
2021-02-25 01:36:34.305876 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__issue_issue_id".
2021-02-25 01:36:34.305933 (Thread-1): Compiling test.github_source.not_null_stg_github__issue_issue_id
2021-02-25 01:36:34.313657 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__issue_issue_id"
2021-02-25 01:36:34.325784 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.326030 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.326223 (Thread-1): Finished running node test.github_source.not_null_stg_github__issue_issue_id
2021-02-25 01:36:34.326324 (Thread-1): Began running node test.github_source.unique_stg_github__issue_issue_id
2021-02-25 01:36:34.326418 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__issue_issue_id".
2021-02-25 01:36:34.326477 (Thread-1): Compiling test.github_source.unique_stg_github__issue_issue_id
2021-02-25 01:36:34.334239 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__issue_issue_id"
2021-02-25 01:36:34.346718 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.346954 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.347147 (Thread-1): Finished running node test.github_source.unique_stg_github__issue_issue_id
2021-02-25 01:36:34.347249 (Thread-1): Began running node test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id
2021-02-25 01:36:34.347336 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id".
2021-02-25 01:36:34.347394 (Thread-1): Compiling test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id
2021-02-25 01:36:34.355082 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id"
2021-02-25 01:36:34.365898 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.366149 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.366344 (Thread-1): Finished running node test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id
2021-02-25 01:36:34.366446 (Thread-1): Began running node test.github_source.unique_stg_github__pull_request_review_pull_request_review_id
2021-02-25 01:36:34.366536 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__pull_request_review_pull_request_review_id".
2021-02-25 01:36:34.366595 (Thread-1): Compiling test.github_source.unique_stg_github__pull_request_review_pull_request_review_id
2021-02-25 01:36:34.375207 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__pull_request_review_pull_request_review_id"
2021-02-25 01:36:34.386395 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.386621 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.386808 (Thread-1): Finished running node test.github_source.unique_stg_github__pull_request_review_pull_request_review_id
2021-02-25 01:36:34.386906 (Thread-1): Began running node test.github_source.not_null_stg_github__pull_request_pull_request_id
2021-02-25 01:36:34.386992 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__pull_request_pull_request_id".
2021-02-25 01:36:34.387049 (Thread-1): Compiling test.github_source.not_null_stg_github__pull_request_pull_request_id
2021-02-25 01:36:34.394550 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__pull_request_pull_request_id"
2021-02-25 01:36:34.407240 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.407465 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.407656 (Thread-1): Finished running node test.github_source.not_null_stg_github__pull_request_pull_request_id
2021-02-25 01:36:34.407754 (Thread-1): Began running node test.github_source.unique_stg_github__pull_request_pull_request_id
2021-02-25 01:36:34.407839 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__pull_request_pull_request_id".
2021-02-25 01:36:34.407896 (Thread-1): Compiling test.github_source.unique_stg_github__pull_request_pull_request_id
2021-02-25 01:36:34.415717 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__pull_request_pull_request_id"
2021-02-25 01:36:34.428345 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.428595 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.428789 (Thread-1): Finished running node test.github_source.unique_stg_github__pull_request_pull_request_id
2021-02-25 01:36:34.428893 (Thread-1): Began running node test.github_source.not_null_stg_github__repo_team_repository_id
2021-02-25 01:36:34.428981 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__repo_team_repository_id".
2021-02-25 01:36:34.429041 (Thread-1): Compiling test.github_source.not_null_stg_github__repo_team_repository_id
2021-02-25 01:36:34.436785 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__repo_team_repository_id"
2021-02-25 01:36:34.446474 (Thread-12): handling poll request
2021-02-25 01:36:34.446877 (Thread-12): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43e9d970>]}
2021-02-25 01:36:34.459392 (Thread-12): sending response (<Response 73221 bytes [200 OK]>) to 10.0.8.47
2021-02-25 01:36:34.450363 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.450637 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.450843 (Thread-1): Finished running node test.github_source.not_null_stg_github__repo_team_repository_id
2021-02-25 01:36:34.450950 (Thread-1): Began running node test.github_source.not_null_stg_github__repo_team_team_id
2021-02-25 01:36:34.451045 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__repo_team_team_id".
2021-02-25 01:36:34.451107 (Thread-1): Compiling test.github_source.not_null_stg_github__repo_team_team_id
2021-02-25 01:36:34.459100 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__repo_team_team_id"
2021-02-25 01:36:34.472202 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.472462 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.472662 (Thread-1): Finished running node test.github_source.not_null_stg_github__repo_team_team_id
2021-02-25 01:36:34.472766 (Thread-1): Began running node test.github_source.not_null_stg_github__repository_repository_id
2021-02-25 01:36:34.472856 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__repository_repository_id".
2021-02-25 01:36:34.472915 (Thread-1): Compiling test.github_source.not_null_stg_github__repository_repository_id
2021-02-25 01:36:34.480830 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__repository_repository_id"
2021-02-25 01:36:34.494953 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.495200 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.495398 (Thread-1): Finished running node test.github_source.not_null_stg_github__repository_repository_id
2021-02-25 01:36:34.495498 (Thread-1): Began running node test.github_source.unique_stg_github__repository_repository_id
2021-02-25 01:36:34.495586 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__repository_repository_id".
2021-02-25 01:36:34.495644 (Thread-1): Compiling test.github_source.unique_stg_github__repository_repository_id
2021-02-25 01:36:34.503571 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__repository_repository_id"
2021-02-25 01:36:34.515641 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.516006 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.516335 (Thread-1): Finished running node test.github_source.unique_stg_github__repository_repository_id
2021-02-25 01:36:34.516493 (Thread-1): Began running node test.github_source.not_null_stg_github__team_team_id
2021-02-25 01:36:34.516633 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__team_team_id".
2021-02-25 01:36:34.516731 (Thread-1): Compiling test.github_source.not_null_stg_github__team_team_id
2021-02-25 01:36:34.529597 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__team_team_id"
2021-02-25 01:36:34.541505 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.541775 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.541982 (Thread-1): Finished running node test.github_source.not_null_stg_github__team_team_id
2021-02-25 01:36:34.542081 (Thread-1): Began running node test.github_source.unique_stg_github__team_team_id
2021-02-25 01:36:34.542170 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__team_team_id".
2021-02-25 01:36:34.542231 (Thread-1): Compiling test.github_source.unique_stg_github__team_team_id
2021-02-25 01:36:34.552262 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__team_team_id"
2021-02-25 01:36:34.563878 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.564246 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.564569 (Thread-1): Finished running node test.github_source.unique_stg_github__team_team_id
2021-02-25 01:36:34.564716 (Thread-1): Began running node test.github_source.not_null_stg_github__user_user_id
2021-02-25 01:36:34.564844 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__user_user_id".
2021-02-25 01:36:34.564931 (Thread-1): Compiling test.github_source.not_null_stg_github__user_user_id
2021-02-25 01:36:34.576195 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__user_user_id"
2021-02-25 01:36:34.587151 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.587401 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.587595 (Thread-1): Finished running node test.github_source.not_null_stg_github__user_user_id
2021-02-25 01:36:34.587693 (Thread-1): Began running node test.github_source.unique_stg_github__user_user_id
2021-02-25 01:36:34.587780 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__user_user_id".
2021-02-25 01:36:34.587839 (Thread-1): Compiling test.github_source.unique_stg_github__user_user_id
2021-02-25 01:36:34.595952 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__user_user_id"
2021-02-25 01:36:34.607468 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.607702 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.607896 (Thread-1): Finished running node test.github_source.unique_stg_github__user_user_id
2021-02-25 01:36:34.607994 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 01:36:34.608081 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 01:36:34.608140 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 01:36:34.615911 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 01:36:34.632038 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.632285 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.632512 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 01:36:34.632621 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 01:36:34.632712 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 01:36:34.632772 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 01:36:34.640394 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 01:36:34.656123 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.656379 (Thread-1): finished collecting timing info
2021-02-25 01:36:34.656583 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 01:36:34.657680 (MainThread): Connection 'master' was properly closed.
2021-02-25 01:36:34.657773 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 01:36:34.941986 (MainThread): 01:36:34 | Done.
2021-02-25 01:36:35.034870 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-02-25 01:36:35.035013 (MainThread): 01:36:35 | Building catalog
2021-02-25 01:36:35.152686 (MainThread): Opening a new connection, currently in state init
2021-02-25 01:36:35.348546 (MainThread): Skipping catalog for hashpath-demo-data.github - schema does not exist
2021-02-25 01:36:35.348954 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-02-25 01:36:35.364077 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-02-25 01:36:35.368573 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: 
    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_jrosen`.__TABLES__
        where (upper(dataset_id) = upper('dbt_jrosen'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-02-25 01:36:35.755327 (Thread-13): handling poll request
2021-02-25 01:36:35.755810 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50031d30>]}
2021-02-25 01:36:35.763105 (Thread-13): sending response (<Response 41836 bytes [200 OK]>) to 10.0.19.152
2021-02-25 01:36:37.007756 (Thread-14): handling poll request
2021-02-25 01:36:37.008188 (Thread-14): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d500408e0>]}
2021-02-25 01:36:37.009066 (Thread-14): sending response (<Response 306 bytes [200 OK]>) to 10.0.26.158
2021-02-25 01:36:38.284675 (Thread-15): handling poll request
2021-02-25 01:36:38.285097 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50040580>]}
2021-02-25 01:36:38.286082 (Thread-15): sending response (<Response 308 bytes [200 OK]>) to 10.0.5.107
2021-02-25 01:36:39.362511 (MainThread): 01:36:39 | Catalog written to /usr/src/develop/user-7994/environment-9499/repository-16870/target/catalog.json
2021-02-25 01:36:39.585969 (Thread-16): handling poll request
2021-02-25 01:36:39.586402 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50400a60>]}
2021-02-25 01:36:39.592041 (Thread-16): sending response (<Response 12093 bytes [200 OK]>) to 10.0.40.10
2021-02-25 01:36:40.075652 (Thread-17): handling status request
2021-02-25 01:36:40.076105 (Thread-17): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '24dce240-2150-48ee-87be-49ff42f3477a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d500e12e0>]}
2021-02-25 01:36:40.088248 (Thread-17): sending response (<Response 43242 bytes [200 OK]>) to 10.0.32.171
2021-02-25 01:53:05.900576 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50d31dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5625ed60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50d37400>]}
2021-02-25 01:53:05.902645 (MainThread): Flushing usage events
2021-02-25 01:53:05.933895 (MainThread): Runtime Error
  Syntax error near line 5
  ------------------------------
  2  |   - package: fivetran/github_source
  3  |     version: 0.2.2
  4  | 
  5  |    - git: "git@github.com:sethdr/seth_dbt_package_demo.git" # git SSH URL
  
  Raw Error:
  ------------------------------
  while parsing a block collection
    in "<unicode string>", line 2, column 3:
        - package: fivetran/github_source
        ^
  expected <block end>, but found '<block sequence start>'
    in "<unicode string>", line 5, column 4:
         - git: "git@github.com:sethdr/se ... 
         ^
2021-02-25 02:06:27.152996 (MainThread): Running with dbt=0.19.0
2021-02-25 02:06:27.200409 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-02-25 02:06:27.211289 (MainThread): Tracking: tracking
2021-02-25 02:06:27.222040 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d521de5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43c55b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d52232c40>]}
2021-02-25 02:06:27.222310 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=15
2021-02-25 02:06:27.222650 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-02-25 02:06:27.224258 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-02-25 02:06:27.285284 (Thread-19): handling status request
2021-02-25 02:06:27.285779 (Thread-19): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43c043d0>]}
2021-02-25 02:06:27.286492 (Thread-19): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:06:27.629321 (Thread-18): Got an acceptable cached parse result
2021-02-25 02:06:28.385147 (Thread-18): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50514fa0>]}
2021-02-25 02:06:28.601020 (Thread-20): handling status request
2021-02-25 02:06:28.601529 (Thread-20): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43fc5f10>]}
2021-02-25 02:06:28.602490 (Thread-20): sending response (<Response 883 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:06:31.277751 (Thread-21): handling status request
2021-02-25 02:06:31.278276 (Thread-21): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5625ed60>]}
2021-02-25 02:06:31.279211 (Thread-21): sending response (<Response 883 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:06:31.335482 (Thread-22): handling status request
2021-02-25 02:06:31.335920 (Thread-22): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d671718b0>]}
2021-02-25 02:06:31.336879 (Thread-22): sending response (<Response 883 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:06:31.737040 (Thread-23): handling cli_args request
2021-02-25 02:06:31.737525 (Thread-23): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d500f6430>]}
2021-02-25 02:06:32.676357 (Thread-23): sending response (<Response 136 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:06:32.796573 (MainThread): Partial parsing not enabled
2021-02-25 02:06:32.799238 (MainThread): Parsing macros/adapters.sql
2021-02-25 02:06:32.820136 (MainThread): Parsing macros/etc.sql
2021-02-25 02:06:32.822436 (MainThread): Parsing macros/catalog.sql
2021-02-25 02:06:32.828577 (MainThread): Parsing macros/materializations/copy.sql
2021-02-25 02:06:32.833659 (MainThread): Parsing macros/materializations/table.sql
2021-02-25 02:06:32.843763 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-25 02:06:32.856442 (MainThread): Parsing macros/materializations/seed.sql
2021-02-25 02:06:32.859405 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-25 02:06:32.861342 (MainThread): Parsing macros/materializations/view.sql
2021-02-25 02:06:32.864999 (MainThread): Parsing macros/core.sql
2021-02-25 02:06:32.868864 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-25 02:06:32.878240 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-25 02:06:32.892669 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-25 02:06:32.894553 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-25 02:06:32.912607 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-25 02:06:32.940438 (Thread-24): handling poll request
2021-02-25 02:06:32.940883 (Thread-24): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50d24d90>]}
2021-02-25 02:06:32.943600 (Thread-24): sending response (<Response 4645 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:06:32.944962 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-25 02:06:32.950122 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-25 02:06:32.956889 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-25 02:06:32.978765 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-25 02:06:32.985579 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-25 02:06:32.987575 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-25 02:06:32.994871 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-25 02:06:32.996705 (MainThread): Parsing macros/etc/query.sql
2021-02-25 02:06:32.998104 (MainThread): Parsing macros/etc/datetime.sql
2021-02-25 02:06:33.007960 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-25 02:06:33.009069 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-25 02:06:33.011058 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-25 02:06:33.014068 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-25 02:06:33.015770 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-25 02:06:33.019710 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-25 02:06:33.021674 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-25 02:06:33.023475 (MainThread): Parsing macros/adapters/common.sql
2021-02-25 02:06:33.083600 (MainThread): Parsing macros/logger/pretty_time.sql
2021-02-25 02:06:33.087223 (MainThread): Parsing macros/logger/log_info.sql
2021-02-25 02:06:33.090799 (MainThread): Parsing macros/logger/pretty_log_format.sql
2021-02-25 02:06:33.093937 (MainThread): Parsing macros/sql/pivot.sql
2021-02-25 02:06:33.100849 (MainThread): Parsing macros/sql/star.sql
2021-02-25 02:06:33.107364 (MainThread): Parsing macros/sql/surrogate_key.sql
2021-02-25 02:06:33.113884 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2021-02-25 02:06:33.119275 (MainThread): Parsing macros/sql/get_column_values.sql
2021-02-25 02:06:33.126919 (MainThread): Parsing macros/sql/groupby.sql
2021-02-25 02:06:33.130306 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2021-02-25 02:06:33.139631 (MainThread): Parsing macros/sql/nullcheck_table.sql
2021-02-25 02:06:33.143390 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2021-02-25 02:06:33.147153 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2021-02-25 02:06:33.153012 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2021-02-25 02:06:33.158453 (MainThread): Parsing macros/sql/safe_add.sql
2021-02-25 02:06:33.162680 (MainThread): Parsing macros/sql/unpivot.sql
2021-02-25 02:06:33.172980 (MainThread): Parsing macros/sql/generate_series.sql
2021-02-25 02:06:33.179576 (MainThread): Parsing macros/sql/nullcheck.sql
2021-02-25 02:06:33.183508 (MainThread): Parsing macros/sql/union.sql
2021-02-25 02:06:33.197781 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2021-02-25 02:06:33.246886 (MainThread): Parsing macros/web/get_url_parameter.sql
2021-02-25 02:06:33.251920 (MainThread): Parsing macros/web/get_url_path.sql
2021-02-25 02:06:33.258505 (MainThread): Parsing macros/web/get_url_host.sql
2021-02-25 02:06:33.264386 (MainThread): Parsing macros/datetime/date_spine.sql
2021-02-25 02:06:33.273522 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2021-02-25 02:06:33.277832 (MainThread): Parsing macros/schema_tests/not_constant.sql
2021-02-25 02:06:33.281810 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2021-02-25 02:06:33.285316 (MainThread): Parsing macros/schema_tests/equality.sql
2021-02-25 02:06:33.291931 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2021-02-25 02:06:33.295867 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2021-02-25 02:06:33.299503 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2021-02-25 02:06:33.304005 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2021-02-25 02:06:33.313003 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2021-02-25 02:06:33.317820 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2021-02-25 02:06:33.323108 (MainThread): Parsing macros/schema_tests/recency.sql
2021-02-25 02:06:33.326997 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2021-02-25 02:06:33.331560 (MainThread): Parsing macros/geo/haversine_distance.sql
2021-02-25 02:06:33.335559 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2021-02-25 02:06:33.339802 (MainThread): Parsing macros/cross_db_utils/length.sql
2021-02-25 02:06:33.343072 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2021-02-25 02:06:33.348614 (MainThread): Parsing macros/cross_db_utils/_get_utils_namespaces.sql
2021-02-25 02:06:33.351652 (MainThread): Parsing macros/cross_db_utils/right.sql
2021-02-25 02:06:33.356183 (MainThread): Parsing macros/cross_db_utils/hash.sql
2021-02-25 02:06:33.359967 (MainThread): Parsing macros/cross_db_utils/replace.sql
2021-02-25 02:06:33.363495 (MainThread): Parsing macros/cross_db_utils/concat.sql
2021-02-25 02:06:33.367843 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2021-02-25 02:06:33.370741 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2021-02-25 02:06:33.374431 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2021-02-25 02:06:33.386301 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2021-02-25 02:06:33.391490 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2021-02-25 02:06:33.400970 (MainThread): Parsing macros/cross_db_utils/position.sql
2021-02-25 02:06:33.405061 (MainThread): Parsing macros/cross_db_utils/literal.sql
2021-02-25 02:06:33.408814 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2021-02-25 02:06:33.413907 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2021-02-25 02:06:33.421985 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2021-02-25 02:06:33.426045 (MainThread): Parsing macros/cross_db_utils/except.sql
2021-02-25 02:06:33.429038 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2021-02-25 02:06:33.432993 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2021-02-25 02:06:33.438244 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2021-02-25 02:06:33.443198 (MainThread): Parsing macros/get_issue_closed_history_columns.sql
2021-02-25 02:06:33.447290 (MainThread): Parsing macros/get_issue_comment_columns.sql
2021-02-25 02:06:33.451515 (MainThread): Parsing macros/get_requested_reviewer_history_columns.sql
2021-02-25 02:06:33.455224 (MainThread): Parsing macros/get_team_columns.sql
2021-02-25 02:06:33.459767 (MainThread): Parsing macros/get_issue_assignee_columns.sql
2021-02-25 02:06:33.462950 (MainThread): Parsing macros/get_user_columns.sql
2021-02-25 02:06:33.466542 (MainThread): Parsing macros/get_pull_request_columns.sql
2021-02-25 02:06:33.472604 (MainThread): Parsing macros/get_issue_columns.sql
2021-02-25 02:06:33.478171 (MainThread): Parsing macros/get_repo_team_columns.sql
2021-02-25 02:06:33.481617 (MainThread): Parsing macros/get_issue_merged_columns.sql
2021-02-25 02:06:33.485134 (MainThread): Parsing macros/get_issue_label_columns.sql
2021-02-25 02:06:33.488431 (MainThread): Parsing macros/get_repository_columns.sql
2021-02-25 02:06:33.495260 (MainThread): Parsing macros/get_pull_request_review_columns.sql
2021-02-25 02:06:33.501265 (MainThread): Parsing macros/enabled_vars_one_true.sql
2021-02-25 02:06:33.504455 (MainThread): Parsing macros/dummy_coalesce_value.sql
2021-02-25 02:06:33.509596 (MainThread): Parsing macros/enabled_vars.sql
2021-02-25 02:06:33.514920 (MainThread): Parsing macros/_get_utils_namespaces.sql
2021-02-25 02:06:33.517889 (MainThread): Parsing macros/remove_prefix_from_columns.sql
2021-02-25 02:06:33.521495 (MainThread): Parsing macros/first_value.sql
2021-02-25 02:06:33.525844 (MainThread): Parsing macros/generate_columns_macro.sql
2021-02-25 02:06:33.533162 (MainThread): Parsing macros/timestamp_add.sql
2021-02-25 02:06:33.538271 (MainThread): Parsing macros/snowflake_seed_data.sql
2021-02-25 02:06:33.541497 (MainThread): Parsing macros/fill_staging_columns.sql
2021-02-25 02:06:33.547795 (MainThread): Parsing macros/percentile.sql
2021-02-25 02:06:33.551758 (MainThread): Parsing macros/get_columns_for_macro.sql
2021-02-25 02:06:33.559137 (MainThread): Parsing macros/string_agg.sql
2021-02-25 02:06:33.563098 (MainThread): Parsing macros/array_agg.sql
2021-02-25 02:06:33.566832 (MainThread): Parsing macros/union_relations.sql
2021-02-25 02:06:33.590484 (MainThread): Partial parsing not enabled
2021-02-25 02:06:33.657857 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:06:33.696397 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:06:33.713049 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:06:33.727204 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:06:33.739761 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:06:33.755052 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:06:33.769833 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:06:34.115920 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_merged".
2021-02-25 02:06:34.150411 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__repo_team".
2021-02-25 02:06:34.170339 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_label".
2021-02-25 02:06:34.189480 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__repository".
2021-02-25 02:06:34.214493 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_review".
2021-02-25 02:06:34.233999 (Thread-25): handling poll request
2021-02-25 02:06:34.234428 (Thread-25): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43e3c6a0>]}
2021-02-25 02:06:34.244129 (Thread-25): sending response (<Response 32829 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:06:34.238044 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__pull_request".
2021-02-25 02:06:34.263820 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue".
2021-02-25 02:06:34.288020 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__team".
2021-02-25 02:06:34.311509 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_assignee".
2021-02-25 02:06:34.331596 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__user".
2021-02-25 02:06:34.352611 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__requested_reviewer_history".
2021-02-25 02:06:34.372932 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_comment".
2021-02-25 02:06:34.393785 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_closed_history".
2021-02-25 02:06:34.417571 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_merged_tmp".
2021-02-25 02:06:34.433873 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__repo_team_tmp".
2021-02-25 02:06:34.450696 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_label_tmp".
2021-02-25 02:06:34.475690 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__repository_tmp".
2021-02-25 02:06:34.502937 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_review_tmp".
2021-02-25 02:06:34.522337 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_tmp".
2021-02-25 02:06:34.538230 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_tmp".
2021-02-25 02:06:34.554601 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_assignee_tmp".
2021-02-25 02:06:34.570305 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__team_tmp".
2021-02-25 02:06:34.587118 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__user_tmp".
2021-02-25 02:06:34.659358 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_comment_tmp".
2021-02-25 02:06:34.675930 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__requested_reviewer_history_tmp".
2021-02-25 02:06:34.692187 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github__issue_closed_history_tmp".
2021-02-25 02:06:34.795513 (Thread-26): handling kill request
2021-02-25 02:06:34.795979 (Thread-26): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43cbc130>]}
2021-02-25 02:06:34.797813 (Thread-26): sending response (<Response 110 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:06:35.576031 (Thread-27): handling poll request
2021-02-25 02:06:35.576527 (Thread-27): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43c25910>]}
2021-02-25 02:06:35.579199 (Thread-27): sending response (<Response 6999 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:06:35.852661 (Thread-28): handling status request
2021-02-25 02:06:35.853109 (Thread-28): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dcc580>]}
2021-02-25 02:06:35.854089 (Thread-28): sending response (<Response 883 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:06:48.613273 (Thread-29): handling status request
2021-02-25 02:06:48.613778 (Thread-29): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43cbc130>]}
2021-02-25 02:06:48.614698 (Thread-29): sending response (<Response 883 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:06:48.621344 (Thread-30): handling status request
2021-02-25 02:06:48.621696 (Thread-30): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43c25ca0>]}
2021-02-25 02:06:48.622437 (Thread-30): sending response (<Response 883 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:06:48.907259 (Thread-31): handling docs.generate request
2021-02-25 02:06:48.907763 (Thread-31): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43c25880>]}
2021-02-25 02:06:49.823484 (Thread-31): sending response (<Response 136 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:06:49.889390 (MainThread): Found 33 models, 22 tests, 0 snapshots, 0 analyses, 372 macros, 0 operations, 0 seed files, 13 sources, 0 exposures
2021-02-25 02:06:49.892518 (MainThread): 
2021-02-25 02:06:49.892894 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:06:49.957019 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:06:49.957162 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:06:50.131923 (Thread-32): handling poll request
2021-02-25 02:06:50.132374 (Thread-32): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dcc4f0>]}
2021-02-25 02:06:50.134513 (Thread-32): sending response (<Response 1785 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:06:50.174842 (MainThread): 02:06:50 | Concurrency: 1 threads (target='default')
2021-02-25 02:06:50.174973 (MainThread): 02:06:50 | 
2021-02-25 02:06:50.177308 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:06:50.177501 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:06:50.177580 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:06:50.197651 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:06:50.215907 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.216196 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.216403 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:06:50.216499 (Thread-1): Began running node model.github_source.stg_github__issue_assignee_tmp
2021-02-25 02:06:50.216586 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_assignee_tmp".
2021-02-25 02:06:50.216645 (Thread-1): Compiling model.github_source.stg_github__issue_assignee_tmp
2021-02-25 02:06:50.227880 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_assignee_tmp"
2021-02-25 02:06:50.244481 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.244716 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.244912 (Thread-1): Finished running node model.github_source.stg_github__issue_assignee_tmp
2021-02-25 02:06:50.245003 (Thread-1): Began running node model.github_source.stg_github__issue_closed_history_tmp
2021-02-25 02:06:50.245088 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_closed_history_tmp".
2021-02-25 02:06:50.245155 (Thread-1): Compiling model.github_source.stg_github__issue_closed_history_tmp
2021-02-25 02:06:50.253236 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_closed_history_tmp"
2021-02-25 02:06:50.272822 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.273087 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.273287 (Thread-1): Finished running node model.github_source.stg_github__issue_closed_history_tmp
2021-02-25 02:06:50.273402 (Thread-1): Began running node model.github_source.stg_github__issue_comment_tmp
2021-02-25 02:06:50.273519 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_comment_tmp".
2021-02-25 02:06:50.273582 (Thread-1): Compiling model.github_source.stg_github__issue_comment_tmp
2021-02-25 02:06:50.281420 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_comment_tmp"
2021-02-25 02:06:50.304734 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.305077 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.305290 (Thread-1): Finished running node model.github_source.stg_github__issue_comment_tmp
2021-02-25 02:06:50.305415 (Thread-1): Began running node model.github_source.stg_github__issue_label_tmp
2021-02-25 02:06:50.305515 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_label_tmp".
2021-02-25 02:06:50.305581 (Thread-1): Compiling model.github_source.stg_github__issue_label_tmp
2021-02-25 02:06:50.314737 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_label_tmp"
2021-02-25 02:06:50.333859 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.334199 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.334430 (Thread-1): Finished running node model.github_source.stg_github__issue_label_tmp
2021-02-25 02:06:50.334539 (Thread-1): Began running node model.github_source.stg_github__issue_merged_tmp
2021-02-25 02:06:50.334645 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_merged_tmp".
2021-02-25 02:06:50.334714 (Thread-1): Compiling model.github_source.stg_github__issue_merged_tmp
2021-02-25 02:06:50.343669 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_merged_tmp"
2021-02-25 02:06:50.361704 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.362198 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.362498 (Thread-1): Finished running node model.github_source.stg_github__issue_merged_tmp
2021-02-25 02:06:50.362607 (Thread-1): Began running node model.github_source.stg_github__issue_tmp
2021-02-25 02:06:50.362702 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_tmp".
2021-02-25 02:06:50.362767 (Thread-1): Compiling model.github_source.stg_github__issue_tmp
2021-02-25 02:06:50.372158 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_tmp"
2021-02-25 02:06:50.390394 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.390766 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.391005 (Thread-1): Finished running node model.github_source.stg_github__issue_tmp
2021-02-25 02:06:50.391119 (Thread-1): Began running node model.github_source.stg_github__pull_request_review_tmp
2021-02-25 02:06:50.391220 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_review_tmp".
2021-02-25 02:06:50.391285 (Thread-1): Compiling model.github_source.stg_github__pull_request_review_tmp
2021-02-25 02:06:50.400522 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__pull_request_review_tmp"
2021-02-25 02:06:50.418002 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.418347 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.418609 (Thread-1): Finished running node model.github_source.stg_github__pull_request_review_tmp
2021-02-25 02:06:50.418728 (Thread-1): Began running node model.github_source.stg_github__pull_request_tmp
2021-02-25 02:06:50.418833 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_tmp".
2021-02-25 02:06:50.418902 (Thread-1): Compiling model.github_source.stg_github__pull_request_tmp
2021-02-25 02:06:50.429338 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__pull_request_tmp"
2021-02-25 02:06:50.447792 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.448121 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.448334 (Thread-1): Finished running node model.github_source.stg_github__pull_request_tmp
2021-02-25 02:06:50.448433 (Thread-1): Began running node model.github_source.stg_github__repo_team_tmp
2021-02-25 02:06:50.448525 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repo_team_tmp".
2021-02-25 02:06:50.448588 (Thread-1): Compiling model.github_source.stg_github__repo_team_tmp
2021-02-25 02:06:50.457969 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__repo_team_tmp"
2021-02-25 02:06:50.477444 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.477802 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.478033 (Thread-1): Finished running node model.github_source.stg_github__repo_team_tmp
2021-02-25 02:06:50.478139 (Thread-1): Began running node model.github_source.stg_github__repository_tmp
2021-02-25 02:06:50.478235 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repository_tmp".
2021-02-25 02:06:50.478308 (Thread-1): Compiling model.github_source.stg_github__repository_tmp
2021-02-25 02:06:50.486964 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__repository_tmp"
2021-02-25 02:06:50.505273 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.505625 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.505873 (Thread-1): Finished running node model.github_source.stg_github__repository_tmp
2021-02-25 02:06:50.505975 (Thread-1): Began running node model.github_source.stg_github__requested_reviewer_history_tmp
2021-02-25 02:06:50.506070 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__requested_reviewer_history_tmp".
2021-02-25 02:06:50.506134 (Thread-1): Compiling model.github_source.stg_github__requested_reviewer_history_tmp
2021-02-25 02:06:50.514649 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__requested_reviewer_history_tmp"
2021-02-25 02:06:50.532374 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.532836 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.533179 (Thread-1): Finished running node model.github_source.stg_github__requested_reviewer_history_tmp
2021-02-25 02:06:50.533325 (Thread-1): Began running node model.github_source.stg_github__team_tmp
2021-02-25 02:06:50.533466 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__team_tmp".
2021-02-25 02:06:50.533535 (Thread-1): Compiling model.github_source.stg_github__team_tmp
2021-02-25 02:06:50.543136 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__team_tmp"
2021-02-25 02:06:50.563602 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.564069 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.564422 (Thread-1): Finished running node model.github_source.stg_github__team_tmp
2021-02-25 02:06:50.564582 (Thread-1): Began running node model.github_source.stg_github__user_tmp
2021-02-25 02:06:50.564734 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__user_tmp".
2021-02-25 02:06:50.564841 (Thread-1): Compiling model.github_source.stg_github__user_tmp
2021-02-25 02:06:50.578593 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__user_tmp"
2021-02-25 02:06:50.600937 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.601471 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.601848 (Thread-1): Finished running node model.github_source.stg_github__user_tmp
2021-02-25 02:06:50.602015 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:06:50.602177 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:06:50.602287 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:06:50.614382 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:06:50.633421 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.633895 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.634237 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:06:50.634397 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:06:50.634558 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:06:50.634669 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:06:50.647203 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:06:50.665136 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.665457 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.665669 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:06:50.665765 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:06:50.665868 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:06:50.665932 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:06:50.677468 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:06:50.694005 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.694290 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.694497 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:06:50.694594 (Thread-1): Began running node model.github_source.stg_github__issue_assignee
2021-02-25 02:06:50.694686 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_assignee".
2021-02-25 02:06:50.694747 (Thread-1): Compiling model.github_source.stg_github__issue_assignee
2021-02-25 02:06:50.703826 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:50.889238 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_assignee_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_assignee_tmp
2021-02-25 02:06:50.908730 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_assignee"
2021-02-25 02:06:50.928010 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.928467 (Thread-1): finished collecting timing info
2021-02-25 02:06:50.928784 (Thread-1): Finished running node model.github_source.stg_github__issue_assignee
2021-02-25 02:06:50.928936 (Thread-1): Began running node model.github_source.stg_github__issue_closed_history
2021-02-25 02:06:50.929076 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_closed_history".
2021-02-25 02:06:50.929171 (Thread-1): Compiling model.github_source.stg_github__issue_closed_history
2021-02-25 02:06:50.941742 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:51.116403 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_closed_history_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_closed_history_tmp
2021-02-25 02:06:51.125054 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_closed_history"
2021-02-25 02:06:51.142864 (Thread-1): finished collecting timing info
2021-02-25 02:06:51.143315 (Thread-1): finished collecting timing info
2021-02-25 02:06:51.143650 (Thread-1): Finished running node model.github_source.stg_github__issue_closed_history
2021-02-25 02:06:51.143807 (Thread-1): Began running node model.github_source.stg_github__issue_comment
2021-02-25 02:06:51.143956 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_comment".
2021-02-25 02:06:51.144052 (Thread-1): Compiling model.github_source.stg_github__issue_comment
2021-02-25 02:06:51.155729 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:51.342271 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_comment_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_comment_tmp
2021-02-25 02:06:51.352027 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_comment"
2021-02-25 02:06:51.369108 (Thread-1): finished collecting timing info
2021-02-25 02:06:51.369627 (Thread-1): finished collecting timing info
2021-02-25 02:06:51.369966 (Thread-1): Finished running node model.github_source.stg_github__issue_comment
2021-02-25 02:06:51.370164 (Thread-1): Began running node model.github_source.stg_github__issue_label
2021-02-25 02:06:51.370324 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_label".
2021-02-25 02:06:51.370432 (Thread-1): Compiling model.github_source.stg_github__issue_label
2021-02-25 02:06:51.386628 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:51.473617 (Thread-33): handling poll request
2021-02-25 02:06:51.474035 (Thread-33): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43c65130>]}
2021-02-25 02:06:51.489755 (Thread-33): sending response (<Response 70000 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:06:51.587101 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_label_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_label_tmp
2021-02-25 02:06:51.594643 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_label"
2021-02-25 02:06:51.612058 (Thread-1): finished collecting timing info
2021-02-25 02:06:51.612392 (Thread-1): finished collecting timing info
2021-02-25 02:06:51.612605 (Thread-1): Finished running node model.github_source.stg_github__issue_label
2021-02-25 02:06:51.612708 (Thread-1): Began running node model.github_source.stg_github__issue_merged
2021-02-25 02:06:51.612805 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue_merged".
2021-02-25 02:06:51.612870 (Thread-1): Compiling model.github_source.stg_github__issue_merged
2021-02-25 02:06:51.622673 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:51.798963 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_merged_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_merged_tmp
2021-02-25 02:06:51.804715 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue_merged"
2021-02-25 02:06:51.820795 (Thread-1): finished collecting timing info
2021-02-25 02:06:51.821127 (Thread-1): finished collecting timing info
2021-02-25 02:06:51.821364 (Thread-1): Finished running node model.github_source.stg_github__issue_merged
2021-02-25 02:06:51.821502 (Thread-1): Began running node model.github_source.stg_github__issue
2021-02-25 02:06:51.821600 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__issue".
2021-02-25 02:06:51.821665 (Thread-1): Compiling model.github_source.stg_github__issue
2021-02-25 02:06:51.834207 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:52.013939 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__issue_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__issue_tmp
2021-02-25 02:06:52.025044 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__issue"
2021-02-25 02:06:52.040527 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.040892 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.041117 (Thread-1): Finished running node model.github_source.stg_github__issue
2021-02-25 02:06:52.041222 (Thread-1): Began running node model.github_source.stg_github__pull_request_review
2021-02-25 02:06:52.041319 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request_review".
2021-02-25 02:06:52.041415 (Thread-1): Compiling model.github_source.stg_github__pull_request_review
2021-02-25 02:06:52.052393 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:52.261205 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__pull_request_review_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__pull_request_review_tmp
2021-02-25 02:06:52.268710 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__pull_request_review"
2021-02-25 02:06:52.287073 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.287434 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.287659 (Thread-1): Finished running node model.github_source.stg_github__pull_request_review
2021-02-25 02:06:52.287763 (Thread-1): Began running node model.github_source.stg_github__pull_request
2021-02-25 02:06:52.287865 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__pull_request".
2021-02-25 02:06:52.287930 (Thread-1): Compiling model.github_source.stg_github__pull_request
2021-02-25 02:06:52.301762 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:52.481467 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__pull_request_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__pull_request_tmp
2021-02-25 02:06:52.497236 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__pull_request"
2021-02-25 02:06:52.515986 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.516460 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.516830 (Thread-1): Finished running node model.github_source.stg_github__pull_request
2021-02-25 02:06:52.516989 (Thread-1): Began running node model.github_source.stg_github__repo_team
2021-02-25 02:06:52.517106 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repo_team".
2021-02-25 02:06:52.517174 (Thread-1): Compiling model.github_source.stg_github__repo_team
2021-02-25 02:06:52.534057 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:52.709996 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__repo_team_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__repo_team_tmp
2021-02-25 02:06:52.715571 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__repo_team"
2021-02-25 02:06:52.734511 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.734890 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.735118 (Thread-1): Finished running node model.github_source.stg_github__repo_team
2021-02-25 02:06:52.735230 (Thread-1): Began running node model.github_source.stg_github__repository
2021-02-25 02:06:52.735337 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__repository".
2021-02-25 02:06:52.735403 (Thread-1): Compiling model.github_source.stg_github__repository
2021-02-25 02:06:52.745111 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:52.921159 (Thread-34): handling poll request
2021-02-25 02:06:52.921616 (Thread-34): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43b70c40>]}
2021-02-25 02:06:52.926909 (Thread-34): sending response (<Response 25162 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:06:52.929032 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__repository_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__repository_tmp
2021-02-25 02:06:52.938491 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__repository"
2021-02-25 02:06:52.958081 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.958423 (Thread-1): finished collecting timing info
2021-02-25 02:06:52.958642 (Thread-1): Finished running node model.github_source.stg_github__repository
2021-02-25 02:06:52.958746 (Thread-1): Began running node model.github_source.stg_github__requested_reviewer_history
2021-02-25 02:06:52.958844 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__requested_reviewer_history".
2021-02-25 02:06:52.958909 (Thread-1): Compiling model.github_source.stg_github__requested_reviewer_history
2021-02-25 02:06:52.969481 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:53.185608 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__requested_reviewer_history_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__requested_reviewer_history_tmp
2021-02-25 02:06:53.191694 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__requested_reviewer_history"
2021-02-25 02:06:53.210698 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.211025 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.211257 (Thread-1): Finished running node model.github_source.stg_github__requested_reviewer_history
2021-02-25 02:06:53.211357 (Thread-1): Began running node model.github_source.stg_github__team
2021-02-25 02:06:53.211451 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__team".
2021-02-25 02:06:53.211514 (Thread-1): Compiling model.github_source.stg_github__team
2021-02-25 02:06:53.223803 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:53.427223 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__team_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__team_tmp
2021-02-25 02:06:53.435612 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__team"
2021-02-25 02:06:53.453280 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.453667 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.453896 (Thread-1): Finished running node model.github_source.stg_github__team
2021-02-25 02:06:53.454002 (Thread-1): Began running node model.github_source.stg_github__user
2021-02-25 02:06:53.454099 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github__user".
2021-02-25 02:06:53.454163 (Thread-1): Compiling model.github_source.stg_github__user
2021-02-25 02:06:53.466866 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:06:53.641507 (Thread-1): get_columns_in_relation error: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/datasets/dbt_jrosen/tables/stg_github__user_tmp?prettyPrint=false: Not found: Table hashpath-demo-data:dbt_jrosen.stg_github__user_tmp
2021-02-25 02:06:53.646851 (Thread-1): Writing injected SQL for node "model.github_source.stg_github__user"
2021-02-25 02:06:53.665612 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.666034 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.666282 (Thread-1): Finished running node model.github_source.stg_github__user
2021-02-25 02:06:53.666387 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:06:53.666484 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:06:53.666551 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:06:53.674753 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:06:53.692993 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.693304 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.693565 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:06:53.693663 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:06:53.693758 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:06:53.693822 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:06:53.702910 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:06:53.720950 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.721296 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.721552 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:06:53.721653 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:06:53.721748 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:06:53.721812 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:06:53.731228 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:06:53.748629 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.748949 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.749170 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:06:53.749270 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:06:53.749402 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 02:06:53.749490 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:06:53.775475 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 02:06:53.792963 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.793320 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.793695 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:06:53.793842 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:06:53.793993 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 02:06:53.794091 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:06:53.805708 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 02:06:53.823988 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.824407 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.824726 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:06:53.824872 (Thread-1): Began running node test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id
2021-02-25 02:06:53.825014 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id".
2021-02-25 02:06:53.825103 (Thread-1): Compiling test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id
2021-02-25 02:06:53.845860 (Thread-1): Writing injected SQL for node "test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id"
2021-02-25 02:06:53.864372 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.864810 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.865127 (Thread-1): Finished running node test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_assignee_issue_id__user_id
2021-02-25 02:06:53.865273 (Thread-1): Began running node test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at
2021-02-25 02:06:53.865443 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at".
2021-02-25 02:06:53.865543 (Thread-1): Compiling test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at
2021-02-25 02:06:53.877799 (Thread-1): Writing injected SQL for node "test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at"
2021-02-25 02:06:53.895742 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.896073 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.896286 (Thread-1): Finished running node test.github_source.dbt_utils_unique_combination_of_columns_stg_github__issue_closed_history_issue_id__updated_at
2021-02-25 02:06:53.896413 (Thread-1): Began running node test.github_source.not_null_stg_github__issue_comment_issue_comment_id
2021-02-25 02:06:53.896522 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__issue_comment_issue_comment_id".
2021-02-25 02:06:53.896587 (Thread-1): Compiling test.github_source.not_null_stg_github__issue_comment_issue_comment_id
2021-02-25 02:06:53.905087 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__issue_comment_issue_comment_id"
2021-02-25 02:06:53.923531 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.923903 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.924155 (Thread-1): Finished running node test.github_source.not_null_stg_github__issue_comment_issue_comment_id
2021-02-25 02:06:53.924263 (Thread-1): Began running node test.github_source.unique_stg_github__issue_comment_issue_comment_id
2021-02-25 02:06:53.924369 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__issue_comment_issue_comment_id".
2021-02-25 02:06:53.924480 (Thread-1): Compiling test.github_source.unique_stg_github__issue_comment_issue_comment_id
2021-02-25 02:06:53.933576 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__issue_comment_issue_comment_id"
2021-02-25 02:06:53.951055 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.951347 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.951562 (Thread-1): Finished running node test.github_source.unique_stg_github__issue_comment_issue_comment_id
2021-02-25 02:06:53.951657 (Thread-1): Began running node test.github_source.not_null_stg_github__issue_issue_id
2021-02-25 02:06:53.951749 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__issue_issue_id".
2021-02-25 02:06:53.951810 (Thread-1): Compiling test.github_source.not_null_stg_github__issue_issue_id
2021-02-25 02:06:53.960458 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__issue_issue_id"
2021-02-25 02:06:53.977450 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.977776 (Thread-1): finished collecting timing info
2021-02-25 02:06:53.978033 (Thread-1): Finished running node test.github_source.not_null_stg_github__issue_issue_id
2021-02-25 02:06:53.978133 (Thread-1): Began running node test.github_source.unique_stg_github__issue_issue_id
2021-02-25 02:06:53.978226 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__issue_issue_id".
2021-02-25 02:06:53.978287 (Thread-1): Compiling test.github_source.unique_stg_github__issue_issue_id
2021-02-25 02:06:53.987431 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__issue_issue_id"
2021-02-25 02:06:54.005370 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.005793 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.006130 (Thread-1): Finished running node test.github_source.unique_stg_github__issue_issue_id
2021-02-25 02:06:54.006242 (Thread-1): Began running node test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id
2021-02-25 02:06:54.006343 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id".
2021-02-25 02:06:54.006408 (Thread-1): Compiling test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id
2021-02-25 02:06:54.017919 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id"
2021-02-25 02:06:54.034586 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.035025 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.035345 (Thread-1): Finished running node test.github_source.not_null_stg_github__pull_request_review_pull_request_review_id
2021-02-25 02:06:54.035490 (Thread-1): Began running node test.github_source.unique_stg_github__pull_request_review_pull_request_review_id
2021-02-25 02:06:54.035630 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__pull_request_review_pull_request_review_id".
2021-02-25 02:06:54.035726 (Thread-1): Compiling test.github_source.unique_stg_github__pull_request_review_pull_request_review_id
2021-02-25 02:06:54.050118 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__pull_request_review_pull_request_review_id"
2021-02-25 02:06:54.068105 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.068482 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.068799 (Thread-1): Finished running node test.github_source.unique_stg_github__pull_request_review_pull_request_review_id
2021-02-25 02:06:54.068941 (Thread-1): Began running node test.github_source.not_null_stg_github__pull_request_pull_request_id
2021-02-25 02:06:54.069076 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__pull_request_pull_request_id".
2021-02-25 02:06:54.069168 (Thread-1): Compiling test.github_source.not_null_stg_github__pull_request_pull_request_id
2021-02-25 02:06:54.081625 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__pull_request_pull_request_id"
2021-02-25 02:06:54.102368 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.102810 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.103125 (Thread-1): Finished running node test.github_source.not_null_stg_github__pull_request_pull_request_id
2021-02-25 02:06:54.103268 (Thread-1): Began running node test.github_source.unique_stg_github__pull_request_pull_request_id
2021-02-25 02:06:54.103409 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__pull_request_pull_request_id".
2021-02-25 02:06:54.103504 (Thread-1): Compiling test.github_source.unique_stg_github__pull_request_pull_request_id
2021-02-25 02:06:54.116730 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__pull_request_pull_request_id"
2021-02-25 02:06:54.136185 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.136612 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.136918 (Thread-1): Finished running node test.github_source.unique_stg_github__pull_request_pull_request_id
2021-02-25 02:06:54.137063 (Thread-1): Began running node test.github_source.not_null_stg_github__repo_team_repository_id
2021-02-25 02:06:54.137199 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__repo_team_repository_id".
2021-02-25 02:06:54.137293 (Thread-1): Compiling test.github_source.not_null_stg_github__repo_team_repository_id
2021-02-25 02:06:54.150280 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__repo_team_repository_id"
2021-02-25 02:06:54.167649 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.168047 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.168353 (Thread-1): Finished running node test.github_source.not_null_stg_github__repo_team_repository_id
2021-02-25 02:06:54.168495 (Thread-1): Began running node test.github_source.not_null_stg_github__repo_team_team_id
2021-02-25 02:06:54.168632 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__repo_team_team_id".
2021-02-25 02:06:54.168726 (Thread-1): Compiling test.github_source.not_null_stg_github__repo_team_team_id
2021-02-25 02:06:54.181347 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__repo_team_team_id"
2021-02-25 02:06:54.199184 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.199508 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.199720 (Thread-1): Finished running node test.github_source.not_null_stg_github__repo_team_team_id
2021-02-25 02:06:54.199817 (Thread-1): Began running node test.github_source.not_null_stg_github__repository_repository_id
2021-02-25 02:06:54.199908 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__repository_repository_id".
2021-02-25 02:06:54.199969 (Thread-1): Compiling test.github_source.not_null_stg_github__repository_repository_id
2021-02-25 02:06:54.208798 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__repository_repository_id"
2021-02-25 02:06:54.227652 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.227954 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.228164 (Thread-1): Finished running node test.github_source.not_null_stg_github__repository_repository_id
2021-02-25 02:06:54.228261 (Thread-1): Began running node test.github_source.unique_stg_github__repository_repository_id
2021-02-25 02:06:54.228353 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__repository_repository_id".
2021-02-25 02:06:54.228416 (Thread-1): Compiling test.github_source.unique_stg_github__repository_repository_id
2021-02-25 02:06:54.236677 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__repository_repository_id"
2021-02-25 02:06:54.253339 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.253637 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.253855 (Thread-1): Finished running node test.github_source.unique_stg_github__repository_repository_id
2021-02-25 02:06:54.253951 (Thread-1): Began running node test.github_source.not_null_stg_github__team_team_id
2021-02-25 02:06:54.254040 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__team_team_id".
2021-02-25 02:06:54.254100 (Thread-1): Compiling test.github_source.not_null_stg_github__team_team_id
2021-02-25 02:06:54.262384 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__team_team_id"
2021-02-25 02:06:54.277925 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.278187 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.278388 (Thread-1): Finished running node test.github_source.not_null_stg_github__team_team_id
2021-02-25 02:06:54.278483 (Thread-1): Began running node test.github_source.unique_stg_github__team_team_id
2021-02-25 02:06:54.278573 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__team_team_id".
2021-02-25 02:06:54.278650 (Thread-1): Compiling test.github_source.unique_stg_github__team_team_id
2021-02-25 02:06:54.288047 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__team_team_id"
2021-02-25 02:06:54.290655 (Thread-35): handling poll request
2021-02-25 02:06:54.291081 (Thread-35): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43c4eeb0>]}
2021-02-25 02:06:54.317021 (Thread-35): sending response (<Response 86166 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:06:54.306832 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.307104 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.307326 (Thread-1): Finished running node test.github_source.unique_stg_github__team_team_id
2021-02-25 02:06:54.307431 (Thread-1): Began running node test.github_source.not_null_stg_github__user_user_id
2021-02-25 02:06:54.307546 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_stg_github__user_user_id".
2021-02-25 02:06:54.307610 (Thread-1): Compiling test.github_source.not_null_stg_github__user_user_id
2021-02-25 02:06:54.316296 (Thread-1): Writing injected SQL for node "test.github_source.not_null_stg_github__user_user_id"
2021-02-25 02:06:54.336197 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.336506 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.336718 (Thread-1): Finished running node test.github_source.not_null_stg_github__user_user_id
2021-02-25 02:06:54.336819 (Thread-1): Began running node test.github_source.unique_stg_github__user_user_id
2021-02-25 02:06:54.336914 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_stg_github__user_user_id".
2021-02-25 02:06:54.336977 (Thread-1): Compiling test.github_source.unique_stg_github__user_user_id
2021-02-25 02:06:54.345415 (Thread-1): Writing injected SQL for node "test.github_source.unique_stg_github__user_user_id"
2021-02-25 02:06:54.364876 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.365167 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.365398 (Thread-1): Finished running node test.github_source.unique_stg_github__user_user_id
2021-02-25 02:06:54.365508 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:06:54.365601 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 02:06:54.365664 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:06:54.373832 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 02:06:54.389703 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.390097 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.390451 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:06:54.390613 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:06:54.390765 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 02:06:54.390870 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:06:54.404313 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 02:06:54.422731 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.422993 (Thread-1): finished collecting timing info
2021-02-25 02:06:54.423193 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:06:54.424429 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:06:54.424515 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 02:06:54.687274 (MainThread): 02:06:54 | Done.
2021-02-25 02:06:54.752869 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-02-25 02:06:54.753013 (MainThread): 02:06:54 | Building catalog
2021-02-25 02:06:54.870617 (MainThread): Opening a new connection, currently in state init
2021-02-25 02:06:55.048394 (MainThread): Skipping catalog for hashpath-demo-data.github - schema does not exist
2021-02-25 02:06:55.048815 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-02-25 02:06:55.063847 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-02-25 02:06:55.068414 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: 
    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_jrosen`.__TABLES__
        where (upper(dataset_id) = upper('dbt_jrosen'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-02-25 02:06:55.621667 (Thread-36): handling poll request
2021-02-25 02:06:55.622106 (Thread-36): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5040e8b0>]}
2021-02-25 02:06:55.626400 (Thread-36): sending response (<Response 24979 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:06:57.006018 (Thread-37): handling poll request
2021-02-25 02:06:57.006452 (Thread-37): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5040ed60>]}
2021-02-25 02:06:57.007320 (Thread-37): sending response (<Response 293 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:06:58.153575 (MainThread): 02:06:58 | Catalog written to /usr/src/develop/user-7994/environment-9499/repository-16870/target/catalog.json
2021-02-25 02:06:58.427767 (Thread-38): handling poll request
2021-02-25 02:06:58.428278 (Thread-38): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50514c40>]}
2021-02-25 02:06:58.436990 (Thread-38): sending response (<Response 12079 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:06:58.745779 (Thread-39): handling status request
2021-02-25 02:06:58.746229 (Thread-39): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43f155e0>]}
2021-02-25 02:06:58.747165 (Thread-39): sending response (<Response 883 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:07:23.863393 (Thread-40): handling status request
2021-02-25 02:07:23.863836 (Thread-40): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dc6e50>]}
2021-02-25 02:07:23.864789 (Thread-40): sending response (<Response 883 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:07:23.918603 (Thread-41): handling status request
2021-02-25 02:07:23.919007 (Thread-41): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504f1730>]}
2021-02-25 02:07:23.919929 (Thread-41): sending response (<Response 883 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:07:24.193737 (Thread-42): handling deps request
2021-02-25 02:07:24.194320 (Thread-42): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43fd41c0>]}
2021-02-25 02:07:24.245996 (Thread-42): sending response (<Response 136 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:07:24.553053 (Thread-43): handling poll request
2021-02-25 02:07:24.553608 (Thread-43): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d6dee0>]}
2021-02-25 02:07:24.555501 (Thread-43): sending response (<Response 285 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:07:25.873186 (Thread-44): handling poll request
2021-02-25 02:07:25.873708 (Thread-44): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d500daca0>]}
2021-02-25 02:07:25.874655 (Thread-44): sending response (<Response 285 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:07:27.170900 (Thread-45): handling poll request
2021-02-25 02:07:27.171396 (Thread-45): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50507c70>]}
2021-02-25 02:07:27.172311 (Thread-45): sending response (<Response 285 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:07:27.430199 (MainThread): Set downloads directory='/tmp/dbt-downloads-m0fkrd3d'
2021-02-25 02:07:27.431147 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:07:27.639467 (MainThread): STDOUT: "b''"
2021-02-25 02:07:27.639708 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:07:27.640053 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:07:27.640124 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:07:27.645372 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:07:27.645650 (MainThread): STDERR: "b''"
2021-02-25 02:07:27.645732 (MainThread):   Checking out branch master.
2021-02-25 02:07:27.645790 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:07:27.650968 (MainThread): STDOUT: "b''"
2021-02-25 02:07:27.651194 (MainThread): STDERR: "b''"
2021-02-25 02:07:27.651258 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:07:27.741408 (MainThread): STDOUT: "b''"
2021-02-25 02:07:27.741664 (MainThread): STDERR: "b"fatal: Couldn't find remote ref master\n""
2021-02-25 02:07:27.741709 (MainThread): command return code=128
2021-02-25 02:07:27.741891 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/task_handler.py", line 94, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/deps.py", line 34, in handle_request
    self.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/deps.py", line 53, in run
    final_deps = resolve_packages(packages, self.config)
  File "/usr/local/lib/python3.8/dist-packages/dbt/deps/resolver.py", line 137, in resolve_packages
    target = final[package].resolved().fetch_metadata(config, renderer)
  File "/usr/local/lib/python3.8/dist-packages/dbt/deps/base.py", line 85, in fetch_metadata
    self._cached_metadata = self._fetch_metadata(project, renderer)
  File "/usr/local/lib/python3.8/dist-packages/dbt/deps/git.py", line 74, in _fetch_metadata
    path = self._checkout()
  File "/usr/local/lib/python3.8/dist-packages/dbt/deps/git.py", line 59, in _checkout
    dir_ = git.clone_and_checkout(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/git.py", line 100, in clone_and_checkout
    checkout(full_path, repo, branch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/git.py", line 60, in checkout
    dbt.exceptions.bad_package_spec(repo, branch, stderr)
  File "/usr/local/lib/python3.8/dist-packages/dbt/exceptions.py", line 646, in bad_package_spec
    raise InternalException(
dbt.exceptions.InternalException: Error checking out spec='master' for repo https://github.com/sethdr/seth_dbt_package_demo.git
fatal: Couldn't find remote ref master
2021-02-25 02:07:28.802143 (Thread-46): handling poll request
2021-02-25 02:07:28.802606 (Thread-46): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504eb400>]}
2021-02-25 02:07:28.826678 (Thread-46): sending response (<Response 6420 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:07:29.182345 (Thread-47): handling status request
2021-02-25 02:07:29.182759 (Thread-47): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50512100>]}
2021-02-25 02:07:29.184891 (Thread-47): sending response (<Response 18942 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:08:34.948212 (Thread-48): handling status request
2021-02-25 02:08:34.949997 (Thread-48): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50317070>]}
2021-02-25 02:08:34.952081 (Thread-48): sending response (<Response 18942 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:08:34.976350 (Thread-49): handling status request
2021-02-25 02:08:34.976772 (Thread-49): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5040e580>]}
2021-02-25 02:08:34.978898 (Thread-49): sending response (<Response 18942 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:08:35.254195 (Thread-50): handling deps request
2021-02-25 02:08:35.254653 (Thread-50): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50502610>]}
2021-02-25 02:08:35.312115 (Thread-50): sending response (<Response 136 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:08:35.738129 (Thread-51): handling poll request
2021-02-25 02:08:35.738638 (Thread-51): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dac6d0>]}
2021-02-25 02:08:35.740145 (Thread-51): sending response (<Response 285 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:08:36.220938 (MainThread): Set downloads directory='/tmp/dbt-downloads-msihz5f1'
2021-02-25 02:08:36.222233 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:08:36.406644 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.406989 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:08:36.407491 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:08:36.407612 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:08:36.413628 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:08:36.413897 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.414012 (MainThread):   Checking out branch master.
2021-02-25 02:08:36.414083 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:08:36.419256 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.419527 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.419633 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:08:36.605657 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.606015 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:08:36.606136 (MainThread): Executing "git tag --list"
2021-02-25 02:08:36.612477 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.612762 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.612878 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:08:36.626195 (MainThread): STDOUT: "b'HEAD is now at 6e846fa wip\n'"
2021-02-25 02:08:36.626502 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.626639 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:08:36.631317 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:08:36.631600 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.631720 (MainThread):   Checked out at 6e846fa.
2021-02-25 02:08:36.673399 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:08:36.679217 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.679507 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:08:36.679600 (MainThread): command return code=128
2021-02-25 02:08:36.680178 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:08:36.680301 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:08:36.684816 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:08:36.685089 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.685215 (MainThread):   Checking out branch master.
2021-02-25 02:08:36.685296 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:08:36.690481 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.690786 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.690892 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:08:36.885471 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.885829 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:08:36.885971 (MainThread): Executing "git tag --list"
2021-02-25 02:08:36.893258 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.893572 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.893708 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:08:36.899553 (MainThread): STDOUT: "b'HEAD is now at 6e846fa wip\n'"
2021-02-25 02:08:36.899827 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.899950 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:08:36.904145 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:08:36.904415 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.904534 (MainThread):   Already at 6e846fa, nothing to do.
2021-02-25 02:08:36.977435 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:08:36.980697 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:08:36.985416 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.985644 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:08:36.985702 (MainThread): command return code=128
2021-02-25 02:08:36.985828 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:08:36.985891 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:08:36.990120 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:08:36.990342 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.990422 (MainThread):   Checking out branch master.
2021-02-25 02:08:36.990467 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:08:36.996643 (MainThread): STDOUT: "b''"
2021-02-25 02:08:36.996875 (MainThread): STDERR: "b''"
2021-02-25 02:08:36.996942 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:08:37.124292 (Thread-52): handling kill request
2021-02-25 02:08:37.124727 (Thread-52): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daab20>]}
2021-02-25 02:08:37.125612 (Thread-52): sending response (<Response 110 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:08:37.175517 (Thread-53): handling poll request
2021-02-25 02:08:37.175980 (Thread-53): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da01f0>]}
2021-02-25 02:08:37.181974 (Thread-53): sending response (<Response 18064 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:08:37.472175 (Thread-54): handling status request
2021-02-25 02:08:37.472584 (Thread-54): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0a30>]}
2021-02-25 02:08:37.473308 (Thread-54): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:08:38.760069 (Thread-55): handling status request
2021-02-25 02:08:38.760482 (Thread-55): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0d60>]}
2021-02-25 02:08:38.761172 (Thread-55): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:08:40.215711 (Thread-56): handling status request
2021-02-25 02:08:40.216138 (Thread-56): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0310>]}
2021-02-25 02:08:40.216825 (Thread-56): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:08:41.510034 (Thread-57): handling status request
2021-02-25 02:08:41.510455 (Thread-57): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504e9400>]}
2021-02-25 02:08:41.511242 (Thread-57): sending response (<Response 183 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:08:42.799701 (Thread-58): handling status request
2021-02-25 02:08:42.800463 (Thread-58): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504e9520>]}
2021-02-25 02:08:42.801139 (Thread-58): sending response (<Response 183 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:08:44.075238 (Thread-59): handling status request
2021-02-25 02:08:44.075686 (Thread-59): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0880>]}
2021-02-25 02:08:44.076376 (Thread-59): sending response (<Response 183 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:08:45.350521 (Thread-60): handling status request
2021-02-25 02:08:45.350954 (Thread-60): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0c10>]}
2021-02-25 02:08:45.351657 (Thread-60): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:08:46.766354 (Thread-61): handling status request
2021-02-25 02:08:46.766825 (Thread-61): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0940>]}
2021-02-25 02:08:46.767504 (Thread-61): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:08:48.209287 (Thread-62): handling status request
2021-02-25 02:08:48.209749 (Thread-62): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43fd4a90>]}
2021-02-25 02:08:48.210445 (Thread-62): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:08:49.646150 (Thread-63): handling status request
2021-02-25 02:08:49.646571 (Thread-63): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa670>]}
2021-02-25 02:08:49.647265 (Thread-63): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:08:51.072828 (Thread-64): handling status request
2021-02-25 02:08:51.073479 (Thread-64): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dace80>]}
2021-02-25 02:08:51.074298 (Thread-64): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:08:52.456125 (Thread-65): handling status request
2021-02-25 02:08:52.456544 (Thread-65): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d0a850>]}
2021-02-25 02:08:52.457229 (Thread-65): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:08:53.749465 (Thread-66): handling status request
2021-02-25 02:08:53.749909 (Thread-66): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50502e20>]}
2021-02-25 02:08:53.750658 (Thread-66): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:08:55.041251 (Thread-67): handling status request
2021-02-25 02:08:55.041722 (Thread-67): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5050f640>]}
2021-02-25 02:08:55.042515 (Thread-67): sending response (<Response 183 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:08:56.433705 (Thread-68): handling status request
2021-02-25 02:08:56.434221 (Thread-68): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a610>]}
2021-02-25 02:08:56.434918 (Thread-68): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:08:57.825018 (Thread-69): handling status request
2021-02-25 02:08:57.825491 (Thread-69): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9af70>]}
2021-02-25 02:08:57.826268 (Thread-69): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:08:59.283358 (Thread-70): handling status request
2021-02-25 02:08:59.283786 (Thread-70): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a580>]}
2021-02-25 02:08:59.284512 (Thread-70): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:09:00.569163 (Thread-71): handling status request
2021-02-25 02:09:00.569633 (Thread-71): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a970>]}
2021-02-25 02:09:00.570392 (Thread-71): sending response (<Response 183 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:09:01.953471 (Thread-72): handling status request
2021-02-25 02:09:01.953979 (Thread-72): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43e7b8b0>]}
2021-02-25 02:09:01.954697 (Thread-72): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:09:03.438556 (Thread-73): handling status request
2021-02-25 02:09:03.439313 (Thread-73): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50511dc0>]}
2021-02-25 02:09:03.440101 (Thread-73): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:09:04.769813 (Thread-74): handling status request
2021-02-25 02:09:04.770239 (Thread-74): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a3a0>]}
2021-02-25 02:09:04.770939 (Thread-74): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:09:06.276238 (Thread-75): handling status request
2021-02-25 02:09:06.276678 (Thread-75): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a730>]}
2021-02-25 02:09:06.277449 (Thread-75): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:09:07.579551 (Thread-76): handling status request
2021-02-25 02:09:07.580026 (Thread-76): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504f1ac0>]}
2021-02-25 02:09:07.607201 (Thread-76): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:09:08.930806 (Thread-77): handling status request
2021-02-25 02:09:08.931272 (Thread-77): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a700>]}
2021-02-25 02:09:08.932037 (Thread-77): sending response (<Response 183 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:09:10.322298 (Thread-78): handling status request
2021-02-25 02:09:10.322728 (Thread-78): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9ad00>]}
2021-02-25 02:09:10.323421 (Thread-78): sending response (<Response 183 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:09:11.636707 (Thread-79): handling status request
2021-02-25 02:09:11.637129 (Thread-79): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50502610>]}
2021-02-25 02:09:11.637856 (Thread-79): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:09:12.933999 (Thread-80): handling status request
2021-02-25 02:09:12.934531 (Thread-80): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa670>]}
2021-02-25 02:09:12.935328 (Thread-80): sending response (<Response 183 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:09:14.305207 (Thread-81): handling status request
2021-02-25 02:09:14.305740 (Thread-81): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43f15280>]}
2021-02-25 02:09:14.306487 (Thread-81): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:09:15.646299 (Thread-82): handling status request
2021-02-25 02:09:15.646715 (Thread-82): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da03a0>]}
2021-02-25 02:09:15.647400 (Thread-82): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:09:17.118887 (Thread-83): handling status request
2021-02-25 02:09:17.119335 (Thread-83): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da05b0>]}
2021-02-25 02:09:17.120063 (Thread-83): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:09:18.565200 (Thread-84): handling status request
2021-02-25 02:09:18.565657 (Thread-84): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da00d0>]}
2021-02-25 02:09:18.566346 (Thread-84): sending response (<Response 183 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:09:19.864099 (Thread-85): handling status request
2021-02-25 02:09:19.864520 (Thread-85): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0d30>]}
2021-02-25 02:09:19.865210 (Thread-85): sending response (<Response 183 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:09:21.182306 (Thread-86): handling status request
2021-02-25 02:09:21.182732 (Thread-86): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c9a0>]}
2021-02-25 02:09:21.183431 (Thread-86): sending response (<Response 183 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:09:22.478990 (Thread-87): handling status request
2021-02-25 02:09:22.479507 (Thread-87): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c880>]}
2021-02-25 02:09:22.480259 (Thread-87): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:09:23.880303 (Thread-88): handling status request
2021-02-25 02:09:23.880735 (Thread-88): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d505124c0>]}
2021-02-25 02:09:23.881516 (Thread-88): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:09:25.182330 (Thread-89): handling status request
2021-02-25 02:09:25.182854 (Thread-89): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dacc40>]}
2021-02-25 02:09:25.183613 (Thread-89): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:09:26.544862 (Thread-90): handling status request
2021-02-25 02:09:26.545346 (Thread-90): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50502640>]}
2021-02-25 02:09:26.546121 (Thread-90): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:09:27.821132 (Thread-91): handling status request
2021-02-25 02:09:27.821631 (Thread-91): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daab20>]}
2021-02-25 02:09:27.822328 (Thread-91): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:09:29.173191 (Thread-92): handling status request
2021-02-25 02:09:29.173715 (Thread-92): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5050fe50>]}
2021-02-25 02:09:29.174445 (Thread-92): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:09:30.620581 (Thread-93): handling status request
2021-02-25 02:09:30.621035 (Thread-93): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a730>]}
2021-02-25 02:09:30.621832 (Thread-93): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:09:32.080172 (Thread-94): handling status request
2021-02-25 02:09:32.080655 (Thread-94): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a580>]}
2021-02-25 02:09:32.081611 (Thread-94): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:09:33.381503 (Thread-95): handling status request
2021-02-25 02:09:33.381932 (Thread-95): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a130>]}
2021-02-25 02:09:33.382613 (Thread-95): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:09:34.701354 (Thread-96): handling status request
2021-02-25 02:09:34.701835 (Thread-96): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a3d0>]}
2021-02-25 02:09:34.702540 (Thread-96): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:09:36.125449 (Thread-97): handling status request
2021-02-25 02:09:36.125927 (Thread-97): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0a00>]}
2021-02-25 02:09:36.126649 (Thread-97): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:09:37.403619 (Thread-98): handling status request
2021-02-25 02:09:37.404042 (Thread-98): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0a90>]}
2021-02-25 02:09:37.404732 (Thread-98): sending response (<Response 183 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:09:38.822447 (Thread-99): handling status request
2021-02-25 02:09:38.823030 (Thread-99): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0370>]}
2021-02-25 02:09:38.824036 (Thread-99): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:09:40.164949 (Thread-100): handling status request
2021-02-25 02:09:40.165422 (Thread-100): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0700>]}
2021-02-25 02:09:40.166139 (Thread-100): sending response (<Response 183 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:09:41.449918 (Thread-101): handling status request
2021-02-25 02:09:41.450359 (Thread-101): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c760>]}
2021-02-25 02:09:41.451101 (Thread-101): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:09:42.732789 (Thread-102): handling status request
2021-02-25 02:09:42.733481 (Thread-102): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0940>]}
2021-02-25 02:09:42.734190 (Thread-102): sending response (<Response 183 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:09:46.173232 (Thread-103): handling status request
2021-02-25 02:09:46.173693 (Thread-103): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0910>]}
2021-02-25 02:09:46.174438 (Thread-103): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:09:46.175537 (Thread-104): handling ps request
2021-02-25 02:09:46.175987 (Thread-104): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0c40>]}
2021-02-25 02:09:46.178409 (Thread-104): sending response (<Response 1703 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:09:46.500807 (Thread-105): handling poll request
2021-02-25 02:09:46.501246 (Thread-105): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50317070>]}
2021-02-25 02:09:46.507050 (Thread-105): sending response (<Response 18064 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:09:47.554483 (Thread-106): handling status request
2021-02-25 02:09:47.555114 (Thread-106): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0e80>]}
2021-02-25 02:09:47.580312 (Thread-106): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:09:48.984100 (Thread-107): handling status request
2021-02-25 02:09:48.984540 (Thread-107): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a9a0>]}
2021-02-25 02:09:48.985272 (Thread-107): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:09:50.486339 (Thread-108): handling status request
2021-02-25 02:09:50.486802 (Thread-108): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dacca0>]}
2021-02-25 02:09:50.487503 (Thread-108): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:09:51.773759 (Thread-109): handling status request
2021-02-25 02:09:51.774215 (Thread-109): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43f157c0>]}
2021-02-25 02:09:51.774961 (Thread-109): sending response (<Response 183 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:09:53.157698 (Thread-110): handling status request
2021-02-25 02:09:53.158181 (Thread-110): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504ffbe0>]}
2021-02-25 02:09:53.158886 (Thread-110): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:09:54.032776 (Thread-111): handling poll request
2021-02-25 02:09:54.033277 (Thread-111): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa3a0>]}
2021-02-25 02:09:54.073897 (Thread-111): sending response (<Response 218711 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:09:54.566647 (Thread-112): handling status request
2021-02-25 02:09:54.567083 (Thread-112): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa6a0>]}
2021-02-25 02:09:54.567801 (Thread-112): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:09:56.014374 (Thread-113): handling status request
2021-02-25 02:09:56.014795 (Thread-113): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa1c0>]}
2021-02-25 02:09:56.015490 (Thread-113): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:09:57.512754 (Thread-114): handling status request
2021-02-25 02:09:57.513347 (Thread-114): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43f15d00>]}
2021-02-25 02:09:57.514248 (Thread-114): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:09:58.875690 (Thread-115): handling status request
2021-02-25 02:09:58.876132 (Thread-115): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dac6d0>]}
2021-02-25 02:09:58.876836 (Thread-115): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:10:00.338113 (Thread-116): handling status request
2021-02-25 02:10:00.338583 (Thread-116): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dacc70>]}
2021-02-25 02:10:00.339274 (Thread-116): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:10:01.784207 (Thread-117): handling status request
2021-02-25 02:10:01.784888 (Thread-117): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a2b0>]}
2021-02-25 02:10:01.785761 (Thread-117): sending response (<Response 183 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:10:03.218878 (Thread-118): handling status request
2021-02-25 02:10:03.219315 (Thread-118): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9abe0>]}
2021-02-25 02:10:03.220021 (Thread-118): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:10:04.750356 (Thread-119): handling status request
2021-02-25 02:10:04.750779 (Thread-119): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0790>]}
2021-02-25 02:10:04.751440 (Thread-119): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:10:06.046339 (Thread-120): handling status request
2021-02-25 02:10:06.046802 (Thread-120): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0f10>]}
2021-02-25 02:10:06.047527 (Thread-120): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:10:07.331984 (Thread-121): handling status request
2021-02-25 02:10:07.332409 (Thread-121): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0640>]}
2021-02-25 02:10:07.333130 (Thread-121): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:10:08.597052 (Thread-122): handling status request
2021-02-25 02:10:08.597572 (Thread-122): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50502610>]}
2021-02-25 02:10:08.598468 (Thread-122): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:10:09.915900 (Thread-123): handling status request
2021-02-25 02:10:09.916335 (Thread-123): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c700>]}
2021-02-25 02:10:09.917049 (Thread-123): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:10:11.272668 (Thread-124): handling status request
2021-02-25 02:10:11.273118 (Thread-124): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046cac0>]}
2021-02-25 02:10:11.273919 (Thread-124): sending response (<Response 183 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:10:12.603807 (Thread-125): handling status request
2021-02-25 02:10:12.604236 (Thread-125): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c040>]}
2021-02-25 02:10:12.605089 (Thread-125): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:10:14.089887 (Thread-126): handling status request
2021-02-25 02:10:14.090598 (Thread-126): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50502790>]}
2021-02-25 02:10:14.091313 (Thread-126): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:10:15.396450 (Thread-127): handling status request
2021-02-25 02:10:15.396923 (Thread-127): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da02b0>]}
2021-02-25 02:10:15.397801 (Thread-127): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:10:16.742469 (Thread-128): handling status request
2021-02-25 02:10:16.742917 (Thread-128): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43da0460>]}
2021-02-25 02:10:16.743619 (Thread-128): sending response (<Response 183 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:10:18.112216 (Thread-129): handling status request
2021-02-25 02:10:18.112651 (Thread-129): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a3a0>]}
2021-02-25 02:10:18.113353 (Thread-129): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:10:19.574902 (Thread-130): handling status request
2021-02-25 02:10:19.575401 (Thread-130): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a8b0>]}
2021-02-25 02:10:19.576183 (Thread-130): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:10:20.893814 (Thread-131): handling status request
2021-02-25 02:10:20.894238 (Thread-131): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50511820>]}
2021-02-25 02:10:20.894937 (Thread-131): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:10:22.250526 (Thread-132): handling status request
2021-02-25 02:10:22.250963 (Thread-132): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43f15af0>]}
2021-02-25 02:10:22.251685 (Thread-132): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:10:23.653047 (Thread-133): handling status request
2021-02-25 02:10:23.653523 (Thread-133): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dacf70>]}
2021-02-25 02:10:23.654255 (Thread-133): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:10:24.992693 (Thread-134): handling status request
2021-02-25 02:10:24.993406 (Thread-134): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dacb80>]}
2021-02-25 02:10:24.994449 (Thread-134): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:10:26.321366 (Thread-135): handling status request
2021-02-25 02:10:26.321847 (Thread-135): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dfa700>]}
2021-02-25 02:10:26.322539 (Thread-135): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:10:27.852824 (Thread-136): handling status request
2021-02-25 02:10:27.853287 (Thread-136): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa5e0>]}
2021-02-25 02:10:27.879225 (Thread-136): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:10:29.250474 (Thread-137): handling status request
2021-02-25 02:10:29.250920 (Thread-137): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6220>]}
2021-02-25 02:10:29.251660 (Thread-137): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:10:30.563897 (Thread-138): handling status request
2021-02-25 02:10:30.564340 (Thread-138): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6df0>]}
2021-02-25 02:10:30.565044 (Thread-138): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:10:31.966326 (Thread-139): handling status request
2021-02-25 02:10:31.966883 (Thread-139): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c5b0>]}
2021-02-25 02:10:31.967816 (Thread-139): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:10:33.274845 (Thread-140): handling status request
2021-02-25 02:10:33.275278 (Thread-140): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c6d0>]}
2021-02-25 02:10:33.276053 (Thread-140): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:10:34.558528 (Thread-141): handling status request
2021-02-25 02:10:34.559043 (Thread-141): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43fd4a90>]}
2021-02-25 02:10:34.559819 (Thread-141): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:10:35.831388 (Thread-142): handling status request
2021-02-25 02:10:35.831870 (Thread-142): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504f1ac0>]}
2021-02-25 02:10:35.832575 (Thread-142): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:10:37.152538 (Thread-143): handling status request
2021-02-25 02:10:37.152987 (Thread-143): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046caf0>]}
2021-02-25 02:10:37.153734 (Thread-143): sending response (<Response 183 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:10:38.672497 (Thread-144): handling status request
2021-02-25 02:10:38.672927 (Thread-144): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa760>]}
2021-02-25 02:10:38.673651 (Thread-144): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:10:40.038349 (Thread-145): handling status request
2021-02-25 02:10:40.038858 (Thread-145): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa280>]}
2021-02-25 02:10:40.039595 (Thread-145): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:10:41.511517 (Thread-146): handling status request
2021-02-25 02:10:41.511970 (Thread-146): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dacd00>]}
2021-02-25 02:10:41.512716 (Thread-146): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:10:42.824565 (Thread-147): handling status request
2021-02-25 02:10:42.825004 (Thread-147): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dac6d0>]}
2021-02-25 02:10:42.825817 (Thread-147): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:10:44.147880 (Thread-148): handling status request
2021-02-25 02:10:44.148310 (Thread-148): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43f15280>]}
2021-02-25 02:10:44.148998 (Thread-148): sending response (<Response 183 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:10:45.438766 (Thread-149): handling status request
2021-02-25 02:10:45.439193 (Thread-149): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504fff70>]}
2021-02-25 02:10:45.439985 (Thread-149): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:10:46.816749 (Thread-150): handling status request
2021-02-25 02:10:46.817181 (Thread-150): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9ab80>]}
2021-02-25 02:10:46.817948 (Thread-150): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:10:48.250864 (Thread-151): handling status request
2021-02-25 02:10:48.251548 (Thread-151): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d0a970>]}
2021-02-25 02:10:48.252258 (Thread-151): sending response (<Response 183 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:10:49.534439 (Thread-152): handling status request
2021-02-25 02:10:49.535063 (Thread-152): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d50516640>]}
2021-02-25 02:10:49.536113 (Thread-152): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:10:51.113215 (Thread-153): handling status request
2021-02-25 02:10:51.113761 (Thread-153): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dacee0>]}
2021-02-25 02:10:51.114582 (Thread-153): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:10:52.523114 (Thread-154): handling status request
2021-02-25 02:10:52.523647 (Thread-154): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43dac6d0>]}
2021-02-25 02:10:52.524364 (Thread-154): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:10:53.975380 (Thread-155): handling status request
2021-02-25 02:10:53.975961 (Thread-155): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43daa6d0>]}
2021-02-25 02:10:53.976742 (Thread-155): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:10:55.273730 (Thread-156): handling status request
2021-02-25 02:10:55.274158 (Thread-156): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c550>]}
2021-02-25 02:10:55.274874 (Thread-156): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:10:57.599654 (Thread-157): handling status request
2021-02-25 02:10:57.600102 (Thread-157): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046cca0>]}
2021-02-25 02:10:57.600805 (Thread-157): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:10:59.660088 (Thread-158): handling status request
2021-02-25 02:10:59.660514 (Thread-158): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c7c0>]}
2021-02-25 02:10:59.661253 (Thread-158): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:11:01.585516 (Thread-159): handling status request
2021-02-25 02:11:01.586023 (Thread-159): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43fd4a90>]}
2021-02-25 02:11:01.586741 (Thread-159): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:11:03.753302 (Thread-160): handling status request
2021-02-25 02:11:03.753789 (Thread-160): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046c370>]}
2021-02-25 02:11:03.754449 (Thread-160): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:11:05.667202 (Thread-161): handling status request
2021-02-25 02:11:05.667622 (Thread-161): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6eb0>]}
2021-02-25 02:11:05.668309 (Thread-161): sending response (<Response 183 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:11:07.781509 (Thread-162): handling status request
2021-02-25 02:11:07.781960 (Thread-162): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6e50>]}
2021-02-25 02:11:07.782682 (Thread-162): sending response (<Response 183 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:11:09.658044 (Thread-163): handling status request
2021-02-25 02:11:09.658478 (Thread-163): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6a00>]}
2021-02-25 02:11:09.659166 (Thread-163): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:11:11.775209 (Thread-164): handling status request
2021-02-25 02:11:11.775650 (Thread-164): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6940>]}
2021-02-25 02:11:11.776366 (Thread-164): sending response (<Response 183 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:11:13.684909 (Thread-165): handling status request
2021-02-25 02:11:13.685345 (Thread-165): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a760>]}
2021-02-25 02:11:13.686097 (Thread-165): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:11:15.753656 (Thread-166): handling status request
2021-02-25 02:11:15.754351 (Thread-166): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a5b0>]}
2021-02-25 02:11:15.778300 (Thread-166): sending response (<Response 183 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:11:17.778565 (Thread-167): handling status request
2021-02-25 02:11:17.779039 (Thread-167): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9ac10>]}
2021-02-25 02:11:17.779772 (Thread-167): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:11:19.662110 (Thread-168): handling status request
2021-02-25 02:11:19.662585 (Thread-168): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d504eb760>]}
2021-02-25 02:11:19.663271 (Thread-168): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:11:21.799786 (Thread-169): handling status request
2021-02-25 02:11:21.800237 (Thread-169): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6c40>]}
2021-02-25 02:11:21.800978 (Thread-169): sending response (<Response 183 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:11:23.255029 (Thread-170): handling status request
2021-02-25 02:11:23.255475 (Thread-170): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6f10>]}
2021-02-25 02:11:23.256224 (Thread-170): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:11:24.555075 (Thread-171): handling status request
2021-02-25 02:11:24.555503 (Thread-171): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6ac0>]}
2021-02-25 02:11:24.556230 (Thread-171): sending response (<Response 183 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:11:25.908138 (Thread-172): handling status request
2021-02-25 02:11:25.908621 (Thread-172): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9ac10>]}
2021-02-25 02:11:25.909329 (Thread-172): sending response (<Response 183 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:11:27.366605 (Thread-173): handling status request
2021-02-25 02:11:27.367078 (Thread-173): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d43d9a370>]}
2021-02-25 02:11:27.367759 (Thread-173): sending response (<Response 183 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:11:28.818152 (Thread-174): handling status request
2021-02-25 02:11:28.818668 (Thread-174): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d501c6970>]}
2021-02-25 02:11:28.819361 (Thread-174): sending response (<Response 183 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:11:30.213305 (Thread-175): handling status request
2021-02-25 02:11:30.213768 (Thread-175): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '61c319fc-8b73-454a-bba0-30970df99ba8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d5046ceb0>]}
2021-02-25 02:11:30.214460 (Thread-175): sending response (<Response 183 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:11:45.873979 (MainThread): Running with dbt=0.19.0
2021-02-25 02:11:46.021567 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-02-25 02:11:46.033319 (MainThread): Tracking: tracking
2021-02-25 02:11:46.052501 (Thread-1): Parsing macros/adapters.sql
2021-02-25 02:11:46.073479 (Thread-1): Parsing macros/etc.sql
2021-02-25 02:11:46.075742 (Thread-1): Parsing macros/catalog.sql
2021-02-25 02:11:46.081935 (Thread-1): Parsing macros/materializations/copy.sql
2021-02-25 02:11:46.086770 (Thread-1): Parsing macros/materializations/table.sql
2021-02-25 02:11:46.097644 (Thread-1): Parsing macros/materializations/incremental.sql
2021-02-25 02:11:46.111576 (Thread-1): Parsing macros/materializations/seed.sql
2021-02-25 02:11:46.114405 (Thread-1): Parsing macros/materializations/snapshot.sql
2021-02-25 02:11:46.114577 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8885375f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880668850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88806689d0>]}
2021-02-25 02:11:46.116666 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=15
2021-02-25 02:11:46.117089 (Thread-1): Parsing macros/materializations/view.sql
2021-02-25 02:11:46.117232 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-02-25 02:11:46.120245 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-02-25 02:11:46.122111 (Thread-1): Parsing macros/core.sql
2021-02-25 02:11:46.126107 (Thread-1): Parsing macros/materializations/helpers.sql
2021-02-25 02:11:46.135602 (Thread-1): Parsing macros/materializations/common/merge.sql
2021-02-25 02:11:46.149458 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-25 02:11:46.151233 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2021-02-25 02:11:46.168583 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-25 02:11:46.199756 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-25 02:11:46.204734 (Thread-1): Parsing macros/materializations/view/view.sql
2021-02-25 02:11:46.210870 (Thread-1): Parsing macros/materializations/seed/seed.sql
2021-02-25 02:11:46.231202 (Thread-1): Parsing macros/materializations/table/table.sql
2021-02-25 02:11:46.237734 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2021-02-25 02:11:46.239585 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2021-02-25 02:11:46.245571 (Thread-1): Parsing macros/etc/is_incremental.sql
2021-02-25 02:11:46.247215 (Thread-1): Parsing macros/etc/query.sql
2021-02-25 02:11:46.248285 (Thread-1): Parsing macros/etc/datetime.sql
2021-02-25 02:11:46.256936 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2021-02-25 02:11:46.257893 (Thread-1): Parsing macros/etc/get_custom_database.sql
2021-02-25 02:11:46.259537 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2021-02-25 02:11:46.261515 (Thread-1): Parsing macros/schema_tests/not_null.sql
2021-02-25 02:11:46.263056 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2021-02-25 02:11:46.265710 (Thread-1): Parsing macros/schema_tests/relationships.sql
2021-02-25 02:11:46.267608 (Thread-1): Parsing macros/schema_tests/unique.sql
2021-02-25 02:11:46.269379 (Thread-1): Parsing macros/adapters/common.sql
2021-02-25 02:11:46.370537 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:11:46.397030 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:11:46.416265 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:11:46.431392 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:11:46.445319 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:11:46.461321 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:11:46.477174 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:11:46.836935 (Thread-2): handling status request
2021-02-25 02:11:46.838019 (Thread-1): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888039eeb0>]}
2021-02-25 02:11:46.838481 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888038c280>]}
2021-02-25 02:11:46.843542 (Thread-2): sending response (<Response 11270 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:12:07.401982 (Thread-3): handling status request
2021-02-25 02:12:07.403998 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804b7ee0>]}
2021-02-25 02:12:07.407749 (Thread-3): sending response (<Response 11270 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:12:07.487658 (Thread-4): handling status request
2021-02-25 02:12:07.488066 (Thread-4): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88808a3a00>]}
2021-02-25 02:12:07.491729 (Thread-4): sending response (<Response 11270 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:12:07.686461 (Thread-5): handling deps request
2021-02-25 02:12:07.686937 (Thread-5): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804b7c40>]}
2021-02-25 02:12:07.749756 (Thread-5): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-25 02:12:07.804018 (Thread-5): sending response (<Response 136 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:12:08.095123 (Thread-6): handling poll request
2021-02-25 02:12:08.095571 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804fa3d0>]}
2021-02-25 02:12:08.098394 (Thread-6): sending response (<Response 285 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:12:08.591502 (MainThread): Set downloads directory='/tmp/dbt-downloads-cy_4fjz7'
2021-02-25 02:12:08.592312 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:12:08.798592 (MainThread): STDOUT: "b''"
2021-02-25 02:12:08.798828 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:12:08.799183 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:12:08.799252 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:12:08.803986 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:12:08.804210 (MainThread): STDERR: "b''"
2021-02-25 02:12:08.804285 (MainThread):   Checking out branch master.
2021-02-25 02:12:08.804329 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:12:08.809869 (MainThread): STDOUT: "b''"
2021-02-25 02:12:08.810072 (MainThread): STDERR: "b''"
2021-02-25 02:12:08.810136 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:12:09.007265 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.007529 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:12:09.007602 (MainThread): Executing "git tag --list"
2021-02-25 02:12:09.012161 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.012377 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.012456 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:12:09.017233 (MainThread): STDOUT: "b'HEAD is now at 6e846fa wip\n'"
2021-02-25 02:12:09.017442 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.017517 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:12:09.020778 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:12:09.020980 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.021047 (MainThread):   Checked out at 6e846fa.
2021-02-25 02:12:09.047045 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:12:09.050972 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.051215 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:12:09.051262 (MainThread): command return code=128
2021-02-25 02:12:09.051654 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:12:09.051722 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:12:09.055283 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:12:09.055482 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.055559 (MainThread):   Checking out branch master.
2021-02-25 02:12:09.055602 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:12:09.059893 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.060092 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.060158 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:12:09.282697 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.282954 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:12:09.283057 (MainThread): Executing "git tag --list"
2021-02-25 02:12:09.287811 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.288031 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.288111 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:12:09.293129 (MainThread): STDOUT: "b'HEAD is now at 6e846fa wip\n'"
2021-02-25 02:12:09.293348 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.293427 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:12:09.296888 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:12:09.297103 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.297174 (MainThread):   Already at 6e846fa, nothing to do.
2021-02-25 02:12:09.346917 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:12:09.349944 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:12:09.354623 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.354845 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:12:09.354895 (MainThread): command return code=128
2021-02-25 02:12:09.355060 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:12:09.355127 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:12:09.359180 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:12:09.359386 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.359464 (MainThread):   Checking out branch master.
2021-02-25 02:12:09.359508 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:12:09.364021 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.364229 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.364296 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:12:09.524139 (Thread-7): handling poll request
2021-02-25 02:12:09.524565 (Thread-7): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804890d0>]}
2021-02-25 02:12:09.530337 (Thread-7): sending response (<Response 17976 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:12:09.541071 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.541333 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:12:09.541408 (MainThread): Executing "git tag --list"
2021-02-25 02:12:09.547139 (MainThread): STDOUT: "b''"
2021-02-25 02:12:09.547315 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.547391 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:12:09.553312 (MainThread): STDOUT: "b'HEAD is now at 6e846fa wip\n'"
2021-02-25 02:12:09.553519 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.553596 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:12:09.557921 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:12:09.558123 (MainThread): STDERR: "b''"
2021-02-25 02:12:09.558196 (MainThread):   Already at 6e846fa, nothing to do.
2021-02-25 02:12:10.640648 (MainThread):   Installed from revision master

2021-02-25 02:12:10.641012 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'c85af215-085e-40c6-b94d-31b87b447c4f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b3a3c1ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b3a3c1c40>]}
2021-02-25 02:12:10.841504 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): project hash mismatch: values missing, cache invalidated: {'seth_test'}
2021-02-25 02:12:10.843525 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/adapters.sql
2021-02-25 02:12:10.862865 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/etc.sql
2021-02-25 02:12:10.865022 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/catalog.sql
2021-02-25 02:12:10.871298 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/copy.sql
2021-02-25 02:12:10.875620 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/table.sql
2021-02-25 02:12:10.885783 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/incremental.sql
2021-02-25 02:12:10.903111 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/seed.sql
2021-02-25 02:12:10.907630 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/snapshot.sql
2021-02-25 02:12:10.910660 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/view.sql
2021-02-25 02:12:10.916000 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/core.sql
2021-02-25 02:12:10.920682 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/helpers.sql
2021-02-25 02:12:10.929819 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/common/merge.sql
2021-02-25 02:12:10.943901 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-25 02:12:10.946316 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/snapshot/strategies.sql
2021-02-25 02:12:10.966690 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-25 02:12:11.000675 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-25 02:12:11.005611 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/view/view.sql
2021-02-25 02:12:11.012466 (Thread-8): handling poll request
2021-02-25 02:12:11.012647 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/seed/seed.sql
2021-02-25 02:12:11.013056 (Thread-8): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888030b520>]}
2021-02-25 02:12:11.025257 (Thread-8): sending response (<Response 4324 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:12:11.039503 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/table/table.sql
2021-02-25 02:12:11.046165 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/incremental/helpers.sql
2021-02-25 02:12:11.048039 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/materializations/incremental/incremental.sql
2021-02-25 02:12:11.054318 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/etc/is_incremental.sql
2021-02-25 02:12:11.055946 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/etc/query.sql
2021-02-25 02:12:11.056989 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/etc/datetime.sql
2021-02-25 02:12:11.065750 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/etc/get_custom_alias.sql
2021-02-25 02:12:11.066686 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/etc/get_custom_database.sql
2021-02-25 02:12:11.069250 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/etc/get_custom_schema.sql
2021-02-25 02:12:11.072188 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/schema_tests/not_null.sql
2021-02-25 02:12:11.074457 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/schema_tests/accepted_values.sql
2021-02-25 02:12:11.078540 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/schema_tests/relationships.sql
2021-02-25 02:12:11.081169 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/schema_tests/unique.sql
2021-02-25 02:12:11.083172 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Parsing macros/adapters/common.sql
2021-02-25 02:12:11.165884 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): project hash mismatch: values missing, cache invalidated: {'seth_test'}
2021-02-25 02:12:11.204081 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:12:11.224317 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:12:11.242012 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:12:11.269603 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:12:11.297451 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:12:11.313473 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:12:11.329163 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:12:11.541887 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:12:11.649198 (c93308f4-635e-42d7-a7cc-1c0c9223ba32-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880163880>]}
2021-02-25 02:12:12.388310 (Thread-9): handling poll request
2021-02-25 02:12:12.388747 (Thread-9): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801ad2e0>]}
2021-02-25 02:12:12.389746 (Thread-9): sending response (<Response 357 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:12:12.842617 (Thread-10): handling status request
2021-02-25 02:12:12.843129 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801ad580>]}
2021-02-25 02:12:12.849542 (Thread-10): sending response (<Response 21911 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:12:28.953156 (Thread-11): handling status request
2021-02-25 02:12:28.953596 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8896360a00>]}
2021-02-25 02:12:28.960136 (Thread-11): sending response (<Response 21911 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:12:28.985670 (Thread-12): handling status request
2021-02-25 02:12:28.986005 (Thread-12): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880159130>]}
2021-02-25 02:12:28.992508 (Thread-12): sending response (<Response 21911 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:12:29.314816 (Thread-13): handling docs.generate request
2021-02-25 02:12:29.315252 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880654370>]}
2021-02-25 02:12:29.317428 (Thread-13): Connection 'model.seth_test.viz1' was properly closed.
2021-02-25 02:12:30.174524 (Thread-13): sending response (<Response 136 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:12:30.240974 (MainThread): Found 8 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:12:30.242143 (MainThread): 
2021-02-25 02:12:30.242430 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:12:30.259884 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:12:30.259992 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:12:30.459156 (Thread-14): handling poll request
2021-02-25 02:12:30.460140 (Thread-14): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88806546a0>]}
2021-02-25 02:12:30.461936 (Thread-14): sending response (<Response 1781 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:12:30.465698 (MainThread): 02:12:30 | Concurrency: 1 threads (target='default')
2021-02-25 02:12:30.465826 (MainThread): 02:12:30 | 
2021-02-25 02:12:30.467945 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:12:30.468120 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:12:30.468202 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:12:30.489119 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:12:30.506556 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.506810 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.507037 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:12:30.507154 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:12:30.507244 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:12:30.507305 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:12:30.515554 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:12:30.534682 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.534923 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.535168 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:12:30.535270 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:12:30.535357 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:12:30.535417 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:12:30.548134 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:12:30.563216 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.563483 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.563688 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:12:30.563785 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:12:30.563872 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:12:30.563934 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:12:30.573568 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:12:30.588570 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.588813 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.589030 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:12:30.589125 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:12:30.589208 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:12:30.589269 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:12:30.596167 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:12:30.612743 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.612971 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.613164 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:12:30.613256 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:12:30.613337 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:12:30.613396 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:12:30.621042 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:12:30.636555 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.636778 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.636968 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:12:30.637058 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:12:30.637137 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:12:30.637194 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:12:30.645589 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:12:30.662491 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.662735 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.662933 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:12:30.663048 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 02:12:30.663136 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:12:30.663197 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 02:12:30.670199 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 02:12:30.698908 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.699174 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.699372 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 02:12:30.699465 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:12:30.699549 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 02:12:30.699609 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:12:30.722844 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 02:12:30.737690 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.737927 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.738122 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:12:30.738216 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:12:30.738305 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 02:12:30.738367 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:12:30.750064 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 02:12:30.765638 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.765937 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.766162 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:12:30.766266 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:12:30.766370 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 02:12:30.766457 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:12:30.774374 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 02:12:30.788231 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.788494 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.788699 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:12:30.788795 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:12:30.788884 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 02:12:30.788945 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:12:30.796308 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 02:12:30.813509 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.813737 (Thread-1): finished collecting timing info
2021-02-25 02:12:30.813931 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:12:30.814873 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:12:30.814967 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 02:12:30.926648 (MainThread): 02:12:30 | Done.
2021-02-25 02:12:30.997335 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-02-25 02:12:30.997476 (MainThread): 02:12:30 | Building catalog
2021-02-25 02:12:31.016173 (MainThread): Opening a new connection, currently in state init
2021-02-25 02:12:31.206483 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-02-25 02:12:31.220944 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-02-25 02:12:31.225311 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: 
    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_jrosen`.__TABLES__
        where (upper(dataset_id) = upper('dbt_jrosen'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-02-25 02:12:31.872754 (Thread-15): handling poll request
2021-02-25 02:12:31.873181 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880159910>]}
2021-02-25 02:12:31.881751 (Thread-15): sending response (<Response 48008 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:12:33.300923 (Thread-16): handling poll request
2021-02-25 02:12:33.301343 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ae8c790>]}
2021-02-25 02:12:33.302200 (Thread-16): sending response (<Response 294 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:12:34.588858 (Thread-17): handling poll request
2021-02-25 02:12:34.589291 (Thread-17): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ae8c9d0>]}
2021-02-25 02:12:34.590171 (Thread-17): sending response (<Response 294 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:12:34.829034 (MainThread): 02:12:34 | Catalog written to /usr/src/develop/user-7994/environment-9499/repository-16870/target/catalog.json
2021-02-25 02:12:36.000678 (Thread-18): handling poll request
2021-02-25 02:12:36.001100 (Thread-18): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ae8cc10>]}
2021-02-25 02:12:36.006817 (Thread-18): sending response (<Response 12079 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:12:36.382561 (Thread-19): handling status request
2021-02-25 02:12:36.382972 (Thread-19): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aea6e20>]}
2021-02-25 02:12:36.389435 (Thread-19): sending response (<Response 21911 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:33:42.166841 (Thread-20): handling status request
2021-02-25 02:33:42.168838 (Thread-20): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aea1580>]}
2021-02-25 02:33:42.175376 (Thread-20): sending response (<Response 21911 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:33:42.214017 (Thread-21): handling status request
2021-02-25 02:33:42.214428 (Thread-21): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aeac640>]}
2021-02-25 02:33:42.220804 (Thread-21): sending response (<Response 21911 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:33:42.454169 (Thread-22): handling docs.generate request
2021-02-25 02:33:42.454601 (Thread-22): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aeac850>]}
2021-02-25 02:33:43.289972 (Thread-22): sending response (<Response 136 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:33:43.365048 (MainThread): Found 8 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:33:43.366365 (MainThread): 
2021-02-25 02:33:43.366674 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:33:43.383852 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:33:43.383975 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:33:43.574534 (Thread-23): handling poll request
2021-02-25 02:33:43.575043 (Thread-23): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aea1130>]}
2021-02-25 02:33:43.576854 (Thread-23): sending response (<Response 1782 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:33:43.582988 (MainThread): 02:33:43 | Concurrency: 1 threads (target='default')
2021-02-25 02:33:43.583120 (MainThread): 02:33:43 | 
2021-02-25 02:33:43.585157 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:33:43.585317 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:33:43.585397 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:33:43.605720 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:33:43.625743 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.626033 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.626248 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:33:43.626342 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:33:43.626446 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:33:43.626510 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:33:43.634883 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:33:43.649050 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.649318 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.649527 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:33:43.649625 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:33:43.649713 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:33:43.649774 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:33:43.660287 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:33:43.675803 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.676068 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.676269 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:33:43.676365 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:33:43.676450 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:33:43.676511 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:33:43.686103 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:33:43.708204 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.708503 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.708744 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:33:43.708841 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:33:43.708928 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:33:43.708990 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:33:43.716499 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:33:43.735181 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.735496 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.735709 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:33:43.735806 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:33:43.735896 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:33:43.735960 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:33:43.744091 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:33:43.760388 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.760710 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.760957 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:33:43.761063 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:33:43.761154 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:33:43.761218 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:33:43.770082 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:33:43.786204 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.786489 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.786698 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:33:43.786795 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 02:33:43.786883 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:33:43.786944 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 02:33:43.794166 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 02:33:43.812031 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.812337 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.812561 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 02:33:43.812655 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:33:43.812748 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 02:33:43.812811 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:33:43.836557 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 02:33:43.853653 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.854000 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.854218 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:33:43.854316 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:33:43.854410 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 02:33:43.854476 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:33:43.866501 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 02:33:43.882090 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.882430 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.882649 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:33:43.882747 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:33:43.882839 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 02:33:43.882902 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:33:43.890703 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 02:33:43.906055 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.906348 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.906554 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:33:43.906647 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:33:43.906734 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 02:33:43.906795 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:33:43.914339 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 02:33:43.929781 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.930092 (Thread-1): finished collecting timing info
2021-02-25 02:33:43.930302 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:33:43.931350 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:33:43.931447 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 02:33:44.061429 (MainThread): 02:33:44 | Done.
2021-02-25 02:33:44.147100 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-02-25 02:33:44.147240 (MainThread): 02:33:44 | Building catalog
2021-02-25 02:33:44.167072 (MainThread): Opening a new connection, currently in state init
2021-02-25 02:33:44.350821 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-02-25 02:33:44.365132 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-02-25 02:33:44.369536 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: 
    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_jrosen`.__TABLES__
        where (upper(dataset_id) = upper('dbt_jrosen'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-02-25 02:33:44.854553 (Thread-24): handling poll request
2021-02-25 02:33:44.854974 (Thread-24): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aebaa90>]}
2021-02-25 02:33:44.863232 (Thread-24): sending response (<Response 48008 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:33:46.222753 (Thread-25): handling poll request
2021-02-25 02:33:46.223195 (Thread-25): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aecbd60>]}
2021-02-25 02:33:46.224096 (Thread-25): sending response (<Response 294 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:33:47.522304 (Thread-26): handling poll request
2021-02-25 02:33:47.522723 (Thread-26): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aecb340>]}
2021-02-25 02:33:47.523647 (Thread-26): sending response (<Response 294 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:33:48.907240 (Thread-27): handling poll request
2021-02-25 02:33:48.907676 (Thread-27): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af3ddc0>]}
2021-02-25 02:33:48.908545 (Thread-27): sending response (<Response 294 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:33:48.965021 (MainThread): 02:33:48 | Catalog written to /usr/src/develop/user-7994/environment-9499/repository-16870/target/catalog.json
2021-02-25 02:33:50.337268 (Thread-28): handling poll request
2021-02-25 02:33:50.337720 (Thread-28): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af3d700>]}
2021-02-25 02:33:50.369995 (Thread-28): sending response (<Response 12078 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:33:50.774204 (Thread-29): handling status request
2021-02-25 02:33:50.774634 (Thread-29): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aff42b0>]}
2021-02-25 02:33:50.781199 (Thread-29): sending response (<Response 21911 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:34:05.523690 (Thread-30): handling status request
2021-02-25 02:34:05.524719 (Thread-31): handling status request
2021-02-25 02:34:05.524907 (Thread-30): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af20370>]}
2021-02-25 02:34:05.525275 (Thread-31): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af20790>]}
2021-02-25 02:34:05.541437 (Thread-31): sending response (<Response 21911 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:34:05.544435 (Thread-30): sending response (<Response 21911 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:34:05.798012 (Thread-32): handling deps request
2021-02-25 02:34:05.798439 (Thread-32): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aff40d0>]}
2021-02-25 02:34:05.845422 (Thread-32): sending response (<Response 136 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:34:06.317530 (Thread-33): handling poll request
2021-02-25 02:34:06.317994 (Thread-33): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ae7b220>]}
2021-02-25 02:34:06.319442 (Thread-33): sending response (<Response 285 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:34:07.021613 (MainThread): Set downloads directory='/tmp/dbt-downloads-s0fynz73'
2021-02-25 02:34:07.022542 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:34:07.237475 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.237721 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:34:07.238068 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:34:07.238140 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:34:07.242782 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:34:07.242990 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.243086 (MainThread):   Checking out branch master.
2021-02-25 02:34:07.243131 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:34:07.247664 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.247864 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.247921 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:34:07.434282 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.434505 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:34:07.434573 (MainThread): Executing "git tag --list"
2021-02-25 02:34:07.439096 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.439305 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.439380 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:34:07.444311 (MainThread): STDOUT: "b'HEAD is now at ad743c6 wip\n'"
2021-02-25 02:34:07.444511 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.444585 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:34:07.448190 (MainThread): STDOUT: "b'ad743c6dbb373a9d7087a95fcb08b1c6f72ec6d1\n'"
2021-02-25 02:34:07.448390 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.448460 (MainThread):   Checked out at ad743c6.
2021-02-25 02:34:07.473505 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:34:07.477072 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.477276 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:34:07.477321 (MainThread): command return code=128
2021-02-25 02:34:07.477684 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:34:07.477750 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:34:07.481139 (MainThread): STDOUT: "b'ad743c6dbb373a9d7087a95fcb08b1c6f72ec6d1\n'"
2021-02-25 02:34:07.481336 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.481410 (MainThread):   Checking out branch master.
2021-02-25 02:34:07.481454 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:34:07.485588 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.485787 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.485846 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:34:07.564144 (Thread-34): handling poll request
2021-02-25 02:34:07.564575 (Thread-34): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8896329700>]}
2021-02-25 02:34:07.568269 (Thread-34): sending response (<Response 10842 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:34:07.689990 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.690255 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:34:07.690332 (MainThread): Executing "git tag --list"
2021-02-25 02:34:07.695102 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.695289 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.695363 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:34:07.700181 (MainThread): STDOUT: "b'HEAD is now at ad743c6 wip\n'"
2021-02-25 02:34:07.700398 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.700474 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:34:07.704027 (MainThread): STDOUT: "b'ad743c6dbb373a9d7087a95fcb08b1c6f72ec6d1\n'"
2021-02-25 02:34:07.704233 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.704301 (MainThread):   Already at ad743c6, nothing to do.
2021-02-25 02:34:07.755098 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:34:07.757843 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:34:07.762260 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.762467 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:34:07.762516 (MainThread): command return code=128
2021-02-25 02:34:07.762643 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:34:07.762705 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:34:07.766437 (MainThread): STDOUT: "b'ad743c6dbb373a9d7087a95fcb08b1c6f72ec6d1\n'"
2021-02-25 02:34:07.766636 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.766713 (MainThread):   Checking out branch master.
2021-02-25 02:34:07.766755 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:34:07.770903 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.771117 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.771179 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:34:07.965675 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.965938 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:34:07.966009 (MainThread): Executing "git tag --list"
2021-02-25 02:34:07.970617 (MainThread): STDOUT: "b''"
2021-02-25 02:34:07.970819 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.970904 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:34:07.975794 (MainThread): STDOUT: "b'HEAD is now at ad743c6 wip\n'"
2021-02-25 02:34:07.975998 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.976079 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:34:07.979504 (MainThread): STDOUT: "b'ad743c6dbb373a9d7087a95fcb08b1c6f72ec6d1\n'"
2021-02-25 02:34:07.979698 (MainThread): STDERR: "b''"
2021-02-25 02:34:07.979770 (MainThread):   Already at ad743c6, nothing to do.
2021-02-25 02:34:09.139764 (Thread-35): handling poll request
2021-02-25 02:34:09.140181 (Thread-35): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ae08b20>]}
2021-02-25 02:34:09.143892 (Thread-35): sending response (<Response 10724 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:34:09.198188 (MainThread):   Installed from revision master

2021-02-25 02:34:09.198603 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'a2d134d0-9517-4d08-a9d2-ca6a7c8651fa', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50e5341f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50e6c86f40>]}
2021-02-25 02:34:09.547761 (c778cf21-3ada-4e21-9d01-69b0294176d4-handler-deps): Got an acceptable cached parse result
2021-02-25 02:34:09.708954 (c778cf21-3ada-4e21-9d01-69b0294176d4-handler-deps): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:34:10.607707 (Thread-36): handling poll request
2021-02-25 02:34:10.608161 (Thread-36): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880172ca0>]}
2021-02-25 02:34:10.609122 (Thread-36): sending response (<Response 233 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:34:10.992174 (Thread-37): handling status request
2021-02-25 02:34:10.992602 (Thread-37): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aff2a90>]}
2021-02-25 02:34:10.999922 (Thread-37): sending response (<Response 22052 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:35:56.924213 (Thread-38): handling status request
2021-02-25 02:35:56.926094 (Thread-38): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88806598e0>]}
2021-02-25 02:35:56.932946 (Thread-38): sending response (<Response 22052 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:35:56.940568 (Thread-39): handling status request
2021-02-25 02:35:56.940886 (Thread-39): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88808b9be0>]}
2021-02-25 02:35:56.947386 (Thread-39): sending response (<Response 22052 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:35:57.260508 (Thread-40): handling deps request
2021-02-25 02:35:57.260922 (Thread-40): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88808b94c0>]}
2021-02-25 02:35:57.305205 (Thread-40): Connection 'model.seth_test.viz2' was properly closed.
2021-02-25 02:35:57.312318 (Thread-40): sending response (<Response 136 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:35:57.582666 (Thread-41): handling poll request
2021-02-25 02:35:57.583182 (Thread-41): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801652b0>]}
2021-02-25 02:35:57.584580 (Thread-41): sending response (<Response 285 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:35:58.559727 (MainThread): Set downloads directory='/tmp/dbt-downloads-_wncsz16'
2021-02-25 02:35:58.560619 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:35:58.764687 (MainThread): STDOUT: "b''"
2021-02-25 02:35:58.764932 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:35:58.765263 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:35:58.765332 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:35:58.770022 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:35:58.770211 (MainThread): STDERR: "b''"
2021-02-25 02:35:58.770291 (MainThread):   Checking out branch master.
2021-02-25 02:35:58.770335 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:35:58.774726 (MainThread): STDOUT: "b''"
2021-02-25 02:35:58.774919 (MainThread): STDERR: "b''"
2021-02-25 02:35:58.775023 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:35:58.833233 (Thread-42): handling poll request
2021-02-25 02:35:58.833689 (Thread-42): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8896329b50>]}
2021-02-25 02:35:58.835750 (Thread-42): sending response (<Response 3904 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:35:58.965010 (MainThread): STDOUT: "b''"
2021-02-25 02:35:58.965225 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:35:58.965291 (MainThread): Executing "git tag --list"
2021-02-25 02:35:58.969817 (MainThread): STDOUT: "b''"
2021-02-25 02:35:58.970035 (MainThread): STDERR: "b''"
2021-02-25 02:35:58.970108 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:35:58.975147 (MainThread): STDOUT: "b'HEAD is now at ffaffde wip\n'"
2021-02-25 02:35:58.975350 (MainThread): STDERR: "b''"
2021-02-25 02:35:58.975434 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:35:58.978701 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:35:58.978913 (MainThread): STDERR: "b''"
2021-02-25 02:35:58.978977 (MainThread):   Checked out at ffaffde.
2021-02-25 02:35:59.003844 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:35:59.007134 (MainThread): STDOUT: "b''"
2021-02-25 02:35:59.007334 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:35:59.007380 (MainThread): command return code=128
2021-02-25 02:35:59.007737 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:35:59.007801 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:35:59.011157 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:35:59.011355 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.011428 (MainThread):   Checking out branch master.
2021-02-25 02:35:59.011472 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:35:59.015597 (MainThread): STDOUT: "b''"
2021-02-25 02:35:59.015794 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.015854 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:35:59.200373 (MainThread): STDOUT: "b''"
2021-02-25 02:35:59.200638 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:35:59.200710 (MainThread): Executing "git tag --list"
2021-02-25 02:35:59.205382 (MainThread): STDOUT: "b''"
2021-02-25 02:35:59.205604 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.205681 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:35:59.210808 (MainThread): STDOUT: "b'HEAD is now at ffaffde wip\n'"
2021-02-25 02:35:59.211043 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.211120 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:35:59.214507 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:35:59.214704 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.214766 (MainThread):   Already at ffaffde, nothing to do.
2021-02-25 02:35:59.260712 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:35:59.263543 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:35:59.267981 (MainThread): STDOUT: "b''"
2021-02-25 02:35:59.268196 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:35:59.268248 (MainThread): command return code=128
2021-02-25 02:35:59.268366 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:35:59.268430 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:35:59.272465 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:35:59.272672 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.272749 (MainThread):   Checking out branch master.
2021-02-25 02:35:59.272792 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:35:59.277119 (MainThread): STDOUT: "b''"
2021-02-25 02:35:59.277282 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.277337 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:35:59.466569 (MainThread): STDOUT: "b''"
2021-02-25 02:35:59.466793 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:35:59.466917 (MainThread): Executing "git tag --list"
2021-02-25 02:35:59.471862 (MainThread): STDOUT: "b''"
2021-02-25 02:35:59.472119 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.472205 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:35:59.477621 (MainThread): STDOUT: "b'HEAD is now at ffaffde wip\n'"
2021-02-25 02:35:59.477855 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.477934 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:35:59.481709 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:35:59.481924 (MainThread): STDERR: "b''"
2021-02-25 02:35:59.481996 (MainThread):   Already at ffaffde, nothing to do.
2021-02-25 02:36:00.084999 (Thread-43): handling poll request
2021-02-25 02:36:00.085411 (Thread-43): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aff4760>]}
2021-02-25 02:36:00.091562 (Thread-43): sending response (<Response 17660 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:36:00.741783 (MainThread):   Installed from revision master

2021-02-25 02:36:00.742117 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'c61ce98f-3ea1-4be7-bdf7-e8960fb886a7', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e0e13a0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6e0e4aedf0>]}
2021-02-25 02:36:00.953310 (c5c73a30-f78b-4298-99f2-a0b2ffd5f00f-handler-deps): Got an acceptable cached parse result
2021-02-25 02:36:01.125480 (c5c73a30-f78b-4298-99f2-a0b2ffd5f00f-handler-deps): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:36:01.239022 (c5c73a30-f78b-4298-99f2-a0b2ffd5f00f-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887adffa30>]}
2021-02-25 02:36:01.343963 (Thread-44): handling poll request
2021-02-25 02:36:01.344391 (Thread-44): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801bf880>]}
2021-02-25 02:36:01.345530 (Thread-44): sending response (<Response 1167 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:36:01.633463 (Thread-45): handling status request
2021-02-25 02:36:01.633920 (Thread-45): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801bf070>]}
2021-02-25 02:36:01.640838 (Thread-45): sending response (<Response 21989 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:36:11.612481 (Thread-46): handling status request
2021-02-25 02:36:11.612908 (Thread-46): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801bf940>]}
2021-02-25 02:36:11.621068 (Thread-46): sending response (<Response 21989 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:36:11.623388 (Thread-47): handling status request
2021-02-25 02:36:11.623692 (Thread-47): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801bf730>]}
2021-02-25 02:36:11.629938 (Thread-47): sending response (<Response 21989 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:36:11.910608 (Thread-48): handling docs.generate request
2021-02-25 02:36:11.911139 (Thread-48): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887adffa30>]}
2021-02-25 02:36:11.912349 (Thread-48): Connection 'model.seth_test.viz2' was properly closed.
2021-02-25 02:36:12.766750 (Thread-48): sending response (<Response 136 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:36:12.833955 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:36:12.835545 (MainThread): 
2021-02-25 02:36:12.835919 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:36:12.855200 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:36:12.855302 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:36:13.018278 (Thread-49): handling poll request
2021-02-25 02:36:13.018745 (Thread-49): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801bffd0>]}
2021-02-25 02:36:13.020567 (Thread-49): sending response (<Response 1782 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:36:13.062850 (MainThread): 02:36:13 | Concurrency: 1 threads (target='default')
2021-02-25 02:36:13.062974 (MainThread): 02:36:13 | 
2021-02-25 02:36:13.065017 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:36:13.065200 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:36:13.065310 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:36:13.088001 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:36:13.104879 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.105252 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.105597 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:36:13.105754 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:36:13.105900 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:36:13.106002 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:36:13.118880 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:36:13.135864 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.136081 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.136273 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:36:13.136367 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:36:13.136452 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:36:13.136511 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:36:13.146584 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:36:13.162821 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.163062 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.163259 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:36:13.163350 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:36:13.163434 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:36:13.163491 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:36:13.172726 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:36:13.187084 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.187301 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.187492 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:36:13.187581 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:36:13.187662 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:36:13.187718 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:36:13.194506 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:36:13.209732 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.209959 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.210155 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:36:13.210242 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 02:36:13.210324 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:36:13.210381 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 02:36:13.217610 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 02:36:13.232309 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.232530 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.232720 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 02:36:13.232807 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:36:13.232888 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:36:13.232945 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:36:13.240245 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:36:13.256271 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.256551 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.256754 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:36:13.256848 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:36:13.256934 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:36:13.256993 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:36:13.265047 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:36:13.281286 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.281534 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.281733 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:36:13.281827 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:36:13.281914 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 02:36:13.281971 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:36:13.305919 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 02:36:13.322199 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.322445 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.322638 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:36:13.322727 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:36:13.322807 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 02:36:13.322864 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:36:13.333808 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 02:36:13.350964 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.351240 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.351443 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:36:13.351536 (Thread-1): Began running node model.seth_test.viz2
2021-02-25 02:36:13.351622 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:36:13.351680 (Thread-1): Compiling model.seth_test.viz2
2021-02-25 02:36:13.359335 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.359580 (Thread-1): Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 13, in top-level template code
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 460, in call
    if not __self.is_safe_callable(__obj):
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 360, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
jinja2.exceptions.UndefinedError: 'filter' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
2021-02-25 02:36:13.360802 (Thread-1): Finished running node model.seth_test.viz2
2021-02-25 02:36:13.360911 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:36:13.360996 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 02:36:13.361057 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:36:13.374998 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 02:36:13.391397 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.391675 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.391879 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:36:13.391974 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:36:13.392060 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 02:36:13.392120 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:36:13.399862 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 02:36:13.415419 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.415787 (Thread-1): finished collecting timing info
2021-02-25 02:36:13.416009 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:36:13.416541 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:36:13.416632 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 02:36:13.416684 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/task_handler.py", line 94, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/project_commands.py", line 57, in handle_request
    return self.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/generate.py", line 213, in run
    compile_results = CompileTask.run(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 384, in execute_with_hooks
    res = self.execute_nodes()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 339, in execute_nodes
    self.run_queue(pool)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 267, in run_queue
    self._raise_set_error()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 222, in _raise_set_error
    raise self._raise_next_tick
dbt.exceptions.RuntimeException: Runtime Error
  Compilation Error in model viz2 (models/viz2.sql)
    'filter' is undefined
2021-02-25 02:36:14.537485 (Thread-50): handling poll request
2021-02-25 02:36:14.537934 (Thread-50): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801cae20>]}
2021-02-25 02:36:14.539582 (Thread-50): sending response (<Response 45461 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:36:14.830269 (Thread-51): handling status request
2021-02-25 02:36:14.830742 (Thread-51): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880178910>]}
2021-02-25 02:36:14.837936 (Thread-51): sending response (<Response 21989 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:36:59.242073 (Thread-52): handling status request
2021-02-25 02:36:59.242496 (Thread-52): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880178c10>]}
2021-02-25 02:36:59.248869 (Thread-52): sending response (<Response 21989 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:36:59.255721 (Thread-53): handling status request
2021-02-25 02:36:59.256031 (Thread-53): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880178580>]}
2021-02-25 02:36:59.262559 (Thread-53): sending response (<Response 21989 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:36:59.556534 (Thread-54): handling deps request
2021-02-25 02:36:59.557106 (Thread-54): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880178b20>]}
2021-02-25 02:36:59.619711 (Thread-54): sending response (<Response 136 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:37:00.002234 (Thread-55): handling poll request
2021-02-25 02:37:00.002753 (Thread-55): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880581f70>]}
2021-02-25 02:37:00.004245 (Thread-55): sending response (<Response 285 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:37:00.870924 (MainThread): Set downloads directory='/tmp/dbt-downloads-3z_y64zn'
2021-02-25 02:37:00.871886 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:37:01.176121 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.176449 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:37:01.176931 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:37:01.177045 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:37:01.181820 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:37:01.182036 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.182109 (MainThread):   Checking out branch master.
2021-02-25 02:37:01.182154 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:37:01.187217 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.187380 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.187437 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:37:01.318266 (Thread-56): handling poll request
2021-02-25 02:37:01.318680 (Thread-56): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880165130>]}
2021-02-25 02:37:01.320553 (Thread-56): sending response (<Response 3906 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:37:01.446055 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.446319 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:37:01.446386 (MainThread): Executing "git tag --list"
2021-02-25 02:37:01.451184 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.451390 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.451467 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:37:01.456745 (MainThread): STDOUT: "b'HEAD is now at ffaffde wip\n'"
2021-02-25 02:37:01.456968 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.457043 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:37:01.460693 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:37:01.460959 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.461052 (MainThread):   Checked out at ffaffde.
2021-02-25 02:37:01.487837 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:37:01.491825 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.492034 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:37:01.492082 (MainThread): command return code=128
2021-02-25 02:37:01.492458 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:37:01.492524 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:37:01.496081 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:37:01.496284 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.496361 (MainThread):   Checking out branch master.
2021-02-25 02:37:01.496419 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:37:01.500703 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.500877 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.500937 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:37:01.771726 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.771955 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:37:01.772049 (MainThread): Executing "git tag --list"
2021-02-25 02:37:01.778130 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.778366 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.778447 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:37:01.783557 (MainThread): STDOUT: "b'HEAD is now at ffaffde wip\n'"
2021-02-25 02:37:01.783841 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.783960 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:37:01.787842 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:37:01.788124 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.788231 (MainThread):   Already at ffaffde, nothing to do.
2021-02-25 02:37:01.835874 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:37:01.838669 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:37:01.844510 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.844721 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:37:01.844770 (MainThread): command return code=128
2021-02-25 02:37:01.844889 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:37:01.844951 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:37:01.849898 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:37:01.850103 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.850182 (MainThread):   Checking out branch master.
2021-02-25 02:37:01.850229 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:37:01.855950 (MainThread): STDOUT: "b''"
2021-02-25 02:37:01.856155 (MainThread): STDERR: "b''"
2021-02-25 02:37:01.856218 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:37:02.154331 (MainThread): STDOUT: "b''"
2021-02-25 02:37:02.154596 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:37:02.154667 (MainThread): Executing "git tag --list"
2021-02-25 02:37:02.160846 (MainThread): STDOUT: "b''"
2021-02-25 02:37:02.161088 (MainThread): STDERR: "b''"
2021-02-25 02:37:02.161171 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:37:02.166635 (MainThread): STDOUT: "b'HEAD is now at ffaffde wip\n'"
2021-02-25 02:37:02.166856 (MainThread): STDERR: "b''"
2021-02-25 02:37:02.166935 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:37:02.171505 (MainThread): STDOUT: "b'ffaffde2a3cdf45406eff461dc0d811df775f324\n'"
2021-02-25 02:37:02.171730 (MainThread): STDERR: "b''"
2021-02-25 02:37:02.171806 (MainThread):   Already at ffaffde, nothing to do.
2021-02-25 02:37:02.622341 (Thread-57): handling poll request
2021-02-25 02:37:02.622784 (Thread-57): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888057ecd0>]}
2021-02-25 02:37:02.649915 (Thread-57): sending response (<Response 17660 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:37:03.462040 (MainThread):   Installed from revision master

2021-02-25 02:37:03.462368 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ba2acbe5-2976-4c00-a59a-1506313597ee', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dd59fba00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dd7621dc0>]}
2021-02-25 02:37:03.684716 (5e3faa4a-91f7-4ffc-9cf7-861731b5967f-handler-deps): Got an acceptable cached parse result
2021-02-25 02:37:03.965476 (Thread-58): handling poll request
2021-02-25 02:37:03.972116 (Thread-58): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aeff700>]}
2021-02-25 02:37:03.973196 (Thread-58): sending response (<Response 1095 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:37:04.081380 (5e3faa4a-91f7-4ffc-9cf7-861731b5967f-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88808fa5b0>]}
2021-02-25 02:37:05.274030 (Thread-59): handling poll request
2021-02-25 02:37:05.274440 (Thread-59): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ad83bb0>]}
2021-02-25 02:37:05.275373 (Thread-59): sending response (<Response 357 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:37:05.704232 (Thread-60): handling status request
2021-02-25 02:37:05.704675 (Thread-60): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880615460>]}
2021-02-25 02:37:05.711320 (Thread-60): sending response (<Response 21989 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:37:35.047723 (Thread-61): handling status request
2021-02-25 02:37:35.048156 (Thread-61): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880613160>]}
2021-02-25 02:37:35.055396 (Thread-61): sending response (<Response 21989 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:37:35.062591 (Thread-62): handling status request
2021-02-25 02:37:35.062886 (Thread-62): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88806130d0>]}
2021-02-25 02:37:35.069669 (Thread-62): sending response (<Response 21989 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:37:35.326624 (Thread-63): handling docs.generate request
2021-02-25 02:37:35.327060 (Thread-63): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880319730>]}
2021-02-25 02:37:36.164907 (Thread-63): sending response (<Response 136 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:37:36.228100 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:37:36.229385 (MainThread): 
2021-02-25 02:37:36.229662 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:37:36.248204 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:37:36.248315 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:37:36.450184 (MainThread): 02:37:36 | Concurrency: 1 threads (target='default')
2021-02-25 02:37:36.450311 (MainThread): 02:37:36 | 
2021-02-25 02:37:36.452347 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:37:36.452534 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:37:36.452625 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:37:36.473474 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:37:36.491027 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.491358 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.491690 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:37:36.491841 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:37:36.491946 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:37:36.492011 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:37:36.500148 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:37:36.516178 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.516413 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.516604 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:37:36.516694 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:37:36.516777 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:37:36.516835 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:37:36.527598 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:37:36.543792 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.544012 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.544196 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:37:36.544286 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:37:36.544369 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:37:36.544425 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:37:36.554267 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:37:36.569311 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.569527 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.569710 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:37:36.569797 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:37:36.569876 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:37:36.569932 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:37:36.576670 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:37:36.592140 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.592357 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.592540 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:37:36.592629 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 02:37:36.592710 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:37:36.592768 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 02:37:36.599358 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 02:37:36.614337 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.614578 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.614767 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 02:37:36.614859 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:37:36.614942 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:37:36.615017 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:37:36.622794 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:37:36.639331 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.639564 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.639751 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:37:36.639840 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:37:36.639923 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:37:36.639982 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:37:36.647727 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:37:36.650292 (Thread-64): handling poll request
2021-02-25 02:37:36.650846 (Thread-64): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88808e9070>]}
2021-02-25 02:37:36.658343 (Thread-64): sending response (<Response 25208 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:37:36.664046 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.664264 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.664446 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:37:36.664536 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:37:36.664633 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 02:37:36.664691 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:37:36.688961 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 02:37:36.705851 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.706074 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.706260 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:37:36.706351 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:37:36.706432 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 02:37:36.706489 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:37:36.717984 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 02:37:36.733051 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.733290 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.733480 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:37:36.733573 (Thread-1): Began running node model.seth_test.viz2
2021-02-25 02:37:36.733659 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:37:36.733716 (Thread-1): Compiling model.seth_test.viz2
2021-02-25 02:37:36.741628 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.741867 (Thread-1): Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 13, in top-level template code
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 460, in call
    if not __self.is_safe_callable(__obj):
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 360, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
jinja2.exceptions.UndefinedError: 'filter' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
2021-02-25 02:37:36.743089 (Thread-1): Finished running node model.seth_test.viz2
2021-02-25 02:37:36.743192 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:37:36.743280 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 02:37:36.743339 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:37:36.751195 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 02:37:36.769368 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.769698 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.770005 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:37:36.770118 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:37:36.770208 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 02:37:36.770267 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:37:36.778696 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 02:37:36.796114 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.796366 (Thread-1): finished collecting timing info
2021-02-25 02:37:36.796565 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:37:36.797185 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:37:36.797290 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 02:37:36.797345 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/task_handler.py", line 94, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/project_commands.py", line 57, in handle_request
    return self.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/generate.py", line 213, in run
    compile_results = CompileTask.run(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 384, in execute_with_hooks
    res = self.execute_nodes()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 339, in execute_nodes
    self.run_queue(pool)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 267, in run_queue
    self._raise_set_error()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 222, in _raise_set_error
    raise self._raise_next_tick
dbt.exceptions.RuntimeException: Runtime Error
  Compilation Error in model viz2 (models/viz2.sql)
    'filter' is undefined
2021-02-25 02:37:37.930153 (Thread-65): handling poll request
2021-02-25 02:37:37.930571 (Thread-65): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804b7d00>]}
2021-02-25 02:37:37.932175 (Thread-65): sending response (<Response 45461 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:37:38.251145 (Thread-66): handling status request
2021-02-25 02:37:38.251556 (Thread-66): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88805138b0>]}
2021-02-25 02:37:38.258183 (Thread-66): sending response (<Response 21989 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:38:15.633998 (Thread-67): handling status request
2021-02-25 02:38:15.634646 (Thread-67): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880513d00>]}
2021-02-25 02:38:15.645033 (Thread-67): sending response (<Response 21989 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:38:15.674357 (Thread-68): handling status request
2021-02-25 02:38:15.674671 (Thread-68): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880513c70>]}
2021-02-25 02:38:15.681002 (Thread-68): sending response (<Response 21989 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:38:15.972221 (Thread-69): handling cli_args request
2021-02-25 02:38:15.972640 (Thread-69): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880513e80>]}
2021-02-25 02:38:16.826722 (Thread-69): sending response (<Response 136 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:38:16.924362 (MainThread): Partial parsing not enabled
2021-02-25 02:38:16.926601 (MainThread): Parsing macros/adapters.sql
2021-02-25 02:38:16.946067 (MainThread): Parsing macros/etc.sql
2021-02-25 02:38:16.948213 (MainThread): Parsing macros/catalog.sql
2021-02-25 02:38:16.954226 (MainThread): Parsing macros/materializations/copy.sql
2021-02-25 02:38:16.958818 (MainThread): Parsing macros/materializations/table.sql
2021-02-25 02:38:16.968545 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-25 02:38:16.981410 (MainThread): Parsing macros/materializations/seed.sql
2021-02-25 02:38:16.984134 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-25 02:38:16.985954 (MainThread): Parsing macros/materializations/view.sql
2021-02-25 02:38:16.989439 (MainThread): Parsing macros/core.sql
2021-02-25 02:38:16.993328 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-25 02:38:17.002313 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-25 02:38:17.016135 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-25 02:38:17.017911 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-25 02:38:17.037173 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-25 02:38:17.071773 (Thread-70): handling poll request
2021-02-25 02:38:17.072199 (Thread-70): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888053a190>]}
2021-02-25 02:38:17.074837 (Thread-70): sending response (<Response 4645 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:38:17.080366 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-25 02:38:17.087894 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-25 02:38:17.097427 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-25 02:38:17.122427 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-25 02:38:17.129123 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-25 02:38:17.131048 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-25 02:38:17.136959 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-25 02:38:17.138602 (MainThread): Parsing macros/etc/query.sql
2021-02-25 02:38:17.139706 (MainThread): Parsing macros/etc/datetime.sql
2021-02-25 02:38:17.148402 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-25 02:38:17.149396 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-25 02:38:17.151089 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-25 02:38:17.153066 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-25 02:38:17.154601 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-25 02:38:17.157265 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-25 02:38:17.159187 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-25 02:38:17.160970 (MainThread): Parsing macros/adapters/common.sql
2021-02-25 02:38:17.221133 (MainThread): Partial parsing not enabled
2021-02-25 02:38:17.267917 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:38:17.290768 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:38:17.306422 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:38:17.318950 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:38:17.331341 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:38:17.345536 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:38:17.360148 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:38:17.557112 (MainThread): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:38:17.570260 (MainThread): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:38:17.675028 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc6010460>]}
2021-02-25 02:38:17.711664 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:38:17.712706 (MainThread): 
2021-02-25 02:38:17.712989 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:38:17.723352 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-02-25 02:38:17.723472 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:38:17.920353 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:38:17.920487 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-25 02:38:18.143261 (MainThread): 02:38:18 | Concurrency: 1 threads (target='default')
2021-02-25 02:38:18.143392 (MainThread): 02:38:18 | 
2021-02-25 02:38:18.145383 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:38:18.146616 (Thread-1): 02:38:18 | 1 of 9 START view model dbt_jrosen.new_model......................... [RUN]
2021-02-25 02:38:18.146940 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:38:18.147077 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:38:18.163590 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:38:18.177496 (Thread-1): finished collecting timing info
2021-02-25 02:38:18.209976 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:38:18.260219 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:38:18.264623 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-02-25 02:38:18.375062 (Thread-71): handling poll request
2021-02-25 02:38:18.375492 (Thread-71): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804c73d0>]}
2021-02-25 02:38:18.379889 (Thread-71): sending response (<Response 14783 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:38:18.949565 (Thread-1): finished collecting timing info
2021-02-25 02:38:18.950155 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc5f97ac0>]}
2021-02-25 02:38:18.951170 (Thread-1): 02:38:18 | 1 of 9 OK created view model dbt_jrosen.new_model.................... [OK in 0.80s]
2021-02-25 02:38:18.951262 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:38:18.951366 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:38:18.952145 (Thread-1): 02:38:18 | 2 of 9 START table model dbt_jrosen.sightings_by_day_by_state........ [RUN]
2021-02-25 02:38:18.952346 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:38:18.952418 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:38:18.958261 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:38:18.975880 (Thread-1): finished collecting timing info
2021-02-25 02:38:18.991601 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:38:19.177941 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:38:19.199228 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-02-25 02:38:19.640676 (Thread-72): handling poll request
2021-02-25 02:38:19.641112 (Thread-72): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803c50a0>]}
2021-02-25 02:38:19.643293 (Thread-72): sending response (<Response 6161 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:38:21.042842 (Thread-73): handling poll request
2021-02-25 02:38:21.043284 (Thread-73): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88808a3700>]}
2021-02-25 02:38:21.044137 (Thread-73): sending response (<Response 284 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:38:21.515512 (Thread-1): finished collecting timing info
2021-02-25 02:38:21.516139 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc47b5d60>]}
2021-02-25 02:38:21.517094 (Thread-1): 02:38:21 | 2 of 9 OK created table model dbt_jrosen.sightings_by_day_by_state... [CREATE TABLE (3.7k rows, 76.6 KB processed) in 2.56s]
2021-02-25 02:38:21.517178 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:38:21.517281 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:38:21.518081 (Thread-1): 02:38:21 | 3 of 9 START view model dbt_jrosen.joke.............................. [RUN]
2021-02-25 02:38:21.518288 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:38:21.518361 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:38:21.528580 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:38:21.544376 (Thread-1): finished collecting timing info
2021-02-25 02:38:21.548311 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.joke"
2021-02-25 02:38:21.560996 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:38:21.565270 (Thread-1): On model.hashpath_demo.joke: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.joke"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`joke`
  OPTIONS()
  as 




 
  On the first day of christmas my true love gave to me 
      
            a partridge in a pear tree

 
  On the second day of christmas my true love gave to me 
      
            Two turtle doves and   
            a partridge in a pear tree

 
  On the third day of christmas my true love gave to me 
      
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fourth day of christmas my true love gave to me 
      
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fifth day of christmas my true love gave to me 
      
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the sixth day of christmas my true love gave to me 
      
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the seventh day of christmas my true love gave to me 
      
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eigth day of christmas my true love gave to me 
      
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the ninth day of christmas my true love gave to me 
      
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the tenth day of christmas my true love gave to me 
      
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eleventh day of christmas my true love gave to me 
      
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the twelth day of christmas my true love gave to me 
      
            twelve drummers drumming  
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree
;


2021-02-25 02:38:21.896189 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/9587153b-4874-4495-b708-a9d7067e8b6f?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]')
2021-02-25 02:38:22.529419 (Thread-74): handling poll request
2021-02-25 02:38:22.529847 (Thread-74): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880489a00>]}
2021-02-25 02:38:22.531937 (Thread-74): sending response (<Response 9937 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:38:23.291655 (Thread-1): finished collecting timing info
2021-02-25 02:38:23.292178 (Thread-1): Database Error in model joke (models/test/joke.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
  compiled SQL at target/run/hashpath_demo/models/test/joke.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/abd81db8-60b3-482f-8aef-cfa4b804be97?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]

(job ID: abd81db8-60b3-482f-8aef-cfa4b804be97)

                                                      -----Query Job SQL Follows-----                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.joke"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`joke`
   5:  OPTIONS()
   6:  as 
   7:
   8:
   9:
  10:
  11: 
  12:  On the first day of christmas my true love gave to me 
  13:      
  14:            a partridge in a pear tree
  15:
  16: 
  17:  On the second day of christmas my true love gave to me 
  18:      
  19:            Two turtle doves and   
  20:            a partridge in a pear tree
  21:
  22: 
  23:  On the third day of christmas my true love gave to me 
  24:      
  25:            Three French hens  
  26:            Two turtle doves and   
  27:            a partridge in a pear tree
  28:
  29: 
  30:  On the fourth day of christmas my true love gave to me 
  31:      
  32:            four calling birds  
  33:            Three French hens  
  34:            Two turtle doves and   
  35:            a partridge in a pear tree
  36:
  37: 
  38:  On the fifth day of christmas my true love gave to me 
  39:      
  40:            five gold rings  
  41:            four calling birds  
  42:            Three French hens  
  43:            Two turtle doves and   
  44:            a partridge in a pear tree
  45:
  46: 
  47:  On the sixth day of christmas my true love gave to me 
  48:      
  49:            six geese a-laying  
  50:            five gold rings  
  51:            four calling birds  
  52:            Three French hens  
  53:            Two turtle doves and   
  54:            a partridge in a pear tree
  55:
  56: 
  57:  On the seventh day of christmas my true love gave to me 
  58:      
  59:            seven swans a-swimming  
  60:            six geese a-laying  
  61:            five gold rings  
  62:            four calling birds  
  63:            Three French hens  
  64:            Two turtle doves and   
  65:            a partridge in a pear tree
  66:
  67: 
  68:  On the eigth day of christmas my true love gave to me 
  69:      
  70:            eight maids a-milking  
  71:            seven swans a-swimming  
  72:            six geese a-laying  
  73:            five gold rings  
  74:            four calling birds  
  75:            Three French hens  
  76:            Two turtle doves and   
  77:            a partridge in a pear tree
  78:
  79: 
  80:  On the ninth day of christmas my true love gave to me 
  81:      
  82:            nine ladies dancing  
  83:            eight maids a-milking  
  84:            seven swans a-swimming  
  85:            six geese a-laying  
  86:            five gold rings  
  87:            four calling birds  
  88:            Three French hens  
  89:            Two turtle doves and   
  90:            a partridge in a pear tree
  91:
  92: 
  93:  On the tenth day of christmas my true love gave to me 
  94:      
  95:            ten lords a-leaping  
  96:            nine ladies dancing  
  97:            eight maids a-milking  
  98:            seven swans a-swimming  
  99:            six geese a-laying  
 100:            five gold rings  
 101:            four calling birds  
 102:            Three French hens  
 103:            Two turtle doves and   
 104:            a partridge in a pear tree
 105:
 106: 
 107:  On the eleventh day of christmas my true love gave to me 
 108:      
 109:            eleven pipers piping  
 110:            ten lords a-leaping  
 111:            nine ladies dancing  
 112:            eight maids a-milking  
 113:            seven swans a-swimming  
 114:            six geese a-laying  
 115:            five gold rings  
 116:            four calling birds  
 117:            Three French hens  
 118:            Two turtle doves and   
 119:            a partridge in a pear tree
 120:
 121: 
 122:  On the twelth day of christmas my true love gave to me 
 123:      
 124:            twelve drummers drumming  
 125:            eleven pipers piping  
 126:            ten lords a-leaping  
 127:            nine ladies dancing  
 128:            eight maids a-milking  
 129:            seven swans a-swimming  
 130:            six geese a-laying  
 131:            five gold rings  
 132:            four calling birds  
 133:            Three French hens  
 134:            Two turtle doves and   
 135:            a partridge in a pear tree
 136:;
 137:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model joke (models/test/joke.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
  compiled SQL at target/run/hashpath_demo/models/test/joke.sql
2021-02-25 02:38:23.295168 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc47664f0>]}
2021-02-25 02:38:23.296221 (Thread-1): 02:38:23 | 3 of 9 ERROR creating view model dbt_jrosen.joke..................... [ERROR in 1.78s]
2021-02-25 02:38:23.296302 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:38:23.296410 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:38:23.297202 (Thread-1): 02:38:23 | 4 of 9 START table model dbt_jrosen.all_sightings.................... [RUN]
2021-02-25 02:38:23.297416 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:38:23.297487 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:38:23.307397 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:38:23.324452 (Thread-1): finished collecting timing info
2021-02-25 02:38:23.328176 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:38:23.510365 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:38:23.522858 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  );
    
2021-02-25 02:38:23.897313 (Thread-75): handling poll request
2021-02-25 02:38:23.897738 (Thread-75): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804b1670>]}
2021-02-25 02:38:23.899813 (Thread-75): sending response (<Response 19432 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:38:25.354644 (Thread-76): handling poll request
2021-02-25 02:38:25.355091 (Thread-76): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803f6d90>]}
2021-02-25 02:38:25.355973 (Thread-76): sending response (<Response 284 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:38:26.413926 (Thread-1): finished collecting timing info
2021-02-25 02:38:26.414529 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4652c10>]}
2021-02-25 02:38:26.415504 (Thread-1): 02:38:26 | 4 of 9 OK created table model dbt_jrosen.all_sightings............... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 3.12s]
2021-02-25 02:38:26.415591 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:38:26.415695 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:38:26.416475 (Thread-1): 02:38:26 | 5 of 9 START table model dbt_jrosen.sightings_by_day................. [RUN]
2021-02-25 02:38:26.416673 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:38:26.416746 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:38:26.423668 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:38:26.440643 (Thread-1): finished collecting timing info
2021-02-25 02:38:26.444262 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:38:26.614764 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:38:26.627072 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-02-25 02:38:26.756769 (Thread-77): handling poll request
2021-02-25 02:38:26.757198 (Thread-77): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803f6880>]}
2021-02-25 02:38:26.759123 (Thread-77): sending response (<Response 6092 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:38:28.171695 (Thread-78): handling poll request
2021-02-25 02:38:28.172181 (Thread-78): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803f6df0>]}
2021-02-25 02:38:28.173144 (Thread-78): sending response (<Response 284 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:38:28.619661 (Thread-1): finished collecting timing info
2021-02-25 02:38:28.620274 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc46526d0>]}
2021-02-25 02:38:28.621381 (Thread-1): 02:38:28 | 5 of 9 OK created table model dbt_jrosen.sightings_by_day............ [CREATE TABLE (2.9k rows, 57.6 KB processed) in 2.20s]
2021-02-25 02:38:28.621467 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:38:28.621575 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 02:38:28.622737 (Thread-1): 02:38:28 | 6 of 9 START view model dbt_jrosen.viz1.............................. [RUN]
2021-02-25 02:38:28.622944 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:38:28.623042 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 02:38:28.629675 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 02:38:28.647959 (Thread-1): finished collecting timing info
2021-02-25 02:38:28.651911 (Thread-1): Writing runtime SQL for node "model.seth_test.viz1"
2021-02-25 02:38:28.676526 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:38:28.680775 (Thread-1): On model.seth_test.viz1: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.seth_test.viz1"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`viz1`
  OPTIONS()
  as 

SELECT
DATE_TRUNC(date,year),
count(*)
FROM `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
WHERE date IS NOT NULL
AND date > '1960-01-01'
GROUP BY 1
ORDER BY 1 ASC;


2021-02-25 02:38:29.102344 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/5fdfb448-fb59-456b-a0f3-d3bf513223fb?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 1 has no name at [8:1]')
2021-02-25 02:38:29.461190 (Thread-79): handling poll request
2021-02-25 02:38:29.461621 (Thread-79): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803f9fd0>]}
2021-02-25 02:38:29.463720 (Thread-79): sending response (<Response 6362 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:38:30.118925 (Thread-1): finished collecting timing info
2021-02-25 02:38:30.119475 (Thread-1): Database Error in model viz1 (models/viz1.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [8:1]
  compiled SQL at target/run/seth_test/models/viz1.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/b6b46822-525c-418b-8d6d-2bf3ded24824?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 1 has no name at [8:1]

(job ID: b6b46822-525c-418b-8d6d-2bf3ded24824)

                                                    -----Query Job SQL Follows-----                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.seth_test.viz1"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`viz1`
   5:  OPTIONS()
   6:  as 
   7:
   8:SELECT
   9:DATE_TRUNC(date,year),
  10:count(*)
  11:FROM `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  12:WHERE date IS NOT NULL
  13:AND date > '1960-01-01'
  14:GROUP BY 1
  15:ORDER BY 1 ASC;
  16:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model viz1 (models/viz1.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [8:1]
  compiled SQL at target/run/seth_test/models/viz1.sql
2021-02-25 02:38:30.120312 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4652370>]}
2021-02-25 02:38:30.121394 (Thread-1): 02:38:30 | 6 of 9 ERROR creating view model dbt_jrosen.viz1..................... [ERROR in 1.50s]
2021-02-25 02:38:30.121477 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 02:38:30.121584 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:38:30.122373 (Thread-1): 02:38:30 | 7 of 9 START view model dbt_jrosen.demo_123.......................... [RUN]
2021-02-25 02:38:30.122595 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:38:30.122670 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:38:30.132000 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:38:30.148582 (Thread-1): finished collecting timing info
2021-02-25 02:38:30.152585 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:38:30.172497 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:38:30.177002 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='Utah';


2021-02-25 02:38:30.733625 (Thread-1): finished collecting timing info
2021-02-25 02:38:30.734246 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc45a3790>]}
2021-02-25 02:38:30.735382 (Thread-1): 02:38:30 | 7 of 9 OK created view model dbt_jrosen.demo_123..................... [OK in 0.61s]
2021-02-25 02:38:30.735471 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:38:30.735575 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:38:30.736374 (Thread-1): 02:38:30 | 8 of 9 START view model dbt_jrosen.massachusetts_sightings........... [RUN]
2021-02-25 02:38:30.736799 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:38:30.736886 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:38:30.744708 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:38:30.761402 (Thread-1): finished collecting timing info
2021-02-25 02:38:30.769018 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:38:30.780740 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:38:30.784986 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='California';


2021-02-25 02:38:30.910320 (Thread-80): handling poll request
2021-02-25 02:38:30.910937 (Thread-80): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803f9a00>]}
2021-02-25 02:38:30.913991 (Thread-80): sending response (<Response 21025 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:38:31.465568 (Thread-1): finished collecting timing info
2021-02-25 02:38:31.466470 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd960fc81-545e-4e8b-8d95-f8059de3da37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc455c3d0>]}
2021-02-25 02:38:31.467657 (Thread-1): 02:38:31 | 8 of 9 OK created view model dbt_jrosen.massachusetts_sightings...... [OK in 0.73s]
2021-02-25 02:38:31.467745 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:38:31.467849 (Thread-1): Began running node model.seth_test.viz2
2021-02-25 02:38:31.467936 (Thread-1): 02:38:31 | 9 of 9 SKIP relation dbt_jrosen.viz2................................. [SKIP]
2021-02-25 02:38:31.467995 (Thread-1): Finished running node model.seth_test.viz2
2021-02-25 02:38:31.469600 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:38:31.469880 (MainThread): 02:38:31 | 
2021-02-25 02:38:31.469946 (MainThread): 02:38:31 | Finished running 6 view models, 3 table models in 13.76s.
2021-02-25 02:38:31.469995 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:38:31.470036 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-25 02:38:31.587216 (MainThread): 
2021-02-25 02:38:31.587371 (MainThread): Completed with 2 errors and 0 warnings:
2021-02-25 02:38:31.587430 (MainThread): 
2021-02-25 02:38:31.587489 (MainThread): Database Error in model joke (models/test/joke.sql)
2021-02-25 02:38:31.587535 (MainThread):   Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
2021-02-25 02:38:31.587575 (MainThread):   compiled SQL at target/run/hashpath_demo/models/test/joke.sql
2021-02-25 02:38:31.587618 (MainThread): 
2021-02-25 02:38:31.587665 (MainThread): Database Error in model viz1 (models/viz1.sql)
2021-02-25 02:38:31.587708 (MainThread):   CREATE VIEW columns must be named, but column 1 has no name at [8:1]
2021-02-25 02:38:31.587747 (MainThread):   compiled SQL at target/run/seth_test/models/viz1.sql
2021-02-25 02:38:31.587806 (MainThread): 
Done. PASS=6 WARN=0 ERROR=2 SKIP=1 TOTAL=9
2021-02-25 02:38:32.197619 (Thread-81): handling poll request
2021-02-25 02:38:32.198053 (Thread-81): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803f6d60>]}
2021-02-25 02:38:32.220881 (Thread-81): sending response (<Response 32777 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:38:32.568380 (Thread-82): handling status request
2021-02-25 02:38:32.568806 (Thread-82): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88805e84f0>]}
2021-02-25 02:38:32.575493 (Thread-82): sending response (<Response 21989 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:39:35.354937 (Thread-83): handling status request
2021-02-25 02:39:35.356829 (Thread-83): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888049ba90>]}
2021-02-25 02:39:35.363484 (Thread-83): sending response (<Response 21989 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:39:35.389968 (Thread-84): handling status request
2021-02-25 02:39:35.390300 (Thread-84): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803c5280>]}
2021-02-25 02:39:35.396823 (Thread-84): sending response (<Response 21989 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:39:35.669580 (Thread-85): handling cli_args request
2021-02-25 02:39:35.670027 (Thread-85): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804c7490>]}
2021-02-25 02:39:36.501843 (Thread-85): sending response (<Response 136 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:39:36.604681 (MainThread): Partial parsing not enabled
2021-02-25 02:39:36.607134 (MainThread): Parsing macros/adapters.sql
2021-02-25 02:39:36.626486 (MainThread): Parsing macros/etc.sql
2021-02-25 02:39:36.628656 (MainThread): Parsing macros/catalog.sql
2021-02-25 02:39:36.634614 (MainThread): Parsing macros/materializations/copy.sql
2021-02-25 02:39:36.639115 (MainThread): Parsing macros/materializations/table.sql
2021-02-25 02:39:36.649133 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-25 02:39:36.662055 (MainThread): Parsing macros/materializations/seed.sql
2021-02-25 02:39:36.664801 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-25 02:39:36.666651 (MainThread): Parsing macros/materializations/view.sql
2021-02-25 02:39:36.670182 (MainThread): Parsing macros/core.sql
2021-02-25 02:39:36.674084 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-25 02:39:36.683094 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-25 02:39:36.696882 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-25 02:39:36.698707 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-25 02:39:36.716041 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-25 02:39:36.746993 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-25 02:39:36.751976 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-25 02:39:36.758595 (Thread-86): handling poll request
2021-02-25 02:39:36.759051 (Thread-86): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804fad90>]}
2021-02-25 02:39:36.758302 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-25 02:39:36.778658 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-25 02:39:36.787705 (Thread-86): sending response (<Response 5777 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:39:36.785292 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-25 02:39:36.787204 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-25 02:39:36.793216 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-25 02:39:36.794966 (MainThread): Parsing macros/etc/query.sql
2021-02-25 02:39:36.796125 (MainThread): Parsing macros/etc/datetime.sql
2021-02-25 02:39:36.805037 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-25 02:39:36.806059 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-25 02:39:36.807797 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-25 02:39:36.809818 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-25 02:39:36.811438 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-25 02:39:36.814146 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-25 02:39:36.816103 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-25 02:39:36.817911 (MainThread): Parsing macros/adapters/common.sql
2021-02-25 02:39:36.869584 (MainThread): Partial parsing not enabled
2021-02-25 02:39:36.916372 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:39:36.939658 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:39:36.955463 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:39:36.967867 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:39:36.979655 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:39:36.993699 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:39:37.008271 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:39:37.202745 (MainThread): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:39:37.215935 (MainThread): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:39:37.315715 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1fa3c67d-9615-4ebb-ae47-d154dac70648', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc32161e700>]}
2021-02-25 02:39:37.353561 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:39:37.354512 (MainThread): 
2021-02-25 02:39:37.354765 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:39:37.365025 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-02-25 02:39:37.365144 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:39:37.576184 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:39:37.576317 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-25 02:39:37.741513 (MainThread): 02:39:37 | Concurrency: 1 threads (target='default')
2021-02-25 02:39:37.741646 (MainThread): 02:39:37 | 
2021-02-25 02:39:37.743580 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:39:37.744547 (Thread-1): 02:39:37 | 1 of 9 START view model dbt_jrosen.new_model......................... [RUN]
2021-02-25 02:39:37.744779 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:39:37.744856 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:39:37.757978 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:39:37.777613 (Thread-1): finished collecting timing info
2021-02-25 02:39:37.807528 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:39:37.829807 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:39:37.834082 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-02-25 02:39:38.268735 (Thread-87): handling poll request
2021-02-25 02:39:38.269166 (Thread-87): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804fa250>]}
2021-02-25 02:39:38.273517 (Thread-87): sending response (<Response 13651 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:39:38.344774 (Thread-88): handling kill request
2021-02-25 02:39:38.345188 (Thread-88): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880489ac0>]}
2021-02-25 02:39:38.346889 (Thread-88): sending response (<Response 110 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:39:38.347231 (MainThread): 02:39:38 | The bigquery adapter does not support query cancellation. Some queries may still be running!
2021-02-25 02:39:38.779253 (Thread-1): finished collecting timing info
2021-02-25 02:39:38.779852 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1fa3c67d-9615-4ebb-ae47-d154dac70648', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc320715eb0>]}
2021-02-25 02:39:38.780808 (Thread-1): 02:39:38 | 1 of 9 OK created view model dbt_jrosen.new_model.................... [OK in 1.04s]
2021-02-25 02:39:38.780908 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:39:38.781118 (MainThread): 
2021-02-25 02:39:38.781227 (MainThread): Exited because of keyboard interrupt.
2021-02-25 02:39:38.781281 (MainThread): 
Done. PASS=0 WARN=0 ERROR=0 SKIP=0 TOTAL=0
2021-02-25 02:39:38.781340 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:39:38.781381 (MainThread): Connection 'model.hashpath_demo.new_model' was properly closed.
2021-02-25 02:39:39.521730 (Thread-89): handling poll request
2021-02-25 02:39:39.522152 (Thread-89): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804c5100>]}
2021-02-25 02:39:39.523957 (Thread-89): sending response (<Response 4191 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:39:39.928451 (Thread-90): handling status request
2021-02-25 02:39:39.928866 (Thread-90): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88808b1940>]}
2021-02-25 02:39:39.935523 (Thread-90): sending response (<Response 21989 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:39:44.203956 (Thread-91): handling status request
2021-02-25 02:39:44.204394 (Thread-91): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804ef100>]}
2021-02-25 02:39:44.210780 (Thread-91): sending response (<Response 21989 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:39:44.233237 (Thread-92): handling status request
2021-02-25 02:39:44.233524 (Thread-92): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804efb80>]}
2021-02-25 02:39:44.239836 (Thread-92): sending response (<Response 21989 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:39:44.494428 (Thread-93): handling deps request
2021-02-25 02:39:44.494844 (Thread-93): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804b7580>]}
2021-02-25 02:39:44.542413 (Thread-93): sending response (<Response 136 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:39:44.809700 (Thread-94): handling poll request
2021-02-25 02:39:44.810213 (Thread-94): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801e7790>]}
2021-02-25 02:39:44.811675 (Thread-94): sending response (<Response 285 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:39:45.774358 (MainThread): Set downloads directory='/tmp/dbt-downloads-jex4ogbb'
2021-02-25 02:39:45.775319 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:39:45.954327 (MainThread): STDOUT: "b''"
2021-02-25 02:39:45.954575 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:39:45.954910 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:39:45.954976 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:39:45.959520 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:39:45.959734 (MainThread): STDERR: "b''"
2021-02-25 02:39:45.959806 (MainThread):   Checking out branch master.
2021-02-25 02:39:45.959849 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:39:45.964507 (MainThread): STDOUT: "b''"
2021-02-25 02:39:45.964702 (MainThread): STDERR: "b''"
2021-02-25 02:39:45.964758 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:39:46.093257 (Thread-95): handling poll request
2021-02-25 02:39:46.093671 (Thread-95): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801e7a60>]}
2021-02-25 02:39:46.095619 (Thread-95): sending response (<Response 3906 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:39:46.151408 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.151667 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:39:46.151734 (MainThread): Executing "git tag --list"
2021-02-25 02:39:46.156334 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.156544 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.156621 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:39:46.161577 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:39:46.161779 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.161850 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:39:46.165030 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:39:46.165228 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.165292 (MainThread):   Checked out at 07141e6.
2021-02-25 02:39:46.189944 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:39:46.192938 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.193138 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:39:46.193185 (MainThread): command return code=128
2021-02-25 02:39:46.193540 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:39:46.193602 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:39:46.196849 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:39:46.197046 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.197117 (MainThread):   Checking out branch master.
2021-02-25 02:39:46.197159 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:39:46.201343 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.201540 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.201599 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:39:46.379566 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.379832 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:39:46.379903 (MainThread): Executing "git tag --list"
2021-02-25 02:39:46.384647 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.384870 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.384944 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:39:46.389779 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:39:46.389989 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.390059 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:39:46.393239 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:39:46.393402 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.393468 (MainThread):   Already at 07141e6, nothing to do.
2021-02-25 02:39:46.437295 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:39:46.440595 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:39:46.444655 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.444860 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:39:46.444908 (MainThread): command return code=128
2021-02-25 02:39:46.445027 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:39:46.445086 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:39:46.448749 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:39:46.448945 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.449017 (MainThread):   Checking out branch master.
2021-02-25 02:39:46.449060 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:39:46.453441 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.453637 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.453698 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:39:46.654408 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.654680 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:39:46.654754 (MainThread): Executing "git tag --list"
2021-02-25 02:39:46.659291 (MainThread): STDOUT: "b''"
2021-02-25 02:39:46.659463 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.659535 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:39:46.664146 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:39:46.664344 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.664421 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:39:46.667518 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:39:46.667671 (MainThread): STDERR: "b''"
2021-02-25 02:39:46.667743 (MainThread):   Already at 07141e6, nothing to do.
2021-02-25 02:39:47.502357 (Thread-96): handling poll request
2021-02-25 02:39:47.502782 (Thread-96): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88804ef460>]}
2021-02-25 02:39:47.508691 (Thread-96): sending response (<Response 17660 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:39:47.916587 (MainThread):   Installed from revision master

2021-02-25 02:39:47.916921 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '9d586598-51cb-4148-b6d2-ada8643a17ad', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f18803910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3f1a429a60>]}
2021-02-25 02:39:48.127035 (90897385-3097-494a-bdff-f905c5c005bd-handler-deps): Got an acceptable cached parse result
2021-02-25 02:39:48.290575 (90897385-3097-494a-bdff-f905c5c005bd-handler-deps): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:39:48.401370 (90897385-3097-494a-bdff-f905c5c005bd-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88802de700>]}
2021-02-25 02:39:48.896913 (Thread-97): handling poll request
2021-02-25 02:39:48.897339 (Thread-97): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880210fd0>]}
2021-02-25 02:39:48.898447 (Thread-97): sending response (<Response 1167 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:39:49.358583 (Thread-98): handling status request
2021-02-25 02:39:49.359027 (Thread-98): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880210640>]}
2021-02-25 02:39:49.365709 (Thread-98): sending response (<Response 21989 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:40:17.019385 (Thread-99): handling status request
2021-02-25 02:40:17.019809 (Thread-99): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880489520>]}
2021-02-25 02:40:17.026217 (Thread-99): sending response (<Response 21989 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:40:17.035392 (Thread-100): handling status request
2021-02-25 02:40:17.035676 (Thread-100): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880210ac0>]}
2021-02-25 02:40:17.041883 (Thread-100): sending response (<Response 21989 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:40:17.295592 (Thread-101): handling deps request
2021-02-25 02:40:17.296011 (Thread-101): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88806545b0>]}
2021-02-25 02:40:17.336514 (Thread-101): Connection 'model.seth_test.viz2' was properly closed.
2021-02-25 02:40:17.343437 (Thread-101): sending response (<Response 136 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:40:17.800582 (Thread-102): handling poll request
2021-02-25 02:40:17.801064 (Thread-102): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887adf8c70>]}
2021-02-25 02:40:17.802518 (Thread-102): sending response (<Response 285 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:40:18.561412 (MainThread): Set downloads directory='/tmp/dbt-downloads-sbso7yo9'
2021-02-25 02:40:18.562317 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:40:18.751066 (MainThread): STDOUT: "b''"
2021-02-25 02:40:18.751406 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:40:18.751786 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:40:18.751857 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:40:18.756924 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:40:18.757180 (MainThread): STDERR: "b''"
2021-02-25 02:40:18.757285 (MainThread):   Checking out branch master.
2021-02-25 02:40:18.757359 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:40:18.762647 (MainThread): STDOUT: "b''"
2021-02-25 02:40:18.762894 (MainThread): STDERR: "b''"
2021-02-25 02:40:18.762982 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:40:18.967634 (MainThread): STDOUT: "b''"
2021-02-25 02:40:18.967887 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:40:18.967956 (MainThread): Executing "git tag --list"
2021-02-25 02:40:18.972557 (MainThread): STDOUT: "b''"
2021-02-25 02:40:18.972766 (MainThread): STDERR: "b''"
2021-02-25 02:40:18.972841 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:40:18.977665 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:40:18.977850 (MainThread): STDERR: "b''"
2021-02-25 02:40:18.977923 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:40:18.981154 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:40:18.981339 (MainThread): STDERR: "b''"
2021-02-25 02:40:18.981407 (MainThread):   Checked out at 07141e6.
2021-02-25 02:40:19.006070 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:40:19.009121 (MainThread): STDOUT: "b''"
2021-02-25 02:40:19.009318 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:40:19.009364 (MainThread): command return code=128
2021-02-25 02:40:19.009715 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:40:19.009780 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:40:19.013006 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:40:19.013194 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.013268 (MainThread):   Checking out branch master.
2021-02-25 02:40:19.013314 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:40:19.017465 (MainThread): STDOUT: "b''"
2021-02-25 02:40:19.017652 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.017711 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:40:19.055712 (Thread-103): handling poll request
2021-02-25 02:40:19.056087 (Thread-103): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887adf8790>]}
2021-02-25 02:40:19.060285 (Thread-103): sending response (<Response 10842 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:40:19.224885 (MainThread): STDOUT: "b''"
2021-02-25 02:40:19.225144 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:40:19.225217 (MainThread): Executing "git tag --list"
2021-02-25 02:40:19.230113 (MainThread): STDOUT: "b''"
2021-02-25 02:40:19.230340 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.230414 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:40:19.236129 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:40:19.236398 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.236508 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:40:19.239634 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:40:19.239805 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.239872 (MainThread):   Already at 07141e6, nothing to do.
2021-02-25 02:40:19.291382 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:40:19.294218 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:40:19.301653 (MainThread): STDOUT: "b''"
2021-02-25 02:40:19.301930 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:40:19.302007 (MainThread): command return code=128
2021-02-25 02:40:19.302187 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:40:19.302279 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:40:19.308128 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:40:19.308388 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.308485 (MainThread):   Checking out branch master.
2021-02-25 02:40:19.308533 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:40:19.313130 (MainThread): STDOUT: "b''"
2021-02-25 02:40:19.313294 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.313351 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:40:19.493681 (MainThread): STDOUT: "b''"
2021-02-25 02:40:19.494040 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:40:19.494147 (MainThread): Executing "git tag --list"
2021-02-25 02:40:19.500061 (MainThread): STDOUT: "b''"
2021-02-25 02:40:19.500304 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.500419 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:40:19.505636 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:40:19.505894 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.506004 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:40:19.509835 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:40:19.510030 (MainThread): STDERR: "b''"
2021-02-25 02:40:19.510104 (MainThread):   Already at 07141e6, nothing to do.
2021-02-25 02:40:20.453210 (Thread-104): handling poll request
2021-02-25 02:40:20.453675 (Thread-104): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88802101c0>]}
2021-02-25 02:40:20.457329 (Thread-104): sending response (<Response 10724 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:40:20.758317 (MainThread):   Installed from revision master

2021-02-25 02:40:20.758655 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'e67ce677-b6a8-4169-9b12-141a9e78225c', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb5619dc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb55e290d0>]}
2021-02-25 02:40:20.962060 (989d5f7e-2a71-4107-acec-30d5737517c5-handler-deps): Got an acceptable cached parse result
2021-02-25 02:40:21.220093 (989d5f7e-2a71-4107-acec-30d5737517c5-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880533cd0>]}
2021-02-25 02:40:21.879679 (Thread-105): handling poll request
2021-02-25 02:40:21.880115 (Thread-105): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a531b80>]}
2021-02-25 02:40:21.881284 (Thread-105): sending response (<Response 1167 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:40:22.160622 (Thread-106): handling status request
2021-02-25 02:40:22.161059 (Thread-106): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a531910>]}
2021-02-25 02:40:22.168146 (Thread-106): sending response (<Response 21989 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:40:44.809451 (Thread-107): handling status request
2021-02-25 02:40:44.809899 (Thread-107): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ae8f0a0>]}
2021-02-25 02:40:44.816814 (Thread-107): sending response (<Response 21989 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:40:44.818360 (Thread-108): handling status request
2021-02-25 02:40:44.818677 (Thread-108): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a531f40>]}
2021-02-25 02:40:44.824835 (Thread-108): sending response (<Response 21989 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:40:45.075359 (Thread-109): handling docs.generate request
2021-02-25 02:40:45.075827 (Thread-109): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888063fb20>]}
2021-02-25 02:40:45.978117 (Thread-109): sending response (<Response 136 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:40:46.047077 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:40:46.048408 (MainThread): 
2021-02-25 02:40:46.048696 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:40:46.067769 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:40:46.067881 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:40:46.270100 (MainThread): 02:40:46 | Concurrency: 1 threads (target='default')
2021-02-25 02:40:46.270228 (MainThread): 02:40:46 | 
2021-02-25 02:40:46.277348 (Thread-110): handling poll request
2021-02-25 02:40:46.272320 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:40:46.277973 (Thread-110): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888063fb20>]}
2021-02-25 02:40:46.280178 (Thread-110): sending response (<Response 2988 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:40:46.272493 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:40:46.272570 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:40:46.295583 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:40:46.312988 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.313303 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.313612 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:40:46.313719 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:40:46.313808 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:40:46.313870 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:40:46.322374 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:40:46.338616 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.338881 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.339128 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:40:46.339237 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:40:46.339333 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:40:46.339401 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:40:46.349819 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:40:46.365413 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.365652 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.365845 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:40:46.365935 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:40:46.366020 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:40:46.366077 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:40:46.375537 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:40:46.392103 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.392326 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.392514 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:40:46.392604 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:40:46.392686 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:40:46.392743 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:40:46.399593 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:40:46.417323 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.417593 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.417788 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:40:46.417885 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 02:40:46.417971 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:40:46.418029 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 02:40:46.426282 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 02:40:46.441997 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.442365 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.442652 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 02:40:46.442860 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:40:46.443067 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:40:46.443161 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:40:46.450837 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:40:46.468085 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.468311 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.468499 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:40:46.468589 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:40:46.468673 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:40:46.468730 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:40:46.476651 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:40:46.492912 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.493145 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.493333 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:40:46.493422 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:40:46.493508 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 02:40:46.493565 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:40:46.517618 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 02:40:46.532565 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.533037 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.533358 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:40:46.533457 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:40:46.533546 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 02:40:46.533610 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:40:46.545279 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 02:40:46.560984 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.561266 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.561471 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:40:46.561567 (Thread-1): Began running node model.seth_test.viz2
2021-02-25 02:40:46.561659 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:40:46.561721 (Thread-1): Compiling model.seth_test.viz2
2021-02-25 02:40:46.569939 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.570208 (Thread-1): Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 13, in top-level template code
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 460, in call
    if not __self.is_safe_callable(__obj):
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 360, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
jinja2.exceptions.UndefinedError: 'filter' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
2021-02-25 02:40:46.571533 (Thread-1): Finished running node model.seth_test.viz2
2021-02-25 02:40:46.571652 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:40:46.571742 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 02:40:46.571805 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:40:46.579358 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 02:40:46.594785 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.595062 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.595263 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:40:46.595356 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:40:46.595441 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 02:40:46.595501 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:40:46.603132 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 02:40:46.621782 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.622083 (Thread-1): finished collecting timing info
2021-02-25 02:40:46.622293 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:40:46.622680 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:40:46.622769 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 02:40:46.622822 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/task_handler.py", line 94, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/project_commands.py", line 57, in handle_request
    return self.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/generate.py", line 213, in run
    compile_results = CompileTask.run(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 384, in execute_with_hooks
    res = self.execute_nodes()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 339, in execute_nodes
    self.run_queue(pool)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 267, in run_queue
    self._raise_set_error()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 222, in _raise_set_error
    raise self._raise_next_tick
dbt.exceptions.RuntimeException: Runtime Error
  Compilation Error in model viz2 (models/viz2.sql)
    'filter' is undefined
2021-02-25 02:40:47.607513 (Thread-111): handling poll request
2021-02-25 02:40:47.607991 (Thread-111): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4589d0>]}
2021-02-25 02:40:47.609532 (Thread-111): sending response (<Response 45461 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:40:47.931551 (Thread-112): handling status request
2021-02-25 02:40:47.931970 (Thread-112): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4e9970>]}
2021-02-25 02:40:47.938541 (Thread-112): sending response (<Response 21989 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:41:42.059260 (Thread-113): handling status request
2021-02-25 02:41:42.059701 (Thread-113): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4e9a30>]}
2021-02-25 02:41:42.066135 (Thread-113): sending response (<Response 21989 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:41:42.088160 (Thread-114): handling ps request
2021-02-25 02:41:42.088566 (Thread-114): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a51b7c0>]}
2021-02-25 02:41:42.118009 (Thread-114): sending response (<Response 5339 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:41:42.431676 (Thread-115): handling poll request
2021-02-25 02:41:42.432114 (Thread-115): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a51b5e0>]}
2021-02-25 02:41:42.438760 (Thread-115): sending response (<Response 22167 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:41:42.737223 (Thread-116): handling status request
2021-02-25 02:41:42.737657 (Thread-116): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a51b520>]}
2021-02-25 02:41:42.744306 (Thread-116): sending response (<Response 21989 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:41:58.233895 (Thread-117): handling status request
2021-02-25 02:41:58.234324 (Thread-117): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a51b9a0>]}
2021-02-25 02:41:58.241070 (Thread-117): sending response (<Response 21989 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:41:58.513204 (Thread-118): handling compile_sql request
2021-02-25 02:41:58.513630 (Thread-118): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a51b1c0>]}
2021-02-25 02:41:59.359333 (Thread-118): sending response (<Response 136 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:41:59.408247 (MainThread): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-02-25 02:41:59.428911 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:41:59.429362 (Thread-1): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-02-25 02:41:59.429469 (Thread-1): Compiling rpc.hashpath_demo.request
2021-02-25 02:41:59.445849 (Thread-1): finished collecting timing info
2021-02-25 02:41:59.446209 (Thread-1): Got an exception: Compilation Error in rpc request (from remote system)
  'filter' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 13, in top-level template code
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 460, in call
    if not __self.is_safe_callable(__obj):
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 360, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
jinja2.exceptions.UndefinedError: 'filter' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/node_runners.py", line 45, in compile
    return compiler.compile_node(self.node, manifest, {}, write=False)
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in rpc request (from remote system)
  'filter' is undefined
2021-02-25 02:41:59.447769 (Thread-1): Got exception RPCException(10004, Compilation Error, {'type': 'CompilationException', 'message': "Compilation Error in rpc request (from remote system)\n  'filter' is undefined", 'raw_sql': "{{ config(\n\ttype='table', \n\tdimensions=[1],\n\ttitle='Bigfoot Sightings',\n    sortable=true,\n    searchable=true,\n    download_csv=true\n)}}\n\nSELECT sightings.state, sightings.season, ss.humidity, ss.moon_phase as moon, ss.wind_speed as wind\nFROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings_ts` sightings\nLEFT JOIN {{ ref('viz1') }} ss on ss.geohash = sightings.geohash \nWHERE sightings.state='{{ filter('state') }}'\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': None, 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/sql_commands.py", line 145, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 360, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/node_runners.py", line 56, in error_result
    raise error
dbt.rpc.error.RPCException: RPCException(10004, Compilation Error, {'type': 'CompilationException', 'message': "Compilation Error in rpc request (from remote system)\n  'filter' is undefined", 'raw_sql': "{{ config(\n\ttype='table', \n\tdimensions=[1],\n\ttitle='Bigfoot Sightings',\n    sortable=true,\n    searchable=true,\n    download_csv=true\n)}}\n\nSELECT sightings.state, sightings.season, ss.humidity, ss.moon_phase as moon, ss.wind_speed as wind\nFROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings_ts` sightings\nLEFT JOIN {{ ref('viz1') }} ss on ss.geohash = sightings.geohash \nWHERE sightings.state='{{ filter('state') }}'\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': None, 'tags': None}, None)
2021-02-25 02:41:59.789684 (Thread-119): handling poll request
2021-02-25 02:41:59.790166 (Thread-119): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a51b1c0>]}
2021-02-25 02:41:59.791550 (Thread-119): sending response (<Response 7768 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:42:15.655630 (Thread-120): handling status request
2021-02-25 02:42:15.656086 (Thread-120): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4c85e0>]}
2021-02-25 02:42:15.662856 (Thread-120): sending response (<Response 21989 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:42:15.721555 (Thread-121): handling status request
2021-02-25 02:42:15.721923 (Thread-121): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4c8070>]}
2021-02-25 02:42:15.728216 (Thread-121): sending response (<Response 21989 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:42:16.027385 (Thread-122): handling cli_args request
2021-02-25 02:42:16.027805 (Thread-122): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a53a520>]}
2021-02-25 02:42:16.896378 (Thread-122): sending response (<Response 136 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:42:16.990604 (MainThread): Partial parsing not enabled
2021-02-25 02:42:16.992841 (MainThread): Parsing macros/adapters.sql
2021-02-25 02:42:17.012310 (MainThread): Parsing macros/etc.sql
2021-02-25 02:42:17.014410 (MainThread): Parsing macros/catalog.sql
2021-02-25 02:42:17.020396 (MainThread): Parsing macros/materializations/copy.sql
2021-02-25 02:42:17.024935 (MainThread): Parsing macros/materializations/table.sql
2021-02-25 02:42:17.034684 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-25 02:42:17.047519 (MainThread): Parsing macros/materializations/seed.sql
2021-02-25 02:42:17.050206 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-25 02:42:17.052042 (MainThread): Parsing macros/materializations/view.sql
2021-02-25 02:42:17.055515 (MainThread): Parsing macros/core.sql
2021-02-25 02:42:17.059394 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-25 02:42:17.068379 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-25 02:42:17.082324 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-25 02:42:17.084160 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-25 02:42:17.101500 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-25 02:42:17.132573 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-25 02:42:17.139301 (Thread-123): handling poll request
2021-02-25 02:42:17.139743 (Thread-123): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4c5940>]}
2021-02-25 02:42:17.142552 (Thread-123): sending response (<Response 4941 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:42:17.137527 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-25 02:42:17.143856 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-25 02:42:17.164525 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-25 02:42:17.171546 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-25 02:42:17.173559 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-25 02:42:17.179632 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-25 02:42:17.181282 (MainThread): Parsing macros/etc/query.sql
2021-02-25 02:42:17.182374 (MainThread): Parsing macros/etc/datetime.sql
2021-02-25 02:42:17.191063 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-25 02:42:17.192062 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-25 02:42:17.193741 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-25 02:42:17.195758 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-25 02:42:17.197289 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-25 02:42:17.199977 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-25 02:42:17.201895 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-25 02:42:17.203681 (MainThread): Parsing macros/adapters/common.sql
2021-02-25 02:42:17.256455 (MainThread): Partial parsing not enabled
2021-02-25 02:42:17.303942 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:42:17.327197 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:42:17.342995 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:42:17.356453 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:42:17.374172 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:42:17.395541 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:42:17.409726 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:42:17.608900 (MainThread): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:42:17.622696 (MainThread): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:42:17.734825 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd54799dca0>]}
2021-02-25 02:42:17.771134 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:42:17.772147 (MainThread): 
2021-02-25 02:42:17.772423 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:42:17.782828 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-02-25 02:42:17.782949 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:42:17.975659 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:42:17.975797 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-25 02:42:18.180959 (MainThread): 02:42:18 | Concurrency: 1 threads (target='default')
2021-02-25 02:42:18.181084 (MainThread): 02:42:18 | 
2021-02-25 02:42:18.183219 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:42:18.184195 (Thread-1): 02:42:18 | 1 of 9 START view model dbt_jrosen.new_model......................... [RUN]
2021-02-25 02:42:18.184425 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:42:18.184500 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:42:18.197793 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:42:18.218380 (Thread-1): finished collecting timing info
2021-02-25 02:42:18.249527 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:42:18.264959 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:42:18.269380 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-02-25 02:42:18.428728 (Thread-124): handling poll request
2021-02-25 02:42:18.429186 (Thread-124): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4c5d00>]}
2021-02-25 02:42:18.433945 (Thread-124): sending response (<Response 14487 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:42:19.034521 (Thread-1): finished collecting timing info
2021-02-25 02:42:19.035147 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd546a76e80>]}
2021-02-25 02:42:19.036097 (Thread-1): 02:42:19 | 1 of 9 OK created view model dbt_jrosen.new_model.................... [OK in 0.85s]
2021-02-25 02:42:19.036184 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:42:19.036289 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:42:19.037058 (Thread-1): 02:42:19 | 2 of 9 START table model dbt_jrosen.sightings_by_day_by_state........ [RUN]
2021-02-25 02:42:19.037256 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:42:19.037331 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:42:19.043309 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:42:19.063572 (Thread-1): finished collecting timing info
2021-02-25 02:42:19.079423 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:42:19.271217 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:42:19.286889 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-02-25 02:42:19.705646 (Thread-125): handling poll request
2021-02-25 02:42:19.706068 (Thread-125): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4c5b20>]}
2021-02-25 02:42:19.708005 (Thread-125): sending response (<Response 6161 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:42:21.106807 (Thread-126): handling poll request
2021-02-25 02:42:21.107261 (Thread-126): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a519b80>]}
2021-02-25 02:42:21.108123 (Thread-126): sending response (<Response 284 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:42:22.144621 (Thread-1): finished collecting timing info
2021-02-25 02:42:22.145641 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd54521df70>]}
2021-02-25 02:42:22.147255 (Thread-1): 02:42:22 | 2 of 9 OK created table model dbt_jrosen.sightings_by_day_by_state... [CREATE TABLE (3.7k rows, 76.6 KB processed) in 3.11s]
2021-02-25 02:42:22.147390 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:42:22.147557 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:42:22.148917 (Thread-1): 02:42:22 | 3 of 9 START view model dbt_jrosen.joke.............................. [RUN]
2021-02-25 02:42:22.149260 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:42:22.149378 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:42:22.165304 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:42:22.181752 (Thread-1): finished collecting timing info
2021-02-25 02:42:22.185892 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.joke"
2021-02-25 02:42:22.201888 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:42:22.206172 (Thread-1): On model.hashpath_demo.joke: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.joke"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`joke`
  OPTIONS()
  as 




 
  On the first day of christmas my true love gave to me 
      
            a partridge in a pear tree

 
  On the second day of christmas my true love gave to me 
      
            Two turtle doves and   
            a partridge in a pear tree

 
  On the third day of christmas my true love gave to me 
      
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fourth day of christmas my true love gave to me 
      
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fifth day of christmas my true love gave to me 
      
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the sixth day of christmas my true love gave to me 
      
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the seventh day of christmas my true love gave to me 
      
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eigth day of christmas my true love gave to me 
      
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the ninth day of christmas my true love gave to me 
      
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the tenth day of christmas my true love gave to me 
      
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eleventh day of christmas my true love gave to me 
      
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the twelth day of christmas my true love gave to me 
      
            twelve drummers drumming  
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree
;


2021-02-25 02:42:22.392540 (Thread-127): handling poll request
2021-02-25 02:42:22.392993 (Thread-127): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4daa00>]}
2021-02-25 02:42:22.394936 (Thread-127): sending response (<Response 9361 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:42:22.751963 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/56281474-3bf6-41c2-bc25-31c7afdebb8c?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]')
2021-02-25 02:42:23.667066 (Thread-128): handling poll request
2021-02-25 02:42:23.667503 (Thread-128): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4dad60>]}
2021-02-25 02:42:23.668479 (Thread-128): sending response (<Response 858 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:42:24.025355 (Thread-1): finished collecting timing info
2021-02-25 02:42:24.025879 (Thread-1): Database Error in model joke (models/test/joke.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
  compiled SQL at target/run/hashpath_demo/models/test/joke.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/25e34c3e-48f4-45fa-b703-7d56514cfae7?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]

(job ID: 25e34c3e-48f4-45fa-b703-7d56514cfae7)

                                                      -----Query Job SQL Follows-----                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.joke"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`joke`
   5:  OPTIONS()
   6:  as 
   7:
   8:
   9:
  10:
  11: 
  12:  On the first day of christmas my true love gave to me 
  13:      
  14:            a partridge in a pear tree
  15:
  16: 
  17:  On the second day of christmas my true love gave to me 
  18:      
  19:            Two turtle doves and   
  20:            a partridge in a pear tree
  21:
  22: 
  23:  On the third day of christmas my true love gave to me 
  24:      
  25:            Three French hens  
  26:            Two turtle doves and   
  27:            a partridge in a pear tree
  28:
  29: 
  30:  On the fourth day of christmas my true love gave to me 
  31:      
  32:            four calling birds  
  33:            Three French hens  
  34:            Two turtle doves and   
  35:            a partridge in a pear tree
  36:
  37: 
  38:  On the fifth day of christmas my true love gave to me 
  39:      
  40:            five gold rings  
  41:            four calling birds  
  42:            Three French hens  
  43:            Two turtle doves and   
  44:            a partridge in a pear tree
  45:
  46: 
  47:  On the sixth day of christmas my true love gave to me 
  48:      
  49:            six geese a-laying  
  50:            five gold rings  
  51:            four calling birds  
  52:            Three French hens  
  53:            Two turtle doves and   
  54:            a partridge in a pear tree
  55:
  56: 
  57:  On the seventh day of christmas my true love gave to me 
  58:      
  59:            seven swans a-swimming  
  60:            six geese a-laying  
  61:            five gold rings  
  62:            four calling birds  
  63:            Three French hens  
  64:            Two turtle doves and   
  65:            a partridge in a pear tree
  66:
  67: 
  68:  On the eigth day of christmas my true love gave to me 
  69:      
  70:            eight maids a-milking  
  71:            seven swans a-swimming  
  72:            six geese a-laying  
  73:            five gold rings  
  74:            four calling birds  
  75:            Three French hens  
  76:            Two turtle doves and   
  77:            a partridge in a pear tree
  78:
  79: 
  80:  On the ninth day of christmas my true love gave to me 
  81:      
  82:            nine ladies dancing  
  83:            eight maids a-milking  
  84:            seven swans a-swimming  
  85:            six geese a-laying  
  86:            five gold rings  
  87:            four calling birds  
  88:            Three French hens  
  89:            Two turtle doves and   
  90:            a partridge in a pear tree
  91:
  92: 
  93:  On the tenth day of christmas my true love gave to me 
  94:      
  95:            ten lords a-leaping  
  96:            nine ladies dancing  
  97:            eight maids a-milking  
  98:            seven swans a-swimming  
  99:            six geese a-laying  
 100:            five gold rings  
 101:            four calling birds  
 102:            Three French hens  
 103:            Two turtle doves and   
 104:            a partridge in a pear tree
 105:
 106: 
 107:  On the eleventh day of christmas my true love gave to me 
 108:      
 109:            eleven pipers piping  
 110:            ten lords a-leaping  
 111:            nine ladies dancing  
 112:            eight maids a-milking  
 113:            seven swans a-swimming  
 114:            six geese a-laying  
 115:            five gold rings  
 116:            four calling birds  
 117:            Three French hens  
 118:            Two turtle doves and   
 119:            a partridge in a pear tree
 120:
 121: 
 122:  On the twelth day of christmas my true love gave to me 
 123:      
 124:            twelve drummers drumming  
 125:            eleven pipers piping  
 126:            ten lords a-leaping  
 127:            nine ladies dancing  
 128:            eight maids a-milking  
 129:            seven swans a-swimming  
 130:            six geese a-laying  
 131:            five gold rings  
 132:            four calling birds  
 133:            Three French hens  
 134:            Two turtle doves and   
 135:            a partridge in a pear tree
 136:;
 137:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model joke (models/test/joke.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
  compiled SQL at target/run/hashpath_demo/models/test/joke.sql
2021-02-25 02:42:24.028847 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5451e2460>]}
2021-02-25 02:42:24.029893 (Thread-1): 02:42:24 | 3 of 9 ERROR creating view model dbt_jrosen.joke..................... [ERROR in 1.88s]
2021-02-25 02:42:24.029980 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:42:24.030088 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:42:24.030896 (Thread-1): 02:42:24 | 4 of 9 START table model dbt_jrosen.all_sightings.................... [RUN]
2021-02-25 02:42:24.031146 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:42:24.031220 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:42:24.041058 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:42:24.056361 (Thread-1): finished collecting timing info
2021-02-25 02:42:24.060047 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:42:24.260312 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:42:24.275912 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  );
    
2021-02-25 02:42:24.907615 (Thread-129): handling poll request
2021-02-25 02:42:24.908039 (Thread-129): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4cf0d0>]}
2021-02-25 02:42:24.910108 (Thread-129): sending response (<Response 19432 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:42:26.179127 (Thread-130): handling poll request
2021-02-25 02:42:26.179572 (Thread-130): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a534580>]}
2021-02-25 02:42:26.180426 (Thread-130): sending response (<Response 285 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:42:27.447290 (Thread-131): handling poll request
2021-02-25 02:42:27.447722 (Thread-131): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a5343a0>]}
2021-02-25 02:42:27.448596 (Thread-131): sending response (<Response 285 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:42:28.037816 (Thread-1): finished collecting timing info
2021-02-25 02:42:28.038430 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5450d12e0>]}
2021-02-25 02:42:28.039545 (Thread-1): 02:42:28 | 4 of 9 OK created table model dbt_jrosen.all_sightings............... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 4.01s]
2021-02-25 02:42:28.039634 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:42:28.039738 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:42:28.040501 (Thread-1): 02:42:28 | 5 of 9 START table model dbt_jrosen.sightings_by_day................. [RUN]
2021-02-25 02:42:28.040701 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:42:28.040774 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:42:28.047720 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:42:28.063693 (Thread-1): finished collecting timing info
2021-02-25 02:42:28.067473 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:42:28.247566 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:42:28.264755 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-02-25 02:42:28.868444 (Thread-132): handling poll request
2021-02-25 02:42:28.868879 (Thread-132): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a534ac0>]}
2021-02-25 02:42:28.870802 (Thread-132): sending response (<Response 6092 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:42:30.139595 (Thread-133): handling poll request
2021-02-25 02:42:30.140032 (Thread-133): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a457e50>]}
2021-02-25 02:42:30.140911 (Thread-133): sending response (<Response 285 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:42:31.550716 (Thread-134): handling poll request
2021-02-25 02:42:31.551188 (Thread-134): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4578b0>]}
2021-02-25 02:42:31.552080 (Thread-134): sending response (<Response 285 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:42:32.143225 (Thread-1): finished collecting timing info
2021-02-25 02:42:32.143868 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5450d18b0>]}
2021-02-25 02:42:32.144838 (Thread-1): 02:42:32 | 5 of 9 OK created table model dbt_jrosen.sightings_by_day............ [CREATE TABLE (2.9k rows, 57.6 KB processed) in 4.10s]
2021-02-25 02:42:32.144929 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:42:32.145033 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 02:42:32.146296 (Thread-1): 02:42:32 | 6 of 9 START view model dbt_jrosen.viz1.............................. [RUN]
2021-02-25 02:42:32.146517 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:42:32.146601 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 02:42:32.153574 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 02:42:32.168987 (Thread-1): finished collecting timing info
2021-02-25 02:42:32.172876 (Thread-1): Writing runtime SQL for node "model.seth_test.viz1"
2021-02-25 02:42:32.188453 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:42:32.192725 (Thread-1): On model.seth_test.viz1: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.seth_test.viz1"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`viz1`
  OPTIONS()
  as 

SELECT
DATE_TRUNC(date,year),
count(*)
FROM `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
WHERE date IS NOT NULL
AND date > '1960-01-01'
GROUP BY 1
ORDER BY 1 ASC;


2021-02-25 02:42:32.703485 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/b0d9e76c-0286-4671-ae0e-65a99de2e7ef?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 1 has no name at [8:1]')
2021-02-25 02:42:32.819858 (Thread-135): handling poll request
2021-02-25 02:42:32.820447 (Thread-135): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a531d30>]}
2021-02-25 02:42:32.823628 (Thread-135): sending response (<Response 6362 bytes [200 OK]>) to 10.0.8.47
2021-02-25 02:42:34.083244 (Thread-1): finished collecting timing info
2021-02-25 02:42:34.083758 (Thread-1): Database Error in model viz1 (models/viz1.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [8:1]
  compiled SQL at target/run/seth_test/models/viz1.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/8feb5f46-2540-4148-9799-83c4f7453bdb?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 1 has no name at [8:1]

(job ID: 8feb5f46-2540-4148-9799-83c4f7453bdb)

                                                    -----Query Job SQL Follows-----                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.seth_test.viz1"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`viz1`
   5:  OPTIONS()
   6:  as 
   7:
   8:SELECT
   9:DATE_TRUNC(date,year),
  10:count(*)
  11:FROM `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  12:WHERE date IS NOT NULL
  13:AND date > '1960-01-01'
  14:GROUP BY 1
  15:ORDER BY 1 ASC;
  16:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model viz1 (models/viz1.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [8:1]
  compiled SQL at target/run/seth_test/models/viz1.sql
2021-02-25 02:42:34.084631 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5450d1970>]}
2021-02-25 02:42:34.085702 (Thread-1): 02:42:34 | 6 of 9 ERROR creating view model dbt_jrosen.viz1..................... [ERROR in 1.94s]
2021-02-25 02:42:34.085788 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 02:42:34.085903 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:42:34.086708 (Thread-1): 02:42:34 | 7 of 9 START view model dbt_jrosen.demo_123.......................... [RUN]
2021-02-25 02:42:34.086940 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:42:34.087035 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:42:34.096400 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:42:34.111421 (Thread-1): finished collecting timing info
2021-02-25 02:42:34.115366 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:42:34.149118 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:42:34.153489 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='Utah';


2021-02-25 02:42:34.156484 (Thread-136): handling poll request
2021-02-25 02:42:34.156864 (Thread-136): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a5343d0>]}
2021-02-25 02:42:34.158918 (Thread-136): sending response (<Response 15110 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:42:35.041491 (Thread-1): finished collecting timing info
2021-02-25 02:42:35.042100 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd54502cc70>]}
2021-02-25 02:42:35.043220 (Thread-1): 02:42:35 | 7 of 9 OK created view model dbt_jrosen.demo_123..................... [OK in 0.96s]
2021-02-25 02:42:35.043316 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:42:35.043427 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:42:35.044215 (Thread-1): 02:42:35 | 8 of 9 START view model dbt_jrosen.massachusetts_sightings........... [RUN]
2021-02-25 02:42:35.044424 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:42:35.044498 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:42:35.053561 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:42:35.069980 (Thread-1): finished collecting timing info
2021-02-25 02:42:35.079627 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:42:35.095477 (Thread-1): Opening a new connection, currently in state closed
2021-02-25 02:42:35.099772 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='California';


2021-02-25 02:42:35.420698 (Thread-137): handling poll request
2021-02-25 02:42:35.421141 (Thread-137): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a5190a0>]}
2021-02-25 02:42:35.423094 (Thread-137): sending response (<Response 6198 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:42:35.990050 (Thread-1): finished collecting timing info
2021-02-25 02:42:35.990657 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e691a62-2247-4bce-9a01-83ba4939c8f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5489331c0>]}
2021-02-25 02:42:35.991654 (Thread-1): 02:42:35 | 8 of 9 OK created view model dbt_jrosen.massachusetts_sightings...... [OK in 0.95s]
2021-02-25 02:42:35.991740 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:42:35.991844 (Thread-1): Began running node model.seth_test.viz2
2021-02-25 02:42:35.991929 (Thread-1): 02:42:35 | 9 of 9 SKIP relation dbt_jrosen.viz2................................. [SKIP]
2021-02-25 02:42:35.991987 (Thread-1): Finished running node model.seth_test.viz2
2021-02-25 02:42:35.993475 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:42:35.993917 (MainThread): 02:42:35 | 
2021-02-25 02:42:35.993992 (MainThread): 02:42:35 | Finished running 6 view models, 3 table models in 18.22s.
2021-02-25 02:42:35.994043 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:42:35.994083 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-25 02:42:36.109382 (MainThread): 
2021-02-25 02:42:36.109535 (MainThread): Completed with 2 errors and 0 warnings:
2021-02-25 02:42:36.109594 (MainThread): 
2021-02-25 02:42:36.109651 (MainThread): Database Error in model joke (models/test/joke.sql)
2021-02-25 02:42:36.109696 (MainThread):   Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
2021-02-25 02:42:36.109735 (MainThread):   compiled SQL at target/run/hashpath_demo/models/test/joke.sql
2021-02-25 02:42:36.109776 (MainThread): 
2021-02-25 02:42:36.109824 (MainThread): Database Error in model viz1 (models/viz1.sql)
2021-02-25 02:42:36.109864 (MainThread):   CREATE VIEW columns must be named, but column 1 has no name at [8:1]
2021-02-25 02:42:36.109903 (MainThread):   compiled SQL at target/run/seth_test/models/viz1.sql
2021-02-25 02:42:36.109961 (MainThread): 
Done. PASS=6 WARN=0 ERROR=2 SKIP=1 TOTAL=9
2021-02-25 02:42:36.863242 (Thread-138): handling poll request
2021-02-25 02:42:36.863700 (Thread-138): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a457cd0>]}
2021-02-25 02:42:36.885081 (Thread-138): sending response (<Response 32866 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:42:37.313447 (Thread-139): handling status request
2021-02-25 02:42:37.313876 (Thread-139): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a519040>]}
2021-02-25 02:42:37.320288 (Thread-139): sending response (<Response 21989 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:43:46.567703 (Thread-140): handling status request
2021-02-25 02:43:46.569750 (Thread-140): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4daaf0>]}
2021-02-25 02:43:46.576030 (Thread-140): sending response (<Response 21989 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:43:46.578598 (Thread-141): handling status request
2021-02-25 02:43:46.578899 (Thread-141): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a534d90>]}
2021-02-25 02:43:46.585078 (Thread-141): sending response (<Response 21989 bytes [200 OK]>) to 10.0.32.171
2021-02-25 02:43:46.827925 (Thread-142): handling deps request
2021-02-25 02:43:46.828339 (Thread-142): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4c01c0>]}
2021-02-25 02:43:46.883809 (Thread-142): sending response (<Response 136 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:43:47.137636 (Thread-143): handling poll request
2021-02-25 02:43:47.138081 (Thread-143): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4253a0>]}
2021-02-25 02:43:47.139531 (Thread-143): sending response (<Response 285 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:43:48.102622 (MainThread): Set downloads directory='/tmp/dbt-downloads-1whodby5'
2021-02-25 02:43:48.103561 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:43:48.295204 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.295457 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:43:48.295797 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:43:48.295862 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:43:48.300573 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:43:48.300785 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.300858 (MainThread):   Checking out branch master.
2021-02-25 02:43:48.300909 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:43:48.305675 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.305880 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.305936 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:43:48.405154 (Thread-144): handling poll request
2021-02-25 02:43:48.405587 (Thread-144): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887aeb1520>]}
2021-02-25 02:43:48.432852 (Thread-144): sending response (<Response 3906 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:43:48.498019 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.498235 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:43:48.498300 (MainThread): Executing "git tag --list"
2021-02-25 02:43:48.503184 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.503362 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.503441 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:43:48.508569 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:43:48.508779 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.508856 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:43:48.512362 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:43:48.512554 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.512620 (MainThread):   Checked out at 07141e6.
2021-02-25 02:43:48.537592 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:43:48.541241 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.541438 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:43:48.541483 (MainThread): command return code=128
2021-02-25 02:43:48.541843 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:43:48.541907 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:43:48.545275 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:43:48.545470 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.545543 (MainThread):   Checking out branch master.
2021-02-25 02:43:48.545586 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:43:48.549782 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.549974 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.550034 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:43:48.747073 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.747355 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:43:48.747431 (MainThread): Executing "git tag --list"
2021-02-25 02:43:48.752023 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.752237 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.752315 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:43:48.757237 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:43:48.757447 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.757525 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:43:48.760832 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:43:48.761032 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.761102 (MainThread):   Already at 07141e6, nothing to do.
2021-02-25 02:43:48.808045 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:43:48.810906 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:43:48.815313 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.815481 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:43:48.815526 (MainThread): command return code=128
2021-02-25 02:43:48.815642 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:43:48.815700 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:43:48.819431 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:43:48.819627 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.819707 (MainThread):   Checking out branch master.
2021-02-25 02:43:48.819748 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:43:48.824382 (MainThread): STDOUT: "b''"
2021-02-25 02:43:48.824578 (MainThread): STDERR: "b''"
2021-02-25 02:43:48.824643 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:43:49.029634 (MainThread): STDOUT: "b''"
2021-02-25 02:43:49.029851 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:43:49.029920 (MainThread): Executing "git tag --list"
2021-02-25 02:43:49.034397 (MainThread): STDOUT: "b''"
2021-02-25 02:43:49.034606 (MainThread): STDERR: "b''"
2021-02-25 02:43:49.034685 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:43:49.039571 (MainThread): STDOUT: "b'HEAD is now at 07141e6 wip\n'"
2021-02-25 02:43:49.039736 (MainThread): STDERR: "b''"
2021-02-25 02:43:49.039812 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:43:49.042920 (MainThread): STDOUT: "b'07141e65b9413444d3a0395e7fee35ae4251b8d8\n'"
2021-02-25 02:43:49.043134 (MainThread): STDERR: "b''"
2021-02-25 02:43:49.043208 (MainThread):   Already at 07141e6, nothing to do.
2021-02-25 02:43:49.701686 (Thread-145): handling poll request
2021-02-25 02:43:49.702111 (Thread-145): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a425490>]}
2021-02-25 02:43:49.707804 (Thread-145): sending response (<Response 17660 bytes [200 OK]>) to 10.0.10.7
2021-02-25 02:43:50.331918 (MainThread):   Installed from revision master

2021-02-25 02:43:50.332263 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '7b4433fa-9164-492b-a0a8-a658f069b2f6', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3b9e0baf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3b9a970d0>]}
2021-02-25 02:43:50.563754 (1d29a5d8-7935-40f8-afb6-83eba1fa7ff1-handler-deps): Got an acceptable cached parse result
2021-02-25 02:43:50.958613 (1d29a5d8-7935-40f8-afb6-83eba1fa7ff1-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801898e0>]}
2021-02-25 02:43:50.968587 (Thread-146): handling poll request
2021-02-25 02:43:50.968964 (Thread-146): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880189af0>]}
2021-02-25 02:43:50.970042 (Thread-146): sending response (<Response 1167 bytes [200 OK]>) to 10.0.31.134
2021-02-25 02:43:51.361699 (Thread-147): handling status request
2021-02-25 02:43:51.362117 (Thread-147): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a388340>]}
2021-02-25 02:43:51.368745 (Thread-147): sending response (<Response 21989 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:45:43.145317 (Thread-148): handling status request
2021-02-25 02:45:43.147428 (Thread-148): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801a2f40>]}
2021-02-25 02:45:43.153844 (Thread-148): sending response (<Response 21989 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:45:43.163474 (Thread-149): handling status request
2021-02-25 02:45:43.163788 (Thread-149): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801a2820>]}
2021-02-25 02:45:43.171082 (Thread-149): sending response (<Response 21989 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:45:43.445480 (Thread-150): handling deps request
2021-02-25 02:45:43.445924 (Thread-150): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88801a2430>]}
2021-02-25 02:45:43.497937 (Thread-150): sending response (<Response 136 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:45:43.878932 (Thread-151): handling poll request
2021-02-25 02:45:43.879463 (Thread-151): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888018e4f0>]}
2021-02-25 02:45:43.880961 (Thread-151): sending response (<Response 285 bytes [200 OK]>) to 10.0.36.20
2021-02-25 02:45:44.827868 (MainThread): Set downloads directory='/tmp/dbt-downloads-u37bpq30'
2021-02-25 02:45:44.829196 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:45:45.041206 (MainThread): STDOUT: "b''"
2021-02-25 02:45:45.041456 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:45:45.041806 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:45:45.041873 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:45:45.046831 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:45:45.047114 (MainThread): STDERR: "b''"
2021-02-25 02:45:45.047200 (MainThread):   Checking out branch master.
2021-02-25 02:45:45.047245 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:45:45.052689 (MainThread): STDOUT: "b''"
2021-02-25 02:45:45.052906 (MainThread): STDERR: "b''"
2021-02-25 02:45:45.052989 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:45:45.304367 (Thread-152): handling poll request
2021-02-25 02:45:45.304982 (Thread-152): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a42cb20>]}
2021-02-25 02:45:45.307892 (Thread-152): sending response (<Response 3906 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:45:46.249006 (MainThread): STDOUT: "b''"
2021-02-25 02:45:46.249262 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:45:46.249332 (MainThread): Executing "git tag --list"
2021-02-25 02:45:46.254276 (MainThread): STDOUT: "b''"
2021-02-25 02:45:46.254497 (MainThread): STDERR: "b''"
2021-02-25 02:45:46.254574 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:45:46.259958 (MainThread): STDOUT: "b'HEAD is now at 0f83575 test\n'"
2021-02-25 02:45:46.260166 (MainThread): STDERR: "b''"
2021-02-25 02:45:46.260244 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:45:46.263901 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:45:46.264103 (MainThread): STDERR: "b''"
2021-02-25 02:45:46.264171 (MainThread):   Checked out at 0f83575.
2021-02-25 02:45:46.289538 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:45:46.293628 (MainThread): STDOUT: "b''"
2021-02-25 02:45:46.293848 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:45:46.293895 (MainThread): command return code=128
2021-02-25 02:45:46.294265 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:45:46.294344 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:45:46.298124 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:45:46.298321 (MainThread): STDERR: "b''"
2021-02-25 02:45:46.298398 (MainThread):   Checking out branch master.
2021-02-25 02:45:46.298442 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:45:46.302763 (MainThread): STDOUT: "b''"
2021-02-25 02:45:46.302962 (MainThread): STDERR: "b''"
2021-02-25 02:45:46.303044 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:45:46.735494 (Thread-153): handling poll request
2021-02-25 02:45:46.735926 (Thread-153): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f888018e730>]}
2021-02-25 02:45:46.738729 (Thread-153): sending response (<Response 7220 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:45:47.513876 (MainThread): STDOUT: "b''"
2021-02-25 02:45:47.514226 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:45:47.514350 (MainThread): Executing "git tag --list"
2021-02-25 02:45:47.519712 (MainThread): STDOUT: "b''"
2021-02-25 02:45:47.519945 (MainThread): STDERR: "b''"
2021-02-25 02:45:47.520028 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:45:47.526537 (MainThread): STDOUT: "b'HEAD is now at 0f83575 test\n'"
2021-02-25 02:45:47.526760 (MainThread): STDERR: "b''"
2021-02-25 02:45:47.526846 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:45:47.530432 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:45:47.530640 (MainThread): STDERR: "b''"
2021-02-25 02:45:47.530711 (MainThread):   Already at 0f83575, nothing to do.
2021-02-25 02:45:47.578519 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:45:47.582571 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:45:47.589035 (MainThread): STDOUT: "b''"
2021-02-25 02:45:47.589310 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:45:47.589388 (MainThread): command return code=128
2021-02-25 02:45:47.589567 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:45:47.589664 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:45:47.594972 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:45:47.595291 (MainThread): STDERR: "b''"
2021-02-25 02:45:47.595415 (MainThread):   Checking out branch master.
2021-02-25 02:45:47.595487 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:45:47.601988 (MainThread): STDOUT: "b''"
2021-02-25 02:45:47.602258 (MainThread): STDERR: "b''"
2021-02-25 02:45:47.602358 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:45:47.886768 (MainThread): STDOUT: "b''"
2021-02-25 02:45:47.887053 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:45:47.887129 (MainThread): Executing "git tag --list"
2021-02-25 02:45:47.892826 (MainThread): STDOUT: "b''"
2021-02-25 02:45:47.893050 (MainThread): STDERR: "b''"
2021-02-25 02:45:47.893128 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:45:47.897965 (MainThread): STDOUT: "b'HEAD is now at 0f83575 test\n'"
2021-02-25 02:45:47.898216 (MainThread): STDERR: "b''"
2021-02-25 02:45:47.898335 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:45:47.902837 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:45:47.903073 (MainThread): STDERR: "b''"
2021-02-25 02:45:47.903151 (MainThread):   Already at 0f83575, nothing to do.
2021-02-25 02:45:48.119750 (Thread-154): handling poll request
2021-02-25 02:45:48.120190 (Thread-154): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af8f310>]}
2021-02-25 02:45:48.123981 (Thread-154): sending response (<Response 10726 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:45:49.217129 (MainThread):   Installed from revision master

2021-02-25 02:45:49.217484 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '934e05fa-1767-4432-895b-abea22906124', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9690788b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe9687d21f0>]}
2021-02-25 02:45:49.385808 (Thread-155): handling poll request
2021-02-25 02:45:49.386277 (Thread-155): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af8fa90>]}
2021-02-25 02:45:49.387457 (Thread-155): sending response (<Response 1095 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:45:49.489251 (f5a7a669-aba6-45d0-9886-60384e1d9b44-handler-deps): Got an acceptable cached parse result
2021-02-25 02:45:49.680909 (f5a7a669-aba6-45d0-9886-60384e1d9b44-handler-deps): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:45:49.829280 (f5a7a669-aba6-45d0-9886-60384e1d9b44-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a50fa00>]}
2021-02-25 02:45:50.787914 (Thread-156): handling poll request
2021-02-25 02:45:50.788347 (Thread-156): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880189a90>]}
2021-02-25 02:45:50.789296 (Thread-156): sending response (<Response 357 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:45:51.184499 (Thread-157): handling status request
2021-02-25 02:45:51.184927 (Thread-157): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880189850>]}
2021-02-25 02:45:51.191640 (Thread-157): sending response (<Response 21992 bytes [200 OK]>) to 10.0.45.17
2021-02-25 02:47:08.462838 (Thread-158): handling ps request
2021-02-25 02:47:08.463332 (Thread-158): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887afd91c0>]}
2021-02-25 02:47:08.466829 (Thread-158): sending response (<Response 7046 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:47:08.514342 (Thread-159): handling status request
2021-02-25 02:47:08.514749 (Thread-159): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880189340>]}
2021-02-25 02:47:08.521301 (Thread-159): sending response (<Response 21992 bytes [200 OK]>) to 10.0.15.163
2021-02-25 02:47:08.777435 (Thread-160): handling poll request
2021-02-25 02:47:08.777874 (Thread-160): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a529250>]}
2021-02-25 02:47:08.784723 (Thread-160): sending response (<Response 22170 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:47:09.161127 (Thread-161): handling status request
2021-02-25 02:47:09.161558 (Thread-161): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a529a00>]}
2021-02-25 02:47:09.168132 (Thread-161): sending response (<Response 21992 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:47:44.410872 (Thread-162): handling status request
2021-02-25 02:47:44.411333 (Thread-162): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a5294f0>]}
2021-02-25 02:47:44.417864 (Thread-162): sending response (<Response 21992 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:47:44.440179 (Thread-163): handling status request
2021-02-25 02:47:44.440516 (Thread-163): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a5295e0>]}
2021-02-25 02:47:44.448267 (Thread-163): sending response (<Response 21992 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:47:44.698527 (Thread-164): handling deps request
2021-02-25 02:47:44.698946 (Thread-164): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a529130>]}
2021-02-25 02:47:44.737712 (Thread-164): Connection 'model.seth_test.viz2' was properly closed.
2021-02-25 02:47:44.744723 (Thread-164): sending response (<Response 136 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:47:44.991707 (Thread-165): handling poll request
2021-02-25 02:47:44.992178 (Thread-165): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a50f9a0>]}
2021-02-25 02:47:44.993661 (Thread-165): sending response (<Response 285 bytes [200 OK]>) to 10.0.26.158
2021-02-25 02:47:46.004012 (MainThread): Set downloads directory='/tmp/dbt-downloads-z2clzz0r'
2021-02-25 02:47:46.004936 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:47:46.227975 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.228215 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 02:47:46.228572 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:47:46.228647 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:47:46.233370 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 02:47:46.233574 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.233646 (MainThread):   Checking out branch master.
2021-02-25 02:47:46.233689 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:47:46.238277 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.238470 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.238539 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:47:46.317896 (Thread-166): handling poll request
2021-02-25 02:47:46.318321 (Thread-166): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a388eb0>]}
2021-02-25 02:47:46.320271 (Thread-166): sending response (<Response 3919 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:47:46.479226 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.479483 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 02:47:46.479552 (MainThread): Executing "git tag --list"
2021-02-25 02:47:46.484374 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.484582 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.484656 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:47:46.489907 (MainThread): STDOUT: "b'HEAD is now at 0f83575 test\n'"
2021-02-25 02:47:46.490107 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.490179 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:47:46.493540 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:47:46.493730 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.493794 (MainThread):   Checked out at 0f83575.
2021-02-25 02:47:46.519608 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:47:46.523738 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.523941 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:47:46.523988 (MainThread): command return code=128
2021-02-25 02:47:46.524356 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:47:46.524422 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:47:46.528036 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:47:46.528232 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.528307 (MainThread):   Checking out branch master.
2021-02-25 02:47:46.528348 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:47:46.532686 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.532879 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.532941 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:47:46.734648 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.734905 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:47:46.734980 (MainThread): Executing "git tag --list"
2021-02-25 02:47:46.739821 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.740041 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.740121 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:47:46.744763 (MainThread): STDOUT: "b'HEAD is now at 0f83575 test\n'"
2021-02-25 02:47:46.744965 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.745041 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:47:46.748073 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:47:46.748228 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.748292 (MainThread):   Already at 0f83575, nothing to do.
2021-02-25 02:47:46.794606 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 02:47:46.799198 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 02:47:46.803618 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.803820 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 02:47:46.803868 (MainThread): command return code=128
2021-02-25 02:47:46.803982 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 02:47:46.804044 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:47:46.807835 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:47:46.808033 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.808109 (MainThread):   Checking out branch master.
2021-02-25 02:47:46.808152 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 02:47:46.812356 (MainThread): STDOUT: "b''"
2021-02-25 02:47:46.812550 (MainThread): STDERR: "b''"
2021-02-25 02:47:46.812612 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 02:47:47.011612 (MainThread): STDOUT: "b''"
2021-02-25 02:47:47.011889 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 02:47:47.011965 (MainThread): Executing "git tag --list"
2021-02-25 02:47:47.016755 (MainThread): STDOUT: "b''"
2021-02-25 02:47:47.016984 (MainThread): STDERR: "b''"
2021-02-25 02:47:47.017067 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 02:47:47.022160 (MainThread): STDOUT: "b'HEAD is now at 0f83575 test\n'"
2021-02-25 02:47:47.022379 (MainThread): STDERR: "b''"
2021-02-25 02:47:47.022456 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 02:47:47.025873 (MainThread): STDOUT: "b'0f835753aa1981208de8d6831c5277ab0e098ed6\n'"
2021-02-25 02:47:47.026067 (MainThread): STDERR: "b''"
2021-02-25 02:47:47.026136 (MainThread):   Already at 0f83575, nothing to do.
2021-02-25 02:47:47.755058 (Thread-167): handling poll request
2021-02-25 02:47:47.755490 (Thread-167): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a4faf10>]}
2021-02-25 02:47:47.761496 (Thread-167): sending response (<Response 17726 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:47:48.324836 (MainThread):   Installed from revision master

2021-02-25 02:47:48.325176 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '0068139b-1752-462b-b015-e76b4fcaa494', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6331501040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f632fbb8bb0>]}
2021-02-25 02:47:48.536830 (df1350f7-b7a2-43df-93de-ec4feed173b1-handler-deps): Got an acceptable cached parse result
2021-02-25 02:47:48.807554 (df1350f7-b7a2-43df-93de-ec4feed173b1-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880553dc0>]}
2021-02-25 02:47:49.050707 (Thread-168): handling poll request
2021-02-25 02:47:49.051167 (Thread-168): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a21cf10>]}
2021-02-25 02:47:49.052290 (Thread-168): sending response (<Response 1169 bytes [200 OK]>) to 10.0.28.107
2021-02-25 02:47:49.347277 (Thread-169): handling status request
2021-02-25 02:47:49.347864 (Thread-169): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803f5070>]}
2021-02-25 02:47:49.358353 (Thread-169): sending response (<Response 22070 bytes [200 OK]>) to 10.0.33.218
2021-02-25 02:48:30.210938 (Thread-170): handling status request
2021-02-25 02:48:30.211402 (Thread-170): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a5294c0>]}
2021-02-25 02:48:30.217691 (Thread-170): sending response (<Response 22070 bytes [200 OK]>) to 10.0.19.152
2021-02-25 02:48:30.228271 (Thread-171): handling status request
2021-02-25 02:48:30.228557 (Thread-171): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a2d3190>]}
2021-02-25 02:48:30.259517 (Thread-171): sending response (<Response 22070 bytes [200 OK]>) to 10.0.12.26
2021-02-25 02:48:30.481654 (Thread-172): handling docs.generate request
2021-02-25 02:48:30.482079 (Thread-172): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a50fcd0>]}
2021-02-25 02:48:31.310963 (Thread-172): sending response (<Response 136 bytes [200 OK]>) to 10.0.12.44
2021-02-25 02:48:31.381367 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 02:48:31.382655 (MainThread): 
2021-02-25 02:48:31.382927 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 02:48:31.400760 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 02:48:31.400867 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 02:48:31.593439 (MainThread): 02:48:31 | Concurrency: 1 threads (target='default')
2021-02-25 02:48:31.593566 (MainThread): 02:48:31 | 
2021-02-25 02:48:31.595673 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 02:48:31.595856 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 02:48:31.595936 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 02:48:31.616085 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 02:48:31.623658 (Thread-173): handling poll request
2021-02-25 02:48:31.624077 (Thread-173): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a5294f0>]}
2021-02-25 02:48:31.626458 (Thread-173): sending response (<Response 4000 bytes [200 OK]>) to 10.0.40.10
2021-02-25 02:48:31.632222 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.632478 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.632685 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 02:48:31.632779 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:48:31.632865 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 02:48:31.632925 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:48:31.641255 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 02:48:31.658136 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.658402 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.658625 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 02:48:31.658725 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 02:48:31.658828 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 02:48:31.658904 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 02:48:31.669772 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 02:48:31.686667 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.686883 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.687079 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 02:48:31.687166 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 02:48:31.687247 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 02:48:31.687307 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 02:48:31.696438 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 02:48:31.724129 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.724360 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.724548 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 02:48:31.724638 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 02:48:31.724719 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 02:48:31.724779 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 02:48:31.731714 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 02:48:31.747656 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.747947 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.748157 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 02:48:31.748269 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 02:48:31.748371 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 02:48:31.748447 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 02:48:31.756541 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 02:48:31.772410 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.772634 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.772818 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 02:48:31.772906 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 02:48:31.772987 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 02:48:31.773045 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 02:48:31.780296 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 02:48:31.795739 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.795958 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.796138 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 02:48:31.796226 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:48:31.796305 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 02:48:31.796361 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 02:48:31.803945 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 02:48:31.819422 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.819639 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.819818 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 02:48:31.819911 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:48:31.819995 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 02:48:31.820052 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:48:31.842629 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 02:48:31.862370 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.862599 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.862786 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 02:48:31.862878 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:48:31.862958 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 02:48:31.863039 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:48:31.873809 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 02:48:31.889420 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.889639 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.889821 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 02:48:31.889910 (Thread-1): Began running node model.seth_test.viz2
2021-02-25 02:48:31.889990 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 02:48:31.890046 (Thread-1): Compiling model.seth_test.viz2
2021-02-25 02:48:31.897647 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.897878 (Thread-1): Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 14, in top-level template code
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 460, in call
    if not __self.is_safe_callable(__obj):
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 360, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
jinja2.exceptions.UndefinedError: 'filter' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
2021-02-25 02:48:31.899071 (Thread-1): Finished running node model.seth_test.viz2
2021-02-25 02:48:31.899180 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:48:31.899264 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 02:48:31.899323 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:48:31.906297 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 02:48:31.928787 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.929022 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.929202 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 02:48:31.929288 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:48:31.929366 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 02:48:31.929422 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:48:31.936410 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 02:48:31.953013 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.953301 (Thread-1): finished collecting timing info
2021-02-25 02:48:31.953515 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 02:48:31.954087 (MainThread): Connection 'master' was properly closed.
2021-02-25 02:48:31.954189 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 02:48:31.954244 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/task_handler.py", line 94, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/project_commands.py", line 57, in handle_request
    return self.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/generate.py", line 213, in run
    compile_results = CompileTask.run(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 384, in execute_with_hooks
    res = self.execute_nodes()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 339, in execute_nodes
    self.run_queue(pool)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 267, in run_queue
    self._raise_set_error()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 222, in _raise_set_error
    raise self._raise_next_tick
dbt.exceptions.RuntimeException: Runtime Error
  Compilation Error in model viz2 (models/viz2.sql)
    'filter' is undefined
2021-02-25 02:48:32.983659 (Thread-174): handling poll request
2021-02-25 02:48:32.984089 (Thread-174): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ad610d0>]}
2021-02-25 02:48:32.985505 (Thread-174): sending response (<Response 45561 bytes [200 OK]>) to 10.0.5.107
2021-02-25 02:48:33.457349 (Thread-175): handling status request
2021-02-25 02:48:33.457756 (Thread-175): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a497b20>]}
2021-02-25 02:48:33.466987 (Thread-175): sending response (<Response 22070 bytes [200 OK]>) to 10.0.12.26
2021-02-25 03:39:19.561418 (Thread-176): handling ps request
2021-02-25 03:39:19.561845 (Thread-176): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a497160>]}
2021-02-25 03:39:19.566016 (Thread-176): sending response (<Response 7855 bytes [200 OK]>) to 10.0.12.26
2021-02-25 03:39:19.566844 (Thread-177): handling status request
2021-02-25 03:39:19.571727 (Thread-177): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a497760>]}
2021-02-25 03:39:19.578250 (Thread-177): sending response (<Response 22070 bytes [200 OK]>) to 10.0.32.171
2021-02-25 03:39:19.857957 (Thread-178): handling poll request
2021-02-25 03:39:19.858381 (Thread-178): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880251730>]}
2021-02-25 03:39:19.865017 (Thread-178): sending response (<Response 22248 bytes [200 OK]>) to 10.0.28.107
2021-02-25 03:39:35.229255 (Thread-179): handling status request
2021-02-25 03:39:35.229682 (Thread-179): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a497160>]}
2021-02-25 03:39:35.235995 (Thread-179): sending response (<Response 22070 bytes [200 OK]>) to 10.0.31.134
2021-02-25 03:39:35.237026 (Thread-180): handling status request
2021-02-25 03:39:35.237447 (Thread-180): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a2a37f0>]}
2021-02-25 03:39:35.243955 (Thread-180): sending response (<Response 22070 bytes [200 OK]>) to 10.0.5.107
2021-02-25 03:39:35.531883 (Thread-181): handling deps request
2021-02-25 03:39:35.532326 (Thread-181): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a21c4f0>]}
2021-02-25 03:39:35.579941 (Thread-181): sending response (<Response 136 bytes [200 OK]>) to 10.0.32.171
2021-02-25 03:39:36.036272 (Thread-182): handling poll request
2021-02-25 03:39:36.036743 (Thread-182): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880120bb0>]}
2021-02-25 03:39:36.038209 (Thread-182): sending response (<Response 285 bytes [200 OK]>) to 10.0.36.20
2021-02-25 03:39:36.814692 (MainThread): Set downloads directory='/tmp/dbt-downloads-mdzneqrw'
2021-02-25 03:39:36.815623 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 03:39:37.033152 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.033403 (MainThread): STDERR: "b"Cloning into '6b9c3d8105777fcb6c2bd2733a8c433a'...\n""
2021-02-25 03:39:37.033756 (MainThread): Pulling new dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 03:39:37.033823 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 03:39:37.038446 (MainThread): STDOUT: "b'6e846fa6d507baa9b8ddda7ca022347749983e6b\n'"
2021-02-25 03:39:37.038674 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.038745 (MainThread):   Checking out branch master.
2021-02-25 03:39:37.038789 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 03:39:37.043445 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.043655 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.043713 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 03:39:37.238940 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.239226 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\n'"
2021-02-25 03:39:37.239294 (MainThread): Executing "git tag --list"
2021-02-25 03:39:37.243953 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.244174 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.244248 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 03:39:37.249293 (MainThread): STDOUT: "b'HEAD is now at b43ae74 wip\n'"
2021-02-25 03:39:37.249501 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.249572 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 03:39:37.252802 (MainThread): STDOUT: "b'b43ae7436cd1b32622b23e5a5646811599e38faf\n'"
2021-02-25 03:39:37.253008 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.253074 (MainThread):   Checked out at b43ae74.
2021-02-25 03:39:37.280571 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 03:39:37.283797 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.283997 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 03:39:37.284044 (MainThread): command return code=128
2021-02-25 03:39:37.284391 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 03:39:37.284455 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 03:39:37.287768 (MainThread): STDOUT: "b'b43ae7436cd1b32622b23e5a5646811599e38faf\n'"
2021-02-25 03:39:37.287969 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.288040 (MainThread):   Checking out branch master.
2021-02-25 03:39:37.288084 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 03:39:37.292192 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.292392 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.292451 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 03:39:37.465251 (Thread-183): handling poll request
2021-02-25 03:39:37.465706 (Thread-183): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a529940>]}
2021-02-25 03:39:37.469417 (Thread-183): sending response (<Response 10880 bytes [200 OK]>) to 10.0.40.10
2021-02-25 03:39:37.473754 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.473971 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 03:39:37.474038 (MainThread): Executing "git tag --list"
2021-02-25 03:39:37.478369 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.478595 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.478667 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 03:39:37.483214 (MainThread): STDOUT: "b'HEAD is now at b43ae74 wip\n'"
2021-02-25 03:39:37.483422 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.483495 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 03:39:37.486757 (MainThread): STDOUT: "b'b43ae7436cd1b32622b23e5a5646811599e38faf\n'"
2021-02-25 03:39:37.486965 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.487054 (MainThread):   Already at b43ae74, nothing to do.
2021-02-25 03:39:37.533677 (MainThread): Installing https://github.com/sethdr/seth_dbt_package_demo.git@master
2021-02-25 03:39:37.536555 (MainThread): Executing "git clone --depth 1 https://github.com/sethdr/seth_dbt_package_demo.git 6b9c3d8105777fcb6c2bd2733a8c433a"
2021-02-25 03:39:37.541010 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.541219 (MainThread): STDERR: "b"fatal: destination path '6b9c3d8105777fcb6c2bd2733a8c433a' already exists and is not an empty directory.\n""
2021-02-25 03:39:37.541267 (MainThread): command return code=128
2021-02-25 03:39:37.541390 (MainThread): Updating existing dependency 6b9c3d8105777fcb6c2bd2733a8c433a.
2021-02-25 03:39:37.541452 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 03:39:37.545184 (MainThread): STDOUT: "b'b43ae7436cd1b32622b23e5a5646811599e38faf\n'"
2021-02-25 03:39:37.545387 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.545464 (MainThread):   Checking out branch master.
2021-02-25 03:39:37.545507 (MainThread): Executing "git remote set-branches origin master"
2021-02-25 03:39:37.549817 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.550015 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.550074 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2021-02-25 03:39:37.741113 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.741381 (MainThread): STDERR: "b'From https://github.com/sethdr/seth_dbt_package_demo\n * branch            master     -> FETCH_HEAD\n'"
2021-02-25 03:39:37.741452 (MainThread): Executing "git tag --list"
2021-02-25 03:39:37.746164 (MainThread): STDOUT: "b''"
2021-02-25 03:39:37.746396 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.746476 (MainThread): Executing "git reset --hard origin/master"
2021-02-25 03:39:37.751595 (MainThread): STDOUT: "b'HEAD is now at b43ae74 wip\n'"
2021-02-25 03:39:37.751822 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.751899 (MainThread): Executing "git rev-parse HEAD"
2021-02-25 03:39:37.755162 (MainThread): STDOUT: "b'b43ae7436cd1b32622b23e5a5646811599e38faf\n'"
2021-02-25 03:39:37.755376 (MainThread): STDERR: "b''"
2021-02-25 03:39:37.755450 (MainThread):   Already at b43ae74, nothing to do.
2021-02-25 03:39:38.919498 (Thread-184): handling poll request
2021-02-25 03:39:38.919919 (Thread-184): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a28e640>]}
2021-02-25 03:39:38.923560 (Thread-184): sending response (<Response 10762 bytes [200 OK]>) to 10.0.45.17
2021-02-25 03:39:39.094447 (MainThread):   Installed from revision master

2021-02-25 03:39:39.094774 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '6c773d7a-e074-4ff0-b087-09707f39dc8c', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1093dbbf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1092475b80>]}
2021-02-25 03:39:39.435337 (f02b72bd-70bc-4efa-969c-18d2b89aae5d-handler-deps): Got an acceptable cached parse result
2021-02-25 03:39:39.706993 (f02b72bd-70bc-4efa-969c-18d2b89aae5d-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af3e400>]}
2021-02-25 03:39:40.318900 (Thread-185): handling poll request
2021-02-25 03:39:40.319361 (Thread-185): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af3e580>]}
2021-02-25 03:39:40.320478 (Thread-185): sending response (<Response 1169 bytes [200 OK]>) to 10.0.5.107
2021-02-25 03:39:40.739582 (Thread-186): handling status request
2021-02-25 03:39:40.740012 (Thread-186): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a31d9d0>]}
2021-02-25 03:39:40.747700 (Thread-186): sending response (<Response 22067 bytes [200 OK]>) to 10.0.28.107
2021-02-25 03:39:56.863664 (Thread-187): handling status request
2021-02-25 03:39:56.864110 (Thread-187): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887a3ccee0>]}
2021-02-25 03:39:56.870549 (Thread-187): sending response (<Response 22067 bytes [200 OK]>) to 10.0.31.134
2021-02-25 03:39:56.897059 (Thread-188): handling status request
2021-02-25 03:39:56.897371 (Thread-188): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803e1be0>]}
2021-02-25 03:39:56.903696 (Thread-188): sending response (<Response 22067 bytes [200 OK]>) to 10.0.10.7
2021-02-25 03:39:57.158719 (Thread-189): handling docs.generate request
2021-02-25 03:39:57.159164 (Thread-189): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88803e1b50>]}
2021-02-25 03:39:58.008737 (Thread-189): sending response (<Response 136 bytes [200 OK]>) to 10.0.31.134
2021-02-25 03:39:58.079560 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-25 03:39:58.080936 (MainThread): 
2021-02-25 03:39:58.081252 (MainThread): Acquiring new bigquery connection "master".
2021-02-25 03:39:58.099461 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-25 03:39:58.099571 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-25 03:39:58.299926 (MainThread): 03:39:58 | Concurrency: 1 threads (target='default')
2021-02-25 03:39:58.300057 (MainThread): 03:39:58 | 
2021-02-25 03:39:58.302103 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-25 03:39:58.302283 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-25 03:39:58.302364 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-25 03:39:58.323335 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-25 03:39:58.338031 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.338307 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.338525 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-25 03:39:58.338620 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 03:39:58.338712 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-25 03:39:58.338774 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-25 03:39:58.347160 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-25 03:39:58.352773 (Thread-190): handling poll request
2021-02-25 03:39:58.353222 (Thread-190): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887af3ea00>]}
2021-02-25 03:39:58.356287 (Thread-190): sending response (<Response 7125 bytes [200 OK]>) to 10.0.10.7
2021-02-25 03:39:58.370637 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.370952 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.371198 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-25 03:39:58.371294 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-25 03:39:58.371387 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-25 03:39:58.371451 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-25 03:39:58.381935 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-25 03:39:58.397072 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.397351 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.397557 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-25 03:39:58.397653 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-25 03:39:58.397746 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-25 03:39:58.397809 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-25 03:39:58.407435 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-25 03:39:58.424180 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.424453 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.424656 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-25 03:39:58.424753 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-25 03:39:58.424845 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-25 03:39:58.424906 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-25 03:39:58.432049 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-25 03:39:58.449125 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.449387 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.449590 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-25 03:39:58.449682 (Thread-1): Began running node model.seth_test.viz1
2021-02-25 03:39:58.449771 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-25 03:39:58.449834 (Thread-1): Compiling model.seth_test.viz1
2021-02-25 03:39:58.456896 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-25 03:39:58.476504 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.476760 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.476961 (Thread-1): Finished running node model.seth_test.viz1
2021-02-25 03:39:58.477057 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-25 03:39:58.477147 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-25 03:39:58.477208 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-25 03:39:58.484907 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-25 03:39:58.501918 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.502158 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.502354 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-25 03:39:58.502446 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-25 03:39:58.502533 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-25 03:39:58.502592 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-25 03:39:58.510436 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-25 03:39:58.527954 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.528176 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.528364 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-25 03:39:58.528456 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 03:39:58.528543 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-02-25 03:39:58.528601 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 03:39:58.554657 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-02-25 03:39:58.572217 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.572490 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.572693 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-02-25 03:39:58.572788 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 03:39:58.572878 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-02-25 03:39:58.572939 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 03:39:58.584157 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-02-25 03:39:58.601268 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.601508 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.601703 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-02-25 03:39:58.601796 (Thread-1): Began running node model.seth_test.viz2
2021-02-25 03:39:58.601884 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-25 03:39:58.601943 (Thread-1): Compiling model.seth_test.viz2
2021-02-25 03:39:58.609606 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.609856 (Thread-1): Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.8/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.8/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 14, in top-level template code
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 460, in call
    if not __self.is_safe_callable(__obj):
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 360, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
jinja2.exceptions.UndefinedError: 'filter' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 281, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/compile.py", line 32, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 502, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.8/dist-packages/dbt/compilation.py", line 404, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model viz2 (models/viz2.sql)
  'filter' is undefined
2021-02-25 03:39:58.611079 (Thread-1): Finished running node model.seth_test.viz2
2021-02-25 03:39:58.611188 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 03:39:58.611279 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-02-25 03:39:58.611340 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 03:39:58.618520 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-02-25 03:39:58.634180 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.634415 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.634606 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-02-25 03:39:58.634698 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 03:39:58.634785 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-02-25 03:39:58.634845 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 03:39:58.642044 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-02-25 03:39:58.660539 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.660865 (Thread-1): finished collecting timing info
2021-02-25 03:39:58.661100 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-02-25 03:39:58.661490 (MainThread): Connection 'master' was properly closed.
2021-02-25 03:39:58.661587 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-02-25 03:39:58.661641 (MainThread): dbt runtime exception
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/task_handler.py", line 94, in task_exec
    result = self.task.handle_request()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/project_commands.py", line 57, in handle_request
    return self.run()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/generate.py", line 213, in run
    compile_results = CompileTask.run(self)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 426, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 384, in execute_with_hooks
    res = self.execute_nodes()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 339, in execute_nodes
    self.run_queue(pool)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 267, in run_queue
    self._raise_set_error()
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/runnable.py", line 222, in _raise_set_error
    raise self._raise_next_tick
dbt.exceptions.RuntimeException: Runtime Error
  Compilation Error in model viz2 (models/viz2.sql)
    'filter' is undefined
2021-02-25 03:39:59.631587 (Thread-191): handling poll request
2021-02-25 03:39:59.632037 (Thread-191): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f887ad85a30>]}
2021-02-25 03:39:59.633791 (Thread-191): sending response (<Response 45561 bytes [200 OK]>) to 10.0.10.7
2021-02-25 03:39:59.902864 (Thread-192): handling status request
2021-02-25 03:39:59.903332 (Thread-192): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '8684d229-3827-412e-b6eb-e47e117e2038', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8880441610>]}
2021-02-25 03:39:59.909903 (Thread-192): sending response (<Response 22067 bytes [200 OK]>) to 10.0.19.152
2021-02-26 22:33:42.266312 (MainThread): Running with dbt=0.19.0
2021-02-26 22:33:42.426583 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-02-26 22:33:42.439606 (MainThread): Tracking: tracking
2021-02-26 22:33:42.464046 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ade8e49d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ade8e4ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ade8e49a0>]}
2021-02-26 22:33:42.464467 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=16
2021-02-26 22:33:42.475149 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-02-26 22:33:42.476744 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-02-26 22:33:42.484347 (Thread-1): Parsing macros/adapters.sql
2021-02-26 22:33:42.505601 (Thread-1): Parsing macros/etc.sql
2021-02-26 22:33:42.507853 (Thread-1): Parsing macros/catalog.sql
2021-02-26 22:33:42.514178 (Thread-1): Parsing macros/materializations/copy.sql
2021-02-26 22:33:42.519059 (Thread-1): Parsing macros/materializations/table.sql
2021-02-26 22:33:42.529963 (Thread-1): Parsing macros/materializations/incremental.sql
2021-02-26 22:33:42.542639 (Thread-1): Parsing macros/materializations/seed.sql
2021-02-26 22:33:42.545448 (Thread-1): Parsing macros/materializations/snapshot.sql
2021-02-26 22:33:42.547400 (Thread-1): Parsing macros/materializations/view.sql
2021-02-26 22:33:42.550897 (Thread-1): Parsing macros/core.sql
2021-02-26 22:33:42.554745 (Thread-1): Parsing macros/materializations/helpers.sql
2021-02-26 22:33:42.563603 (Thread-1): Parsing macros/materializations/common/merge.sql
2021-02-26 22:33:42.577128 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-26 22:33:42.578871 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2021-02-26 22:33:42.596060 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-26 22:33:42.626930 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-26 22:33:42.631762 (Thread-1): Parsing macros/materializations/view/view.sql
2021-02-26 22:33:42.637831 (Thread-1): Parsing macros/materializations/seed/seed.sql
2021-02-26 22:33:42.658068 (Thread-1): Parsing macros/materializations/table/table.sql
2021-02-26 22:33:42.664592 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2021-02-26 22:33:42.666383 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2021-02-26 22:33:42.672316 (Thread-1): Parsing macros/etc/is_incremental.sql
2021-02-26 22:33:42.673912 (Thread-1): Parsing macros/etc/query.sql
2021-02-26 22:33:42.674954 (Thread-1): Parsing macros/etc/datetime.sql
2021-02-26 22:33:42.683517 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2021-02-26 22:33:42.684465 (Thread-1): Parsing macros/etc/get_custom_database.sql
2021-02-26 22:33:42.686081 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2021-02-26 22:33:42.688099 (Thread-1): Parsing macros/schema_tests/not_null.sql
2021-02-26 22:33:42.689605 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2021-02-26 22:33:42.692254 (Thread-1): Parsing macros/schema_tests/relationships.sql
2021-02-26 22:33:42.694124 (Thread-1): Parsing macros/schema_tests/unique.sql
2021-02-26 22:33:42.695851 (Thread-1): Parsing macros/adapters/common.sql
2021-02-26 22:33:42.799286 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:33:42.829960 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-26 22:33:42.851499 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:33:42.868680 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:33:42.884695 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:33:42.901118 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:33:42.919162 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:33:43.222744 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-26 22:33:43.238156 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-26 22:33:43.337581 (Thread-1): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8128040>]}
2021-02-26 22:33:43.418548 (Thread-2): handling status request
2021-02-26 22:33:43.419047 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac80eda30>]}
2021-02-26 22:33:43.423871 (Thread-2): sending response (<Response 12016 bytes [200 OK]>) to 10.0.3.75
2021-02-26 22:33:55.277307 (Thread-3): handling status request
2021-02-26 22:33:55.277734 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac82e5d00>]}
2021-02-26 22:33:55.281499 (Thread-3): sending response (<Response 12016 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:33:55.309094 (Thread-4): handling status request
2021-02-26 22:33:55.309426 (Thread-4): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac829eb20>]}
2021-02-26 22:33:55.313138 (Thread-4): sending response (<Response 12016 bytes [200 OK]>) to 10.0.0.148
2021-02-26 22:33:55.570017 (Thread-5): handling cli_args request
2021-02-26 22:33:55.572565 (Thread-5): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac830cc40>]}
2021-02-26 22:33:55.583925 (Thread-5): Connection 'model.seth_test.viz2' was properly closed.
2021-02-26 22:33:56.468291 (Thread-5): sending response (<Response 136 bytes [200 OK]>) to 10.0.22.116
2021-02-26 22:33:56.585452 (MainThread): Partial parsing not enabled
2021-02-26 22:33:56.588357 (MainThread): Parsing macros/adapters.sql
2021-02-26 22:33:56.609164 (MainThread): Parsing macros/etc.sql
2021-02-26 22:33:56.611706 (MainThread): Parsing macros/catalog.sql
2021-02-26 22:33:56.618471 (MainThread): Parsing macros/materializations/copy.sql
2021-02-26 22:33:56.623688 (MainThread): Parsing macros/materializations/table.sql
2021-02-26 22:33:56.634200 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-26 22:33:56.647880 (MainThread): Parsing macros/materializations/seed.sql
2021-02-26 22:33:56.650798 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-26 22:33:56.652824 (MainThread): Parsing macros/materializations/view.sql
2021-02-26 22:33:56.656555 (MainThread): Parsing macros/core.sql
2021-02-26 22:33:56.660772 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-26 22:33:56.670096 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-26 22:33:56.684106 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-26 22:33:56.686037 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-26 22:33:56.703522 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-26 22:33:56.737464 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-26 22:33:56.742752 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-26 22:33:56.749310 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-26 22:33:56.770895 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-26 22:33:56.778034 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-26 22:33:56.780202 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-26 22:33:56.787137 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-26 22:33:56.789572 (MainThread): Parsing macros/etc/query.sql
2021-02-26 22:33:56.791112 (MainThread): Parsing macros/etc/datetime.sql
2021-02-26 22:33:56.800332 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-26 22:33:56.801492 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-26 22:33:56.804086 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-26 22:33:56.807531 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-26 22:33:56.810130 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-26 22:33:56.814610 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-26 22:33:56.817333 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-26 22:33:56.819243 (MainThread): Parsing macros/adapters/common.sql
2021-02-26 22:33:56.832468 (Thread-6): handling poll request
2021-02-26 22:33:56.833187 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8293910>]}
2021-02-26 22:33:56.840866 (Thread-6): sending response (<Response 9308 bytes [200 OK]>) to 10.0.5.121
2021-02-26 22:33:56.878353 (MainThread): Partial parsing not enabled
2021-02-26 22:33:56.926751 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:33:56.950069 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-26 22:33:56.968423 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:33:56.982692 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:33:56.994597 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:33:57.009314 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:33:57.023850 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:33:57.237057 (MainThread): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-26 22:33:57.250475 (MainThread): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-26 22:33:57.365744 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6cc4c87c0>]}
2021-02-26 22:33:57.402274 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-26 22:33:57.403513 (MainThread): 
2021-02-26 22:33:57.403850 (MainThread): Acquiring new bigquery connection "master".
2021-02-26 22:33:57.415758 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-02-26 22:33:57.415933 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-26 22:33:57.628630 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-26 22:33:57.628768 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-26 22:33:57.826162 (MainThread): 22:33:57 | Concurrency: 1 threads (target='default')
2021-02-26 22:33:57.826343 (MainThread): 22:33:57 | 
2021-02-26 22:33:57.828784 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-26 22:33:57.829713 (Thread-1): 22:33:57 | 1 of 9 START view model dbt_jrosen.new_model......................... [RUN]
2021-02-26 22:33:57.829949 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:33:57.830032 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-26 22:33:57.843622 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-26 22:33:57.862432 (Thread-1): finished collecting timing info
2021-02-26 22:33:57.892857 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-02-26 22:33:57.909154 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:33:57.913493 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-02-26 22:33:58.183332 (Thread-7): handling poll request
2021-02-26 22:33:58.183752 (Thread-7): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac80ad550>]}
2021-02-26 22:33:58.187071 (Thread-7): sending response (<Response 10058 bytes [200 OK]>) to 10.0.0.148
2021-02-26 22:33:58.808361 (Thread-1): finished collecting timing info
2021-02-26 22:33:58.808991 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6cc1754c0>]}
2021-02-26 22:33:58.809961 (Thread-1): 22:33:58 | 1 of 9 OK created view model dbt_jrosen.new_model.................... [OK in 0.98s]
2021-02-26 22:33:58.810045 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-26 22:33:58.810156 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:33:58.810949 (Thread-1): 22:33:58 | 2 of 9 START table model dbt_jrosen.sightings_by_day_by_state........ [RUN]
2021-02-26 22:33:58.811172 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:33:58.811246 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:33:58.817265 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-26 22:33:58.832233 (Thread-1): finished collecting timing info
2021-02-26 22:33:58.850584 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:33:59.048741 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-26 22:33:59.065448 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-02-26 22:33:59.454774 (Thread-8): handling poll request
2021-02-26 22:33:59.455213 (Thread-8): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac811cd60>]}
2021-02-26 22:33:59.457116 (Thread-8): sending response (<Response 6148 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:34:00.855521 (Thread-9): handling poll request
2021-02-26 22:34:00.855935 (Thread-9): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac82a9820>]}
2021-02-26 22:34:00.856784 (Thread-9): sending response (<Response 284 bytes [200 OK]>) to 10.0.41.240
2021-02-26 22:34:00.904055 (Thread-1): finished collecting timing info
2021-02-26 22:34:00.904836 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6cc1bdeb0>]}
2021-02-26 22:34:00.905990 (Thread-1): 22:34:00 | 2 of 9 OK created table model dbt_jrosen.sightings_by_day_by_state... [CREATE TABLE (3.7k rows, 76.6 KB processed) in 2.09s]
2021-02-26 22:34:00.906102 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:34:00.906222 (Thread-1): Began running node model.hashpath_demo.joke
2021-02-26 22:34:00.907186 (Thread-1): 22:34:00 | 3 of 9 START view model dbt_jrosen.joke.............................. [RUN]
2021-02-26 22:34:00.907462 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.joke".
2021-02-26 22:34:00.907547 (Thread-1): Compiling model.hashpath_demo.joke
2021-02-26 22:34:00.918830 (Thread-1): Writing injected SQL for node "model.hashpath_demo.joke"
2021-02-26 22:34:00.936963 (Thread-1): finished collecting timing info
2021-02-26 22:34:00.941934 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.joke"
2021-02-26 22:34:00.960054 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:34:00.964729 (Thread-1): On model.hashpath_demo.joke: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.joke"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`joke`
  OPTIONS()
  as 




 
  On the first day of christmas my true love gave to me 
      
            a partridge in a pear tree

 
  On the second day of christmas my true love gave to me 
      
            Two turtle doves and   
            a partridge in a pear tree

 
  On the third day of christmas my true love gave to me 
      
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fourth day of christmas my true love gave to me 
      
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fifth day of christmas my true love gave to me 
      
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the sixth day of christmas my true love gave to me 
      
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the seventh day of christmas my true love gave to me 
      
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eigth day of christmas my true love gave to me 
      
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the ninth day of christmas my true love gave to me 
      
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the tenth day of christmas my true love gave to me 
      
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eleventh day of christmas my true love gave to me 
      
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the twelth day of christmas my true love gave to me 
      
            twelve drummers drumming  
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree
;


2021-02-26 22:34:01.350899 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/f5f82750-6c41-4ee8-a5c8-60ed495ea50e?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]')
2021-02-26 22:34:02.249762 (Thread-10): handling poll request
2021-02-26 22:34:02.250196 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac80a4cd0>]}
2021-02-26 22:34:02.252235 (Thread-10): sending response (<Response 9923 bytes [200 OK]>) to 10.0.7.123
2021-02-26 22:34:02.784817 (Thread-1): finished collecting timing info
2021-02-26 22:34:02.785411 (Thread-1): Database Error in model joke (models/test/joke.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
  compiled SQL at target/run/hashpath_demo/models/test/joke.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/8dcf19d5-cf7a-4b52-a5f5-0873205784b9?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]

(job ID: 8dcf19d5-cf7a-4b52-a5f5-0873205784b9)

                                                      -----Query Job SQL Follows-----                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.joke"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`joke`
   5:  OPTIONS()
   6:  as 
   7:
   8:
   9:
  10:
  11: 
  12:  On the first day of christmas my true love gave to me 
  13:      
  14:            a partridge in a pear tree
  15:
  16: 
  17:  On the second day of christmas my true love gave to me 
  18:      
  19:            Two turtle doves and   
  20:            a partridge in a pear tree
  21:
  22: 
  23:  On the third day of christmas my true love gave to me 
  24:      
  25:            Three French hens  
  26:            Two turtle doves and   
  27:            a partridge in a pear tree
  28:
  29: 
  30:  On the fourth day of christmas my true love gave to me 
  31:      
  32:            four calling birds  
  33:            Three French hens  
  34:            Two turtle doves and   
  35:            a partridge in a pear tree
  36:
  37: 
  38:  On the fifth day of christmas my true love gave to me 
  39:      
  40:            five gold rings  
  41:            four calling birds  
  42:            Three French hens  
  43:            Two turtle doves and   
  44:            a partridge in a pear tree
  45:
  46: 
  47:  On the sixth day of christmas my true love gave to me 
  48:      
  49:            six geese a-laying  
  50:            five gold rings  
  51:            four calling birds  
  52:            Three French hens  
  53:            Two turtle doves and   
  54:            a partridge in a pear tree
  55:
  56: 
  57:  On the seventh day of christmas my true love gave to me 
  58:      
  59:            seven swans a-swimming  
  60:            six geese a-laying  
  61:            five gold rings  
  62:            four calling birds  
  63:            Three French hens  
  64:            Two turtle doves and   
  65:            a partridge in a pear tree
  66:
  67: 
  68:  On the eigth day of christmas my true love gave to me 
  69:      
  70:            eight maids a-milking  
  71:            seven swans a-swimming  
  72:            six geese a-laying  
  73:            five gold rings  
  74:            four calling birds  
  75:            Three French hens  
  76:            Two turtle doves and   
  77:            a partridge in a pear tree
  78:
  79: 
  80:  On the ninth day of christmas my true love gave to me 
  81:      
  82:            nine ladies dancing  
  83:            eight maids a-milking  
  84:            seven swans a-swimming  
  85:            six geese a-laying  
  86:            five gold rings  
  87:            four calling birds  
  88:            Three French hens  
  89:            Two turtle doves and   
  90:            a partridge in a pear tree
  91:
  92: 
  93:  On the tenth day of christmas my true love gave to me 
  94:      
  95:            ten lords a-leaping  
  96:            nine ladies dancing  
  97:            eight maids a-milking  
  98:            seven swans a-swimming  
  99:            six geese a-laying  
 100:            five gold rings  
 101:            four calling birds  
 102:            Three French hens  
 103:            Two turtle doves and   
 104:            a partridge in a pear tree
 105:
 106: 
 107:  On the eleventh day of christmas my true love gave to me 
 108:      
 109:            eleven pipers piping  
 110:            ten lords a-leaping  
 111:            nine ladies dancing  
 112:            eight maids a-milking  
 113:            seven swans a-swimming  
 114:            six geese a-laying  
 115:            five gold rings  
 116:            four calling birds  
 117:            Three French hens  
 118:            Two turtle doves and   
 119:            a partridge in a pear tree
 120:
 121: 
 122:  On the twelth day of christmas my true love gave to me 
 123:      
 124:            twelve drummers drumming  
 125:            eleven pipers piping  
 126:            ten lords a-leaping  
 127:            nine ladies dancing  
 128:            eight maids a-milking  
 129:            seven swans a-swimming  
 130:            six geese a-laying  
 131:            five gold rings  
 132:            four calling birds  
 133:            Three French hens  
 134:            Two turtle doves and   
 135:            a partridge in a pear tree
 136:;
 137:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model joke (models/test/joke.sql)
  Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
  compiled SQL at target/run/hashpath_demo/models/test/joke.sql
2021-02-26 22:34:02.788911 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6cc0fc490>]}
2021-02-26 22:34:02.790527 (Thread-1): 22:34:02 | 3 of 9 ERROR creating view model dbt_jrosen.joke..................... [ERROR in 1.88s]
2021-02-26 22:34:02.790675 (Thread-1): Finished running node model.hashpath_demo.joke
2021-02-26 22:34:02.790802 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-26 22:34:02.791785 (Thread-1): 22:34:02 | 4 of 9 START table model dbt_jrosen.all_sightings.................... [RUN]
2021-02-26 22:34:02.792122 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:34:02.792210 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-26 22:34:02.804426 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-26 22:34:02.818613 (Thread-1): finished collecting timing info
2021-02-26 22:34:02.823404 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:34:03.027202 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-02-26 22:34:03.042474 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  );
    
2021-02-26 22:34:03.582542 (Thread-11): handling poll request
2021-02-26 22:34:03.582983 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac80a4070>]}
2021-02-26 22:34:03.585143 (Thread-11): sending response (<Response 19418 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:34:04.899217 (Thread-12): handling poll request
2021-02-26 22:34:04.899656 (Thread-12): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac80a4580>]}
2021-02-26 22:34:04.900542 (Thread-12): sending response (<Response 284 bytes [200 OK]>) to 10.0.0.148
2021-02-26 22:34:05.947823 (Thread-1): finished collecting timing info
2021-02-26 22:34:05.948783 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6cc0f9610>]}
2021-02-26 22:34:05.950439 (Thread-1): 22:34:05 | 4 of 9 OK created table model dbt_jrosen.all_sightings............... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 3.16s]
2021-02-26 22:34:05.950564 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-26 22:34:05.950723 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-26 22:34:05.952090 (Thread-1): 22:34:05 | 5 of 9 START table model dbt_jrosen.sightings_by_day................. [RUN]
2021-02-26 22:34:05.952415 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:34:05.952533 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-26 22:34:05.964172 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-26 22:34:05.980137 (Thread-1): finished collecting timing info
2021-02-26 22:34:05.985965 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:34:06.173281 (Thread-13): handling poll request
2021-02-26 22:34:06.173724 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac809aa00>]}
2021-02-26 22:34:06.175518 (Thread-13): sending response (<Response 4980 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:34:06.182736 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-26 22:34:06.201061 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-02-26 22:34:07.490983 (Thread-14): handling poll request
2021-02-26 22:34:07.491407 (Thread-14): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac809a130>]}
2021-02-26 22:34:07.492437 (Thread-14): sending response (<Response 1382 bytes [200 OK]>) to 10.0.47.69
2021-02-26 22:34:08.037056 (Thread-1): finished collecting timing info
2021-02-26 22:34:08.037695 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6c5b62ee0>]}
2021-02-26 22:34:08.038657 (Thread-1): 22:34:08 | 5 of 9 OK created table model dbt_jrosen.sightings_by_day............ [CREATE TABLE (2.9k rows, 57.6 KB processed) in 2.09s]
2021-02-26 22:34:08.038740 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-26 22:34:08.038850 (Thread-1): Began running node model.seth_test.viz1
2021-02-26 22:34:08.039690 (Thread-1): 22:34:08 | 6 of 9 START view model dbt_jrosen.viz1.............................. [RUN]
2021-02-26 22:34:08.039899 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-26 22:34:08.039974 (Thread-1): Compiling model.seth_test.viz1
2021-02-26 22:34:08.047532 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-26 22:34:08.061941 (Thread-1): finished collecting timing info
2021-02-26 22:34:08.066171 (Thread-1): Writing runtime SQL for node "model.seth_test.viz1"
2021-02-26 22:34:08.084701 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:34:08.089148 (Thread-1): On model.seth_test.viz1: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.seth_test.viz1"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`viz1`
  OPTIONS()
  as 

SELECT
DATE_TRUNC(date,year),
count(*)
FROM `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
WHERE date IS NOT NULL
AND date > '1960-01-01'
GROUP BY 1
ORDER BY 1 ASC;


2021-02-26 22:34:08.490839 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/5349a8e4-2431-45c2-828a-7a7aee019b04?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 1 has no name at [8:1]')
2021-02-26 22:34:08.827307 (Thread-15): handling poll request
2021-02-26 22:34:08.827728 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac809ad90>]}
2021-02-26 22:34:08.829899 (Thread-15): sending response (<Response 6348 bytes [200 OK]>) to 10.0.44.55
2021-02-26 22:34:09.268280 (Thread-1): finished collecting timing info
2021-02-26 22:34:09.268798 (Thread-1): Database Error in model viz1 (models/viz1.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [8:1]
  compiled SQL at target/run/seth_test/models/viz1.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/3af98207-b2e8-40ba-b3ee-5d622d7a73e8?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 1 has no name at [8:1]

(job ID: 3af98207-b2e8-40ba-b3ee-5d622d7a73e8)

                                                    -----Query Job SQL Follows-----                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.seth_test.viz1"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`viz1`
   5:  OPTIONS()
   6:  as 
   7:
   8:SELECT
   9:DATE_TRUNC(date,year),
  10:count(*)
  11:FROM `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  12:WHERE date IS NOT NULL
  13:AND date > '1960-01-01'
  14:GROUP BY 1
  15:ORDER BY 1 ASC;
  16:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model viz1 (models/viz1.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [8:1]
  compiled SQL at target/run/seth_test/models/viz1.sql
2021-02-26 22:34:09.269651 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6c5b2ed60>]}
2021-02-26 22:34:09.270841 (Thread-1): 22:34:09 | 6 of 9 ERROR creating view model dbt_jrosen.viz1..................... [ERROR in 1.23s]
2021-02-26 22:34:09.270930 (Thread-1): Finished running node model.seth_test.viz1
2021-02-26 22:34:09.271060 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-26 22:34:09.271880 (Thread-1): 22:34:09 | 7 of 9 START view model dbt_jrosen.demo_123.......................... [RUN]
2021-02-26 22:34:09.272095 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:34:09.272168 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-26 22:34:09.279921 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-26 22:34:09.301281 (Thread-1): finished collecting timing info
2021-02-26 22:34:09.305287 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-02-26 22:34:09.324425 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:34:09.328696 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='Utah';


2021-02-26 22:34:09.907670 (Thread-1): finished collecting timing info
2021-02-26 22:34:09.908582 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6c5b2e940>]}
2021-02-26 22:34:09.910093 (Thread-1): 22:34:09 | 7 of 9 OK created view model dbt_jrosen.demo_123..................... [OK in 0.64s]
2021-02-26 22:34:09.910229 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-26 22:34:09.910402 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-26 22:34:09.911496 (Thread-1): 22:34:09 | 8 of 9 START view model dbt_jrosen.massachusetts_sightings........... [RUN]
2021-02-26 22:34:09.911807 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:34:09.911929 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-26 22:34:09.923736 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-26 22:34:09.946709 (Thread-1): finished collecting timing info
2021-02-26 22:34:09.951205 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-26 22:34:09.966061 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:34:09.970358 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='California';


2021-02-26 22:34:10.236925 (Thread-16): handling poll request
2021-02-26 22:34:10.237350 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac809a700>]}
2021-02-26 22:34:10.240370 (Thread-16): sending response (<Response 20998 bytes [200 OK]>) to 10.0.4.19
2021-02-26 22:34:10.479608 (Thread-1): finished collecting timing info
2021-02-26 22:34:10.480221 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2203ffe0-9ae4-49ec-9613-b914b10bb250', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6c5b3eca0>]}
2021-02-26 22:34:10.483604 (Thread-1): 22:34:10 | 8 of 9 OK created view model dbt_jrosen.massachusetts_sightings...... [OK in 0.57s]
2021-02-26 22:34:10.483705 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-26 22:34:10.483814 (Thread-1): Began running node model.seth_test.viz2
2021-02-26 22:34:10.483913 (Thread-1): 22:34:10 | 9 of 9 SKIP relation dbt_jrosen.viz2................................. [SKIP]
2021-02-26 22:34:10.483988 (Thread-1): Finished running node model.seth_test.viz2
2021-02-26 22:34:10.485277 (MainThread): Acquiring new bigquery connection "master".
2021-02-26 22:34:10.485592 (MainThread): 22:34:10 | 
2021-02-26 22:34:10.485660 (MainThread): 22:34:10 | Finished running 6 view models, 3 table models in 13.08s.
2021-02-26 22:34:10.485709 (MainThread): Connection 'master' was properly closed.
2021-02-26 22:34:10.485750 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-26 22:34:10.674631 (MainThread): 
2021-02-26 22:34:10.674843 (MainThread): Completed with 2 errors and 0 warnings:
2021-02-26 22:34:10.674903 (MainThread): 
2021-02-26 22:34:10.674962 (MainThread): Database Error in model joke (models/test/joke.sql)
2021-02-26 22:34:10.675048 (MainThread):   Syntax error: Expected "(" or keyword SELECT or keyword WITH but got keyword ON at [12:3]
2021-02-26 22:34:10.675096 (MainThread):   compiled SQL at target/run/hashpath_demo/models/test/joke.sql
2021-02-26 22:34:10.675142 (MainThread): 
2021-02-26 22:34:10.675193 (MainThread): Database Error in model viz1 (models/viz1.sql)
2021-02-26 22:34:10.675237 (MainThread):   CREATE VIEW columns must be named, but column 1 has no name at [8:1]
2021-02-26 22:34:10.675277 (MainThread):   compiled SQL at target/run/seth_test/models/viz1.sql
2021-02-26 22:34:10.675340 (MainThread): 
Done. PASS=6 WARN=0 ERROR=2 SKIP=1 TOTAL=9
2021-02-26 22:34:11.559142 (Thread-17): handling poll request
2021-02-26 22:34:11.559575 (Thread-17): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac81880a0>]}
2021-02-26 22:34:11.582585 (Thread-17): sending response (<Response 32852 bytes [200 OK]>) to 10.0.5.121
2021-02-26 22:34:11.866122 (Thread-18): handling status request
2021-02-26 22:34:11.866574 (Thread-18): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8177340>]}
2021-02-26 22:34:11.870568 (Thread-18): sending response (<Response 12016 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:34:48.641338 (Thread-19): handling status request
2021-02-26 22:34:48.643626 (Thread-19): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8177970>]}
2021-02-26 22:34:48.647430 (Thread-19): sending response (<Response 12016 bytes [200 OK]>) to 10.0.11.216
2021-02-26 22:34:48.977650 (Thread-20): handling run_sql request
2021-02-26 22:34:48.978207 (Thread-20): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac81800a0>]}
2021-02-26 22:34:49.861567 (Thread-20): sending response (<Response 136 bytes [200 OK]>) to 10.0.47.69
2021-02-26 22:34:49.925620 (MainThread): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-02-26 22:34:49.950836 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-26 22:34:49.951313 (Thread-1): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-02-26 22:34:49.951429 (Thread-1): Compiling rpc.hashpath_demo.request
2021-02-26 22:34:49.979736 (Thread-1): finished collecting timing info
2021-02-26 22:34:49.980133 (Thread-1): Opening a new connection, currently in state init
2021-02-26 22:34:49.987180 (Thread-1): On rpc.hashpath_demo.request: 




 
  On the first day of christmas my true love gave to me 
      
            a partridge in a pear tree

 
  On the second day of christmas my true love gave to me 
      
            Two turtle doves and   
            a partridge in a pear tree

 
  On the third day of christmas my true love gave to me 
      
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fourth day of christmas my true love gave to me 
      
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fifth day of christmas my true love gave to me 
      
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the sixth day of christmas my true love gave to me 
      
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the seventh day of christmas my true love gave to me 
      
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eigth day of christmas my true love gave to me 
      
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the ninth day of christmas my true love gave to me 
      
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the tenth day of christmas my true love gave to me 
      
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eleventh day of christmas my true love gave to me 
      
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the twelth day of christmas my true love gave to me 
      
            twelve drummers drumming  
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

limit 500
/* limit added automatically by dbt cloud */
2021-02-26 22:34:50.245144 (Thread-21): handling poll request
2021-02-26 22:34:50.245599 (Thread-21): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac818b9a0>]}
2021-02-26 22:34:50.247563 (Thread-21): sending response (<Response 6241 bytes [200 OK]>) to 10.0.7.123
2021-02-26 22:34:50.389748 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/c8a55959-4917-4418-9e7c-97035d2be0d5?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got keyword ON at [7:3]')
2021-02-26 22:34:51.057708 (Thread-1): finished collecting timing info
2021-02-26 22:34:51.058165 (Thread-1): Got an exception: Database Error
  Syntax error: Expected end of input but got keyword ON at [7:3]
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/f72aa172-2840-459b-93f6-9075e80f4034?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got keyword ON at [7:3]

(job ID: f72aa172-2840-459b-93f6-9075e80f4034)

                -----Query Job SQL Follows-----                 

    |    .    |    .    |    .    |    .    |    .    |
   1:
   2:
   3:
   4:
   5:
   6: 
   7:  On the first day of christmas my true love gave to me 
   8:      
   9:            a partridge in a pear tree
  10:
  11: 
  12:  On the second day of christmas my true love gave to me 
  13:      
  14:            Two turtle doves and   
  15:            a partridge in a pear tree
  16:
  17: 
  18:  On the third day of christmas my true love gave to me 
  19:      
  20:            Three French hens  
  21:            Two turtle doves and   
  22:            a partridge in a pear tree
  23:
  24: 
  25:  On the fourth day of christmas my true love gave to me 
  26:      
  27:            four calling birds  
  28:            Three French hens  
  29:            Two turtle doves and   
  30:            a partridge in a pear tree
  31:
  32: 
  33:  On the fifth day of christmas my true love gave to me 
  34:      
  35:            five gold rings  
  36:            four calling birds  
  37:            Three French hens  
  38:            Two turtle doves and   
  39:            a partridge in a pear tree
  40:
  41: 
  42:  On the sixth day of christmas my true love gave to me 
  43:      
  44:            six geese a-laying  
  45:            five gold rings  
  46:            four calling birds  
  47:            Three French hens  
  48:            Two turtle doves and   
  49:            a partridge in a pear tree
  50:
  51: 
  52:  On the seventh day of christmas my true love gave to me 
  53:      
  54:            seven swans a-swimming  
  55:            six geese a-laying  
  56:            five gold rings  
  57:            four calling birds  
  58:            Three French hens  
  59:            Two turtle doves and   
  60:            a partridge in a pear tree
  61:
  62: 
  63:  On the eigth day of christmas my true love gave to me 
  64:      
  65:            eight maids a-milking  
  66:            seven swans a-swimming  
  67:            six geese a-laying  
  68:            five gold rings  
  69:            four calling birds  
  70:            Three French hens  
  71:            Two turtle doves and   
  72:            a partridge in a pear tree
  73:
  74: 
  75:  On the ninth day of christmas my true love gave to me 
  76:      
  77:            nine ladies dancing  
  78:            eight maids a-milking  
  79:            seven swans a-swimming  
  80:            six geese a-laying  
  81:            five gold rings  
  82:            four calling birds  
  83:            Three French hens  
  84:            Two turtle doves and   
  85:            a partridge in a pear tree
  86:
  87: 
  88:  On the tenth day of christmas my true love gave to me 
  89:      
  90:            ten lords a-leaping  
  91:            nine ladies dancing  
  92:            eight maids a-milking  
  93:            seven swans a-swimming  
  94:            six geese a-laying  
  95:            five gold rings  
  96:            four calling birds  
  97:            Three French hens  
  98:            Two turtle doves and   
  99:            a partridge in a pear tree
 100:
 101: 
 102:  On the eleventh day of christmas my true love gave to me 
 103:      
 104:            eleven pipers piping  
 105:            ten lords a-leaping  
 106:            nine ladies dancing  
 107:            eight maids a-milking  
 108:            seven swans a-swimming  
 109:            six geese a-laying  
 110:            five gold rings  
 111:            four calling birds  
 112:            Three French hens  
 113:            Two turtle doves and   
 114:            a partridge in a pear tree
 115:
 116: 
 117:  On the twelth day of christmas my true love gave to me 
 118:      
 119:            twelve drummers drumming  
 120:            eleven pipers piping  
 121:            ten lords a-leaping  
 122:            nine ladies dancing  
 123:            eight maids a-milking  
 124:            seven swans a-swimming  
 125:            six geese a-laying  
 126:            five gold rings  
 127:            four calling birds  
 128:            Three French hens  
 129:            Two turtle doves and   
 130:            a partridge in a pear tree
 131:
 132:limit 500
 133:/* limit added automatically by dbt cloud */
    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Syntax error: Expected end of input but got keyword ON at [7:3]
2021-02-26 22:34:51.061065 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Syntax error: Expected end of input but got keyword ON at [7:3]', 'raw_sql': '{% set gifts = ["a partridge in a pear tree", "Two turtle doves", "Three French hens","four calling birds","five gold rings","six geese a-laying","seven swans a-swimming"\n,"eight maids a-milking","nine ladies dancing","ten lords a-leaping","eleven pipers piping","twelve drummers drumming"] %}\n\n{% set days = ["first", "second", "third","fourth","fifth","sixth","seventh"\n,"eigth","ninth","tenth","eleventh","twelth"] %}\n\n{% for day in days %}\n {% set outerloop = loop %}\n  On the {{day}} day of christmas my true love gave to me \n    {% for gift in gifts  | reverse %}\n     {%- set innerloop = loop -%}\n        {%- if 13 - innerloop.index   <= outerloop.index -%}\n           {% if innerloop.last and not outerloop.first %} and {% endif %}  \n            {{ gift }} \n        {%- endif  -%}    \n    {% endfor %}\n{% endfor %}\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\n\n\n\n \n  On the first day of christmas my true love gave to me \n      \n            a partridge in a pear tree\n\n \n  On the second day of christmas my true love gave to me \n      \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the third day of christmas my true love gave to me \n      \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the fourth day of christmas my true love gave to me \n      \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the fifth day of christmas my true love gave to me \n      \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the sixth day of christmas my true love gave to me \n      \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the seventh day of christmas my true love gave to me \n      \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the eigth day of christmas my true love gave to me \n      \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the ninth day of christmas my true love gave to me \n      \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the tenth day of christmas my true love gave to me \n      \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the eleventh day of christmas my true love gave to me \n      \n            eleven pipers piping  \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the twelth day of christmas my true love gave to me \n      \n            twelve drummers drumming  \n            eleven pipers piping  \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/sql_commands.py", line 145, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 360, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/node_runners.py", line 56, in error_result
    raise error
dbt.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Syntax error: Expected end of input but got keyword ON at [7:3]', 'raw_sql': '{% set gifts = ["a partridge in a pear tree", "Two turtle doves", "Three French hens","four calling birds","five gold rings","six geese a-laying","seven swans a-swimming"\n,"eight maids a-milking","nine ladies dancing","ten lords a-leaping","eleven pipers piping","twelve drummers drumming"] %}\n\n{% set days = ["first", "second", "third","fourth","fifth","sixth","seventh"\n,"eigth","ninth","tenth","eleventh","twelth"] %}\n\n{% for day in days %}\n {% set outerloop = loop %}\n  On the {{day}} day of christmas my true love gave to me \n    {% for gift in gifts  | reverse %}\n     {%- set innerloop = loop -%}\n        {%- if 13 - innerloop.index   <= outerloop.index -%}\n           {% if innerloop.last and not outerloop.first %} and {% endif %}  \n            {{ gift }} \n        {%- endif  -%}    \n    {% endfor %}\n{% endfor %}\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\n\n\n\n \n  On the first day of christmas my true love gave to me \n      \n            a partridge in a pear tree\n\n \n  On the second day of christmas my true love gave to me \n      \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the third day of christmas my true love gave to me \n      \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the fourth day of christmas my true love gave to me \n      \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the fifth day of christmas my true love gave to me \n      \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the sixth day of christmas my true love gave to me \n      \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the seventh day of christmas my true love gave to me \n      \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the eigth day of christmas my true love gave to me \n      \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the ninth day of christmas my true love gave to me \n      \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the tenth day of christmas my true love gave to me \n      \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the eleventh day of christmas my true love gave to me \n      \n            eleven pipers piping  \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the twelth day of christmas my true love gave to me \n      \n            twelve drummers drumming  \n            eleven pipers piping  \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2021-02-26 22:34:51.625746 (Thread-22): handling poll request
2021-02-26 22:34:51.626188 (Thread-22): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac818b8b0>]}
2021-02-26 22:34:51.627171 (Thread-22): sending response (<Response 32609 bytes [200 OK]>) to 10.0.4.19
2021-02-26 22:35:15.023658 (Thread-23): handling status request
2021-02-26 22:35:15.024111 (Thread-23): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac818bf70>]}
2021-02-26 22:35:15.028205 (Thread-23): sending response (<Response 12016 bytes [200 OK]>) to 10.0.3.75
2021-02-26 22:35:15.340308 (Thread-24): handling run_sql request
2021-02-26 22:35:15.340749 (Thread-24): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac818bd60>]}
2021-02-26 22:35:16.229295 (Thread-24): sending response (<Response 136 bytes [200 OK]>) to 10.0.15.46
2021-02-26 22:35:16.279721 (MainThread): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-02-26 22:35:16.301931 (MainThread): Found 9 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-26 22:35:16.302366 (Thread-1): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-02-26 22:35:16.302471 (Thread-1): Compiling rpc.hashpath_demo.request
2021-02-26 22:35:16.320494 (Thread-1): finished collecting timing info
2021-02-26 22:35:16.320745 (Thread-1): Opening a new connection, currently in state init
2021-02-26 22:35:16.325127 (Thread-1): On rpc.hashpath_demo.request: 




 
  On the first day of christmas my true love gave to me 
      
            a partridge in a pear tree

 
  On the second day of christmas my true love gave to me 
      
            Two turtle doves and   
            a partridge in a pear tree

 
  On the third day of christmas my true love gave to me 
      
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fourth day of christmas my true love gave to me 
      
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the fifth day of christmas my true love gave to me 
      
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the sixth day of christmas my true love gave to me 
      
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the seventh day of christmas my true love gave to me 
      
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eigth day of christmas my true love gave to me 
      
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the ninth day of christmas my true love gave to me 
      
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the tenth day of christmas my true love gave to me 
      
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the eleventh day of christmas my true love gave to me 
      
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

 
  On the twelth day of christmas my true love gave to me 
      
            twelve drummers drumming  
            eleven pipers piping  
            ten lords a-leaping  
            nine ladies dancing  
            eight maids a-milking  
            seven swans a-swimming  
            six geese a-laying  
            five gold rings  
            four calling birds  
            Three French hens  
            Two turtle doves and   
            a partridge in a pear tree

limit 500
/* limit added automatically by dbt cloud */
2021-02-26 22:35:16.483783 (Thread-25): handling poll request
2021-02-26 22:35:16.484319 (Thread-25): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac82467f0>]}
2021-02-26 22:35:16.486301 (Thread-25): sending response (<Response 6241 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:35:16.913044 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/2ba41de4-7ffc-4f32-83b2-b8531f429be1?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got keyword ON at [7:3]')
2021-02-26 22:35:18.221024 (Thread-26): handling poll request
2021-02-26 22:35:18.221458 (Thread-26): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac82464c0>]}
2021-02-26 22:35:18.222457 (Thread-26): sending response (<Response 886 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:35:18.453185 (Thread-1): finished collecting timing info
2021-02-26 22:35:18.453515 (Thread-1): Got an exception: Database Error
  Syntax error: Expected end of input but got keyword ON at [7:3]
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/c14ed5fd-cdbc-44ae-8423-fc576b7d6005?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected end of input but got keyword ON at [7:3]

(job ID: c14ed5fd-cdbc-44ae-8423-fc576b7d6005)

                -----Query Job SQL Follows-----                 

    |    .    |    .    |    .    |    .    |    .    |
   1:
   2:
   3:
   4:
   5:
   6: 
   7:  On the first day of christmas my true love gave to me 
   8:      
   9:            a partridge in a pear tree
  10:
  11: 
  12:  On the second day of christmas my true love gave to me 
  13:      
  14:            Two turtle doves and   
  15:            a partridge in a pear tree
  16:
  17: 
  18:  On the third day of christmas my true love gave to me 
  19:      
  20:            Three French hens  
  21:            Two turtle doves and   
  22:            a partridge in a pear tree
  23:
  24: 
  25:  On the fourth day of christmas my true love gave to me 
  26:      
  27:            four calling birds  
  28:            Three French hens  
  29:            Two turtle doves and   
  30:            a partridge in a pear tree
  31:
  32: 
  33:  On the fifth day of christmas my true love gave to me 
  34:      
  35:            five gold rings  
  36:            four calling birds  
  37:            Three French hens  
  38:            Two turtle doves and   
  39:            a partridge in a pear tree
  40:
  41: 
  42:  On the sixth day of christmas my true love gave to me 
  43:      
  44:            six geese a-laying  
  45:            five gold rings  
  46:            four calling birds  
  47:            Three French hens  
  48:            Two turtle doves and   
  49:            a partridge in a pear tree
  50:
  51: 
  52:  On the seventh day of christmas my true love gave to me 
  53:      
  54:            seven swans a-swimming  
  55:            six geese a-laying  
  56:            five gold rings  
  57:            four calling birds  
  58:            Three French hens  
  59:            Two turtle doves and   
  60:            a partridge in a pear tree
  61:
  62: 
  63:  On the eigth day of christmas my true love gave to me 
  64:      
  65:            eight maids a-milking  
  66:            seven swans a-swimming  
  67:            six geese a-laying  
  68:            five gold rings  
  69:            four calling birds  
  70:            Three French hens  
  71:            Two turtle doves and   
  72:            a partridge in a pear tree
  73:
  74: 
  75:  On the ninth day of christmas my true love gave to me 
  76:      
  77:            nine ladies dancing  
  78:            eight maids a-milking  
  79:            seven swans a-swimming  
  80:            six geese a-laying  
  81:            five gold rings  
  82:            four calling birds  
  83:            Three French hens  
  84:            Two turtle doves and   
  85:            a partridge in a pear tree
  86:
  87: 
  88:  On the tenth day of christmas my true love gave to me 
  89:      
  90:            ten lords a-leaping  
  91:            nine ladies dancing  
  92:            eight maids a-milking  
  93:            seven swans a-swimming  
  94:            six geese a-laying  
  95:            five gold rings  
  96:            four calling birds  
  97:            Three French hens  
  98:            Two turtle doves and   
  99:            a partridge in a pear tree
 100:
 101: 
 102:  On the eleventh day of christmas my true love gave to me 
 103:      
 104:            eleven pipers piping  
 105:            ten lords a-leaping  
 106:            nine ladies dancing  
 107:            eight maids a-milking  
 108:            seven swans a-swimming  
 109:            six geese a-laying  
 110:            five gold rings  
 111:            four calling birds  
 112:            Three French hens  
 113:            Two turtle doves and   
 114:            a partridge in a pear tree
 115:
 116: 
 117:  On the twelth day of christmas my true love gave to me 
 118:      
 119:            twelve drummers drumming  
 120:            eleven pipers piping  
 121:            ten lords a-leaping  
 122:            nine ladies dancing  
 123:            eight maids a-milking  
 124:            seven swans a-swimming  
 125:            six geese a-laying  
 126:            five gold rings  
 127:            four calling birds  
 128:            Three French hens  
 129:            Two turtle doves and   
 130:            a partridge in a pear tree
 131:
 132:limit 500
 133:/* limit added automatically by dbt cloud */
    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Syntax error: Expected end of input but got keyword ON at [7:3]
2021-02-26 22:35:18.456056 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Syntax error: Expected end of input but got keyword ON at [7:3]', 'raw_sql': '{% set gifts = ["a partridge in a pear tree", "Two turtle doves", "Three French hens","four calling birds","five gold rings","six geese a-laying","seven swans a-swimming"\n,"eight maids a-milking","nine ladies dancing","ten lords a-leaping","eleven pipers piping","twelve drummers drumming"] %}\n\n{% set days = ["first", "second", "third","fourth","fifth","sixth","seventh","eigth","ninth","tenth","eleventh","twelth"] %}\n\n{% for day in days %}\n {% set outerloop = loop %}\n  On the {{day}} day of christmas my true love gave to me \n    {% for gift in gifts  | reverse %}\n     {%- set innerloop = loop -%}\n        {%- if 13 - innerloop.index   <= outerloop.index -%}\n           {% if innerloop.last and not outerloop.first %} and {% endif %}  \n            {{ gift }} \n        {%- endif  -%}    \n    {% endfor %}\n{% endfor %}\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\n\n\n\n \n  On the first day of christmas my true love gave to me \n      \n            a partridge in a pear tree\n\n \n  On the second day of christmas my true love gave to me \n      \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the third day of christmas my true love gave to me \n      \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the fourth day of christmas my true love gave to me \n      \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the fifth day of christmas my true love gave to me \n      \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the sixth day of christmas my true love gave to me \n      \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the seventh day of christmas my true love gave to me \n      \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the eigth day of christmas my true love gave to me \n      \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the ninth day of christmas my true love gave to me \n      \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the tenth day of christmas my true love gave to me \n      \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the eleventh day of christmas my true love gave to me \n      \n            eleven pipers piping  \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the twelth day of christmas my true love gave to me \n      \n            twelve drummers drumming  \n            eleven pipers piping  \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/sql_commands.py", line 145, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 360, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/node_runners.py", line 56, in error_result
    raise error
dbt.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Syntax error: Expected end of input but got keyword ON at [7:3]', 'raw_sql': '{% set gifts = ["a partridge in a pear tree", "Two turtle doves", "Three French hens","four calling birds","five gold rings","six geese a-laying","seven swans a-swimming"\n,"eight maids a-milking","nine ladies dancing","ten lords a-leaping","eleven pipers piping","twelve drummers drumming"] %}\n\n{% set days = ["first", "second", "third","fourth","fifth","sixth","seventh","eigth","ninth","tenth","eleventh","twelth"] %}\n\n{% for day in days %}\n {% set outerloop = loop %}\n  On the {{day}} day of christmas my true love gave to me \n    {% for gift in gifts  | reverse %}\n     {%- set innerloop = loop -%}\n        {%- if 13 - innerloop.index   <= outerloop.index -%}\n           {% if innerloop.last and not outerloop.first %} and {% endif %}  \n            {{ gift }} \n        {%- endif  -%}    \n    {% endfor %}\n{% endfor %}\nlimit 500\n/* limit added automatically by dbt cloud */', 'compiled_sql': '\n\n\n\n\n \n  On the first day of christmas my true love gave to me \n      \n            a partridge in a pear tree\n\n \n  On the second day of christmas my true love gave to me \n      \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the third day of christmas my true love gave to me \n      \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the fourth day of christmas my true love gave to me \n      \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the fifth day of christmas my true love gave to me \n      \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the sixth day of christmas my true love gave to me \n      \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the seventh day of christmas my true love gave to me \n      \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the eigth day of christmas my true love gave to me \n      \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the ninth day of christmas my true love gave to me \n      \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the tenth day of christmas my true love gave to me \n      \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the eleventh day of christmas my true love gave to me \n      \n            eleven pipers piping  \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\n \n  On the twelth day of christmas my true love gave to me \n      \n            twelve drummers drumming  \n            eleven pipers piping  \n            ten lords a-leaping  \n            nine ladies dancing  \n            eight maids a-milking  \n            seven swans a-swimming  \n            six geese a-laying  \n            five gold rings  \n            four calling birds  \n            Three French hens  \n            Two turtle doves and   \n            a partridge in a pear tree\n\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2021-02-26 22:35:19.627810 (Thread-27): handling poll request
2021-02-26 22:35:19.628252 (Thread-27): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8246640>]}
2021-02-26 22:35:19.629212 (Thread-27): sending response (<Response 32601 bytes [200 OK]>) to 10.0.15.121
2021-02-26 22:35:43.585636 (Thread-28): Got an acceptable cached parse result
2021-02-26 22:35:43.854518 (Thread-28): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac37e0760>]}
2021-02-26 22:35:44.007716 (Thread-29): handling status request
2021-02-26 22:35:44.008148 (Thread-29): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac379a6a0>]}
2021-02-26 22:35:44.033158 (Thread-29): sending response (<Response 883 bytes [200 OK]>) to 10.0.32.128
2021-02-26 22:39:48.938423 (Thread-30): handling ps request
2021-02-26 22:39:48.939121 (Thread-31): handling status request
2021-02-26 22:39:48.939594 (Thread-30): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac81dec10>]}
2021-02-26 22:39:48.939939 (Thread-31): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8210f40>]}
2021-02-26 22:39:48.942249 (Thread-30): sending response (<Response 1485 bytes [200 OK]>) to 10.0.22.116
2021-02-26 22:39:48.943158 (Thread-31): sending response (<Response 883 bytes [200 OK]>) to 10.0.41.240
2021-02-26 22:39:49.287924 (Thread-32): handling poll request
2021-02-26 22:39:49.288344 (Thread-32): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac81d3a30>]}
2021-02-26 22:39:49.321177 (Thread-32): sending response (<Response 118873 bytes [200 OK]>) to 10.0.41.240
2021-02-26 22:39:49.629442 (Thread-33): handling status request
2021-02-26 22:39:49.629875 (Thread-33): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8180070>]}
2021-02-26 22:39:49.630769 (Thread-33): sending response (<Response 883 bytes [200 OK]>) to 10.0.15.46
2021-02-26 22:40:10.849106 (Thread-34): handling status request
2021-02-26 22:40:10.849545 (Thread-34): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac81def10>]}
2021-02-26 22:40:10.850451 (Thread-34): sending response (<Response 883 bytes [200 OK]>) to 10.0.0.148
2021-02-26 22:40:22.616898 (Thread-35): Parsing macros/adapters.sql
2021-02-26 22:40:22.636932 (Thread-35): Parsing macros/etc.sql
2021-02-26 22:40:22.639263 (Thread-35): Parsing macros/catalog.sql
2021-02-26 22:40:22.646674 (Thread-35): Parsing macros/materializations/copy.sql
2021-02-26 22:40:22.651456 (Thread-35): Parsing macros/materializations/table.sql
2021-02-26 22:40:22.661754 (Thread-35): Parsing macros/materializations/incremental.sql
2021-02-26 22:40:22.674446 (Thread-35): Parsing macros/materializations/seed.sql
2021-02-26 22:40:22.677488 (Thread-35): Parsing macros/materializations/snapshot.sql
2021-02-26 22:40:22.679344 (Thread-35): Parsing macros/materializations/view.sql
2021-02-26 22:40:22.682846 (Thread-35): Parsing macros/core.sql
2021-02-26 22:40:22.686691 (Thread-35): Parsing macros/materializations/helpers.sql
2021-02-26 22:40:22.695756 (Thread-35): Parsing macros/materializations/common/merge.sql
2021-02-26 22:40:22.715156 (Thread-35): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-26 22:40:22.717705 (Thread-35): Parsing macros/materializations/snapshot/strategies.sql
2021-02-26 22:40:22.736021 (Thread-35): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-26 22:40:22.767403 (Thread-35): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-26 22:40:22.776253 (Thread-35): Parsing macros/materializations/view/view.sql
2021-02-26 22:40:22.783037 (Thread-35): Parsing macros/materializations/seed/seed.sql
2021-02-26 22:40:22.803770 (Thread-35): Parsing macros/materializations/table/table.sql
2021-02-26 22:40:22.810331 (Thread-35): Parsing macros/materializations/incremental/helpers.sql
2021-02-26 22:40:22.812185 (Thread-35): Parsing macros/materializations/incremental/incremental.sql
2021-02-26 22:40:22.818017 (Thread-35): Parsing macros/etc/is_incremental.sql
2021-02-26 22:40:22.819628 (Thread-35): Parsing macros/etc/query.sql
2021-02-26 22:40:22.820671 (Thread-35): Parsing macros/etc/datetime.sql
2021-02-26 22:40:22.829292 (Thread-35): Parsing macros/etc/get_custom_alias.sql
2021-02-26 22:40:22.830223 (Thread-35): Parsing macros/etc/get_custom_database.sql
2021-02-26 22:40:22.831871 (Thread-35): Parsing macros/etc/get_custom_schema.sql
2021-02-26 22:40:22.833812 (Thread-35): Parsing macros/schema_tests/not_null.sql
2021-02-26 22:40:22.835331 (Thread-35): Parsing macros/schema_tests/accepted_values.sql
2021-02-26 22:40:22.837963 (Thread-35): Parsing macros/schema_tests/relationships.sql
2021-02-26 22:40:22.839834 (Thread-35): Parsing macros/schema_tests/unique.sql
2021-02-26 22:40:22.841556 (Thread-35): Parsing macros/adapters/common.sql
2021-02-26 22:40:22.886488 (Thread-36): handling status request
2021-02-26 22:40:22.892124 (Thread-36): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac35c53d0>]}
2021-02-26 22:40:22.895191 (Thread-36): sending response (<Response 183 bytes [200 OK]>) to 10.0.32.128
2021-02-26 22:40:22.948567 (Thread-35): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:40:22.964329 (Thread-35): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:40:22.978734 (Thread-35): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:40:22.991133 (Thread-35): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:40:23.007262 (Thread-35): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:40:23.029057 (Thread-35): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:40:23.347854 (Thread-35): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-26 22:40:23.362163 (Thread-35): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-26 22:40:23.464882 (Thread-35): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac34e42e0>]}
2021-02-26 22:40:24.167634 (Thread-37): handling status request
2021-02-26 22:40:24.168125 (Thread-37): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac831b400>]}
2021-02-26 22:40:24.172071 (Thread-37): sending response (<Response 11764 bytes [200 OK]>) to 10.0.22.116
2021-02-26 22:51:49.851647 (Thread-38): handling status request
2021-02-26 22:51:49.852254 (Thread-38): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac34f56a0>]}
2021-02-26 22:51:49.852849 (Thread-39): handling ps request
2021-02-26 22:51:49.856926 (Thread-38): sending response (<Response 11764 bytes [200 OK]>) to 10.0.5.121
2021-02-26 22:51:49.857426 (Thread-39): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac34dba90>]}
2021-02-26 22:51:49.859268 (Thread-39): sending response (<Response 1485 bytes [200 OK]>) to 10.0.3.75
2021-02-26 22:51:50.147562 (Thread-40): handling poll request
2021-02-26 22:51:50.148005 (Thread-40): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac34e6e20>]}
2021-02-26 22:51:50.181382 (Thread-40): sending response (<Response 118873 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:51:50.506362 (Thread-41): handling status request
2021-02-26 22:51:50.506835 (Thread-41): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8ef3c70>]}
2021-02-26 22:51:50.510706 (Thread-41): sending response (<Response 11764 bytes [200 OK]>) to 10.0.15.46
2021-02-26 22:52:21.413043 (MainThread): Connection 'model.seth_test.viz2' was properly closed.
2021-02-26 22:52:21.488924 (Thread-42): Got an acceptable cached parse result
2021-02-26 22:52:21.683800 (Thread-43): handling status request
2021-02-26 22:52:21.684208 (Thread-43): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac37bed60>]}
2021-02-26 22:52:21.684900 (Thread-43): sending response (<Response 183 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:52:21.759106 (Thread-42): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac377b7f0>]}
2021-02-26 22:52:22.970382 (Thread-44): handling status request
2021-02-26 22:52:22.970802 (Thread-44): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac81729a0>]}
2021-02-26 22:52:22.971729 (Thread-44): sending response (<Response 883 bytes [200 OK]>) to 10.0.22.116
2021-02-26 22:52:24.289930 (Thread-45): handling status request
2021-02-26 22:52:24.290381 (Thread-45): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac348d2e0>]}
2021-02-26 22:52:24.291320 (Thread-45): sending response (<Response 883 bytes [200 OK]>) to 10.0.7.123
2021-02-26 22:52:24.307318 (Thread-46): handling status request
2021-02-26 22:52:24.307648 (Thread-46): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac815e730>]}
2021-02-26 22:52:24.308387 (Thread-46): sending response (<Response 883 bytes [200 OK]>) to 10.0.5.121
2021-02-26 22:52:24.622102 (Thread-47): handling cli_args request
2021-02-26 22:52:24.622529 (Thread-47): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac348d160>]}
2021-02-26 22:52:25.540194 (Thread-47): sending response (<Response 136 bytes [200 OK]>) to 10.0.32.128
2021-02-26 22:52:25.625169 (MainThread): Partial parsing not enabled
2021-02-26 22:52:25.627693 (MainThread): Parsing macros/adapters.sql
2021-02-26 22:52:25.647090 (MainThread): Parsing macros/etc.sql
2021-02-26 22:52:25.649163 (MainThread): Parsing macros/catalog.sql
2021-02-26 22:52:25.655095 (MainThread): Parsing macros/materializations/copy.sql
2021-02-26 22:52:25.659642 (MainThread): Parsing macros/materializations/table.sql
2021-02-26 22:52:25.669324 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-26 22:52:25.682074 (MainThread): Parsing macros/materializations/seed.sql
2021-02-26 22:52:25.684791 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-26 22:52:25.686592 (MainThread): Parsing macros/materializations/view.sql
2021-02-26 22:52:25.690061 (MainThread): Parsing macros/core.sql
2021-02-26 22:52:25.693927 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-26 22:52:25.702778 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-26 22:52:25.716551 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-26 22:52:25.718340 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-26 22:52:25.735607 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-26 22:52:25.766437 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-26 22:52:25.771352 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-26 22:52:25.777537 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-26 22:52:25.801253 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-26 22:52:25.807847 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-26 22:52:25.809705 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-26 22:52:25.815694 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-26 22:52:25.817312 (MainThread): Parsing macros/etc/query.sql
2021-02-26 22:52:25.818455 (MainThread): Parsing macros/etc/datetime.sql
2021-02-26 22:52:25.824546 (Thread-48): handling poll request
2021-02-26 22:52:25.825025 (Thread-48): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac82bd850>]}
2021-02-26 22:52:25.828587 (Thread-48): sending response (<Response 7152 bytes [200 OK]>) to 10.0.15.121
2021-02-26 22:52:25.827212 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-26 22:52:25.828225 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-26 22:52:25.829964 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-26 22:52:25.831957 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-26 22:52:25.833514 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-26 22:52:25.836217 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-26 22:52:25.838104 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-26 22:52:25.839959 (MainThread): Parsing macros/adapters/common.sql
2021-02-26 22:52:25.891472 (MainThread): Partial parsing not enabled
2021-02-26 22:52:25.937312 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:52:25.959976 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:52:25.972814 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:52:25.984564 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:52:25.998513 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:52:26.012315 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:52:26.220493 (MainThread): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-26 22:52:26.233816 (MainThread): Acquiring new bigquery connection "model.seth_test.viz2".
2021-02-26 22:52:26.337237 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6257a813-7125-4115-91f5-86ec7207fddf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3519141c0>]}
2021-02-26 22:52:26.373630 (MainThread): Found 8 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-26 22:52:26.374544 (MainThread): 
2021-02-26 22:52:26.374805 (MainThread): Acquiring new bigquery connection "master".
2021-02-26 22:52:26.383756 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-02-26 22:52:26.383874 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-26 22:52:26.593223 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-26 22:52:26.593356 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-26 22:52:26.812720 (MainThread): 22:52:26 | Concurrency: 1 threads (target='default')
2021-02-26 22:52:26.812862 (MainThread): 22:52:26 | 
2021-02-26 22:52:26.815043 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-26 22:52:26.816406 (Thread-1): 22:52:26 | 1 of 8 START view model dbt_jrosen.new_model......................... [RUN]
2021-02-26 22:52:26.816716 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:52:26.816803 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-26 22:52:26.831360 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-26 22:52:26.847011 (Thread-1): finished collecting timing info
2021-02-26 22:52:26.879924 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-02-26 22:52:26.896318 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:52:26.901435 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-02-26 22:52:27.116372 (Thread-49): handling poll request
2021-02-26 22:52:27.116814 (Thread-49): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac82cc2b0>]}
2021-02-26 22:52:27.120470 (Thread-49): sending response (<Response 11980 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:52:27.951337 (Thread-1): finished collecting timing info
2021-02-26 22:52:27.951960 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6257a813-7125-4115-91f5-86ec7207fddf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd351960c10>]}
2021-02-26 22:52:27.952971 (Thread-1): 22:52:27 | 1 of 8 OK created view model dbt_jrosen.new_model.................... [OK in 1.14s]
2021-02-26 22:52:27.953064 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-26 22:52:27.953177 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:52:27.954015 (Thread-1): 22:52:27 | 2 of 8 START table model dbt_jrosen.sightings_by_day_by_state........ [RUN]
2021-02-26 22:52:27.954240 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:52:27.954316 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:52:27.960588 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-26 22:52:27.980578 (Thread-1): finished collecting timing info
2021-02-26 22:52:27.996972 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:52:28.192938 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-26 22:52:28.207574 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-02-26 22:52:28.420540 (Thread-50): handling poll request
2021-02-26 22:52:28.421046 (Thread-50): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac37bee50>]}
2021-02-26 22:52:28.423239 (Thread-50): sending response (<Response 6161 bytes [200 OK]>) to 10.0.11.216
2021-02-26 22:52:29.837268 (Thread-51): handling poll request
2021-02-26 22:52:29.837687 (Thread-51): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8168df0>]}
2021-02-26 22:52:29.838561 (Thread-51): sending response (<Response 284 bytes [200 OK]>) to 10.0.7.123
2021-02-26 22:52:30.054033 (Thread-1): finished collecting timing info
2021-02-26 22:52:30.054653 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6257a813-7125-4115-91f5-86ec7207fddf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd351999f70>]}
2021-02-26 22:52:30.055794 (Thread-1): 22:52:30 | 2 of 8 OK created table model dbt_jrosen.sightings_by_day_by_state... [CREATE TABLE (3.7k rows, 76.6 KB processed) in 2.10s]
2021-02-26 22:52:30.055884 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:52:30.055992 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-26 22:52:30.056773 (Thread-1): 22:52:30 | 3 of 8 START table model dbt_jrosen.all_sightings.................... [RUN]
2021-02-26 22:52:30.056979 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:52:30.057053 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-26 22:52:30.066633 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-26 22:52:30.080982 (Thread-1): finished collecting timing info
2021-02-26 22:52:30.084685 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:52:30.282711 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-02-26 22:52:30.299407 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  );
    
2021-02-26 22:52:31.136778 (Thread-52): handling poll request
2021-02-26 22:52:31.137198 (Thread-52): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8299b80>]}
2021-02-26 22:52:31.139117 (Thread-52): sending response (<Response 6099 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:52:32.452329 (Thread-53): handling poll request
2021-02-26 22:52:32.452788 (Thread-53): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac35f64f0>]}
2021-02-26 22:52:32.453705 (Thread-53): sending response (<Response 284 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:52:32.563122 (Thread-1): finished collecting timing info
2021-02-26 22:52:32.563887 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6257a813-7125-4115-91f5-86ec7207fddf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35022aa60>]}
2021-02-26 22:52:32.565072 (Thread-1): 22:52:32 | 3 of 8 OK created table model dbt_jrosen.all_sightings............... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 2.51s]
2021-02-26 22:52:32.565187 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-26 22:52:32.565303 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-26 22:52:32.566161 (Thread-1): 22:52:32 | 4 of 8 START table model dbt_jrosen.sightings_by_day................. [RUN]
2021-02-26 22:52:32.566437 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:52:32.566521 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-26 22:52:32.574180 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-26 22:52:32.589754 (Thread-1): finished collecting timing info
2021-02-26 22:52:32.593770 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:52:32.788280 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-26 22:52:32.806696 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-02-26 22:52:33.781713 (Thread-54): handling poll request
2021-02-26 22:52:33.782139 (Thread-54): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac35f6eb0>]}
2021-02-26 22:52:33.784103 (Thread-54): sending response (<Response 6091 bytes [200 OK]>) to 10.0.22.116
2021-02-26 22:52:34.540249 (Thread-1): finished collecting timing info
2021-02-26 22:52:34.540972 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6257a813-7125-4115-91f5-86ec7207fddf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35020e7c0>]}
2021-02-26 22:52:34.542095 (Thread-1): 22:52:34 | 4 of 8 OK created table model dbt_jrosen.sightings_by_day............ [CREATE TABLE (2.9k rows, 57.6 KB processed) in 1.97s]
2021-02-26 22:52:34.542223 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-26 22:52:34.542353 (Thread-1): Began running node model.seth_test.viz1
2021-02-26 22:52:34.543327 (Thread-1): 22:52:34 | 5 of 8 START view model dbt_jrosen.viz1.............................. [RUN]
2021-02-26 22:52:34.543644 (Thread-1): Acquiring new bigquery connection "model.seth_test.viz1".
2021-02-26 22:52:34.543749 (Thread-1): Compiling model.seth_test.viz1
2021-02-26 22:52:34.551827 (Thread-1): Writing injected SQL for node "model.seth_test.viz1"
2021-02-26 22:52:34.568900 (Thread-1): finished collecting timing info
2021-02-26 22:52:34.573897 (Thread-1): Writing runtime SQL for node "model.seth_test.viz1"
2021-02-26 22:52:34.591367 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:52:34.596181 (Thread-1): On model.seth_test.viz1: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.seth_test.viz1"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`viz1`
  OPTIONS()
  as 

SELECT
DATE_TRUNC(date,year),
count(*)
FROM `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
WHERE date IS NOT NULL
AND date > '1960-01-01'
GROUP BY 1
ORDER BY 1 ASC;


2021-02-26 22:52:35.088131 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/a912353e-fa85-4780-92ef-ab921d61b01d?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 1 has no name at [8:1]')
2021-02-26 22:52:35.157789 (Thread-55): handling poll request
2021-02-26 22:52:35.158208 (Thread-55): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac35f69d0>]}
2021-02-26 22:52:35.160375 (Thread-55): sending response (<Response 6362 bytes [200 OK]>) to 10.0.47.69
2021-02-26 22:52:36.464128 (Thread-56): handling poll request
2021-02-26 22:52:36.464547 (Thread-56): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac35f61c0>]}
2021-02-26 22:52:36.465457 (Thread-56): sending response (<Response 285 bytes [200 OK]>) to 10.0.4.19
2021-02-26 22:52:36.558230 (Thread-1): finished collecting timing info
2021-02-26 22:52:36.558770 (Thread-1): Database Error in model viz1 (models/viz1.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [8:1]
  compiled SQL at target/run/seth_test/models/viz1.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/0ecc5ad9-5447-486b-9035-3338ab965dee?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 1 has no name at [8:1]

(job ID: 0ecc5ad9-5447-486b-9035-3338ab965dee)

                                                    -----Query Job SQL Follows-----                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.seth_test.viz1"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`viz1`
   5:  OPTIONS()
   6:  as 
   7:
   8:SELECT
   9:DATE_TRUNC(date,year),
  10:count(*)
  11:FROM `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  12:WHERE date IS NOT NULL
  13:AND date > '1960-01-01'
  14:GROUP BY 1
  15:ORDER BY 1 ASC;
  16:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.8/dist-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model viz1 (models/viz1.sql)
  CREATE VIEW columns must be named, but column 1 has no name at [8:1]
  compiled SQL at target/run/seth_test/models/viz1.sql
2021-02-26 22:52:36.561781 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6257a813-7125-4115-91f5-86ec7207fddf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3501f5670>]}
2021-02-26 22:52:36.562876 (Thread-1): 22:52:36 | 5 of 8 ERROR creating view model dbt_jrosen.viz1..................... [ERROR in 2.02s]
2021-02-26 22:52:36.562968 (Thread-1): Finished running node model.seth_test.viz1
2021-02-26 22:52:36.563097 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-26 22:52:36.563936 (Thread-1): 22:52:36 | 6 of 8 START view model dbt_jrosen.demo_123.......................... [RUN]
2021-02-26 22:52:36.564649 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:52:36.564739 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-26 22:52:36.572337 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-26 22:52:36.586313 (Thread-1): finished collecting timing info
2021-02-26 22:52:36.591561 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-02-26 22:52:36.609082 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:52:36.613377 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='Utah';


2021-02-26 22:52:37.486333 (Thread-1): finished collecting timing info
2021-02-26 22:52:37.486962 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6257a813-7125-4115-91f5-86ec7207fddf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3501f58b0>]}
2021-02-26 22:52:37.487986 (Thread-1): 22:52:37 | 6 of 8 OK created view model dbt_jrosen.demo_123..................... [OK in 0.92s]
2021-02-26 22:52:37.488079 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-26 22:52:37.488186 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-26 22:52:37.489022 (Thread-1): 22:52:37 | 7 of 8 START view model dbt_jrosen.massachusetts_sightings........... [RUN]
2021-02-26 22:52:37.489248 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:52:37.489328 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-26 22:52:37.498491 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-26 22:52:37.514637 (Thread-1): finished collecting timing info
2021-02-26 22:52:37.519744 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-26 22:52:37.537650 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:52:37.542291 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='California';


2021-02-26 22:52:37.795933 (Thread-57): handling poll request
2021-02-26 22:52:37.796370 (Thread-57): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8299cd0>]}
2021-02-26 22:52:37.799577 (Thread-57): sending response (<Response 21025 bytes [200 OK]>) to 10.0.7.123
2021-02-26 22:52:38.132108 (Thread-1): finished collecting timing info
2021-02-26 22:52:38.132710 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6257a813-7125-4115-91f5-86ec7207fddf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35004ba30>]}
2021-02-26 22:52:38.133693 (Thread-1): 22:52:38 | 7 of 8 OK created view model dbt_jrosen.massachusetts_sightings...... [OK in 0.64s]
2021-02-26 22:52:38.133786 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-26 22:52:38.133892 (Thread-1): Began running node model.seth_test.viz2
2021-02-26 22:52:38.133977 (Thread-1): 22:52:38 | 8 of 8 SKIP relation dbt_jrosen.viz2................................. [SKIP]
2021-02-26 22:52:38.134035 (Thread-1): Finished running node model.seth_test.viz2
2021-02-26 22:52:38.135494 (MainThread): Acquiring new bigquery connection "master".
2021-02-26 22:52:38.135802 (MainThread): 22:52:38 | 
2021-02-26 22:52:38.135877 (MainThread): 22:52:38 | Finished running 5 view models, 3 table models in 11.76s.
2021-02-26 22:52:38.135934 (MainThread): Connection 'master' was properly closed.
2021-02-26 22:52:38.135976 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-26 22:52:38.235790 (MainThread): 
2021-02-26 22:52:38.235958 (MainThread): Completed with 1 error and 0 warnings:
2021-02-26 22:52:38.236023 (MainThread): 
2021-02-26 22:52:38.236080 (MainThread): Database Error in model viz1 (models/viz1.sql)
2021-02-26 22:52:38.236126 (MainThread):   CREATE VIEW columns must be named, but column 1 has no name at [8:1]
2021-02-26 22:52:38.236166 (MainThread):   compiled SQL at target/run/seth_test/models/viz1.sql
2021-02-26 22:52:38.236224 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=1 TOTAL=8
2021-02-26 22:52:39.100655 (Thread-58): handling poll request
2021-02-26 22:52:39.101145 (Thread-58): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac82bbbb0>]}
2021-02-26 22:52:39.123229 (Thread-58): sending response (<Response 25029 bytes [200 OK]>) to 10.0.11.216
2021-02-26 22:52:39.415395 (Thread-59): handling status request
2021-02-26 22:52:39.415945 (Thread-59): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8139d30>]}
2021-02-26 22:52:39.442813 (Thread-59): sending response (<Response 883 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:52:55.091147 (Thread-60): handling status request
2021-02-26 22:52:55.091581 (Thread-60): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac35e8760>]}
2021-02-26 22:52:55.092468 (Thread-60): sending response (<Response 883 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:52:55.206332 (Thread-61): handling status request
2021-02-26 22:52:55.206729 (Thread-61): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8139b20>]}
2021-02-26 22:52:55.207649 (Thread-61): sending response (<Response 883 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:52:55.407326 (Thread-62): handling deps request
2021-02-26 22:52:55.407741 (Thread-62): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac82bb0a0>]}
2021-02-26 22:52:55.458243 (Thread-62): sending response (<Response 136 bytes [200 OK]>) to 10.0.11.216
2021-02-26 22:52:55.738401 (Thread-63): handling poll request
2021-02-26 22:52:55.738871 (Thread-63): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac81723d0>]}
2021-02-26 22:52:55.740315 (Thread-63): sending response (<Response 285 bytes [200 OK]>) to 10.0.3.75
2021-02-26 22:52:56.698032 (MainThread): Warning: No packages were found in packages.yml
2021-02-26 22:52:56.873407 (0cc6b108-5cee-465c-95e3-c8d1d1e6731e-handler-deps): Got an acceptable cached parse result
2021-02-26 22:52:57.096440 (Thread-64): handling poll request
2021-02-26 22:52:57.117423 (Thread-64): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac841d280>]}
2021-02-26 22:52:57.117948 (0cc6b108-5cee-465c-95e3-c8d1d1e6731e-handler-deps): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac34dbd30>]}
2021-02-26 22:52:57.119381 (Thread-64): sending response (<Response 562 bytes [200 OK]>) to 10.0.41.240
2021-02-26 22:52:58.596398 (Thread-65): handling poll request
2021-02-26 22:52:58.596868 (Thread-65): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac3463e80>]}
2021-02-26 22:52:58.597961 (Thread-65): sending response (<Response 357 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:52:58.879479 (Thread-66): handling status request
2021-02-26 22:52:58.879897 (Thread-66): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac343d6d0>]}
2021-02-26 22:52:58.880704 (Thread-66): sending response (<Response 457 bytes [200 OK]>) to 10.0.22.116
2021-02-26 22:53:03.277304 (Thread-67): handling status request
2021-02-26 22:53:03.277758 (Thread-67): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac343d910>]}
2021-02-26 22:53:03.278594 (Thread-67): sending response (<Response 457 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:53:03.299787 (Thread-68): handling status request
2021-02-26 22:53:03.300080 (Thread-68): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac343d9d0>]}
2021-02-26 22:53:03.300769 (Thread-68): sending response (<Response 457 bytes [200 OK]>) to 10.0.7.123
2021-02-26 22:53:03.561156 (Thread-69): handling cli_args request
2021-02-26 22:53:03.561732 (Thread-69): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac3504190>]}
2021-02-26 22:53:04.475194 (Thread-69): sending response (<Response 136 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:53:04.554730 (MainThread): Partial parsing not enabled
2021-02-26 22:53:04.557228 (MainThread): Parsing macros/adapters.sql
2021-02-26 22:53:04.577100 (MainThread): Parsing macros/etc.sql
2021-02-26 22:53:04.579276 (MainThread): Parsing macros/catalog.sql
2021-02-26 22:53:04.585214 (MainThread): Parsing macros/materializations/copy.sql
2021-02-26 22:53:04.589573 (MainThread): Parsing macros/materializations/table.sql
2021-02-26 22:53:04.599342 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-26 22:53:04.611769 (MainThread): Parsing macros/materializations/seed.sql
2021-02-26 22:53:04.614488 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-26 22:53:04.616333 (MainThread): Parsing macros/materializations/view.sql
2021-02-26 22:53:04.619798 (MainThread): Parsing macros/core.sql
2021-02-26 22:53:04.623686 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-26 22:53:04.632547 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-26 22:53:04.646285 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-26 22:53:04.648127 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-26 22:53:04.665809 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-26 22:53:04.696841 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-26 22:53:04.701890 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-26 22:53:04.708106 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-26 22:53:04.728521 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-26 22:53:04.735180 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-26 22:53:04.737127 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-26 22:53:04.743112 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-26 22:53:04.744795 (MainThread): Parsing macros/etc/query.sql
2021-02-26 22:53:04.745890 (MainThread): Parsing macros/etc/datetime.sql
2021-02-26 22:53:04.754723 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-26 22:53:04.755773 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-26 22:53:04.757449 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-26 22:53:04.759443 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-26 22:53:04.761004 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-26 22:53:04.763715 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-26 22:53:04.765602 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-26 22:53:04.767407 (MainThread): Parsing macros/adapters/common.sql
2021-02-26 22:53:04.819651 (MainThread): Partial parsing not enabled
2021-02-26 22:53:04.847247 (Thread-70): handling poll request
2021-02-26 22:53:04.847764 (Thread-70): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac3525850>]}
2021-02-26 22:53:04.852122 (Thread-70): sending response (<Response 9601 bytes [200 OK]>) to 10.0.7.123
2021-02-26 22:53:04.881974 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:53:04.911670 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:53:04.925330 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:53:04.939396 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:53:04.956988 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:53:04.972577 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:53:05.220598 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '45984134-90f2-4310-9d5f-e591f14daf3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c2c76f250>]}
2021-02-26 22:53:05.268635 (MainThread): Found 6 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-26 22:53:05.269558 (MainThread): 
2021-02-26 22:53:05.269840 (MainThread): Acquiring new bigquery connection "master".
2021-02-26 22:53:05.277366 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-02-26 22:53:05.277490 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-26 22:53:05.489953 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-26 22:53:05.490100 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-26 22:53:05.676077 (MainThread): 22:53:05 | Concurrency: 1 threads (target='default')
2021-02-26 22:53:05.676206 (MainThread): 22:53:05 | 
2021-02-26 22:53:05.678120 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-26 22:53:05.679356 (Thread-1): 22:53:05 | 1 of 6 START view model dbt_jrosen.new_model......................... [RUN]
2021-02-26 22:53:05.679580 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:53:05.679656 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-26 22:53:05.692778 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-26 22:53:05.709137 (Thread-1): finished collecting timing info
2021-02-26 22:53:05.738704 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-02-26 22:53:05.753900 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:53:05.758283 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-02-26 22:53:06.162236 (Thread-71): handling poll request
2021-02-26 22:53:06.162653 (Thread-71): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac3525e80>]}
2021-02-26 22:53:06.165407 (Thread-71): sending response (<Response 8946 bytes [200 OK]>) to 10.0.15.121
2021-02-26 22:53:06.334392 (Thread-1): finished collecting timing info
2021-02-26 22:53:06.335039 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45984134-90f2-4310-9d5f-e591f14daf3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c2c77bac0>]}
2021-02-26 22:53:06.336014 (Thread-1): 22:53:06 | 1 of 6 OK created view model dbt_jrosen.new_model.................... [OK in 0.66s]
2021-02-26 22:53:06.336095 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-26 22:53:06.336200 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:53:06.336976 (Thread-1): 22:53:06 | 2 of 6 START table model dbt_jrosen.sightings_by_day_by_state........ [RUN]
2021-02-26 22:53:06.337178 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:53:06.337250 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:53:06.343185 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-26 22:53:06.360599 (Thread-1): finished collecting timing info
2021-02-26 22:53:06.378314 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:53:06.595885 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-26 22:53:06.611182 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-02-26 22:53:07.435945 (Thread-72): handling poll request
2021-02-26 22:53:07.436390 (Thread-72): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac3527760>]}
2021-02-26 22:53:07.438354 (Thread-72): sending response (<Response 6161 bytes [200 OK]>) to 10.0.22.116
2021-02-26 22:53:08.471800 (Thread-1): finished collecting timing info
2021-02-26 22:53:08.472429 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45984134-90f2-4310-9d5f-e591f14daf3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c2c77baf0>]}
2021-02-26 22:53:08.473388 (Thread-1): 22:53:08 | 2 of 6 OK created table model dbt_jrosen.sightings_by_day_by_state... [CREATE TABLE (3.7k rows, 76.6 KB processed) in 2.14s]
2021-02-26 22:53:08.473471 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-26 22:53:08.473585 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-26 22:53:08.474377 (Thread-1): 22:53:08 | 3 of 6 START table model dbt_jrosen.all_sightings.................... [RUN]
2021-02-26 22:53:08.474585 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:53:08.474657 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-26 22:53:08.484100 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-26 22:53:08.499914 (Thread-1): finished collecting timing info
2021-02-26 22:53:08.506420 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:53:08.697831 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-02-26 22:53:08.714398 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  );
    
2021-02-26 22:53:08.793558 (Thread-73): handling poll request
2021-02-26 22:53:08.794011 (Thread-73): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac343d4f0>]}
2021-02-26 22:53:08.796090 (Thread-73): sending response (<Response 6099 bytes [200 OK]>) to 10.0.18.94
2021-02-26 22:53:10.101770 (Thread-74): handling poll request
2021-02-26 22:53:10.102180 (Thread-74): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac34e6640>]}
2021-02-26 22:53:10.103073 (Thread-74): sending response (<Response 284 bytes [200 OK]>) to 10.0.7.123
2021-02-26 22:53:11.052193 (Thread-1): finished collecting timing info
2021-02-26 22:53:11.053176 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45984134-90f2-4310-9d5f-e591f14daf3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c25fa5100>]}
2021-02-26 22:53:11.054910 (Thread-1): 22:53:11 | 3 of 6 OK created table model dbt_jrosen.all_sightings............... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 2.58s]
2021-02-26 22:53:11.055069 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-26 22:53:11.055246 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-26 22:53:11.056599 (Thread-1): 22:53:11 | 4 of 6 START table model dbt_jrosen.sightings_by_day................. [RUN]
2021-02-26 22:53:11.056934 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:53:11.057059 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-26 22:53:11.069185 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-26 22:53:11.085539 (Thread-1): finished collecting timing info
2021-02-26 22:53:11.091761 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:53:11.280487 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-26 22:53:11.295447 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-02-26 22:53:11.425290 (Thread-75): handling poll request
2021-02-26 22:53:11.425752 (Thread-75): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac36fd7c0>]}
2021-02-26 22:53:11.427683 (Thread-75): sending response (<Response 6091 bytes [200 OK]>) to 10.0.15.46
2021-02-26 22:53:12.736035 (Thread-76): handling poll request
2021-02-26 22:53:12.736501 (Thread-76): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac36c2430>]}
2021-02-26 22:53:12.737490 (Thread-76): sending response (<Response 284 bytes [200 OK]>) to 10.0.3.75
2021-02-26 22:53:13.077549 (Thread-1): finished collecting timing info
2021-02-26 22:53:13.078255 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45984134-90f2-4310-9d5f-e591f14daf3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c2c8288e0>]}
2021-02-26 22:53:13.079396 (Thread-1): 22:53:13 | 4 of 6 OK created table model dbt_jrosen.sightings_by_day............ [CREATE TABLE (2.9k rows, 57.6 KB processed) in 2.02s]
2021-02-26 22:53:13.079511 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-26 22:53:13.079643 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-26 22:53:13.080494 (Thread-1): 22:53:13 | 5 of 6 START view model dbt_jrosen.demo_123.......................... [RUN]
2021-02-26 22:53:13.080790 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:53:13.080871 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-26 22:53:13.089336 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-26 22:53:13.104865 (Thread-1): finished collecting timing info
2021-02-26 22:53:13.109210 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-02-26 22:53:13.124047 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:53:13.128409 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='Utah';


2021-02-26 22:53:13.700215 (Thread-1): finished collecting timing info
2021-02-26 22:53:13.700875 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45984134-90f2-4310-9d5f-e591f14daf3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c25f56550>]}
2021-02-26 22:53:13.701841 (Thread-1): 22:53:13 | 5 of 6 OK created view model dbt_jrosen.demo_123..................... [OK in 0.62s]
2021-02-26 22:53:13.701927 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-26 22:53:13.702031 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-26 22:53:13.702818 (Thread-1): 22:53:13 | 6 of 6 START view model dbt_jrosen.massachusetts_sightings........... [RUN]
2021-02-26 22:53:13.703045 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:53:13.703123 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-26 22:53:13.711321 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-26 22:53:13.728521 (Thread-1): finished collecting timing info
2021-02-26 22:53:13.732711 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-26 22:53:13.749569 (Thread-1): Opening a new connection, currently in state closed
2021-02-26 22:53:13.753918 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='California';


2021-02-26 22:53:13.997080 (Thread-77): handling poll request
2021-02-26 22:53:13.997524 (Thread-77): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac36c2730>]}
2021-02-26 22:53:14.000633 (Thread-77): sending response (<Response 11888 bytes [200 OK]>) to 10.0.29.185
2021-02-26 22:53:14.327216 (Thread-1): finished collecting timing info
2021-02-26 22:53:14.327824 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45984134-90f2-4310-9d5f-e591f14daf3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c25f56070>]}
2021-02-26 22:53:14.328780 (Thread-1): 22:53:14 | 6 of 6 OK created view model dbt_jrosen.massachusetts_sightings...... [OK in 0.62s]
2021-02-26 22:53:14.328867 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-26 22:53:14.330229 (MainThread): Acquiring new bigquery connection "master".
2021-02-26 22:53:14.330511 (MainThread): 22:53:14 | 
2021-02-26 22:53:14.330576 (MainThread): 22:53:14 | Finished running 3 view models, 3 table models in 9.06s.
2021-02-26 22:53:14.330624 (MainThread): Connection 'master' was properly closed.
2021-02-26 22:53:14.330664 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-26 22:53:14.423641 (MainThread): 
2021-02-26 22:53:14.423773 (MainThread): Completed successfully
2021-02-26 22:53:14.423857 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-02-26 22:53:15.386814 (Thread-78): handling poll request
2021-02-26 22:53:15.387271 (Thread-78): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8216f10>]}
2021-02-26 22:53:15.401776 (Thread-78): sending response (<Response 18009 bytes [200 OK]>) to 10.0.47.69
2021-02-26 22:53:15.721653 (Thread-79): handling status request
2021-02-26 22:53:15.722277 (Thread-79): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac8139fd0>]}
2021-02-26 22:53:15.723439 (Thread-79): sending response (<Response 457 bytes [200 OK]>) to 10.0.15.121
2021-02-26 22:53:25.965541 (Thread-80): handling status request
2021-02-26 22:53:25.965964 (Thread-80): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac35271c0>]}
2021-02-26 22:53:25.966761 (Thread-80): sending response (<Response 457 bytes [200 OK]>) to 10.0.3.75
2021-02-26 22:53:33.871325 (Thread-81): Parsing macros/adapters.sql
2021-02-26 22:53:33.890114 (Thread-81): Parsing macros/etc.sql
2021-02-26 22:53:33.892183 (Thread-81): Parsing macros/catalog.sql
2021-02-26 22:53:33.898054 (Thread-81): Parsing macros/materializations/copy.sql
2021-02-26 22:53:33.902353 (Thread-81): Parsing macros/materializations/table.sql
2021-02-26 22:53:33.911990 (Thread-81): Parsing macros/materializations/incremental.sql
2021-02-26 22:53:33.924210 (Thread-81): Parsing macros/materializations/seed.sql
2021-02-26 22:53:33.926817 (Thread-81): Parsing macros/materializations/snapshot.sql
2021-02-26 22:53:33.928599 (Thread-81): Parsing macros/materializations/view.sql
2021-02-26 22:53:33.932021 (Thread-81): Parsing macros/core.sql
2021-02-26 22:53:33.935819 (Thread-81): Parsing macros/materializations/helpers.sql
2021-02-26 22:53:33.945431 (Thread-81): Parsing macros/materializations/common/merge.sql
2021-02-26 22:53:33.959134 (Thread-81): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-26 22:53:33.960862 (Thread-81): Parsing macros/materializations/snapshot/strategies.sql
2021-02-26 22:53:33.979061 (Thread-81): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-26 22:53:34.012970 (Thread-81): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-26 22:53:34.021030 (Thread-81): Parsing macros/materializations/view/view.sql
2021-02-26 22:53:34.029563 (Thread-81): Parsing macros/materializations/seed/seed.sql
2021-02-26 22:53:34.051804 (Thread-81): Parsing macros/materializations/table/table.sql
2021-02-26 22:53:34.058761 (Thread-81): Parsing macros/materializations/incremental/helpers.sql
2021-02-26 22:53:34.060920 (Thread-81): Parsing macros/materializations/incremental/incremental.sql
2021-02-26 22:53:34.067213 (Thread-81): Parsing macros/etc/is_incremental.sql
2021-02-26 22:53:34.069138 (Thread-81): Parsing macros/etc/query.sql
2021-02-26 22:53:34.070394 (Thread-81): Parsing macros/etc/datetime.sql
2021-02-26 22:53:34.079792 (Thread-81): Parsing macros/etc/get_custom_alias.sql
2021-02-26 22:53:34.080930 (Thread-81): Parsing macros/etc/get_custom_database.sql
2021-02-26 22:53:34.082692 (Thread-81): Parsing macros/etc/get_custom_schema.sql
2021-02-26 22:53:34.084764 (Thread-81): Parsing macros/schema_tests/not_null.sql
2021-02-26 22:53:34.086309 (Thread-81): Parsing macros/schema_tests/accepted_values.sql
2021-02-26 22:53:34.089002 (Thread-81): Parsing macros/schema_tests/relationships.sql
2021-02-26 22:53:34.090873 (Thread-81): Parsing macros/schema_tests/unique.sql
2021-02-26 22:53:34.092708 (Thread-81): Parsing macros/adapters/common.sql
2021-02-26 22:53:34.177659 (Thread-81): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-26 22:53:34.192509 (Thread-81): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-26 22:53:34.206300 (Thread-81): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-26 22:53:34.218613 (Thread-81): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-26 22:53:34.234673 (Thread-81): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-26 22:53:34.248702 (Thread-81): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-26 22:53:34.639729 (Thread-81): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23604924-b4a3-4eb7-8619-afa92b750c22', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac847b5b0>]}
2021-02-27 23:55:25.823543 (MainThread): Running with dbt=0.19.0
2021-02-27 23:55:25.976518 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-02-27 23:55:25.989238 (MainThread): Tracking: tracking
2021-02-27 23:55:26.011557 (Thread-1): Parsing macros/adapters.sql
2021-02-27 23:55:26.032045 (Thread-1): Parsing macros/etc.sql
2021-02-27 23:55:26.034450 (Thread-1): Parsing macros/catalog.sql
2021-02-27 23:55:26.040802 (Thread-1): Parsing macros/materializations/copy.sql
2021-02-27 23:55:26.045397 (Thread-1): Parsing macros/materializations/table.sql
2021-02-27 23:55:26.055291 (Thread-1): Parsing macros/materializations/incremental.sql
2021-02-27 23:55:26.055485 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f56183c5be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5602ad4e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5602ad48e0>]}
2021-02-27 23:55:26.069692 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=15
2021-02-27 23:55:26.070121 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-02-27 23:55:26.070378 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-02-27 23:55:26.070539 (Thread-1): Parsing macros/materializations/seed.sql
2021-02-27 23:55:26.073699 (Thread-1): Parsing macros/materializations/snapshot.sql
2021-02-27 23:55:26.075703 (Thread-1): Parsing macros/materializations/view.sql
2021-02-27 23:55:26.079173 (Thread-1): Parsing macros/core.sql
2021-02-27 23:55:26.083114 (Thread-1): Parsing macros/materializations/helpers.sql
2021-02-27 23:55:26.094265 (Thread-1): Parsing macros/materializations/common/merge.sql
2021-02-27 23:55:26.108277 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-27 23:55:26.110082 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2021-02-27 23:55:26.127440 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-27 23:55:26.158133 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-27 23:55:26.162998 (Thread-1): Parsing macros/materializations/view/view.sql
2021-02-27 23:55:26.169170 (Thread-1): Parsing macros/materializations/seed/seed.sql
2021-02-27 23:55:26.189308 (Thread-1): Parsing macros/materializations/table/table.sql
2021-02-27 23:55:26.196876 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2021-02-27 23:55:26.198718 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2021-02-27 23:55:26.204589 (Thread-1): Parsing macros/etc/is_incremental.sql
2021-02-27 23:55:26.206213 (Thread-1): Parsing macros/etc/query.sql
2021-02-27 23:55:26.207274 (Thread-1): Parsing macros/etc/datetime.sql
2021-02-27 23:55:26.216023 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2021-02-27 23:55:26.216973 (Thread-1): Parsing macros/etc/get_custom_database.sql
2021-02-27 23:55:26.218627 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2021-02-27 23:55:26.220776 (Thread-1): Parsing macros/schema_tests/not_null.sql
2021-02-27 23:55:26.222426 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2021-02-27 23:55:26.225071 (Thread-1): Parsing macros/schema_tests/relationships.sql
2021-02-27 23:55:26.226935 (Thread-1): Parsing macros/schema_tests/unique.sql
2021-02-27 23:55:26.228778 (Thread-1): Parsing macros/adapters/common.sql
2021-02-27 23:55:26.328021 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-27 23:55:26.354579 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-27 23:55:26.371335 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-27 23:55:26.385992 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-27 23:55:26.402345 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-27 23:55:26.417578 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-27 23:55:26.684551 (Thread-2): handling status request
2021-02-27 23:55:26.691726 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '65efdf56-6b36-40c1-9005-58416375f3f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5601e6a0a0>]}
2021-02-27 23:55:26.693487 (Thread-2): sending response (<Response 183 bytes [200 OK]>) to 10.0.22.116
2021-02-27 23:55:26.772791 (Thread-1): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '65efdf56-6b36-40c1-9005-58416375f3f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5601eef550>]}
2021-02-27 23:55:28.119714 (Thread-3): handling status request
2021-02-27 23:55:28.120145 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '65efdf56-6b36-40c1-9005-58416375f3f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5602b6cca0>]}
2021-02-27 23:55:28.124286 (Thread-3): sending response (<Response 11019 bytes [200 OK]>) to 10.0.44.55
2021-02-28 14:35:19.224995 (MainThread): Running with dbt=0.19.0
2021-02-28 14:35:19.378381 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-02-28 14:35:19.390179 (MainThread): Tracking: tracking
2021-02-28 14:35:19.410952 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4ed7a310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4a2e5d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4a2deeb0>]}
2021-02-28 14:35:19.412026 (Thread-1): Parsing macros/adapters.sql
2021-02-28 14:35:19.427394 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=15
2021-02-28 14:35:19.440444 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-02-28 14:35:19.440928 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-02-28 14:35:19.463057 (Thread-1): Parsing macros/etc.sql
2021-02-28 14:35:19.466481 (Thread-1): Parsing macros/catalog.sql
2021-02-28 14:35:19.476752 (Thread-1): Parsing macros/materializations/copy.sql
2021-02-28 14:35:19.483767 (Thread-1): Parsing macros/materializations/table.sql
2021-02-28 14:35:19.493619 (Thread-1): Parsing macros/materializations/incremental.sql
2021-02-28 14:35:19.506468 (Thread-1): Parsing macros/materializations/seed.sql
2021-02-28 14:35:19.509398 (Thread-1): Parsing macros/materializations/snapshot.sql
2021-02-28 14:35:19.511219 (Thread-1): Parsing macros/materializations/view.sql
2021-02-28 14:35:19.514707 (Thread-1): Parsing macros/core.sql
2021-02-28 14:35:19.518598 (Thread-1): Parsing macros/materializations/helpers.sql
2021-02-28 14:35:19.528166 (Thread-1): Parsing macros/materializations/common/merge.sql
2021-02-28 14:35:19.542112 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-28 14:35:19.543919 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2021-02-28 14:35:19.561509 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-28 14:35:19.592842 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-28 14:35:19.600683 (Thread-1): Parsing macros/materializations/view/view.sql
2021-02-28 14:35:19.610882 (Thread-1): Parsing macros/materializations/seed/seed.sql
2021-02-28 14:35:19.641550 (Thread-1): Parsing macros/materializations/table/table.sql
2021-02-28 14:35:19.651720 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2021-02-28 14:35:19.654472 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2021-02-28 14:35:19.661688 (Thread-1): Parsing macros/etc/is_incremental.sql
2021-02-28 14:35:19.663352 (Thread-1): Parsing macros/etc/query.sql
2021-02-28 14:35:19.664424 (Thread-1): Parsing macros/etc/datetime.sql
2021-02-28 14:35:19.673336 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2021-02-28 14:35:19.674294 (Thread-1): Parsing macros/etc/get_custom_database.sql
2021-02-28 14:35:19.675998 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2021-02-28 14:35:19.677981 (Thread-1): Parsing macros/schema_tests/not_null.sql
2021-02-28 14:35:19.679558 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2021-02-28 14:35:19.682230 (Thread-1): Parsing macros/schema_tests/relationships.sql
2021-02-28 14:35:19.684225 (Thread-1): Parsing macros/schema_tests/unique.sql
2021-02-28 14:35:19.686049 (Thread-1): Parsing macros/adapters/common.sql
2021-02-28 14:35:19.715326 (Thread-2): handling status request
2021-02-28 14:35:19.725971 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4984f0a0>]}
2021-02-28 14:35:19.733880 (Thread-2): sending response (<Response 183 bytes [200 OK]>) to 10.0.11.216
2021-02-28 14:35:19.783623 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-28 14:35:19.809617 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-28 14:35:19.829306 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-28 14:35:19.845338 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-28 14:35:19.860947 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-28 14:35:19.875297 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-28 14:35:20.239440 (Thread-1): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48ec6250>]}
2021-02-28 14:35:21.042834 (Thread-3): handling status request
2021-02-28 14:35:21.043289 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48eec280>]}
2021-02-28 14:35:21.046883 (Thread-3): sending response (<Response 11124 bytes [200 OK]>) to 10.0.11.216
2021-02-28 14:36:34.593271 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-28 14:36:34.642081 (Thread-4): Got an acceptable cached parse result
2021-02-28 14:36:34.691698 (Thread-4): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-02-28 14:36:34.868397 (Thread-4): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48d52fd0>]}
2021-02-28 14:36:34.891806 (Thread-5): handling status request
2021-02-28 14:36:34.892185 (Thread-5): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48ca58e0>]}
2021-02-28 14:36:34.893114 (Thread-5): sending response (<Response 1187 bytes [200 OK]>) to 10.0.44.55
2021-02-28 14:36:50.817790 (MainThread): Connection 'model.hashpath_demo.bigfoot_ephemeral' was properly closed.
2021-02-28 14:36:50.867139 (Thread-6): Got an acceptable cached parse result
2021-02-28 14:36:50.916634 (Thread-6): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-02-28 14:36:51.099695 (Thread-6): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48d55310>]}
2021-02-28 14:36:51.116424 (Thread-7): handling status request
2021-02-28 14:36:51.116772 (Thread-7): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48c31f70>]}
2021-02-28 14:36:51.117683 (Thread-7): sending response (<Response 1187 bytes [200 OK]>) to 10.0.15.121
2021-02-28 14:37:14.561428 (Thread-8): handling status request
2021-02-28 14:37:14.561916 (Thread-8): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48c31f10>]}
2021-02-28 14:37:14.562881 (Thread-8): sending response (<Response 1187 bytes [200 OK]>) to 10.0.32.128
2021-02-28 14:37:17.335032 (Thread-9): handling status request
2021-02-28 14:37:17.335465 (Thread-9): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48be5df0>]}
2021-02-28 14:37:17.336451 (Thread-9): sending response (<Response 1187 bytes [200 OK]>) to 10.0.7.123
2021-02-28 14:37:17.342247 (Thread-10): handling status request
2021-02-28 14:37:17.342551 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48be5460>]}
2021-02-28 14:37:17.343390 (Thread-10): sending response (<Response 1187 bytes [200 OK]>) to 10.0.15.46
2021-02-28 14:37:17.651840 (Thread-11): handling cli_args request
2021-02-28 14:37:17.652413 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48be5ca0>]}
2021-02-28 14:37:17.670415 (Thread-11): Connection 'model.hashpath_demo.bigfoot_ephemeral' was properly closed.
2021-02-28 14:37:18.520380 (Thread-11): sending response (<Response 136 bytes [200 OK]>) to 10.0.0.148
2021-02-28 14:37:18.599268 (MainThread): Partial parsing not enabled
2021-02-28 14:37:18.600727 (MainThread): Parsing macros/adapters.sql
2021-02-28 14:37:18.626770 (MainThread): Parsing macros/etc.sql
2021-02-28 14:37:18.629007 (MainThread): Parsing macros/catalog.sql
2021-02-28 14:37:18.635064 (MainThread): Parsing macros/materializations/copy.sql
2021-02-28 14:37:18.639410 (MainThread): Parsing macros/materializations/table.sql
2021-02-28 14:37:18.649181 (MainThread): Parsing macros/materializations/incremental.sql
2021-02-28 14:37:18.661537 (MainThread): Parsing macros/materializations/seed.sql
2021-02-28 14:37:18.664240 (MainThread): Parsing macros/materializations/snapshot.sql
2021-02-28 14:37:18.666047 (MainThread): Parsing macros/materializations/view.sql
2021-02-28 14:37:18.669520 (MainThread): Parsing macros/core.sql
2021-02-28 14:37:18.673345 (MainThread): Parsing macros/materializations/helpers.sql
2021-02-28 14:37:18.682201 (MainThread): Parsing macros/materializations/common/merge.sql
2021-02-28 14:37:18.696414 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-28 14:37:18.698237 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-02-28 14:37:18.716442 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-28 14:37:18.747264 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-28 14:37:18.752192 (MainThread): Parsing macros/materializations/view/view.sql
2021-02-28 14:37:18.758386 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-02-28 14:37:18.778977 (MainThread): Parsing macros/materializations/table/table.sql
2021-02-28 14:37:18.785836 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-02-28 14:37:18.787743 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-02-28 14:37:18.793720 (MainThread): Parsing macros/etc/is_incremental.sql
2021-02-28 14:37:18.795404 (MainThread): Parsing macros/etc/query.sql
2021-02-28 14:37:18.796535 (MainThread): Parsing macros/etc/datetime.sql
2021-02-28 14:37:18.805281 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-02-28 14:37:18.806301 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-02-28 14:37:18.808026 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-02-28 14:37:18.810031 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-02-28 14:37:18.811668 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-02-28 14:37:18.814393 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-02-28 14:37:18.816374 (MainThread): Parsing macros/schema_tests/unique.sql
2021-02-28 14:37:18.818166 (MainThread): Parsing macros/adapters/common.sql
2021-02-28 14:37:18.868834 (MainThread): Partial parsing not enabled
2021-02-28 14:37:18.891799 (Thread-12): handling poll request
2021-02-28 14:37:18.892229 (Thread-12): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48a7d640>]}
2021-02-28 14:37:18.897783 (Thread-12): sending response (<Response 9601 bytes [200 OK]>) to 10.0.11.216
2021-02-28 14:37:18.915387 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-28 14:37:18.939039 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-28 14:37:18.951755 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-28 14:37:18.964076 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-28 14:37:18.978045 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-02-28 14:37:18.991329 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-28 14:37:19.005142 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-28 14:37:19.256593 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3930aacc-878c-409a-822f-6274071e5218', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d73fcf610>]}
2021-02-28 14:37:19.292331 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 0 sources, 0 exposures
2021-02-28 14:37:19.293333 (MainThread): 
2021-02-28 14:37:19.293644 (MainThread): Acquiring new bigquery connection "master".
2021-02-28 14:37:19.301756 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-02-28 14:37:19.301878 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-02-28 14:37:19.505548 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-02-28 14:37:19.505684 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-02-28 14:37:19.738730 (MainThread): 14:37:19 | Concurrency: 1 threads (target='default')
2021-02-28 14:37:19.738857 (MainThread): 14:37:19 | 
2021-02-28 14:37:19.740790 (Thread-1): Began running node model.hashpath_demo.new_model
2021-02-28 14:37:19.741968 (Thread-1): 14:37:19 | 1 of 6 START view model dbt_jrosen.new_model......................... [RUN]
2021-02-28 14:37:19.742195 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-28 14:37:19.742272 (Thread-1): Compiling model.hashpath_demo.new_model
2021-02-28 14:37:19.755206 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-02-28 14:37:19.774258 (Thread-1): finished collecting timing info
2021-02-28 14:37:19.803241 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-02-28 14:37:19.822615 (Thread-1): Opening a new connection, currently in state closed
2021-02-28 14:37:19.827125 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-02-28 14:37:20.468511 (Thread-13): handling poll request
2021-02-28 14:37:20.468940 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48eec250>]}
2021-02-28 14:37:20.471849 (Thread-13): sending response (<Response 9256 bytes [200 OK]>) to 10.0.18.94
2021-02-28 14:37:20.797167 (Thread-14): Parsing macros/adapters.sql
2021-02-28 14:37:20.816166 (Thread-14): Parsing macros/etc.sql
2021-02-28 14:37:20.818201 (Thread-14): Parsing macros/catalog.sql
2021-02-28 14:37:20.824038 (Thread-14): Parsing macros/materializations/copy.sql
2021-02-28 14:37:20.828426 (Thread-14): Parsing macros/materializations/table.sql
2021-02-28 14:37:20.838185 (Thread-14): Parsing macros/materializations/incremental.sql
2021-02-28 14:37:20.850632 (Thread-14): Parsing macros/materializations/seed.sql
2021-02-28 14:37:20.845371 (Thread-1): finished collecting timing info
2021-02-28 14:37:20.853682 (Thread-14): Parsing macros/materializations/snapshot.sql
2021-02-28 14:37:20.845964 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3930aacc-878c-409a-822f-6274071e5218', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d78224970>]}
2021-02-28 14:37:20.846900 (Thread-1): 14:37:20 | 1 of 6 OK created view model dbt_jrosen.new_model.................... [OK in 1.10s]
2021-02-28 14:37:20.846984 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-02-28 14:37:20.856261 (Thread-14): Parsing macros/materializations/view.sql
2021-02-28 14:37:20.847111 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-02-28 14:37:20.847903 (Thread-1): 14:37:20 | 2 of 6 START table model dbt_jrosen.sightings_by_day_by_state........ [RUN]
2021-02-28 14:37:20.848105 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-28 14:37:20.848174 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-02-28 14:37:20.854197 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-28 14:37:20.860676 (Thread-14): Parsing macros/core.sql
2021-02-28 14:37:20.864560 (Thread-14): Parsing macros/materializations/helpers.sql
2021-02-28 14:37:20.873448 (Thread-14): Parsing macros/materializations/common/merge.sql
2021-02-28 14:37:20.874073 (Thread-1): finished collecting timing info
2021-02-28 14:37:20.887627 (Thread-14): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-02-28 14:37:20.889398 (Thread-14): Parsing macros/materializations/snapshot/strategies.sql
2021-02-28 14:37:20.889861 (Thread-1): Opening a new connection, currently in state closed
2021-02-28 14:37:20.907584 (Thread-14): Parsing macros/materializations/snapshot/snapshot.sql
2021-02-28 14:37:20.939243 (Thread-14): Parsing macros/materializations/view/create_or_replace_view.sql
2021-02-28 14:37:20.944245 (Thread-14): Parsing macros/materializations/view/view.sql
2021-02-28 14:37:20.950500 (Thread-14): Parsing macros/materializations/seed/seed.sql
2021-02-28 14:37:20.971331 (Thread-14): Parsing macros/materializations/table/table.sql
2021-02-28 14:37:20.978014 (Thread-14): Parsing macros/materializations/incremental/helpers.sql
2021-02-28 14:37:20.979866 (Thread-14): Parsing macros/materializations/incremental/incremental.sql
2021-02-28 14:37:20.985916 (Thread-14): Parsing macros/etc/is_incremental.sql
2021-02-28 14:37:20.987563 (Thread-14): Parsing macros/etc/query.sql
2021-02-28 14:37:20.988634 (Thread-14): Parsing macros/etc/datetime.sql
2021-02-28 14:37:20.997953 (Thread-14): Parsing macros/etc/get_custom_alias.sql
2021-02-28 14:37:21.006900 (Thread-14): Parsing macros/etc/get_custom_database.sql
2021-02-28 14:37:21.016871 (Thread-14): Parsing macros/etc/get_custom_schema.sql
2021-02-28 14:37:21.018834 (Thread-14): Parsing macros/schema_tests/not_null.sql
2021-02-28 14:37:21.027380 (Thread-14): Parsing macros/schema_tests/accepted_values.sql
2021-02-28 14:37:21.041527 (Thread-14): Parsing macros/schema_tests/relationships.sql
2021-02-28 14:37:21.043431 (Thread-14): Parsing macros/schema_tests/unique.sql
2021-02-28 14:37:21.045190 (Thread-14): Parsing macros/adapters/common.sql
2021-02-28 14:37:21.092253 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-02-28 14:37:21.108631 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-02-28 14:37:21.130355 (Thread-14): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-28 14:37:21.143869 (Thread-14): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-02-28 14:37:21.156264 (Thread-14): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-02-28 14:37:21.167805 (Thread-14): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-28 14:37:21.176973 (Thread-15): handling status request
2021-02-28 14:37:21.177307 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48913220>]}
2021-02-28 14:37:21.177971 (Thread-15): sending response (<Response 183 bytes [200 OK]>) to 10.0.15.121
2021-02-28 14:37:21.182630 (Thread-14): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-02-28 14:37:21.195930 (Thread-14): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-28 14:37:21.209944 (Thread-14): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-28 14:37:21.551043 (Thread-14): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef4893bfd0>]}
2021-02-28 14:37:21.771902 (Thread-16): handling poll request
2021-02-28 14:37:21.772328 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48f48a90>]}
2021-02-28 14:37:21.774226 (Thread-16): sending response (<Response 6161 bytes [200 OK]>) to 10.0.15.121
2021-02-28 14:37:22.476763 (Thread-17): handling status request
2021-02-28 14:37:22.477176 (Thread-17): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48cdc070>]}
2021-02-28 14:37:22.480894 (Thread-17): sending response (<Response 11491 bytes [200 OK]>) to 10.0.0.148
2021-02-28 14:37:22.816981 (Thread-1): finished collecting timing info
2021-02-28 14:37:22.817615 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3930aacc-878c-409a-822f-6274071e5218', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d780af700>]}
2021-02-28 14:37:22.818629 (Thread-1): 14:37:22 | 2 of 6 OK created table model dbt_jrosen.sightings_by_day_by_state... [CREATE TABLE (3.7k rows, 76.6 KB processed) in 1.97s]
2021-02-28 14:37:22.818715 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-02-28 14:37:22.818816 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-02-28 14:37:22.819055 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-02-28 14:37:22.819130 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-02-28 14:37:22.827629 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-02-28 14:37:22.838843 (Thread-1): finished collecting timing info
2021-02-28 14:37:22.839220 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-02-28 14:37:22.839324 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-02-28 14:37:22.840137 (Thread-1): 14:37:22 | 3 of 6 START table model dbt_jrosen.all_sightings.................... [RUN]
2021-02-28 14:37:22.840336 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-02-28 14:37:22.840402 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-02-28 14:37:22.849547 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-02-28 14:37:22.871801 (Thread-1): finished collecting timing info
2021-02-28 14:37:22.875450 (Thread-1): Opening a new connection, currently in state closed
2021-02-28 14:37:23.043795 (Thread-18): handling poll request
2021-02-28 14:37:23.044197 (Thread-18): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48d55b20>]}
2021-02-28 14:37:23.046430 (Thread-18): sending response (<Response 7621 bytes [200 OK]>) to 10.0.11.216
2021-02-28 14:37:23.071355 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-02-28 14:37:23.090706 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
  );
    
2021-02-28 14:37:24.375355 (Thread-19): handling poll request
2021-02-28 14:37:24.375820 (Thread-19): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48d55d60>]}
2021-02-28 14:37:24.377127 (Thread-19): sending response (<Response 1376 bytes [200 OK]>) to 10.0.7.123
2021-02-28 14:37:25.679994 (Thread-20): handling poll request
2021-02-28 14:37:25.680418 (Thread-20): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48a901c0>]}
2021-02-28 14:37:25.681350 (Thread-20): sending response (<Response 284 bytes [200 OK]>) to 10.0.44.55
2021-02-28 14:37:25.677616 (Thread-1): finished collecting timing info
2021-02-28 14:37:25.678236 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3930aacc-878c-409a-822f-6274071e5218', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d7179cb50>]}
2021-02-28 14:37:25.679455 (Thread-1): 14:37:25 | 3 of 6 OK created table model dbt_jrosen.all_sightings............... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 2.84s]
2021-02-28 14:37:25.679556 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-02-28 14:37:25.679658 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-02-28 14:37:25.680476 (Thread-1): 14:37:25 | 4 of 6 START table model dbt_jrosen.sightings_by_day................. [RUN]
2021-02-28 14:37:25.680700 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-02-28 14:37:25.680775 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-02-28 14:37:25.688049 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-28 14:37:25.706861 (Thread-1): finished collecting timing info
2021-02-28 14:37:25.710420 (Thread-1): Opening a new connection, currently in state closed
2021-02-28 14:37:25.894587 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-02-28 14:37:25.912706 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_jrosen`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-02-28 14:37:26.965043 (Thread-21): handling poll request
2021-02-28 14:37:26.965472 (Thread-21): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef49854040>]}
2021-02-28 14:37:26.967447 (Thread-21): sending response (<Response 6090 bytes [200 OK]>) to 10.0.0.148
2021-02-28 14:37:27.638144 (Thread-1): finished collecting timing info
2021-02-28 14:37:27.638780 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3930aacc-878c-409a-822f-6274071e5218', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d7174fb80>]}
2021-02-28 14:37:27.639801 (Thread-1): 14:37:27 | 4 of 6 OK created table model dbt_jrosen.sightings_by_day............ [CREATE TABLE (2.9k rows, 57.6 KB processed) in 1.96s]
2021-02-28 14:37:27.639897 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-02-28 14:37:27.639997 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-02-28 14:37:27.640854 (Thread-1): 14:37:27 | 5 of 6 START view model dbt_jrosen.demo_123.......................... [RUN]
2021-02-28 14:37:27.641073 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-02-28 14:37:27.641146 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-02-28 14:37:27.648922 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-02-28 14:37:27.666292 (Thread-1): finished collecting timing info
2021-02-28 14:37:27.670303 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-02-28 14:37:27.687132 (Thread-1): Opening a new connection, currently in state closed
2021-02-28 14:37:27.692131 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='Utah';


2021-02-28 14:37:28.234498 (Thread-22): handling poll request
2021-02-28 14:37:28.234958 (Thread-22): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48a14bb0>]}
2021-02-28 14:37:28.236842 (Thread-22): sending response (<Response 5971 bytes [200 OK]>) to 10.0.22.116
2021-02-28 14:37:28.298670 (Thread-1): finished collecting timing info
2021-02-28 14:37:28.299326 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3930aacc-878c-409a-822f-6274071e5218', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d71751c10>]}
2021-02-28 14:37:28.300305 (Thread-1): 14:37:28 | 5 of 6 OK created view model dbt_jrosen.demo_123..................... [OK in 0.66s]
2021-02-28 14:37:28.300395 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-02-28 14:37:28.300499 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-02-28 14:37:28.301328 (Thread-1): 14:37:28 | 6 of 6 START view model dbt_jrosen.massachusetts_sightings........... [RUN]
2021-02-28 14:37:28.301554 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-02-28 14:37:28.301632 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-02-28 14:37:28.309821 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-28 14:37:28.328025 (Thread-1): finished collecting timing info
2021-02-28 14:37:28.331939 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-02-28 14:37:28.350306 (Thread-1): Opening a new connection, currently in state closed
2021-02-28 14:37:28.354567 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "user", "target_name": "default", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_jrosen`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_jrosen`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
where state='California';


2021-02-28 14:37:29.113718 (Thread-1): finished collecting timing info
2021-02-28 14:37:29.114403 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3930aacc-878c-409a-822f-6274071e5218', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d717862e0>]}
2021-02-28 14:37:29.115709 (Thread-1): 14:37:29 | 6 of 6 OK created view model dbt_jrosen.massachusetts_sightings...... [OK in 0.81s]
2021-02-28 14:37:29.115799 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-02-28 14:37:29.117084 (MainThread): Acquiring new bigquery connection "master".
2021-02-28 14:37:29.117363 (MainThread): 14:37:29 | 
2021-02-28 14:37:29.117429 (MainThread): 14:37:29 | Finished running 3 view models, 3 table models in 9.82s.
2021-02-28 14:37:29.117477 (MainThread): Connection 'master' was properly closed.
2021-02-28 14:37:29.117518 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-02-28 14:37:29.231774 (MainThread): 
2021-02-28 14:37:29.231897 (MainThread): Completed successfully
2021-02-28 14:37:29.231964 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2021-02-28 14:37:29.592169 (Thread-23): handling poll request
2021-02-28 14:37:29.592583 (Thread-23): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48dd4910>]}
2021-02-28 14:37:29.608430 (Thread-23): sending response (<Response 23927 bytes [200 OK]>) to 10.0.11.216
2021-02-28 14:37:29.892159 (Thread-24): handling status request
2021-02-28 14:37:29.892587 (Thread-24): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '2f02e15e-bf63-4174-ae9b-2024468bd8bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef48ca9e50>]}
2021-02-28 14:37:29.896219 (Thread-24): sending response (<Response 11491 bytes [200 OK]>) to 10.0.18.94
2021-03-02 02:08:18.811706 (MainThread): Running with dbt=0.19.0
2021-03-02 02:08:18.956632 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-03-02 02:08:18.968369 (MainThread): Tracking: tracking
2021-03-02 02:08:18.988183 (Thread-1): Parsing macros/adapters.sql
2021-03-02 02:08:19.009423 (Thread-1): Parsing macros/etc.sql
2021-03-02 02:08:19.013103 (Thread-1): Parsing macros/catalog.sql
2021-03-02 02:08:19.021989 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f483b7799a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4826fc9ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4826fc9970>]}
2021-03-02 02:08:19.022345 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=16
2021-03-02 02:08:19.022720 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-03-02 02:08:19.022873 (Thread-1): Parsing macros/materializations/copy.sql
2021-03-02 02:08:19.023198 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-03-02 02:08:19.028681 (Thread-1): Parsing macros/materializations/table.sql
2021-03-02 02:08:19.038495 (Thread-1): Parsing macros/materializations/incremental.sql
2021-03-02 02:08:19.051074 (Thread-1): Parsing macros/materializations/seed.sql
2021-03-02 02:08:19.053691 (Thread-1): Parsing macros/materializations/snapshot.sql
2021-03-02 02:08:19.055507 (Thread-1): Parsing macros/materializations/view.sql
2021-03-02 02:08:19.058962 (Thread-1): Parsing macros/core.sql
2021-03-02 02:08:19.062756 (Thread-1): Parsing macros/materializations/helpers.sql
2021-03-02 02:08:19.072090 (Thread-1): Parsing macros/materializations/common/merge.sql
2021-03-02 02:08:19.085616 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-02 02:08:19.087373 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2021-03-02 02:08:19.104563 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-02 02:08:19.135326 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-02 02:08:19.140158 (Thread-1): Parsing macros/materializations/view/view.sql
2021-03-02 02:08:19.146238 (Thread-1): Parsing macros/materializations/seed/seed.sql
2021-03-02 02:08:19.166648 (Thread-1): Parsing macros/materializations/table/table.sql
2021-03-02 02:08:19.173154 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2021-03-02 02:08:19.174945 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2021-03-02 02:08:19.180811 (Thread-1): Parsing macros/etc/is_incremental.sql
2021-03-02 02:08:19.182404 (Thread-1): Parsing macros/etc/query.sql
2021-03-02 02:08:19.183478 (Thread-1): Parsing macros/etc/datetime.sql
2021-03-02 02:08:19.192093 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2021-03-02 02:08:19.193032 (Thread-1): Parsing macros/etc/get_custom_database.sql
2021-03-02 02:08:19.194651 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2021-03-02 02:08:19.196627 (Thread-1): Parsing macros/schema_tests/not_null.sql
2021-03-02 02:08:19.198154 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2021-03-02 02:08:19.200860 (Thread-1): Parsing macros/schema_tests/relationships.sql
2021-03-02 02:08:19.202709 (Thread-1): Parsing macros/schema_tests/unique.sql
2021-03-02 02:08:19.204444 (Thread-1): Parsing macros/adapters/common.sql
2021-03-02 02:08:19.300457 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-02 02:08:19.325241 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-02 02:08:19.338516 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-02 02:08:19.350781 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-02 02:08:19.365817 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-02 02:08:19.378887 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-02 02:08:19.393097 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-02 02:08:19.776612 (Thread-1): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd3fa1811-86db-4354-a4f5-e22fecdedc8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f482625aeb0>]}
2021-03-02 02:08:19.826728 (Thread-2): handling status request
2021-03-02 02:08:19.827213 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'd3fa1811-86db-4354-a4f5-e22fecdedc8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4826236c70>]}
2021-03-02 02:08:19.832029 (Thread-2): sending response (<Response 11388 bytes [200 OK]>) to 10.0.26.40
2021-03-02 23:15:09.190132 (MainThread): Running with dbt=0.19.0
2021-03-02 23:15:09.338540 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2021-03-02 23:15:09.351661 (MainThread): Tracking: tracking
2021-03-02 23:15:09.371200 (Thread-1): Parsing macros/adapters.sql
2021-03-02 23:15:09.392432 (Thread-1): Parsing macros/etc.sql
2021-03-02 23:15:09.394820 (Thread-1): Parsing macros/catalog.sql
2021-03-02 23:15:09.401130 (Thread-1): Parsing macros/materializations/copy.sql
2021-03-02 23:15:09.405856 (Thread-1): Parsing macros/materializations/table.sql
2021-03-02 23:15:09.416117 (Thread-1): Parsing macros/materializations/incremental.sql
2021-03-02 23:15:09.430011 (Thread-1): Parsing macros/materializations/seed.sql
2021-03-02 23:15:09.433019 (Thread-1): Parsing macros/materializations/snapshot.sql
2021-03-02 23:15:09.435064 (Thread-1): Parsing macros/materializations/view.sql
2021-03-02 23:15:09.439375 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44acb069d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a358c2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a358c280>]}
2021-03-02 23:15:09.439754 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=15
2021-03-02 23:15:09.440143 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2021-03-02 23:15:09.440515 (MainThread): Send requests to http://localhost:8580/jsonrpc
2021-03-02 23:15:09.441341 (Thread-1): Parsing macros/core.sql
2021-03-02 23:15:09.445329 (Thread-1): Parsing macros/materializations/helpers.sql
2021-03-02 23:15:09.454142 (Thread-1): Parsing macros/materializations/common/merge.sql
2021-03-02 23:15:09.467780 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-02 23:15:09.469551 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2021-03-02 23:15:09.486835 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-02 23:15:09.517988 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-02 23:15:09.522903 (Thread-1): Parsing macros/materializations/view/view.sql
2021-03-02 23:15:09.529070 (Thread-1): Parsing macros/materializations/seed/seed.sql
2021-03-02 23:15:09.549289 (Thread-1): Parsing macros/materializations/table/table.sql
2021-03-02 23:15:09.555782 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2021-03-02 23:15:09.557607 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2021-03-02 23:15:09.563510 (Thread-1): Parsing macros/etc/is_incremental.sql
2021-03-02 23:15:09.565111 (Thread-1): Parsing macros/etc/query.sql
2021-03-02 23:15:09.566167 (Thread-1): Parsing macros/etc/datetime.sql
2021-03-02 23:15:09.574738 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2021-03-02 23:15:09.575677 (Thread-1): Parsing macros/etc/get_custom_database.sql
2021-03-02 23:15:09.577322 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2021-03-02 23:15:09.579257 (Thread-1): Parsing macros/schema_tests/not_null.sql
2021-03-02 23:15:09.580757 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2021-03-02 23:15:09.583411 (Thread-1): Parsing macros/schema_tests/relationships.sql
2021-03-02 23:15:09.585283 (Thread-1): Parsing macros/schema_tests/unique.sql
2021-03-02 23:15:09.587045 (Thread-1): Parsing macros/adapters/common.sql
2021-03-02 23:15:09.682313 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-02 23:15:09.708445 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-02 23:15:09.725590 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-02 23:15:09.739040 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-02 23:15:09.755730 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-02 23:15:09.771547 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-02 23:15:09.787814 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-02 23:15:10.147783 (Thread-1): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a33393a0>]}
2021-03-02 23:15:10.657237 (Thread-2): handling status request
2021-03-02 23:15:10.657686 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a801e190>]}
2021-03-02 23:15:10.662423 (Thread-2): sending response (<Response 11262 bytes [200 OK]>) to 10.0.21.154
2021-03-03 04:16:24.070770 (Thread-3): handling status request
2021-03-03 04:16:24.071230 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3fce760>]}
2021-03-03 04:16:24.075800 (Thread-3): sending response (<Response 11262 bytes [200 OK]>) to 10.0.28.107
2021-03-03 04:16:24.262269 (Thread-4): handling ps request
2021-03-03 04:16:24.262693 (Thread-4): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3468cd0>]}
2021-03-03 04:16:24.264428 (Thread-4): sending response (<Response 103 bytes [200 OK]>) to 10.0.0.205
2021-03-03 04:18:33.523850 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-03-03 04:18:33.572155 (Thread-5): Got an acceptable cached parse result
2021-03-03 04:18:33.827167 (Thread-5): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a31dde80>]}
2021-03-03 04:18:34.015874 (Thread-6): handling status request
2021-03-03 04:18:34.016322 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a320f700>]}
2021-03-03 04:18:34.017270 (Thread-6): sending response (<Response 881 bytes [200 OK]>) to 10.0.37.132
2021-03-03 04:19:16.647746 (Thread-7): Got an acceptable cached parse result
2021-03-03 04:19:16.905773 (Thread-7): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a347a220>]}
2021-03-03 04:19:16.914131 (Thread-8): handling status request
2021-03-03 04:19:16.914507 (Thread-8): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a32935e0>]}
2021-03-03 04:19:16.915377 (Thread-8): sending response (<Response 881 bytes [200 OK]>) to 10.0.25.94
2021-03-03 04:19:37.855980 (Thread-9): Got an acceptable cached parse result
2021-03-03 04:19:38.105890 (Thread-10): handling status request
2021-03-03 04:19:38.106308 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a2f2d6d0>]}
2021-03-03 04:19:38.107020 (Thread-10): sending response (<Response 183 bytes [200 OK]>) to 10.0.28.149
2021-03-03 04:19:38.191713 (Thread-9): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a312bdf0>]}
2021-03-03 04:19:39.449707 (Thread-11): handling status request
2021-03-03 04:19:39.450172 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a80974c0>]}
2021-03-03 04:19:39.451179 (Thread-11): sending response (<Response 881 bytes [200 OK]>) to 10.0.47.116
2021-03-03 04:20:30.312355 (Thread-12): Got an acceptable cached parse result
2021-03-03 04:20:30.359532 (Thread-12): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-03 04:20:30.557914 (Thread-12): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3552490>]}
2021-03-03 04:20:30.604682 (Thread-13): handling status request
2021-03-03 04:20:30.605142 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a30b6100>]}
2021-03-03 04:20:30.606125 (Thread-13): sending response (<Response 1186 bytes [200 OK]>) to 10.0.28.149
2021-03-03 04:20:31.762777 (Thread-14): handling status request
2021-03-03 04:20:31.763376 (Thread-14): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a8097460>]}
2021-03-03 04:20:31.764579 (Thread-14): sending response (<Response 1186 bytes [200 OK]>) to 10.0.37.132
2021-03-03 04:20:32.194746 (Thread-15): handling compile_sql request
2021-03-03 04:20:32.195183 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a312b400>]}
2021-03-03 04:20:32.197837 (Thread-15): Connection 'model.hashpath_demo.all_sightings' was properly closed.
2021-03-03 04:20:33.120674 (Thread-15): sending response (<Response 136 bytes [200 OK]>) to 10.0.28.149
2021-03-03 04:20:33.177296 (MainThread): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-03-03 04:20:33.199648 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 1 source, 0 exposures
2021-03-03 04:20:33.200205 (Thread-1): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-03-03 04:20:33.200324 (Thread-1): Compiling rpc.hashpath_demo.request
2021-03-03 04:20:33.222077 (Thread-1): finished collecting timing info
2021-03-03 04:20:33.222355 (Thread-1): finished collecting timing info
2021-03-03 04:20:33.411456 (Thread-16): handling poll request
2021-03-03 04:20:33.411936 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a312b3a0>]}
2021-03-03 04:20:33.417790 (Thread-16): sending response (<Response 5131 bytes [200 OK]>) to 10.0.28.107
2021-03-03 04:20:42.860037 (Thread-17): handling status request
2021-03-03 04:20:42.860455 (Thread-17): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a33da9a0>]}
2021-03-03 04:20:42.861479 (Thread-17): sending response (<Response 1186 bytes [200 OK]>) to 10.0.8.71
2021-03-03 04:20:43.174828 (Thread-18): handling run_sql request
2021-03-03 04:20:43.175246 (Thread-18): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3074eb0>]}
2021-03-03 04:20:44.088524 (Thread-18): sending response (<Response 136 bytes [200 OK]>) to 10.0.0.205
2021-03-03 04:20:44.140640 (MainThread): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-03-03 04:20:44.170460 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 1 source, 0 exposures
2021-03-03 04:20:44.197550 (Thread-1): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-03-03 04:20:44.197732 (Thread-1): Compiling rpc.hashpath_demo.request
2021-03-03 04:20:44.216128 (Thread-1): finished collecting timing info
2021-03-03 04:20:44.216405 (Thread-1): Opening a new connection, currently in state init
2021-03-03 04:20:44.221214 (Thread-1): On rpc.hashpath_demo.request: 

SELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings`
-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
limit 500
/* limit added automatically by dbt cloud */
2021-03-03 04:20:44.432620 (Thread-19): handling poll request
2021-03-03 04:20:44.433091 (Thread-19): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3403a90>]}
2021-03-03 04:20:44.435087 (Thread-19): sending response (<Response 2816 bytes [200 OK]>) to 10.0.0.205
2021-03-03 04:20:44.755459 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/667e416a-2ad4-465e-b7a1-62c4b430a241?maxResults=0&location=US&prettyPrint=false: Unrecognized name: s at [3:8]')
2021-03-03 04:20:45.928233 (Thread-20): handling poll request
2021-03-03 04:20:45.928861 (Thread-20): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3403fa0>]}
2021-03-03 04:20:45.930408 (Thread-20): sending response (<Response 874 bytes [200 OK]>) to 10.0.45.150
2021-03-03 04:20:46.047070 (Thread-1): finished collecting timing info
2021-03-03 04:20:46.047520 (Thread-1): Got an exception: Database Error
  Unrecognized name: s at [3:8]
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/lib/python3.8/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.8/dist-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/55fd82aa-3e56-4b38-b767-d742a233e4b4?maxResults=0&location=US&prettyPrint=false: Unrecognized name: s at [3:8]

(job ID: 55fd82aa-3e56-4b38-b767-d742a233e4b4)

                        -----Query Job SQL Follows-----                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:
   2:
   3:SELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings`
   4:-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s
   5:--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
   6:limit 500
   7:/* limit added automatically by dbt cloud */
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/node_runners.py", line 90, in execute
    _, execute_result = self.adapter.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/lib/python3.8/dist-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error
  Unrecognized name: s at [3:8]
2021-03-03 04:20:46.050372 (Thread-1): Got exception RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Unrecognized name: s at [3:8]', 'raw_sql': "{{ config(materialized='table') }}\n\nSELECT s.* FROM {{ source('hashpath_dataset', 'bigfoot_sightings') }}\n-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s\n--cross join {{ ref('new_model') }}\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '\n\nSELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings`\n-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s\n--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/rpc/sql_commands.py", line 145, in _in_thread
    self.node_results.append(runner.safe_run(self.manifest))
  File "/usr/local/lib/python3.8/dist-packages/dbt/task/base.py", line 360, in safe_run
    result = self.error_result(ctx.node, error, started, [])
  File "/usr/local/lib/python3.8/dist-packages/dbt/rpc/node_runners.py", line 56, in error_result
    raise error
dbt.rpc.error.RPCException: RPCException(10003, Database Error, {'type': 'DatabaseException', 'message': 'Database Error in rpc request (from remote system)\n  Unrecognized name: s at [3:8]', 'raw_sql': "{{ config(materialized='table') }}\n\nSELECT s.* FROM {{ source('hashpath_dataset', 'bigfoot_sightings') }}\n-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s\n--cross join {{ ref('new_model') }}\nlimit 500\n/* limit added automatically by dbt cloud */", 'compiled_sql': '\n\nSELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings`\n-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` s\n--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`\nlimit 500\n/* limit added automatically by dbt cloud */', 'tags': None}, None)
2021-03-03 04:20:47.257815 (Thread-21): handling poll request
2021-03-03 04:20:47.258252 (Thread-21): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a31fa430>]}
2021-03-03 04:20:47.259154 (Thread-21): sending response (<Response 12276 bytes [200 OK]>) to 10.0.0.205
2021-03-03 04:21:00.969272 (Thread-22): Got an acceptable cached parse result
2021-03-03 04:21:01.023047 (Thread-22): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-03 04:21:01.238011 (Thread-22): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a33e7820>]}
2021-03-03 04:21:01.252963 (Thread-23): handling status request
2021-03-03 04:21:01.253361 (Thread-23): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a350e0a0>]}
2021-03-03 04:21:01.254332 (Thread-23): sending response (<Response 1186 bytes [200 OK]>) to 10.0.9.138
2021-03-03 04:21:04.506505 (Thread-24): handling status request
2021-03-03 04:21:04.506957 (Thread-24): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3204400>]}
2021-03-03 04:21:04.507933 (Thread-24): sending response (<Response 1186 bytes [200 OK]>) to 10.0.21.154
2021-03-03 04:21:04.812066 (Thread-25): handling run_sql request
2021-03-03 04:21:04.812538 (Thread-25): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a801e970>]}
2021-03-03 04:21:04.813810 (Thread-25): Connection 'model.hashpath_demo.all_sightings' was properly closed.
2021-03-03 04:21:05.714253 (Thread-25): sending response (<Response 136 bytes [200 OK]>) to 10.0.28.149
2021-03-03 04:21:05.771876 (MainThread): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-03-03 04:21:05.795716 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 1 source, 0 exposures
2021-03-03 04:21:05.796363 (Thread-1): Acquiring new bigquery connection "rpc.hashpath_demo.request".
2021-03-03 04:21:05.796557 (Thread-1): Compiling rpc.hashpath_demo.request
2021-03-03 04:21:05.819084 (Thread-1): finished collecting timing info
2021-03-03 04:21:05.819471 (Thread-1): Opening a new connection, currently in state init
2021-03-03 04:21:05.824625 (Thread-1): On rpc.hashpath_demo.request: 

SELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings` s
-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` 
--cross join `hashpath-demo-data`.`dbt_jrosen`.`new_model`
limit 500
/* limit added automatically by dbt cloud */
2021-03-03 04:21:06.100322 (Thread-26): handling poll request
2021-03-03 04:21:06.101320 (Thread-26): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44bdbe65e0>]}
2021-03-03 04:21:06.103319 (Thread-26): sending response (<Response 2817 bytes [200 OK]>) to 10.0.32.229
2021-03-03 04:21:07.411019 (Thread-27): handling poll request
2021-03-03 04:21:07.411543 (Thread-27): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a33f82e0>]}
2021-03-03 04:21:07.412452 (Thread-27): sending response (<Response 402 bytes [200 OK]>) to 10.0.9.138
2021-03-03 04:21:08.419339 (Thread-1): finished collecting timing info
2021-03-03 04:21:08.720331 (Thread-28): handling poll request
2021-03-03 04:21:08.720750 (Thread-28): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a34b69d0>]}
2021-03-03 04:21:08.738926 (Thread-28): sending response (<Response 1098105 bytes [200 OK]>) to 10.0.15.84
2021-03-03 04:21:24.527985 (Thread-29): handling status request
2021-03-03 04:21:24.528390 (Thread-29): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a34b6250>]}
2021-03-03 04:21:24.552238 (Thread-29): sending response (<Response 1186 bytes [200 OK]>) to 10.0.9.138
2021-03-03 04:21:24.565515 (Thread-30): handling status request
2021-03-03 04:21:24.565857 (Thread-30): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3424af0>]}
2021-03-03 04:21:24.566764 (Thread-30): sending response (<Response 1186 bytes [200 OK]>) to 10.0.25.94
2021-03-03 04:21:24.879800 (Thread-31): handling docs.generate request
2021-03-03 04:21:24.880208 (Thread-31): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3424550>]}
2021-03-03 04:21:25.806107 (Thread-31): sending response (<Response 136 bytes [200 OK]>) to 10.0.25.94
2021-03-03 04:21:25.876165 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 1 source, 0 exposures
2021-03-03 04:21:25.877565 (MainThread): 
2021-03-03 04:21:25.877888 (MainThread): Acquiring new bigquery connection "master".
2021-03-03 04:21:25.893222 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_jrosen".
2021-03-03 04:21:25.893330 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-03 04:21:26.115066 (MainThread): 04:21:26 | Concurrency: 1 threads (target='default')
2021-03-03 04:21:26.115189 (MainThread): 04:21:26 | 
2021-03-03 04:21:26.117272 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-03 04:21:26.117455 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-03 04:21:26.133171 (Thread-32): handling poll request
2021-03-03 04:21:26.117536 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-03 04:21:26.133835 (Thread-32): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a34243d0>]}
2021-03-03 04:21:26.136059 (Thread-32): sending response (<Response 3648 bytes [200 OK]>) to 10.0.32.229
2021-03-03 04:21:26.141130 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-03 04:21:26.155527 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.155794 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.156006 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-03 04:21:26.156101 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-03 04:21:26.156203 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-03 04:21:26.156269 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-03 04:21:26.165149 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-03 04:21:26.180058 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.180352 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.180561 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-03 04:21:26.180660 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-03 04:21:26.180752 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-03 04:21:26.180812 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-03 04:21:26.186329 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-03 04:21:26.202207 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.202538 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-03 04:21:26.202645 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-03 04:21:26.202736 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-03 04:21:26.202803 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-03 04:21:26.214380 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-03 04:21:26.229185 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.229483 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.229690 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-03 04:21:26.229785 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-03 04:21:26.229871 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-03 04:21:26.229932 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-03 04:21:26.237308 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-03 04:21:26.252779 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.253150 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.253375 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-03 04:21:26.253473 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-03 04:21:26.253562 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-03 04:21:26.253625 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-03 04:21:26.262000 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-03 04:21:26.276451 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.276711 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.276915 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-03 04:21:26.277034 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-03 04:21:26.277142 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-03 04:21:26.277204 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-03 04:21:26.285229 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-03 04:21:26.299784 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.300126 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.300451 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-03 04:21:26.300606 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-03 04:21:26.300751 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-03-03 04:21:26.300849 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-03-03 04:21:26.340640 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-03-03 04:21:26.355801 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.356169 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.356391 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-03 04:21:26.356504 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-03 04:21:26.356598 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-03-03 04:21:26.356660 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-03-03 04:21:26.368122 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-03-03 04:21:26.382734 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.383020 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.383227 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-03 04:21:26.383324 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-03 04:21:26.383412 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-03-03 04:21:26.383474 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-03 04:21:26.391967 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-03-03 04:21:26.406014 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.406285 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.406487 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-03 04:21:26.406581 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-03 04:21:26.406668 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-03-03 04:21:26.406725 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-03 04:21:26.415159 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-03-03 04:21:26.432301 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.432630 (Thread-1): finished collecting timing info
2021-03-03 04:21:26.432843 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-03 04:21:26.433970 (MainThread): Connection 'master' was properly closed.
2021-03-03 04:21:26.434063 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-03-03 04:21:26.556115 (MainThread): 04:21:26 | Done.
2021-03-03 04:21:26.636233 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-03 04:21:26.636402 (MainThread): 04:21:26 | Building catalog
2021-03-03 04:21:26.665788 (MainThread): Opening a new connection, currently in state init
2021-03-03 04:21:26.861406 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-03 04:21:26.877621 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-03 04:21:26.882047 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: 
    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_jrosen`.__TABLES__
        where (upper(dataset_id) = upper('dbt_jrosen'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_jrosen`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-03 04:21:27.437799 (Thread-33): handling poll request
2021-03-03 04:21:27.438225 (Thread-33): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a2ec2b50>]}
2021-03-03 04:21:27.445903 (Thread-33): sending response (<Response 43100 bytes [200 OK]>) to 10.0.28.107
2021-03-03 04:21:28.775183 (Thread-34): handling poll request
2021-03-03 04:21:28.775587 (Thread-34): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a2ec2fd0>]}
2021-03-03 04:21:28.776460 (Thread-34): sending response (<Response 294 bytes [200 OK]>) to 10.0.47.116
2021-03-03 04:21:30.117298 (Thread-35): handling poll request
2021-03-03 04:21:30.117884 (Thread-35): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a2ec2040>]}
2021-03-03 04:21:30.118804 (Thread-35): sending response (<Response 294 bytes [200 OK]>) to 10.0.45.150
2021-03-03 04:21:30.231969 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-03 04:21:30.234211 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-03 04:21:30.238816 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: 
    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`hashpath_dataset`.__TABLES__
        where (upper(dataset_id) = upper('hashpath_dataset'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`hashpath_dataset`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`hashpath_dataset`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-03 04:21:31.469481 (Thread-36): handling poll request
2021-03-03 04:21:31.469917 (Thread-36): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a8b1bf10>]}
2021-03-03 04:21:31.471087 (Thread-36): sending response (<Response 8244 bytes [200 OK]>) to 10.0.28.149
2021-03-03 04:21:32.785765 (Thread-37): handling poll request
2021-03-03 04:21:32.786204 (Thread-37): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3206910>]}
2021-03-03 04:21:32.787084 (Thread-37): sending response (<Response 294 bytes [200 OK]>) to 10.0.28.107
2021-03-03 04:21:34.087189 (Thread-38): handling poll request
2021-03-03 04:21:34.087593 (Thread-38): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3206af0>]}
2021-03-03 04:21:34.088467 (Thread-38): sending response (<Response 294 bytes [200 OK]>) to 10.0.25.94
2021-03-03 04:21:34.395085 (MainThread): 04:21:34 | Catalog written to /usr/src/develop/user-7994/environment-9499/repository-16870/target/catalog.json
2021-03-03 04:21:35.405276 (Thread-39): handling poll request
2021-03-03 04:21:35.405697 (Thread-39): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a2f04b20>]}
2021-03-03 04:21:35.412448 (Thread-39): sending response (<Response 15270 bytes [200 OK]>) to 10.0.13.227
2021-03-03 04:21:35.777502 (Thread-40): handling status request
2021-03-03 04:21:35.777970 (Thread-40): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3439a90>]}
2021-03-03 04:21:35.779030 (Thread-40): sending response (<Response 1186 bytes [200 OK]>) to 10.0.45.150
2021-03-03 04:23:19.525057 (Thread-41): handling status request
2021-03-03 04:23:19.526610 (Thread-41): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': 'b3e9f1d6-1300-4c25-a0b6-c7fac8713518', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44a3fe7e20>]}
2021-03-03 04:23:19.527655 (Thread-41): sending response (<Response 1186 bytes [200 OK]>) to 10.0.37.131
2021-03-07 19:22:56.468727 (MainThread): Running with dbt=0.19.0
2021-03-07 19:22:57.162011 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, defer=None, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2021-03-07 19:22:57.164672 (MainThread): Tracking: tracking
2021-03-07 19:22:57.177643 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6f0520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d970c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d970b20>]}
2021-03-07 19:22:57.208272 (MainThread): Partial parsing not enabled
2021-03-07 19:22:57.210211 (MainThread): Parsing macros/adapters.sql
2021-03-07 19:22:57.234210 (MainThread): Parsing macros/catalog.sql
2021-03-07 19:22:57.242875 (MainThread): Parsing macros/etc.sql
2021-03-07 19:22:57.246573 (MainThread): Parsing macros/materializations/copy.sql
2021-03-07 19:22:57.252722 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-07 19:22:57.268405 (MainThread): Parsing macros/materializations/seed.sql
2021-03-07 19:22:57.272720 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-07 19:22:57.275767 (MainThread): Parsing macros/materializations/table.sql
2021-03-07 19:22:57.287951 (MainThread): Parsing macros/materializations/view.sql
2021-03-07 19:22:57.294045 (MainThread): Parsing macros/core.sql
2021-03-07 19:22:57.300489 (MainThread): Parsing macros/adapters/common.sql
2021-03-07 19:22:57.351812 (MainThread): Parsing macros/etc/datetime.sql
2021-03-07 19:22:57.366007 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-07 19:22:57.368435 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-07 19:22:57.372032 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-07 19:22:57.375793 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-07 19:22:57.378583 (MainThread): Parsing macros/etc/query.sql
2021-03-07 19:22:57.380672 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-07 19:22:57.393154 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-07 19:22:57.409192 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-07 19:22:57.411704 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-07 19:22:57.422134 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-07 19:22:57.447048 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-07 19:22:57.487019 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-07 19:22:57.490851 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-07 19:22:57.514002 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-07 19:22:57.522943 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-07 19:22:57.529712 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-07 19:22:57.537786 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-07 19:22:57.541234 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-07 19:22:57.543453 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-07 19:22:57.546202 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-07 19:22:57.554719 (MainThread): Partial parsing not enabled
2021-03-07 19:22:57.604729 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-07 19:22:57.632111 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-07 19:22:57.646625 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-07 19:22:57.662123 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-07 19:22:57.681800 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-07 19:22:57.743067 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-07 19:22:57.765597 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-07 19:22:58.019492 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-07 19:22:58.019889 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-07 19:22:58.020096 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-07 19:22:58.089658 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '080eea32-cf25-4879-938f-120e0a923aec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc014c0>]}
2021-03-07 19:22:58.153324 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-07 19:22:58.154629 (MainThread): 
2021-03-07 19:22:58.155027 (MainThread): Acquiring new bigquery connection "master".
2021-03-07 19:22:58.171729 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-07 19:22:58.171921 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-07 19:22:58.176192 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-07 19:22:58.686031 (MainThread): 14:22:58 | Concurrency: 1 threads (target='prod')
2021-03-07 19:22:58.686234 (MainThread): 14:22:58 | 
2021-03-07 19:22:58.688668 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-07 19:22:58.689062 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-07 19:22:58.689259 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-07 19:22:58.704042 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55222), raddr=('172.217.12.170', 443)>
2021-03-07 19:22:58.704227 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55223), raddr=('172.217.9.234', 443)>
2021-03-07 19:22:58.706988 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-07 19:22:58.708037 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.708681 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.709467 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-07 19:22:58.709732 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:22:58.710085 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-07 19:22:58.710251 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:22:58.719202 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-07 19:22:58.719712 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.720061 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.720545 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:22:58.720704 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:22:58.721007 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-07 19:22:58.721292 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:22:58.729563 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-07 19:22:58.730008 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.730811 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:22:58.730972 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-07 19:22:58.731250 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-07 19:22:58.731504 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-07 19:22:58.744951 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-07 19:22:58.745303 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.745544 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.745941 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-07 19:22:58.746077 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-07 19:22:58.746315 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-07 19:22:58.746418 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-07 19:22:58.754770 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-07 19:22:58.755403 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.755822 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.756237 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-07 19:22:58.756371 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-07 19:22:58.756615 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-07 19:22:58.756735 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-07 19:22:58.765104 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-07 19:22:58.765502 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.765893 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.766361 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-07 19:22:58.766522 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-07 19:22:58.766829 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-07 19:22:58.766958 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-07 19:22:58.776058 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-07 19:22:58.776365 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.776590 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.776949 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-07 19:22:58.777076 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:22:58.777309 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-03-07 19:22:58.777410 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:22:58.794254 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-03-07 19:22:58.794638 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.794933 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.795386 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:22:58.795547 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:22:58.795835 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-03-07 19:22:58.795961 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:22:58.804688 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-03-07 19:22:58.804999 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.805261 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.805727 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:22:58.805882 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:22:58.806137 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-03-07 19:22:58.806246 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:22:58.814348 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-03-07 19:22:58.814637 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.814868 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.815225 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:22:58.815351 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:22:58.815578 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-03-07 19:22:58.815678 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:22:58.823909 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-03-07 19:22:58.824339 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.824685 (Thread-1): finished collecting timing info
2021-03-07 19:22:58.825138 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:22:58.826234 (MainThread): Connection 'master' was properly closed.
2021-03-07 19:22:58.826368 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-03-07 19:22:58.884242 (MainThread): 14:22:58 | Done.
2021-03-07 19:22:58.884496 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da29a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d28a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d28a100>]}
2021-03-07 19:22:58.884722 (MainThread): Flushing usage events
2021-03-07 19:23:53.449315 (MainThread): Running with dbt=0.19.0
2021-03-07 19:23:54.117770 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, defer=None, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2021-03-07 19:23:54.119056 (MainThread): Tracking: tracking
2021-03-07 19:23:54.130967 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058cf520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b52f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b52e50>]}
2021-03-07 19:23:54.158498 (MainThread): Partial parsing not enabled
2021-03-07 19:23:54.160130 (MainThread): Parsing macros/adapters.sql
2021-03-07 19:23:54.183268 (MainThread): Parsing macros/catalog.sql
2021-03-07 19:23:54.191203 (MainThread): Parsing macros/etc.sql
2021-03-07 19:23:54.196142 (MainThread): Parsing macros/materializations/copy.sql
2021-03-07 19:23:54.203699 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-07 19:23:54.220227 (MainThread): Parsing macros/materializations/seed.sql
2021-03-07 19:23:54.225828 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-07 19:23:54.229617 (MainThread): Parsing macros/materializations/table.sql
2021-03-07 19:23:54.243880 (MainThread): Parsing macros/materializations/view.sql
2021-03-07 19:23:54.249078 (MainThread): Parsing macros/core.sql
2021-03-07 19:23:54.254606 (MainThread): Parsing macros/adapters/common.sql
2021-03-07 19:23:54.304226 (MainThread): Parsing macros/etc/datetime.sql
2021-03-07 19:23:54.317823 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-07 19:23:54.319491 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-07 19:23:54.321780 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-07 19:23:54.324656 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-07 19:23:54.327246 (MainThread): Parsing macros/etc/query.sql
2021-03-07 19:23:54.329281 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-07 19:23:54.340040 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-07 19:23:54.355815 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-07 19:23:54.358601 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-07 19:23:54.366281 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-07 19:23:54.393967 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-07 19:23:54.436446 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-07 19:23:54.440670 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-07 19:23:54.463771 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-07 19:23:54.473808 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-07 19:23:54.480685 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-07 19:23:54.488696 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-07 19:23:54.493074 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-07 19:23:54.495673 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-07 19:23:54.498317 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-07 19:23:54.507236 (MainThread): Partial parsing not enabled
2021-03-07 19:23:54.561580 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-07 19:23:54.594158 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-07 19:23:54.610952 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-07 19:23:54.627940 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-07 19:23:54.644331 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-07 19:23:54.703707 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-07 19:23:54.723939 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-07 19:23:54.980334 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-07 19:23:54.980678 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-07 19:23:54.980816 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-07 19:23:55.042768 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.hashpath_demo.twitter

2021-03-07 19:23:55.051294 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1fce75ae-9d1b-412a-bd89-fb69ca2889fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd3490>]}
2021-03-07 19:23:55.120554 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-07 19:23:55.121826 (MainThread): 
2021-03-07 19:23:55.122145 (MainThread): Acquiring new bigquery connection "master".
2021-03-07 19:23:55.138044 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-07 19:23:55.138231 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-07 19:23:55.142492 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-07 19:23:55.505294 (MainThread): 14:23:55 | Concurrency: 1 threads (target='prod')
2021-03-07 19:23:55.505501 (MainThread): 14:23:55 | 
2021-03-07 19:23:55.509753 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-07 19:23:55.510265 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-07 19:23:55.510422 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-07 19:23:55.525866 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55235), raddr=('172.217.12.170', 443)>
2021-03-07 19:23:55.526071 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55236), raddr=('172.217.9.234', 443)>
2021-03-07 19:23:55.528894 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-07 19:23:55.529347 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.529869 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.530701 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-07 19:23:55.530919 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:23:55.531251 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-07 19:23:55.531370 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:23:55.539005 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-07 19:23:55.539525 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.539958 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.540416 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:23:55.540557 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:23:55.540810 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-07 19:23:55.540921 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:23:55.547778 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-07 19:23:55.548257 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.550035 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:23:55.550248 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-07 19:23:55.550564 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-07 19:23:55.550687 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-07 19:23:55.564203 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-07 19:23:55.564545 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.564813 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.565280 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-07 19:23:55.565446 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-07 19:23:55.565719 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-07 19:23:55.566039 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-07 19:23:55.575495 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-07 19:23:55.575855 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.576138 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.576589 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-07 19:23:55.576748 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-07 19:23:55.577151 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-07 19:23:55.577367 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-07 19:23:55.586128 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-07 19:23:55.586452 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.586837 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.587250 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-07 19:23:55.587515 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-07 19:23:55.587924 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-07 19:23:55.588117 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-07 19:23:55.597388 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-07 19:23:55.597899 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.598337 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.599068 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-07 19:23:55.599331 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:23:55.599585 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-03-07 19:23:55.599720 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:23:55.615270 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-03-07 19:23:55.615620 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.615873 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.616246 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:23:55.616381 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:23:55.616754 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-03-07 19:23:55.616863 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:23:55.624528 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-03-07 19:23:55.624824 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.625063 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.625422 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:23:55.625552 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:23:55.626082 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-03-07 19:23:55.626199 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:23:55.633987 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-03-07 19:23:55.634286 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.634565 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.634930 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:23:55.635095 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:23:55.635328 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-03-07 19:23:55.635429 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:23:55.644486 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-03-07 19:23:55.644829 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.645120 (Thread-1): finished collecting timing info
2021-03-07 19:23:55.645679 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:23:55.646653 (MainThread): Connection 'master' was properly closed.
2021-03-07 19:23:55.646778 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-03-07 19:23:55.703529 (MainThread): 14:23:55 | Done.
2021-03-07 19:23:55.703893 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e5afa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d59a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e0c580>]}
2021-03-07 19:23:55.704109 (MainThread): Flushing usage events
2021-03-07 19:24:35.052543 (MainThread): Running with dbt=0.19.0
2021-03-07 19:24:35.569740 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, defer=None, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2021-03-07 19:24:35.570930 (MainThread): Tracking: tracking
2021-03-07 19:24:35.579438 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118684f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ad9af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ad9a30>]}
2021-03-07 19:24:35.607740 (MainThread): Partial parsing not enabled
2021-03-07 19:24:35.609183 (MainThread): Parsing macros/adapters.sql
2021-03-07 19:24:35.632244 (MainThread): Parsing macros/catalog.sql
2021-03-07 19:24:35.639128 (MainThread): Parsing macros/etc.sql
2021-03-07 19:24:35.641760 (MainThread): Parsing macros/materializations/copy.sql
2021-03-07 19:24:35.648618 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-07 19:24:35.663836 (MainThread): Parsing macros/materializations/seed.sql
2021-03-07 19:24:35.666938 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-07 19:24:35.669135 (MainThread): Parsing macros/materializations/table.sql
2021-03-07 19:24:35.680766 (MainThread): Parsing macros/materializations/view.sql
2021-03-07 19:24:35.685130 (MainThread): Parsing macros/core.sql
2021-03-07 19:24:35.689575 (MainThread): Parsing macros/adapters/common.sql
2021-03-07 19:24:35.746406 (MainThread): Parsing macros/etc/datetime.sql
2021-03-07 19:24:35.757793 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-07 19:24:35.759176 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-07 19:24:35.761371 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-07 19:24:35.763869 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-07 19:24:35.765737 (MainThread): Parsing macros/etc/query.sql
2021-03-07 19:24:35.766935 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-07 19:24:35.778098 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-07 19:24:35.796087 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-07 19:24:35.798597 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-07 19:24:35.805989 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-07 19:24:35.831005 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-07 19:24:35.873464 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-07 19:24:35.875492 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-07 19:24:35.895621 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-07 19:24:35.905823 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-07 19:24:35.912627 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-07 19:24:35.919958 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-07 19:24:35.922984 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-07 19:24:35.924822 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-07 19:24:35.926897 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-07 19:24:35.937264 (MainThread): Partial parsing not enabled
2021-03-07 19:24:35.988682 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-07 19:24:36.015356 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-07 19:24:36.029167 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-07 19:24:36.047090 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-07 19:24:36.061582 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-07 19:24:36.121366 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-07 19:24:36.139432 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-07 19:24:36.154296 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-07 19:24:36.474813 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf21bb59-114d-4e9a-a97b-89d072021f47', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e03610>]}
2021-03-07 19:24:36.537734 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-07 19:24:36.539173 (MainThread): 
2021-03-07 19:24:36.539647 (MainThread): Acquiring new bigquery connection "master".
2021-03-07 19:24:36.555856 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-07 19:24:36.556028 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-07 19:24:36.560291 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-07 19:24:36.950053 (MainThread): 14:24:36 | Concurrency: 1 threads (target='prod')
2021-03-07 19:24:36.950273 (MainThread): 14:24:36 | 
2021-03-07 19:24:36.952369 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-07 19:24:36.952785 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-07 19:24:36.953131 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-07 19:24:36.970196 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-07 19:24:36.970566 (Thread-1): finished collecting timing info
2021-03-07 19:24:36.970849 (Thread-1): finished collecting timing info
2021-03-07 19:24:36.971288 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-07 19:24:36.971422 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:24:36.971675 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-07 19:24:36.971778 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:24:36.978736 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-07 19:24:36.979195 (Thread-1): finished collecting timing info
2021-03-07 19:24:36.979430 (Thread-1): finished collecting timing info
2021-03-07 19:24:36.979799 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:24:36.979925 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:24:36.980154 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-07 19:24:36.980260 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:24:36.986711 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-07 19:24:36.987210 (Thread-1): finished collecting timing info
2021-03-07 19:24:36.987708 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:24:36.987862 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-07 19:24:36.988136 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-07 19:24:36.988251 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-07 19:24:36.998650 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-07 19:24:36.999626 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.000017 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.000492 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-07 19:24:37.000639 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-07 19:24:37.000889 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-07 19:24:37.001068 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-07 19:24:37.012360 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-07 19:24:37.013502 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.014400 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.015865 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-07 19:24:37.016328 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-07 19:24:37.017140 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-07 19:24:37.017479 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-07 19:24:37.028992 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-07 19:24:37.029617 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.029933 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.030413 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-07 19:24:37.030568 (Thread-1): Began running node test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-07 19:24:37.030852 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_unique_public_metrics_id".
2021-03-07 19:24:37.030977 (Thread-1): Compiling test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-07 19:24:37.047304 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_unique_public_metrics_id"
2021-03-07 19:24:37.047798 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.048056 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.048448 (Thread-1): Finished running node test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-07 19:24:37.048589 (Thread-1): Began running node test.hashpath_demo.unique_unique_public_metrics_id
2021-03-07 19:24:37.048834 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_unique_public_metrics_id".
2021-03-07 19:24:37.048942 (Thread-1): Compiling test.hashpath_demo.unique_unique_public_metrics_id
2021-03-07 19:24:37.056829 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_unique_public_metrics_id"
2021-03-07 19:24:37.057223 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.057454 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.057808 (Thread-1): Finished running node test.hashpath_demo.unique_unique_public_metrics_id
2021-03-07 19:24:37.057937 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-07 19:24:37.058560 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-07 19:24:37.058782 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-07 19:24:37.068399 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-07 19:24:37.068771 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.069061 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.069521 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-07 19:24:37.069682 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-07 19:24:37.069936 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-07 19:24:37.070050 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-07 19:24:37.078849 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-07 19:24:37.079140 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.079492 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.079931 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-07 19:24:37.080077 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:24:37.080473 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-03-07 19:24:37.080761 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:24:37.089596 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-03-07 19:24:37.089916 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.090153 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.090518 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-07 19:24:37.090647 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:24:37.091005 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-03-07 19:24:37.091122 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:24:37.099682 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-03-07 19:24:37.100153 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.100527 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.101161 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-07 19:24:37.101407 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:24:37.101831 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-03-07 19:24:37.101977 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:24:37.113565 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-03-07 19:24:37.114062 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.114761 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.115653 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-07 19:24:37.115932 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:24:37.116299 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-03-07 19:24:37.116420 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:24:37.126628 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-03-07 19:24:37.127064 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.127472 (Thread-1): finished collecting timing info
2021-03-07 19:24:37.128010 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-07 19:24:37.128957 (MainThread): Connection 'master' was properly closed.
2021-03-07 19:24:37.129081 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-03-07 19:24:37.191384 (MainThread): 14:24:37 | Done.
2021-03-07 19:24:37.191660 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d0f100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e1a1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ae93d0>]}
2021-03-07 19:24:37.191891 (MainThread): Flushing usage events
2021-03-07 19:25:10.067400 (MainThread): Running with dbt=0.19.0
2021-03-07 19:25:10.791247 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-07 19:25:10.792493 (MainThread): Tracking: tracking
2021-03-07 19:25:10.810473 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efac520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11021dc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11021dbb0>]}
2021-03-07 19:25:10.842244 (MainThread): Partial parsing not enabled
2021-03-07 19:25:10.844425 (MainThread): Parsing macros/adapters.sql
2021-03-07 19:25:10.868366 (MainThread): Parsing macros/catalog.sql
2021-03-07 19:25:10.876096 (MainThread): Parsing macros/etc.sql
2021-03-07 19:25:10.879327 (MainThread): Parsing macros/materializations/copy.sql
2021-03-07 19:25:10.885457 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-07 19:25:10.900889 (MainThread): Parsing macros/materializations/seed.sql
2021-03-07 19:25:10.904876 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-07 19:25:10.907720 (MainThread): Parsing macros/materializations/table.sql
2021-03-07 19:25:10.920720 (MainThread): Parsing macros/materializations/view.sql
2021-03-07 19:25:10.925486 (MainThread): Parsing macros/core.sql
2021-03-07 19:25:10.930484 (MainThread): Parsing macros/adapters/common.sql
2021-03-07 19:25:10.985439 (MainThread): Parsing macros/etc/datetime.sql
2021-03-07 19:25:10.996239 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-07 19:25:10.998060 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-07 19:25:11.001893 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-07 19:25:11.005241 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-07 19:25:11.008014 (MainThread): Parsing macros/etc/query.sql
2021-03-07 19:25:11.010031 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-07 19:25:11.021128 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-07 19:25:11.038716 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-07 19:25:11.041725 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-07 19:25:11.052301 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-07 19:25:11.079559 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-07 19:25:11.136586 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-07 19:25:11.141034 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-07 19:25:11.166851 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-07 19:25:11.175686 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-07 19:25:11.182029 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-07 19:25:11.192695 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-07 19:25:11.198767 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-07 19:25:11.202723 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-07 19:25:11.207091 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-07 19:25:11.217491 (MainThread): Partial parsing not enabled
2021-03-07 19:25:11.271759 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-07 19:25:11.300137 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-07 19:25:11.315352 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-07 19:25:11.331896 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-07 19:25:11.348633 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-07 19:25:11.406430 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-07 19:25:11.422922 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-07 19:25:11.439830 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-07 19:25:11.820814 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1b62d912-fae2-4677-aef9-300c983a7ca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105458e0>]}
2021-03-07 19:25:11.894683 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-07 19:25:11.896199 (MainThread): 
2021-03-07 19:25:11.896584 (MainThread): Acquiring new bigquery connection "master".
2021-03-07 19:25:11.906182 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-07 19:25:11.906374 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-07 19:25:12.320912 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-07 19:25:12.321090 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-07 19:25:12.325114 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-07 19:25:12.660721 (MainThread): 14:25:12 | Concurrency: 1 threads (target='prod')
2021-03-07 19:25:12.660928 (MainThread): 14:25:12 | 
2021-03-07 19:25:12.663532 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-07 19:25:12.664879 (Thread-1): 14:25:12 | 1 of 7 START view model dbt_demo_production.new_model................ [RUN]
2021-03-07 19:25:12.665217 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-07 19:25:12.665360 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-07 19:25:12.682305 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-07 19:25:12.683567 (Thread-1): finished collecting timing info
2021-03-07 19:25:12.726498 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-03-07 19:25:12.727514 (Thread-1): Opening a new connection, currently in state closed
2021-03-07 19:25:12.731808 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-03-07 19:25:13.811109 (Thread-1): finished collecting timing info
2021-03-07 19:25:13.811911 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b62d912-fae2-4677-aef9-300c983a7ca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103cdfd0>]}
2021-03-07 19:25:13.813185 (Thread-1): 14:25:13 | 1 of 7 OK created view model dbt_demo_production.new_model........... [OK in 1.15s]
2021-03-07 19:25:13.813349 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-07 19:25:13.813513 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:25:13.814652 (Thread-1): 14:25:13 | 2 of 7 START table model dbt_demo_production.sightings_by_day_by_state [RUN]
2021-03-07 19:25:13.815063 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-07 19:25:13.815187 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:25:13.822195 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-07 19:25:13.822552 (Thread-1): finished collecting timing info
2021-03-07 19:25:13.842874 (Thread-1): Opening a new connection, currently in state closed
2021-03-07 19:25:13.847188 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-07 19:25:14.209442 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-07 19:25:14.209847 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-03-07 19:25:16.600602 (Thread-1): finished collecting timing info
2021-03-07 19:25:16.601877 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b62d912-fae2-4677-aef9-300c983a7ca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111671eb0>]}
2021-03-07 19:25:16.603517 (Thread-1): 14:25:16 | 2 of 7 OK created table model dbt_demo_production.sightings_by_day_by_state [CREATE TABLE (3.7k rows, 76.6 KB processed) in 2.79s]
2021-03-07 19:25:16.603716 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-07 19:25:16.603898 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:25:16.604261 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-07 19:25:16.604406 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:25:16.611892 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-07 19:25:16.612270 (Thread-1): finished collecting timing info
2021-03-07 19:25:16.612777 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-07 19:25:16.612941 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-07 19:25:16.614107 (Thread-1): 14:25:16 | 3 of 7 START table model dbt_demo_production.unique_public_metrics... [RUN]
2021-03-07 19:25:16.614518 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-07 19:25:16.614655 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-07 19:25:16.624386 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-07 19:25:16.624701 (Thread-1): finished collecting timing info
2021-03-07 19:25:16.627500 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55262), raddr=('172.217.12.170', 443)>
2021-03-07 19:25:16.627747 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55263), raddr=('172.217.9.234', 443)>
2021-03-07 19:25:16.627915 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55265), raddr=('172.217.9.234', 443)>
2021-03-07 19:25:16.628054 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55264), raddr=('172.217.12.170', 443)>
2021-03-07 19:25:16.628194 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55267), raddr=('172.217.9.234', 443)>
2021-03-07 19:25:16.628325 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55266), raddr=('172.217.12.170', 443)>
2021-03-07 19:25:16.631924 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-07 19:25:16.632587 (Thread-1): Opening a new connection, currently in state closed
2021-03-07 19:25:16.638153 (Thread-1): On model.hashpath_demo.unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.unique_public_metrics"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`
  
  
  OPTIONS()
  as (
    with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data.twitter.public_metrics`) 
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  url
FROM unique_tweets
ORDER BY 3 DESC
LIMIT 10
  );
    
2021-03-07 19:25:19.487075 (Thread-1): finished collecting timing info
2021-03-07 19:25:19.488010 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b62d912-fae2-4677-aef9-300c983a7ca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103e3940>]}
2021-03-07 19:25:19.489412 (Thread-1): 14:25:19 | 3 of 7 OK created table model dbt_demo_production.unique_public_metrics [CREATE TABLE (10.0 rows, 27.5 MB processed) in 2.87s]
2021-03-07 19:25:19.489578 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-07 19:25:19.489740 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-07 19:25:19.490848 (Thread-1): 14:25:19 | 4 of 7 START table model dbt_demo_production.all_sightings........... [RUN]
2021-03-07 19:25:19.491203 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-07 19:25:19.491334 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-07 19:25:19.502287 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-07 19:25:19.502628 (Thread-1): finished collecting timing info
2021-03-07 19:25:19.506981 (Thread-1): Opening a new connection, currently in state closed
2021-03-07 19:25:19.511205 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-07 19:25:19.835690 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-03-07 19:25:19.836375 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings` s
-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` 
--cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  );
    
2021-03-07 19:25:23.172036 (Thread-1): finished collecting timing info
2021-03-07 19:25:23.172914 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b62d912-fae2-4677-aef9-300c983a7ca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103e3940>]}
2021-03-07 19:25:23.174275 (Thread-1): 14:25:23 | 4 of 7 OK created table model dbt_demo_production.all_sightings...... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 3.68s]
2021-03-07 19:25:23.174448 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-07 19:25:23.174642 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-07 19:25:23.175989 (Thread-1): 14:25:23 | 5 of 7 START table model dbt_demo_production.sightings_by_day........ [RUN]
2021-03-07 19:25:23.176494 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-07 19:25:23.176654 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-07 19:25:23.185615 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-07 19:25:23.185954 (Thread-1): finished collecting timing info
2021-03-07 19:25:23.190242 (Thread-1): Opening a new connection, currently in state closed
2021-03-07 19:25:23.194329 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-07 19:25:23.523098 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-07 19:25:23.523677 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-03-07 19:25:26.077360 (Thread-1): finished collecting timing info
2021-03-07 19:25:26.078199 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b62d912-fae2-4677-aef9-300c983a7ca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111707070>]}
2021-03-07 19:25:26.079438 (Thread-1): 14:25:26 | 5 of 7 OK created table model dbt_demo_production.sightings_by_day... [CREATE TABLE (2.9k rows, 57.6 KB processed) in 2.90s]
2021-03-07 19:25:26.079596 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-07 19:25:26.079761 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-07 19:25:26.080858 (Thread-1): 14:25:26 | 6 of 7 START view model dbt_demo_production.demo_123................. [RUN]
2021-03-07 19:25:26.081176 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-07 19:25:26.081307 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-07 19:25:26.091040 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-07 19:25:26.091403 (Thread-1): finished collecting timing info
2021-03-07 19:25:26.096228 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-03-07 19:25:26.096566 (Thread-1): Opening a new connection, currently in state closed
2021-03-07 19:25:26.100530 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='Utah';


2021-03-07 19:25:26.889275 (Thread-1): finished collecting timing info
2021-03-07 19:25:26.890074 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b62d912-fae2-4677-aef9-300c983a7ca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11172efd0>]}
2021-03-07 19:25:26.891336 (Thread-1): 14:25:26 | 6 of 7 OK created view model dbt_demo_production.demo_123............ [OK in 0.81s]
2021-03-07 19:25:26.891494 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-07 19:25:26.891659 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-07 19:25:26.893083 (Thread-1): 14:25:26 | 7 of 7 START view model dbt_demo_production.massachusetts_sightings.. [RUN]
2021-03-07 19:25:26.893492 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-07 19:25:26.893639 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-07 19:25:26.904421 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-07 19:25:26.904847 (Thread-1): finished collecting timing info
2021-03-07 19:25:26.910276 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55268), raddr=('172.217.12.170', 443)>
2021-03-07 19:25:26.910506 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55269), raddr=('172.217.9.234', 443)>
2021-03-07 19:25:26.910663 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55272), raddr=('172.217.9.234', 443)>
2021-03-07 19:25:26.910801 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55271), raddr=('172.217.12.170', 443)>
2021-03-07 19:25:26.910939 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55275), raddr=('172.217.9.234', 443)>
2021-03-07 19:25:26.911075 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55274), raddr=('172.217.12.170', 443)>
2021-03-07 19:25:26.911203 (Thread-1): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55278), raddr=('172.217.9.234', 443)>
2021-03-07 19:25:26.911339 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 55277), raddr=('172.217.12.170', 443)>
2021-03-07 19:25:26.912200 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-07 19:25:26.912550 (Thread-1): Opening a new connection, currently in state closed
2021-03-07 19:25:26.916834 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='California';


2021-03-07 19:25:27.637753 (Thread-1): finished collecting timing info
2021-03-07 19:25:27.638771 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1b62d912-fae2-4677-aef9-300c983a7ca8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111703f40>]}
2021-03-07 19:25:27.640188 (Thread-1): 14:25:27 | 7 of 7 OK created view model dbt_demo_production.massachusetts_sightings [OK in 0.75s]
2021-03-07 19:25:27.640376 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-07 19:25:27.641616 (MainThread): Acquiring new bigquery connection "master".
2021-03-07 19:25:27.642050 (MainThread): 14:25:27 | 
2021-03-07 19:25:27.642180 (MainThread): 14:25:27 | Finished running 3 view models, 4 table models in 15.75s.
2021-03-07 19:25:27.642293 (MainThread): Connection 'master' was properly closed.
2021-03-07 19:25:27.642468 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-03-07 19:25:27.708906 (MainThread): 
2021-03-07 19:25:27.709077 (MainThread): Completed successfully
2021-03-07 19:25:27.709251 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2021-03-07 19:25:27.709572 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101d4fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11053e220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11053e100>]}
2021-03-07 19:25:27.709789 (MainThread): Flushing usage events
2021-03-08 03:48:36.515695 (MainThread): Running with dbt=0.19.0
2021-03-08 03:48:37.241400 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-08 03:48:37.242787 (MainThread): Tracking: tracking
2021-03-08 03:48:37.257625 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9823d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc04fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc04940>]}
2021-03-08 03:48:37.286355 (MainThread): Partial parsing not enabled
2021-03-08 03:48:37.288342 (MainThread): Parsing macros/adapters.sql
2021-03-08 03:48:37.312145 (MainThread): Parsing macros/catalog.sql
2021-03-08 03:48:37.319463 (MainThread): Parsing macros/etc.sql
2021-03-08 03:48:37.324056 (MainThread): Parsing macros/materializations/copy.sql
2021-03-08 03:48:37.330548 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-08 03:48:37.347614 (MainThread): Parsing macros/materializations/seed.sql
2021-03-08 03:48:37.352322 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-08 03:48:37.355852 (MainThread): Parsing macros/materializations/table.sql
2021-03-08 03:48:37.369388 (MainThread): Parsing macros/materializations/view.sql
2021-03-08 03:48:37.374285 (MainThread): Parsing macros/core.sql
2021-03-08 03:48:37.379327 (MainThread): Parsing macros/adapters/common.sql
2021-03-08 03:48:37.431916 (MainThread): Parsing macros/etc/datetime.sql
2021-03-08 03:48:37.442757 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-08 03:48:37.445083 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-08 03:48:37.447918 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-08 03:48:37.450841 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-08 03:48:37.453820 (MainThread): Parsing macros/etc/query.sql
2021-03-08 03:48:37.455865 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-08 03:48:37.467529 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-08 03:48:37.484512 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-08 03:48:37.487034 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-08 03:48:37.495779 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-08 03:48:37.521323 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-08 03:48:37.564407 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-08 03:48:37.567254 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-08 03:48:37.588480 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-08 03:48:37.597294 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-08 03:48:37.603582 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-08 03:48:37.614081 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-08 03:48:37.619132 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-08 03:48:37.621619 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-08 03:48:37.624430 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-08 03:48:37.633940 (MainThread): Partial parsing not enabled
2021-03-08 03:48:37.687513 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-08 03:48:37.718009 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-08 03:48:37.733558 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-08 03:48:37.750842 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-08 03:48:37.766214 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-08 03:48:37.830873 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-08 03:48:37.852293 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-08 03:48:37.869789 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-08 03:48:38.194902 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2bc0ab3a-1035-42c9-8479-1484672a0c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf1c430>]}
2021-03-08 03:48:38.267562 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-08 03:48:38.268864 (MainThread): 
2021-03-08 03:48:38.269202 (MainThread): Acquiring new bigquery connection "master".
2021-03-08 03:48:38.278691 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-08 03:48:38.278887 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-08 03:48:38.789641 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-08 03:48:38.789923 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-08 03:48:38.794529 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-08 03:48:39.128324 (MainThread): 22:48:39 | Concurrency: 1 threads (target='prod')
2021-03-08 03:48:39.128560 (MainThread): 22:48:39 | 
2021-03-08 03:48:39.137116 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-08 03:48:39.138677 (Thread-1): 22:48:39 | 1 of 7 START view model dbt_demo_production.new_model................ [RUN]
2021-03-08 03:48:39.139121 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-08 03:48:39.139296 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-08 03:48:39.157347 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-08 03:48:39.157723 (Thread-1): finished collecting timing info
2021-03-08 03:48:39.197635 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-03-08 03:48:39.198079 (Thread-1): Opening a new connection, currently in state closed
2021-03-08 03:48:39.202360 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-03-08 03:48:40.180915 (Thread-1): finished collecting timing info
2021-03-08 03:48:40.181623 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bc0ab3a-1035-42c9-8479-1484672a0c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be6ee20>]}
2021-03-08 03:48:40.182688 (Thread-1): 22:48:40 | 1 of 7 OK created view model dbt_demo_production.new_model........... [OK in 1.04s]
2021-03-08 03:48:40.182830 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-08 03:48:40.182969 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-08 03:48:40.183954 (Thread-1): 22:48:40 | 2 of 7 START table model dbt_demo_production.sightings_by_day_by_state [RUN]
2021-03-08 03:48:40.184354 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-08 03:48:40.184467 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-08 03:48:40.191393 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-08 03:48:40.191755 (Thread-1): finished collecting timing info
2021-03-08 03:48:40.214684 (Thread-1): Opening a new connection, currently in state closed
2021-03-08 03:48:40.218738 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-08 03:48:40.589329 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-08 03:48:40.589770 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-03-08 03:48:42.942482 (Thread-1): finished collecting timing info
2021-03-08 03:48:42.943423 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bc0ab3a-1035-42c9-8479-1484672a0c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d067700>]}
2021-03-08 03:48:42.944906 (Thread-1): 22:48:42 | 2 of 7 OK created table model dbt_demo_production.sightings_by_day_by_state [CREATE TABLE (3.7k rows, 76.6 KB processed) in 2.76s]
2021-03-08 03:48:42.945082 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-08 03:48:42.945254 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-08 03:48:42.945853 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-08 03:48:42.945996 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-08 03:48:42.952750 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-08 03:48:42.953570 (Thread-1): finished collecting timing info
2021-03-08 03:48:42.954040 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-08 03:48:42.954191 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-08 03:48:42.955264 (Thread-1): 22:48:42 | 3 of 7 START table model dbt_demo_production.unique_public_metrics... [RUN]
2021-03-08 03:48:42.955669 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-08 03:48:42.955793 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-08 03:48:42.962357 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59023), raddr=('142.250.80.10', 443)>
2021-03-08 03:48:42.962586 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59024), raddr=('172.217.9.234', 443)>
2021-03-08 03:48:42.962734 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59026), raddr=('172.217.9.234', 443)>
2021-03-08 03:48:42.962878 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59025), raddr=('142.250.80.10', 443)>
2021-03-08 03:48:42.963012 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59028), raddr=('172.217.9.234', 443)>
2021-03-08 03:48:42.963145 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59027), raddr=('142.250.80.10', 443)>
2021-03-08 03:48:42.967143 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-08 03:48:42.967461 (Thread-1): finished collecting timing info
2021-03-08 03:48:42.971661 (Thread-1): Opening a new connection, currently in state closed
2021-03-08 03:48:42.976740 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-08 03:48:43.295522 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-08 03:48:43.296044 (Thread-1): On model.hashpath_demo.unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.unique_public_metrics"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`
  
  
  OPTIONS()
  as (
    with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data.twitter.public_metrics`) 
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC
LIMIT 10
  );
    
2021-03-08 03:48:45.878860 (Thread-1): finished collecting timing info
2021-03-08 03:48:45.879859 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bc0ab3a-1035-42c9-8479-1484672a0c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d08b4c0>]}
2021-03-08 03:48:45.881270 (Thread-1): 22:48:45 | 3 of 7 OK created table model dbt_demo_production.unique_public_metrics [CREATE TABLE (10.0 rows, 28.7 MB processed) in 2.92s]
2021-03-08 03:48:45.881452 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-08 03:48:45.881622 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-08 03:48:45.882776 (Thread-1): 22:48:45 | 4 of 7 START table model dbt_demo_production.all_sightings........... [RUN]
2021-03-08 03:48:45.883261 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-08 03:48:45.883405 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-08 03:48:45.895153 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-08 03:48:45.901331 (Thread-1): finished collecting timing info
2021-03-08 03:48:45.908005 (Thread-1): Opening a new connection, currently in state closed
2021-03-08 03:48:45.913044 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-08 03:48:46.254220 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-03-08 03:48:46.254818 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings` s
-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` 
--cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  );
    
2021-03-08 03:48:50.357204 (Thread-1): finished collecting timing info
2021-03-08 03:48:50.358038 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bc0ab3a-1035-42c9-8479-1484672a0c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0cf430>]}
2021-03-08 03:48:50.359507 (Thread-1): 22:48:50 | 4 of 7 OK created table model dbt_demo_production.all_sightings...... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 4.47s]
2021-03-08 03:48:50.359747 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-08 03:48:50.360046 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-08 03:48:50.361311 (Thread-1): 22:48:50 | 5 of 7 START table model dbt_demo_production.sightings_by_day........ [RUN]
2021-03-08 03:48:50.361723 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-08 03:48:50.361864 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-08 03:48:50.372009 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-08 03:48:50.372551 (Thread-1): finished collecting timing info
2021-03-08 03:48:50.377572 (Thread-1): Opening a new connection, currently in state closed
2021-03-08 03:48:50.383081 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-08 03:48:50.698777 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-08 03:48:50.704980 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-03-08 03:48:52.913467 (Thread-1): finished collecting timing info
2021-03-08 03:48:52.914459 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bc0ab3a-1035-42c9-8479-1484672a0c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0fff70>]}
2021-03-08 03:48:52.915959 (Thread-1): 22:48:52 | 5 of 7 OK created table model dbt_demo_production.sightings_by_day... [CREATE TABLE (2.9k rows, 57.6 KB processed) in 2.55s]
2021-03-08 03:48:52.916183 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-08 03:48:52.916354 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-08 03:48:52.917491 (Thread-1): 22:48:52 | 6 of 7 START view model dbt_demo_production.demo_123................. [RUN]
2021-03-08 03:48:52.917863 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-08 03:48:52.918011 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-08 03:48:52.928825 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-08 03:48:52.929205 (Thread-1): finished collecting timing info
2021-03-08 03:48:52.934579 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-03-08 03:48:52.935286 (Thread-1): Opening a new connection, currently in state closed
2021-03-08 03:48:52.939708 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='Utah';


2021-03-08 03:48:53.952109 (Thread-1): finished collecting timing info
2021-03-08 03:48:53.952999 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bc0ab3a-1035-42c9-8479-1484672a0c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d07a640>]}
2021-03-08 03:48:53.954313 (Thread-1): 22:48:53 | 6 of 7 OK created view model dbt_demo_production.demo_123............ [OK in 1.04s]
2021-03-08 03:48:53.954488 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-08 03:48:53.954656 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-08 03:48:53.955827 (Thread-1): 22:48:53 | 7 of 7 START view model dbt_demo_production.massachusetts_sightings.. [RUN]
2021-03-08 03:48:53.956328 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-08 03:48:53.956475 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-08 03:48:53.960919 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59030), raddr=('172.217.9.234', 443)>
2021-03-08 03:48:53.961155 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59029), raddr=('142.250.80.10', 443)>
2021-03-08 03:48:53.961321 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59032), raddr=('172.217.9.234', 443)>
2021-03-08 03:48:53.961489 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59031), raddr=('142.250.80.10', 443)>
2021-03-08 03:48:53.961692 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59037), raddr=('172.217.9.234', 443)>
2021-03-08 03:48:53.962000 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59036), raddr=('142.250.80.10', 443)>
2021-03-08 03:48:53.962192 (Thread-1): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59039), raddr=('172.217.9.234', 443)>
2021-03-08 03:48:53.962425 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 59038), raddr=('142.250.80.10', 443)>
2021-03-08 03:48:53.970018 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-08 03:48:53.970393 (Thread-1): finished collecting timing info
2021-03-08 03:48:53.975638 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-08 03:48:53.976024 (Thread-1): Opening a new connection, currently in state closed
2021-03-08 03:48:53.980678 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='California';


2021-03-08 03:48:54.916289 (Thread-1): finished collecting timing info
2021-03-08 03:48:54.917116 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2bc0ab3a-1035-42c9-8479-1484672a0c44', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0b8b20>]}
2021-03-08 03:48:54.918530 (Thread-1): 22:48:54 | 7 of 7 OK created view model dbt_demo_production.massachusetts_sightings [OK in 0.96s]
2021-03-08 03:48:54.918782 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-08 03:48:54.920119 (MainThread): Acquiring new bigquery connection "master".
2021-03-08 03:48:54.920531 (MainThread): 22:48:54 | 
2021-03-08 03:48:54.920680 (MainThread): 22:48:54 | Finished running 3 view models, 4 table models in 16.65s.
2021-03-08 03:48:54.920808 (MainThread): Connection 'master' was properly closed.
2021-03-08 03:48:54.920902 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-03-08 03:48:54.987656 (MainThread): 
2021-03-08 03:48:54.987828 (MainThread): Completed successfully
2021-03-08 03:48:54.988035 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2021-03-08 03:48:54.988352 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be2b730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf0c460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc55940>]}
2021-03-08 03:48:54.988805 (MainThread): Flushing usage events
2021-03-09 00:19:56.672220 (MainThread): Running with dbt=0.19.0
2021-03-09 00:19:57.425213 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 00:19:57.426705 (MainThread): Tracking: tracking
2021-03-09 00:19:57.443276 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d903d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c68c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d903e80>]}
2021-03-09 00:19:57.472055 (MainThread): Partial parsing not enabled
2021-03-09 00:19:57.475124 (MainThread): Parsing macros/adapters.sql
2021-03-09 00:19:57.500598 (MainThread): Parsing macros/catalog.sql
2021-03-09 00:19:57.508724 (MainThread): Parsing macros/etc.sql
2021-03-09 00:19:57.511652 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 00:19:57.517635 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 00:19:57.533447 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 00:19:57.537213 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 00:19:57.539791 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 00:19:57.552144 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 00:19:57.557214 (MainThread): Parsing macros/core.sql
2021-03-09 00:19:57.562422 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 00:19:57.615196 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 00:19:57.626345 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 00:19:57.627707 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 00:19:57.630201 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 00:19:57.633659 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 00:19:57.636195 (MainThread): Parsing macros/etc/query.sql
2021-03-09 00:19:57.638017 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 00:19:57.648962 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 00:19:57.668089 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 00:19:57.671231 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 00:19:57.681905 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 00:19:57.708974 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 00:19:57.749205 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 00:19:57.752358 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 00:19:57.775896 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 00:19:57.786236 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 00:19:57.792947 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 00:19:57.801852 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 00:19:57.807300 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 00:19:57.811004 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 00:19:57.814460 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 00:19:57.824828 (MainThread): Partial parsing not enabled
2021-03-09 00:19:57.880644 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 00:19:57.916845 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 00:19:57.932394 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 00:19:57.949175 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 00:19:57.964749 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 00:19:58.025319 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 00:19:58.046734 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 00:19:58.062280 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 00:19:58.384534 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8b667a75-cf98-40c3-8003-d760ee02f2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc1fdf0>]}
2021-03-09 00:19:58.453429 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 00:19:58.454805 (MainThread): 
2021-03-09 00:19:58.455250 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 00:19:58.465447 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 00:19:58.465658 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 00:19:58.998380 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 00:19:58.998555 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 00:19:59.002617 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 00:19:59.359195 (MainThread): 19:19:59 | Concurrency: 1 threads (target='prod')
2021-03-09 00:19:59.359399 (MainThread): 19:19:59 | 
2021-03-09 00:19:59.368540 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-09 00:19:59.370121 (Thread-1): 19:19:59 | 1 of 7 START view model dbt_demo_production.new_model................ [RUN]
2021-03-09 00:19:59.370545 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 00:19:59.370711 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-09 00:19:59.388904 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-09 00:19:59.389849 (Thread-1): finished collecting timing info
2021-03-09 00:19:59.430799 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-03-09 00:19:59.431479 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 00:19:59.437261 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-03-09 00:20:00.584947 (Thread-1): finished collecting timing info
2021-03-09 00:20:00.585767 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b667a75-cf98-40c3-8003-d760ee02f2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db74fa0>]}
2021-03-09 00:20:00.587208 (Thread-1): 19:20:00 | 1 of 7 OK created view model dbt_demo_production.new_model........... [OK in 1.22s]
2021-03-09 00:20:00.587409 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-09 00:20:00.587660 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 00:20:00.588976 (Thread-1): 19:20:00 | 2 of 7 START table model dbt_demo_production.sightings_by_day_by_state [RUN]
2021-03-09 00:20:00.589503 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 00:20:00.589896 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-09 00:20:00.597844 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-09 00:20:00.598210 (Thread-1): finished collecting timing info
2021-03-09 00:20:00.618554 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 00:20:00.622650 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 00:20:01.020686 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-09 00:20:01.021138 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-03-09 00:20:10.682254 (Thread-1): finished collecting timing info
2021-03-09 00:20:10.685551 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b667a75-cf98-40c3-8003-d760ee02f2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc1f0d0>]}
2021-03-09 00:20:10.687207 (Thread-1): 19:20:10 | 2 of 7 OK created table model dbt_demo_production.sightings_by_day_by_state [CREATE TABLE (3.7k rows, 76.6 KB processed) in 10.10s]
2021-03-09 00:20:10.687408 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 00:20:10.687609 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-09 00:20:10.688003 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 00:20:10.688194 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-09 00:20:10.695308 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-09 00:20:10.695777 (Thread-1): finished collecting timing info
2021-03-09 00:20:10.696286 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-09 00:20:10.696441 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 00:20:10.697520 (Thread-1): 19:20:10 | 3 of 7 START table model dbt_demo_production.unique_public_metrics... [RUN]
2021-03-09 00:20:10.697929 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 00:20:10.698063 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 00:20:10.704756 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57224), raddr=('142.250.64.74', 443)>
2021-03-09 00:20:10.705492 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57225), raddr=('172.217.9.234', 443)>
2021-03-09 00:20:10.705818 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57227), raddr=('172.217.9.234', 443)>
2021-03-09 00:20:10.706300 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57226), raddr=('142.250.64.74', 443)>
2021-03-09 00:20:10.706549 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57230), raddr=('172.217.9.234', 443)>
2021-03-09 00:20:10.706695 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57229), raddr=('142.250.64.74', 443)>
2021-03-09 00:20:10.710674 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 00:20:10.711060 (Thread-1): finished collecting timing info
2021-03-09 00:20:10.715482 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 00:20:10.719531 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 00:20:11.071751 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 00:20:11.078121 (Thread-1): On model.hashpath_demo.unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.unique_public_metrics"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`
  
  
  OPTIONS()
  as (
    with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data.twitter.public_metrics`) 
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC
  );
    
2021-03-09 00:20:18.095826 (Thread-1): finished collecting timing info
2021-03-09 00:20:18.096741 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b667a75-cf98-40c3-8003-d760ee02f2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd64070>]}
2021-03-09 00:20:18.098087 (Thread-1): 19:20:18 | 3 of 7 OK created table model dbt_demo_production.unique_public_metrics [CREATE TABLE (3.9k rows, 29.3 MB processed) in 7.40s]
2021-03-09 00:20:18.098273 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 00:20:18.098451 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-09 00:20:18.099638 (Thread-1): 19:20:18 | 4 of 7 START table model dbt_demo_production.all_sightings........... [RUN]
2021-03-09 00:20:18.100034 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 00:20:18.100182 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-09 00:20:18.114088 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-09 00:20:18.114559 (Thread-1): finished collecting timing info
2021-03-09 00:20:18.119760 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 00:20:18.124463 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 00:20:18.504003 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-03-09 00:20:18.504625 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings` s
-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` 
--cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  );
    
2021-03-09 00:20:25.819907 (Thread-1): finished collecting timing info
2021-03-09 00:20:25.820833 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b667a75-cf98-40c3-8003-d760ee02f2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc02cd0>]}
2021-03-09 00:20:25.822229 (Thread-1): 19:20:25 | 4 of 7 OK created table model dbt_demo_production.all_sightings...... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 7.72s]
2021-03-09 00:20:25.822403 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-09 00:20:25.822615 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-09 00:20:25.823847 (Thread-1): 19:20:25 | 5 of 7 START table model dbt_demo_production.sightings_by_day........ [RUN]
2021-03-09 00:20:25.824357 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 00:20:25.824510 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-09 00:20:25.834182 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-09 00:20:25.840578 (Thread-1): finished collecting timing info
2021-03-09 00:20:25.847044 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 00:20:25.851949 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 00:20:26.181691 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-09 00:20:26.182213 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-03-09 00:20:31.997721 (Thread-1): finished collecting timing info
2021-03-09 00:20:32.004328 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b667a75-cf98-40c3-8003-d760ee02f2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd64370>]}
2021-03-09 00:20:32.006213 (Thread-1): 19:20:32 | 5 of 7 OK created table model dbt_demo_production.sightings_by_day... [CREATE TABLE (2.9k rows, 57.6 KB processed) in 6.18s]
2021-03-09 00:20:32.006420 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-09 00:20:32.006618 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-09 00:20:32.007930 (Thread-1): 19:20:32 | 6 of 7 START view model dbt_demo_production.demo_123................. [RUN]
2021-03-09 00:20:32.008321 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 00:20:32.008490 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-09 00:20:32.019145 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-09 00:20:32.019542 (Thread-1): finished collecting timing info
2021-03-09 00:20:32.024817 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-03-09 00:20:32.025160 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 00:20:32.029548 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='Utah';


2021-03-09 00:20:32.849041 (Thread-1): finished collecting timing info
2021-03-09 00:20:32.850255 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b667a75-cf98-40c3-8003-d760ee02f2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc02460>]}
2021-03-09 00:20:32.851628 (Thread-1): 19:20:32 | 6 of 7 OK created view model dbt_demo_production.demo_123............ [OK in 0.84s]
2021-03-09 00:20:32.851812 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-09 00:20:32.851987 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-09 00:20:32.853087 (Thread-1): 19:20:32 | 7 of 7 START view model dbt_demo_production.massachusetts_sightings.. [RUN]
2021-03-09 00:20:32.853535 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 00:20:32.853673 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-09 00:20:32.858293 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57233), raddr=('172.217.9.234', 443)>
2021-03-09 00:20:32.858553 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57232), raddr=('142.250.64.74', 443)>
2021-03-09 00:20:32.858716 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57235), raddr=('172.217.9.234', 443)>
2021-03-09 00:20:32.858874 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57234), raddr=('142.250.64.74', 443)>
2021-03-09 00:20:32.859062 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57238), raddr=('172.217.9.234', 443)>
2021-03-09 00:20:32.859210 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57237), raddr=('142.250.64.74', 443)>
2021-03-09 00:20:32.859354 (Thread-1): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57240), raddr=('172.217.9.234', 443)>
2021-03-09 00:20:32.859513 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 57239), raddr=('142.250.64.74', 443)>
2021-03-09 00:20:32.867046 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-09 00:20:32.867441 (Thread-1): finished collecting timing info
2021-03-09 00:20:32.873068 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-09 00:20:32.873478 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 00:20:32.878186 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='California';


2021-03-09 00:20:33.957897 (Thread-1): finished collecting timing info
2021-03-09 00:20:33.958736 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b667a75-cf98-40c3-8003-d760ee02f2cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd98040>]}
2021-03-09 00:20:33.959982 (Thread-1): 19:20:33 | 7 of 7 OK created view model dbt_demo_production.massachusetts_sightings [OK in 1.11s]
2021-03-09 00:20:33.960143 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-09 00:20:33.961319 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 00:20:33.961694 (MainThread): 19:20:33 | 
2021-03-09 00:20:33.961829 (MainThread): 19:20:33 | Finished running 3 view models, 4 table models in 35.51s.
2021-03-09 00:20:33.961935 (MainThread): Connection 'master' was properly closed.
2021-03-09 00:20:33.962012 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-03-09 00:20:34.029627 (MainThread): 
2021-03-09 00:20:34.029849 (MainThread): Completed successfully
2021-03-09 00:20:34.030060 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2021-03-09 00:20:34.030335 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d999fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8ed8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8edf70>]}
2021-03-09 00:20:34.030555 (MainThread): Flushing usage events
2021-03-09 18:08:06.695991 (MainThread): Running with dbt=0.19.0
2021-03-09 18:08:07.395351 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:08:07.396747 (MainThread): Tracking: tracking
2021-03-09 18:08:07.413839 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b94fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078774c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b94bb0>]}
2021-03-09 18:08:07.442348 (MainThread): Partial parsing not enabled
2021-03-09 18:08:07.444411 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:08:07.468803 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:08:07.477756 (MainThread): Parsing macros/etc.sql
2021-03-09 18:08:07.480893 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:08:07.487622 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:08:07.503772 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:08:07.507237 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:08:07.509847 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:08:07.521582 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:08:07.526480 (MainThread): Parsing macros/core.sql
2021-03-09 18:08:07.531458 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:08:07.589919 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:08:07.603679 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:08:07.605803 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:08:07.608283 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:08:07.611545 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:08:07.614515 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:08:07.617027 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:08:07.633056 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:08:07.654345 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:08:07.657342 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:08:07.667301 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:08:07.697376 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:08:07.748723 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:08:07.752025 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:08:07.778566 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:08:07.788735 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:08:07.795213 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:08:07.806635 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:08:07.810835 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:08:07.814167 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:08:07.817142 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:08:07.825271 (MainThread): Partial parsing not enabled
2021-03-09 18:08:07.876990 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:08:07.900963 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:08:07.912366 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:08:07.926422 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:08:07.940253 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:08:07.950566 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:08:08.003799 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:08:08.017053 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:08:08.023139 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bb1a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d43430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7fa30>]}
2021-03-09 18:08:08.023442 (MainThread): Flushing usage events
2021-03-09 18:08:08.772322 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:08:08.772549 (MainThread): Encountered an error:
2021-03-09 18:08:08.772752 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  expected token ',', got 'public_metrics'
    line 10
      FROM {{ source('twitter,'public_metrics')}}
2021-03-09 18:08:08.783057 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 10, in template
jinja2.exceptions.TemplateSyntaxError: expected token ',', got 'public_metrics'
  line 10
    FROM {{ source('twitter,'public_metrics')}}

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 854, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 434, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 282, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 232, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 183, in parse_with_cache
    parser.parse_file(block)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/base.py", line 424, in parse_file
    self.parse_node(file_block)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/base.py", line 397, in parse_node
    self.render_update(node, config)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/base.py", line 372, in render_update
    self.render_with_context(node, config)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/base.py", line 288, in render_with_context
    get_rendered(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 570, in get_rendered
    template = get_template(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 499, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  expected token ',', got 'public_metrics'
    line 10
      FROM {{ source('twitter,'public_metrics')}}

2021-03-09 18:08:38.910580 (MainThread): Running with dbt=0.19.0
2021-03-09 18:08:39.380946 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:08:39.381961 (MainThread): Tracking: tracking
2021-03-09 18:08:39.390075 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103460610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046d3c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046d3b50>]}
2021-03-09 18:08:39.416582 (MainThread): Partial parsing not enabled
2021-03-09 18:08:39.417783 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:08:39.443989 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:08:39.450689 (MainThread): Parsing macros/etc.sql
2021-03-09 18:08:39.452903 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:08:39.457990 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:08:39.471958 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:08:39.474843 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:08:39.477078 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:08:39.487651 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:08:39.491704 (MainThread): Parsing macros/core.sql
2021-03-09 18:08:39.496255 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:08:39.541208 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:08:39.552013 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:08:39.553652 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:08:39.556055 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:08:39.558766 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:08:39.560745 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:08:39.561991 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:08:39.573145 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:08:39.589679 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:08:39.591598 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:08:39.598157 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:08:39.620712 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:08:39.656472 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:08:39.658409 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:08:39.677113 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:08:39.685174 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:08:39.690481 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:08:39.697584 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:08:39.700650 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:08:39.702289 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:08:39.704373 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:08:39.713327 (MainThread): Partial parsing not enabled
2021-03-09 18:08:39.763560 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:08:39.785886 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:08:39.795536 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:08:39.806329 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:08:39.819277 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:08:39.830888 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:08:39.896222 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:08:39.909508 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:08:39.913680 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047217c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104895670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048b3dc0>]}
2021-03-09 18:08:39.913920 (MainThread): Flushing usage events
2021-03-09 18:08:40.062554 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:08:40.062791 (MainThread): Encountered an error:
2021-03-09 18:08:40.063010 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  unexpected '}'
    line 10
      FROM {{ source('twitter','public_metrics')} }
2021-03-09 18:08:40.065884 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 941, in from_string
    return cls.from_code(self, self.compile(source), globals, None)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 638, in compile
    self.handle_exception(source=source_hint)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<unknown>", line 10, in template
jinja2.exceptions.TemplateSyntaxError: unexpected '}'
  line 10
    FROM {{ source('twitter','public_metrics')} }

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 854, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 434, in load_all
    loader.load(macro_manifest=macro_manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 282, in load
    self.parse_project(project, macro_manifest, old_results)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 232, in parse_project
    self.parse_with_cache(path, parser, old_results)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 183, in parse_with_cache
    parser.parse_file(block)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/base.py", line 424, in parse_file
    self.parse_node(file_block)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/base.py", line 397, in parse_node
    self.render_update(node, config)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/base.py", line 372, in render_update
    self.render_with_context(node, config)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/base.py", line 288, in render_with_context
    get_rendered(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 570, in get_rendered
    template = get_template(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 523, in get_template
    return env.from_string(template_source, globals=ctx)
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 499, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  unexpected '}'
    line 10
      FROM {{ source('twitter','public_metrics')} }

2021-03-09 18:08:56.456550 (MainThread): Running with dbt=0.19.0
2021-03-09 18:08:56.910713 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:08:56.911672 (MainThread): Tracking: tracking
2021-03-09 18:08:56.920064 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080675b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092d8d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092d8b20>]}
2021-03-09 18:08:56.946548 (MainThread): Partial parsing not enabled
2021-03-09 18:08:56.947768 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:08:56.970223 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:08:56.976863 (MainThread): Parsing macros/etc.sql
2021-03-09 18:08:56.979094 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:08:56.984037 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:08:56.997710 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:08:57.000446 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:08:57.002442 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:08:57.013028 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:08:57.017103 (MainThread): Parsing macros/core.sql
2021-03-09 18:08:57.021307 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:08:57.070928 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:08:57.081298 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:08:57.082323 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:08:57.084438 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:08:57.086616 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:08:57.088395 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:08:57.089544 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:08:57.103013 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:08:57.118958 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:08:57.121002 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:08:57.127732 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:08:57.150040 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:08:57.184859 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:08:57.186862 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:08:57.206835 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:08:57.214383 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:08:57.219821 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:08:57.226507 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:08:57.229249 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:08:57.230769 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:08:57.232669 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:08:57.241130 (MainThread): Partial parsing not enabled
2021-03-09 18:08:57.286325 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:08:57.309276 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:08:57.319223 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:08:57.330106 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:08:57.344966 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:08:57.355121 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:08:57.413002 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:08:57.425937 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:08:57.724336 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:08:57.732325 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '92c71896-e697-4155-992e-c6c7d65d333f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095862b0>]}
2021-03-09 18:08:57.806602 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:08:57.807875 (MainThread): 
2021-03-09 18:08:57.808193 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:08:57.817100 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:08:57.817276 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:08:58.323211 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:08:58.323397 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:08:58.327843 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:08:58.390653 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51718), raddr=('172.217.10.106', 443)>
2021-03-09 18:08:58.390948 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51719), raddr=('172.217.9.234', 443)>
2021-03-09 18:08:58.703450 (MainThread): 13:08:58 | Concurrency: 1 threads (target='prod')
2021-03-09 18:08:58.703651 (MainThread): 13:08:58 | 
2021-03-09 18:08:58.712001 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-09 18:08:58.713569 (Thread-1): 13:08:58 | 1 of 7 START view model dbt_demo_production.new_model................ [RUN]
2021-03-09 18:08:58.713998 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:08:58.714175 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-09 18:08:58.731006 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-09 18:08:58.732459 (Thread-1): finished collecting timing info
2021-03-09 18:08:58.775595 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-03-09 18:08:58.776602 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:08:58.781004 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-03-09 18:09:01.186839 (Thread-1): finished collecting timing info
2021-03-09 18:09:01.187670 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92c71896-e697-4155-992e-c6c7d65d333f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a8b100>]}
2021-03-09 18:09:01.189118 (Thread-1): 13:09:01 | 1 of 7 OK created view model dbt_demo_production.new_model........... [OK in 2.47s]
2021-03-09 18:09:01.189293 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-09 18:09:01.189457 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:09:01.190573 (Thread-1): 13:09:01 | 2 of 7 START table model dbt_demo_production.sightings_by_day_by_state [RUN]
2021-03-09 18:09:01.191038 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:09:01.191175 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:09:01.198812 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-09 18:09:01.199207 (Thread-1): finished collecting timing info
2021-03-09 18:09:01.218008 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:09:01.221884 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:09:01.594813 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-09 18:09:01.595233 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-03-09 18:09:04.715057 (Thread-1): finished collecting timing info
2021-03-09 18:09:04.715963 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92c71896-e697-4155-992e-c6c7d65d333f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10953ad30>]}
2021-03-09 18:09:04.717267 (Thread-1): 13:09:04 | 2 of 7 OK created table model dbt_demo_production.sightings_by_day_by_state [CREATE TABLE (3.7k rows, 76.6 KB processed) in 3.52s]
2021-03-09 18:09:04.717425 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:09:04.717587 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:09:04.717881 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:09:04.718009 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:09:04.724858 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-09 18:09:04.725199 (Thread-1): finished collecting timing info
2021-03-09 18:09:04.725644 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:09:04.725802 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:09:04.726845 (Thread-1): 13:09:04 | 3 of 7 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:09:04.727207 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:09:04.727330 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:09:04.738620 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:09:04.738954 (Thread-1): finished collecting timing info
2021-03-09 18:09:04.740706 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51723), raddr=('172.217.9.234', 443)>
2021-03-09 18:09:04.740886 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51722), raddr=('172.217.10.106', 443)>
2021-03-09 18:09:04.741019 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51725), raddr=('172.217.9.234', 443)>
2021-03-09 18:09:04.741141 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51724), raddr=('172.217.10.106', 443)>
2021-03-09 18:09:04.751013 (Thread-1): finished collecting timing info
2021-03-09 18:09:04.751467 (Thread-1): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:09:04.757892 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92c71896-e697-4155-992e-c6c7d65d333f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109749a60>]}
2021-03-09 18:09:04.760275 (Thread-1): 13:09:04 | 3 of 7 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 0.03s]
2021-03-09 18:09:04.760469 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:09:04.760702 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-09 18:09:04.761762 (Thread-1): 13:09:04 | 4 of 7 START table model dbt_demo_production.all_sightings........... [RUN]
2021-03-09 18:09:04.762059 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:09:04.762168 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-09 18:09:04.771914 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-09 18:09:04.772299 (Thread-1): finished collecting timing info
2021-03-09 18:09:04.778040 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:09:04.782661 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:09:05.117050 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-03-09 18:09:05.117631 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings` s
-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` 
--cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  );
    
2021-03-09 18:09:11.255157 (Thread-1): finished collecting timing info
2021-03-09 18:09:11.256100 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92c71896-e697-4155-992e-c6c7d65d333f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097570a0>]}
2021-03-09 18:09:11.257532 (Thread-1): 13:09:11 | 4 of 7 OK created table model dbt_demo_production.all_sightings...... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 6.49s]
2021-03-09 18:09:11.257692 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-09 18:09:11.257857 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-09 18:09:11.258970 (Thread-1): 13:09:11 | 5 of 7 START table model dbt_demo_production.sightings_by_day........ [RUN]
2021-03-09 18:09:11.259454 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:09:11.259603 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-09 18:09:11.268439 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-09 18:09:11.268773 (Thread-1): finished collecting timing info
2021-03-09 18:09:11.273012 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:09:11.277068 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:09:11.628777 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-09 18:09:11.629275 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-03-09 18:09:14.756979 (Thread-1): finished collecting timing info
2021-03-09 18:09:14.758013 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92c71896-e697-4155-992e-c6c7d65d333f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e26a0>]}
2021-03-09 18:09:14.759570 (Thread-1): 13:09:14 | 5 of 7 OK created table model dbt_demo_production.sightings_by_day... [CREATE TABLE (2.9k rows, 57.6 KB processed) in 3.50s]
2021-03-09 18:09:14.759775 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-09 18:09:14.759987 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-09 18:09:14.761551 (Thread-1): 13:09:14 | 6 of 7 START view model dbt_demo_production.demo_123................. [RUN]
2021-03-09 18:09:14.761916 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:09:14.762063 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-09 18:09:14.771970 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-09 18:09:14.772317 (Thread-1): finished collecting timing info
2021-03-09 18:09:14.777115 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-03-09 18:09:14.777496 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:09:14.781594 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='Utah';


2021-03-09 18:09:15.653407 (Thread-1): finished collecting timing info
2021-03-09 18:09:15.654207 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92c71896-e697-4155-992e-c6c7d65d333f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10957feb0>]}
2021-03-09 18:09:15.655454 (Thread-1): 13:09:15 | 6 of 7 OK created view model dbt_demo_production.demo_123............ [OK in 0.89s]
2021-03-09 18:09:15.655615 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-09 18:09:15.655781 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-09 18:09:15.656959 (Thread-1): 13:09:15 | 7 of 7 START view model dbt_demo_production.massachusetts_sightings.. [RUN]
2021-03-09 18:09:15.657325 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:09:15.657463 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-09 18:09:15.668217 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-09 18:09:15.668604 (Thread-1): finished collecting timing info
2021-03-09 18:09:15.673921 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-09 18:09:15.674343 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:09:15.678603 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='California';


2021-03-09 18:09:15.751621 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51726), raddr=('172.217.10.106', 443)>
2021-03-09 18:09:15.751890 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51727), raddr=('172.217.9.234', 443)>
2021-03-09 18:09:15.752082 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51730), raddr=('172.217.10.106', 443)>
2021-03-09 18:09:15.752281 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51731), raddr=('172.217.9.234', 443)>
2021-03-09 18:09:15.752472 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51732), raddr=('172.217.10.106', 443)>
2021-03-09 18:09:15.752664 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51733), raddr=('172.217.9.234', 443)>
2021-03-09 18:09:16.464768 (Thread-1): finished collecting timing info
2021-03-09 18:09:16.465657 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92c71896-e697-4155-992e-c6c7d65d333f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097f3a60>]}
2021-03-09 18:09:16.467294 (Thread-1): 13:09:16 | 7 of 7 OK created view model dbt_demo_production.massachusetts_sightings [OK in 0.81s]
2021-03-09 18:09:16.467465 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-09 18:09:16.468673 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:09:16.469060 (MainThread): 13:09:16 | 
2021-03-09 18:09:16.469205 (MainThread): 13:09:16 | Finished running 4 view models, 3 table models in 18.66s.
2021-03-09 18:09:16.469329 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:09:16.469422 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-03-09 18:09:16.558083 (MainThread): 
2021-03-09 18:09:16.558278 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:09:16.558397 (MainThread): 
2021-03-09 18:09:16.558516 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:09:16.558630 (MainThread):   Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-03-09 18:09:16.558729 (MainThread):   
2021-03-09 18:09:16.558887 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-03-09 18:09:16.559008 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:09:16.559113 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:09:16.559212 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-03-09 18:09:16.559314 (MainThread):   > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:09:16.559473 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2021-03-09 18:09:16.559717 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109504490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094fb670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c0c3a0>]}
2021-03-09 18:09:16.559930 (MainThread): Flushing usage events
2021-03-09 18:11:04.843806 (MainThread): Running with dbt=0.19.0
2021-03-09 18:11:05.297626 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.deps.DepsTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='deps', single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='deps', write_json=True)
2021-03-09 18:11:05.297981 (MainThread): Tracking: tracking
2021-03-09 18:11:05.305966 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb84910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbad520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbad310>]}
2021-03-09 18:11:05.306819 (MainThread): Warning: No packages were found in packages.yml
2021-03-09 18:11:05.307111 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb84910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbad520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbad310>]}
2021-03-09 18:11:05.307292 (MainThread): Flushing usage events
2021-03-09 18:11:12.091082 (MainThread): Running with dbt=0.19.0
2021-03-09 18:11:12.540415 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:11:12.541264 (MainThread): Tracking: tracking
2021-03-09 18:11:12.549327 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb87580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de00c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de00b20>]}
2021-03-09 18:11:12.576744 (MainThread): Partial parsing not enabled
2021-03-09 18:11:12.578021 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:11:12.603701 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:11:12.610778 (MainThread): Parsing macros/etc.sql
2021-03-09 18:11:12.613032 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:11:12.617769 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:11:12.633545 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:11:12.638283 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:11:12.640746 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:11:12.652038 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:11:12.656189 (MainThread): Parsing macros/core.sql
2021-03-09 18:11:12.660439 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:11:12.710489 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:11:12.722257 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:11:12.723616 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:11:12.726122 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:11:12.728392 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:11:12.730188 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:11:12.731470 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:11:12.741762 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:11:12.757232 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:11:12.759239 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:11:12.766038 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:11:12.789032 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:11:12.830212 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:11:12.832267 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:11:12.852984 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:11:12.860564 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:11:12.866070 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:11:12.873516 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:11:12.876835 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:11:12.878683 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:11:12.881134 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:11:12.889834 (MainThread): Partial parsing not enabled
2021-03-09 18:11:12.936084 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:11:12.959120 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:11:12.969213 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:11:12.980143 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:11:12.995371 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:11:13.005877 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:11:13.017516 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:11:13.074563 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:11:13.358940 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:11:13.367206 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97aa9e70-e63d-4210-8576-bc759706ed70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e100f40>]}
2021-03-09 18:11:13.432985 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:11:13.434338 (MainThread): 
2021-03-09 18:11:13.434696 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:11:13.444730 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:11:13.444935 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:11:13.848564 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:11:13.848737 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:11:13.852817 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:11:14.244815 (MainThread): 13:11:14 | Concurrency: 1 threads (target='prod')
2021-03-09 18:11:14.245026 (MainThread): 13:11:14 | 
2021-03-09 18:11:14.247423 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51782), raddr=('172.217.10.106', 443)>
2021-03-09 18:11:14.247649 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-09 18:11:14.248949 (Thread-1): 13:11:14 | 1 of 7 START view model dbt_demo_production.new_model................ [RUN]
2021-03-09 18:11:14.249262 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51783), raddr=('172.217.9.234', 443)>
2021-03-09 18:11:14.249732 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:11:14.250337 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-09 18:11:14.267406 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-09 18:11:14.267747 (Thread-1): finished collecting timing info
2021-03-09 18:11:14.305207 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.new_model"
2021-03-09 18:11:14.305703 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:11:14.310026 (Thread-1): On model.hashpath_demo.new_model: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.new_model"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  OPTIONS()
  as select 'hello' as hello;


2021-03-09 18:11:15.666828 (Thread-1): finished collecting timing info
2021-03-09 18:11:15.667560 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97aa9e70-e63d-4210-8576-bc759706ed70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de179d0>]}
2021-03-09 18:11:15.668727 (Thread-1): 13:11:15 | 1 of 7 OK created view model dbt_demo_production.new_model........... [OK in 1.42s]
2021-03-09 18:11:15.668875 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-09 18:11:15.669022 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:11:15.669993 (Thread-1): 13:11:15 | 2 of 7 START table model dbt_demo_production.sightings_by_day_by_state [RUN]
2021-03-09 18:11:15.670291 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:11:15.670409 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:11:15.677124 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-09 18:11:15.677795 (Thread-1): finished collecting timing info
2021-03-09 18:11:15.698406 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:11:15.704397 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:11:16.077981 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-09 18:11:16.078367 (Thread-1): On model.hashpath_demo.sightings_by_day_by_state: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day_by_state"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
  
  
  OPTIONS()
  as (
    

SELECT
date,
state,
count(*) as sightings
FROM `hashpath-demo-data.hashpath_dataset.bigfoot_sightings`
GROUP BY 1,2
  );
    
2021-03-09 18:11:18.350079 (Thread-1): finished collecting timing info
2021-03-09 18:11:18.351080 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97aa9e70-e63d-4210-8576-bc759706ed70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e065fd0>]}
2021-03-09 18:11:18.352442 (Thread-1): 13:11:18 | 2 of 7 OK created table model dbt_demo_production.sightings_by_day_by_state [CREATE TABLE (3.7k rows, 76.6 KB processed) in 2.68s]
2021-03-09 18:11:18.352621 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:11:18.352793 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:11:18.353142 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:11:18.353278 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:11:18.360593 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-09 18:11:18.361086 (Thread-1): finished collecting timing info
2021-03-09 18:11:18.361561 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:11:18.361712 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:11:18.362752 (Thread-1): 13:11:18 | 3 of 7 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:11:18.363114 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:11:18.363241 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:11:18.375846 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:11:18.376250 (Thread-1): finished collecting timing info
2021-03-09 18:11:18.387582 (Thread-1): finished collecting timing info
2021-03-09 18:11:18.388725 (Thread-1): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:11:18.390666 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97aa9e70-e63d-4210-8576-bc759706ed70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f28e2e0>]}
2021-03-09 18:11:18.391859 (Thread-1): 13:11:18 | 3 of 7 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 0.03s]
2021-03-09 18:11:18.392009 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:11:18.392156 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-09 18:11:18.393096 (Thread-1): 13:11:18 | 4 of 7 START table model dbt_demo_production.all_sightings........... [RUN]
2021-03-09 18:11:18.393416 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:11:18.393675 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-09 18:11:18.399331 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51787), raddr=('172.217.10.106', 443)>
2021-03-09 18:11:18.399569 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51788), raddr=('172.217.9.234', 443)>
2021-03-09 18:11:18.399771 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51790), raddr=('172.217.9.234', 443)>
2021-03-09 18:11:18.399987 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51789), raddr=('172.217.10.106', 443)>
2021-03-09 18:11:18.408953 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-09 18:11:18.409354 (Thread-1): finished collecting timing info
2021-03-09 18:11:18.414191 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:11:18.418460 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:11:18.786033 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.all_sightings"
2021-03-09 18:11:18.786864 (Thread-1): On model.hashpath_demo.all_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.all_sightings"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
  
  
  OPTIONS()
  as (
    

SELECT s.* FROM `hashpath-demo-data`.`hashpath_dataset`.`bigfoot_sightings` s
-- `hashpath-demo-data.hashpath_dataset.bigfoot_sightings` 
--cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
  );
    
2021-03-09 18:11:24.590008 (Thread-1): finished collecting timing info
2021-03-09 18:11:24.590857 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97aa9e70-e63d-4210-8576-bc759706ed70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e065fd0>]}
2021-03-09 18:11:24.592179 (Thread-1): 13:11:24 | 4 of 7 OK created table model dbt_demo_production.all_sightings...... [CREATE TABLE (4.7k rows, 10.2 MB processed) in 6.20s]
2021-03-09 18:11:24.592390 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-09 18:11:24.592571 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-09 18:11:24.594543 (Thread-1): 13:11:24 | 5 of 7 START table model dbt_demo_production.sightings_by_day........ [RUN]
2021-03-09 18:11:24.594970 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:11:24.595128 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-09 18:11:24.607047 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-09 18:11:24.608516 (Thread-1): finished collecting timing info
2021-03-09 18:11:24.614270 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:11:24.619535 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:11:25.011138 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-09 18:11:25.011698 (Thread-1): On model.hashpath_demo.sightings_by_day: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.sightings_by_day"} */


  create or replace table `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day`
  
  
  OPTIONS()
  as (
    

SELECT
date,
sum(sightings) as sightings
FROM `hashpath-demo-data`.`dbt_demo_production`.`sightings_by_day_by_state`
GROUP BY 1
  );
    
2021-03-09 18:11:27.203232 (Thread-1): finished collecting timing info
2021-03-09 18:11:27.204184 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97aa9e70-e63d-4210-8576-bc759706ed70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0bafd0>]}
2021-03-09 18:11:27.205879 (Thread-1): 13:11:27 | 5 of 7 OK created table model dbt_demo_production.sightings_by_day... [CREATE TABLE (2.9k rows, 57.6 KB processed) in 2.61s]
2021-03-09 18:11:27.206082 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-09 18:11:27.206290 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-09 18:11:27.208031 (Thread-1): 13:11:27 | 6 of 7 START view model dbt_demo_production.demo_123................. [RUN]
2021-03-09 18:11:27.209434 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:11:27.209719 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-09 18:11:27.222516 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-09 18:11:27.223140 (Thread-1): finished collecting timing info
2021-03-09 18:11:27.229235 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.demo_123"
2021-03-09 18:11:27.229679 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:11:27.234957 (Thread-1): On model.hashpath_demo.demo_123: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.demo_123"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`demo_123`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='Utah';


2021-03-09 18:11:28.151774 (Thread-1): finished collecting timing info
2021-03-09 18:11:28.152658 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97aa9e70-e63d-4210-8576-bc759706ed70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de179d0>]}
2021-03-09 18:11:28.154050 (Thread-1): 13:11:28 | 6 of 7 OK created view model dbt_demo_production.demo_123............ [OK in 0.94s]
2021-03-09 18:11:28.154229 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-09 18:11:28.154415 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-09 18:11:28.155692 (Thread-1): 13:11:28 | 7 of 7 START view model dbt_demo_production.massachusetts_sightings.. [RUN]
2021-03-09 18:11:28.156180 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:11:28.156348 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-09 18:11:28.168050 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-09 18:11:28.168453 (Thread-1): finished collecting timing info
2021-03-09 18:11:28.174105 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-09 18:11:28.174506 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:11:28.179178 (Thread-1): On model.hashpath_demo.massachusetts_sightings: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.massachusetts_sightings"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`massachusetts_sightings`
  OPTIONS()
  as select *
from `hashpath-demo-data`.`dbt_demo_production`.`all_sightings`
cross join `hashpath-demo-data`.`dbt_demo_production`.`new_model`
where state='California';


2021-03-09 18:11:29.006351 (Thread-1): finished collecting timing info
2021-03-09 18:11:29.007153 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97aa9e70-e63d-4210-8576-bc759706ed70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f384400>]}
2021-03-09 18:11:29.008408 (Thread-1): 13:11:29 | 7 of 7 OK created view model dbt_demo_production.massachusetts_sightings [OK in 0.85s]
2021-03-09 18:11:29.008580 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-09 18:11:29.009953 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:11:29.010323 (MainThread): 13:11:29 | 
2021-03-09 18:11:29.010466 (MainThread): 13:11:29 | Finished running 4 view models, 3 table models in 15.58s.
2021-03-09 18:11:29.010587 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:11:29.010779 (MainThread): Connection 'model.hashpath_demo.massachusetts_sightings' was properly closed.
2021-03-09 18:11:29.058241 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51792), raddr=('172.217.10.106', 443)>
2021-03-09 18:11:29.058501 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51793), raddr=('172.217.9.234', 443)>
2021-03-09 18:11:29.058722 (MainThread): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51795), raddr=('172.217.12.170', 443)>
2021-03-09 18:11:29.059057 (MainThread): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51796), raddr=('172.217.9.234', 443)>
2021-03-09 18:11:29.059263 (MainThread): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51797), raddr=('172.217.12.170', 443)>
2021-03-09 18:11:29.059504 (MainThread): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51798), raddr=('172.217.9.234', 443)>
2021-03-09 18:11:29.059669 (MainThread): unclosed <socket.socket fd=23, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51799), raddr=('172.217.12.170', 443)>
2021-03-09 18:11:29.059837 (MainThread): unclosed <socket.socket fd=24, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51800), raddr=('172.217.9.234', 443)>
2021-03-09 18:11:29.090405 (MainThread): 
2021-03-09 18:11:29.090581 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:11:29.090693 (MainThread): 
2021-03-09 18:11:29.090811 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:11:29.091001 (MainThread):   Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-03-09 18:11:29.091121 (MainThread):   
2021-03-09 18:11:29.091216 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-03-09 18:11:29.091305 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:11:29.091389 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:11:29.091473 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-03-09 18:11:29.091556 (MainThread):   > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:11:29.091661 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2021-03-09 18:11:29.091846 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de4f1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3bc700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3bcaf0>]}
2021-03-09 18:11:29.092036 (MainThread): Flushing usage events
2021-03-09 18:12:00.943458 (MainThread): Running with dbt=0.19.0
2021-03-09 18:12:01.423886 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:12:01.424971 (MainThread): Tracking: tracking
2021-03-09 18:12:01.433425 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a28460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ca1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ca1bb0>]}
2021-03-09 18:12:01.460950 (MainThread): Partial parsing not enabled
2021-03-09 18:12:01.462146 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:12:01.486197 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:12:01.493534 (MainThread): Parsing macros/etc.sql
2021-03-09 18:12:01.495876 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:12:01.501205 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:12:01.515936 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:12:01.518983 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:12:01.521072 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:12:01.532133 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:12:01.536403 (MainThread): Parsing macros/core.sql
2021-03-09 18:12:01.540700 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:12:01.593476 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:12:01.602788 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:12:01.603801 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:12:01.605607 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:12:01.607834 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:12:01.609590 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:12:01.610963 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:12:01.620781 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:12:01.640045 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:12:01.642252 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:12:01.649448 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:12:01.674162 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:12:01.711043 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:12:01.712976 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:12:01.733226 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:12:01.742516 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:12:01.748932 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:12:01.756539 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:12:01.759965 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:12:01.761714 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:12:01.763775 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:12:01.771780 (MainThread): Partial parsing not enabled
2021-03-09 18:12:01.821716 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:12:01.847274 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:12:01.858013 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:12:01.869267 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:12:01.881266 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:12:01.890008 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:12:01.901911 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:12:01.961630 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:12:02.255581 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:12:02.264146 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd35d0101-48f1-4a07-9f1d-7a0f54d6a148', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112fad610>]}
2021-03-09 18:12:02.332144 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:12:02.333217 (MainThread): 
2021-03-09 18:12:02.333539 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:12:02.335402 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:12:02.335573 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:12:02.763495 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:12:02.763675 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:12:02.767859 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:12:03.107032 (MainThread): 13:12:03 | Concurrency: 1 threads (target='prod')
2021-03-09 18:12:03.107218 (MainThread): 13:12:03 | 
2021-03-09 18:12:03.109160 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:12:03.110433 (Thread-1): 13:12:03 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:12:03.110955 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:12:03.111124 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:12:03.113071 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51805), raddr=('172.217.12.170', 443)>
2021-03-09 18:12:03.113270 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51807), raddr=('172.217.9.234', 443)>
2021-03-09 18:12:03.113413 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51809), raddr=('172.217.9.234', 443)>
2021-03-09 18:12:03.113552 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51808), raddr=('172.217.12.170', 443)>
2021-03-09 18:12:03.134319 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:12:03.134867 (Thread-1): finished collecting timing info
2021-03-09 18:12:03.169953 (Thread-1): finished collecting timing info
2021-03-09 18:12:03.170613 (Thread-1): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:12:03.172893 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35d0101-48f1-4a07-9f1d-7a0f54d6a148', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112dfebe0>]}
2021-03-09 18:12:03.174275 (Thread-1): 13:12:03 | 1 of 1 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 0.06s]
2021-03-09 18:12:03.174449 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:12:03.175700 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:12:03.176170 (MainThread): 13:12:03 | 
2021-03-09 18:12:03.176329 (MainThread): 13:12:03 | Finished running 1 view model in 0.84s.
2021-03-09 18:12:03.176457 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:12:03.176549 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:12:03.241428 (MainThread): 
2021-03-09 18:12:03.241595 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:12:03.241705 (MainThread): 
2021-03-09 18:12:03.241814 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:12:03.241912 (MainThread):   Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-03-09 18:12:03.242004 (MainThread):   
2021-03-09 18:12:03.242110 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-03-09 18:12:03.242274 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:12:03.242386 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:12:03.242480 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-03-09 18:12:03.242569 (MainThread):   > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:12:03.242746 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-03-09 18:12:03.243025 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f9a580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea92b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed6bd30>]}
2021-03-09 18:12:03.243253 (MainThread): Flushing usage events
2021-03-09 18:12:36.478224 (MainThread): Running with dbt=0.19.0
2021-03-09 18:12:36.930261 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:12:36.931539 (MainThread): Tracking: tracking
2021-03-09 18:12:36.939547 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0cc490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e342f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e342e50>]}
2021-03-09 18:12:36.967339 (MainThread): Partial parsing not enabled
2021-03-09 18:12:36.968585 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:12:36.991067 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:12:36.997957 (MainThread): Parsing macros/etc.sql
2021-03-09 18:12:37.000152 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:12:37.005231 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:12:37.019385 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:12:37.022659 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:12:37.024516 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:12:37.035233 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:12:37.039512 (MainThread): Parsing macros/core.sql
2021-03-09 18:12:37.043738 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:12:37.094513 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:12:37.104900 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:12:37.105963 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:12:37.107731 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:12:37.109896 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:12:37.111710 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:12:37.112849 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:12:37.122783 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:12:37.140315 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:12:37.142394 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:12:37.149456 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:12:37.174346 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:12:37.211014 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:12:37.212949 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:12:37.231828 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:12:37.239082 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:12:37.244457 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:12:37.251294 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:12:37.254070 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:12:37.255611 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:12:37.257512 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:12:37.265055 (MainThread): Partial parsing not enabled
2021-03-09 18:12:37.309274 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:12:37.330804 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:12:37.340256 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:12:37.350913 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:12:37.362319 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:12:37.370874 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:12:37.382054 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:12:37.440036 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:12:37.726290 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:12:37.734676 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ff620381-dac1-4cc5-b8d9-b8bfeacddf37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e67d790>]}
2021-03-09 18:12:37.803613 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:12:37.804779 (MainThread): 
2021-03-09 18:12:37.805390 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:12:37.806957 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:12:37.807120 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:12:38.194135 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:12:38.194332 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:12:38.198535 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:12:38.550965 (MainThread): 13:12:38 | Concurrency: 1 threads (target='prod')
2021-03-09 18:12:38.551181 (MainThread): 13:12:38 | 
2021-03-09 18:12:38.553272 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:12:38.554555 (Thread-1): 13:12:38 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:12:38.554891 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:12:38.555034 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:12:38.557102 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51815), raddr=('172.217.12.170', 443)>
2021-03-09 18:12:38.557310 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51816), raddr=('172.217.9.234', 443)>
2021-03-09 18:12:38.557469 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51818), raddr=('172.217.9.234', 443)>
2021-03-09 18:12:38.557629 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51817), raddr=('172.217.12.170', 443)>
2021-03-09 18:12:38.579668 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:12:38.580128 (Thread-1): finished collecting timing info
2021-03-09 18:12:38.612766 (Thread-1): finished collecting timing info
2021-03-09 18:12:38.613253 (Thread-1): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:12:38.615909 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ff620381-dac1-4cc5-b8d9-b8bfeacddf37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5bd490>]}
2021-03-09 18:12:38.617068 (Thread-1): 13:12:38 | 1 of 1 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 0.06s]
2021-03-09 18:12:38.617275 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:12:38.618538 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:12:38.618896 (MainThread): 13:12:38 | 
2021-03-09 18:12:38.619045 (MainThread): 13:12:38 | Finished running 1 view model in 0.81s.
2021-03-09 18:12:38.619170 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:12:38.619261 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:12:38.683613 (MainThread): 
2021-03-09 18:12:38.683779 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:12:38.683895 (MainThread): 
2021-03-09 18:12:38.684004 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:12:38.684100 (MainThread):   Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-03-09 18:12:38.684192 (MainThread):   
2021-03-09 18:12:38.684278 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-03-09 18:12:38.684365 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:12:38.684450 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:12:38.684536 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-03-09 18:12:38.684621 (MainThread):   > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:12:38.684714 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-03-09 18:12:38.684886 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5e0d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6493d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da9f3d0>]}
2021-03-09 18:12:38.685064 (MainThread): Flushing usage events
2021-03-09 18:13:31.612973 (MainThread): Running with dbt=0.19.0
2021-03-09 18:13:32.066895 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:13:32.067796 (MainThread): Tracking: tracking
2021-03-09 18:13:32.076042 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096dafd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096eb250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096eb130>]}
2021-03-09 18:13:32.102433 (MainThread): Partial parsing not enabled
2021-03-09 18:13:32.103645 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:13:32.125632 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:13:32.132124 (MainThread): Parsing macros/etc.sql
2021-03-09 18:13:32.134378 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:13:32.140024 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:13:32.156928 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:13:32.159974 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:13:32.161928 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:13:32.172964 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:13:32.177191 (MainThread): Parsing macros/core.sql
2021-03-09 18:13:32.181954 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:13:32.229217 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:13:32.238910 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:13:32.239913 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:13:32.241651 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:13:32.243735 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:13:32.245649 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:13:32.246833 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:13:32.256045 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:13:32.270461 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:13:32.272425 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:13:32.279518 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:13:32.305945 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:13:32.342199 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:13:32.344106 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:13:32.362280 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:13:32.369475 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:13:32.374487 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:13:32.381026 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:13:32.383751 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:13:32.385281 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:13:32.387192 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:13:32.394784 (MainThread): Partial parsing not enabled
2021-03-09 18:13:32.439556 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:13:32.461224 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:13:32.471805 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:13:32.483043 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:13:32.498053 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:13:32.507002 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:13:32.517834 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:13:32.575256 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:13:32.861348 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:13:32.869757 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '45dfa91f-1e69-4ab9-a351-26ca1bf08282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099f0640>]}
2021-03-09 18:13:32.936375 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:13:32.937637 (MainThread): 
2021-03-09 18:13:32.937967 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:13:32.939806 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:13:32.939978 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:13:33.322017 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:13:33.322205 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:13:33.326441 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:13:33.669359 (MainThread): 13:13:33 | Concurrency: 1 threads (target='prod')
2021-03-09 18:13:33.669565 (MainThread): 13:13:33 | 
2021-03-09 18:13:33.671659 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:13:33.672970 (Thread-1): 13:13:33 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:13:33.673318 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:13:33.673459 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:13:33.675476 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51824), raddr=('172.217.12.170', 443)>
2021-03-09 18:13:33.675664 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51825), raddr=('172.217.9.234', 443)>
2021-03-09 18:13:33.675815 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51828), raddr=('172.217.9.234', 443)>
2021-03-09 18:13:33.675963 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51827), raddr=('172.217.12.170', 443)>
2021-03-09 18:13:33.695847 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:13:33.696283 (Thread-1): finished collecting timing info
2021-03-09 18:13:33.727241 (Thread-1): finished collecting timing info
2021-03-09 18:13:33.727812 (Thread-1): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:13:33.730758 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45dfa91f-1e69-4ab9-a351-26ca1bf08282', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10994c9d0>]}
2021-03-09 18:13:33.732312 (Thread-1): 13:13:33 | 1 of 1 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 0.06s]
2021-03-09 18:13:33.732555 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:13:33.733969 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:13:33.734339 (MainThread): 13:13:33 | 
2021-03-09 18:13:33.734480 (MainThread): 13:13:33 | Finished running 1 view model in 0.80s.
2021-03-09 18:13:33.734650 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:13:33.734758 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:13:33.794991 (MainThread): 
2021-03-09 18:13:33.795162 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:13:33.795270 (MainThread): 
2021-03-09 18:13:33.795426 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:13:33.795590 (MainThread):   Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-03-09 18:13:33.795773 (MainThread):   
2021-03-09 18:13:33.795931 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-03-09 18:13:33.796185 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:13:33.796397 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:13:33.796499 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-03-09 18:13:33.796665 (MainThread):   > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:13:33.796876 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-03-09 18:13:33.797167 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10974c970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098a6b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10980e8b0>]}
2021-03-09 18:13:33.797353 (MainThread): Flushing usage events
2021-03-09 18:14:32.075544 (MainThread): Running with dbt=0.19.0
2021-03-09 18:14:32.519229 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:14:32.520305 (MainThread): Tracking: tracking
2021-03-09 18:14:32.528369 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e10f3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f390190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3900a0>]}
2021-03-09 18:14:32.555085 (MainThread): Partial parsing not enabled
2021-03-09 18:14:32.556304 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:14:32.578529 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:14:32.585039 (MainThread): Parsing macros/etc.sql
2021-03-09 18:14:32.587301 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:14:32.592328 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:14:32.606749 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:14:32.609693 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:14:32.611606 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:14:32.622335 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:14:32.626254 (MainThread): Parsing macros/core.sql
2021-03-09 18:14:32.630485 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:14:32.681608 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:14:32.692460 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:14:32.694387 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:14:32.697286 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:14:32.700007 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:14:32.702217 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:14:32.703438 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:14:32.713570 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:14:32.731523 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:14:32.734562 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:14:32.742131 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:14:32.764619 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:14:32.805382 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:14:32.807928 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:14:32.829132 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:14:32.836586 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:14:32.841861 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:14:32.848533 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:14:32.851283 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:14:32.852841 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:14:32.854758 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:14:32.862431 (MainThread): Partial parsing not enabled
2021-03-09 18:14:32.912258 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:14:32.934009 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:14:32.943845 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:14:32.954825 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:14:32.967355 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:14:32.976064 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:14:32.987660 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:14:33.045115 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:14:33.329253 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:14:33.337370 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'caecc40d-bfad-4420-9d82-fb9837181b8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f61dac0>]}
2021-03-09 18:14:33.408460 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:14:33.409640 (MainThread): 
2021-03-09 18:14:33.409992 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:14:33.411607 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:14:33.411779 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:14:33.978239 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:14:33.978437 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:14:33.982957 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:14:34.330557 (MainThread): 13:14:34 | Concurrency: 1 threads (target='prod')
2021-03-09 18:14:34.330772 (MainThread): 13:14:34 | 
2021-03-09 18:14:34.332814 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:14:34.334232 (Thread-1): 13:14:34 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:14:34.334652 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:14:34.334803 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:14:34.336824 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51842), raddr=('172.217.12.138', 443)>
2021-03-09 18:14:34.337026 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51843), raddr=('172.217.9.234', 443)>
2021-03-09 18:14:34.337180 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51845), raddr=('172.217.9.234', 443)>
2021-03-09 18:14:34.337335 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51844), raddr=('172.217.12.138', 443)>
2021-03-09 18:14:34.356926 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:14:34.357252 (Thread-1): finished collecting timing info
2021-03-09 18:14:34.386820 (Thread-1): finished collecting timing info
2021-03-09 18:14:34.387284 (Thread-1): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:14:34.388979 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'caecc40d-bfad-4420-9d82-fb9837181b8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f563370>]}
2021-03-09 18:14:34.390634 (Thread-1): 13:14:34 | 1 of 1 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 0.05s]
2021-03-09 18:14:34.390947 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:14:34.393312 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:14:34.393682 (MainThread): 13:14:34 | 
2021-03-09 18:14:34.393812 (MainThread): 13:14:34 | Finished running 1 view model in 0.98s.
2021-03-09 18:14:34.393956 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:14:34.394028 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:14:34.457246 (MainThread): 
2021-03-09 18:14:34.457416 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:14:34.457671 (MainThread): 
2021-03-09 18:14:34.457862 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:14:34.458044 (MainThread):   Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-03-09 18:14:34.458199 (MainThread):   
2021-03-09 18:14:34.458386 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-03-09 18:14:34.458552 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:14:34.458683 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:14:34.458859 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-03-09 18:14:34.458992 (MainThread):   > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:14:34.459184 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-03-09 18:14:34.459473 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f647fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f68c1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f68c700>]}
2021-03-09 18:14:34.459715 (MainThread): Flushing usage events
2021-03-09 18:14:52.606003 (MainThread): Running with dbt=0.19.0
2021-03-09 18:14:53.044156 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:14:53.045304 (MainThread): Tracking: tracking
2021-03-09 18:14:53.053305 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11037d8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103942e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103941c0>]}
2021-03-09 18:14:53.079418 (MainThread): Partial parsing not enabled
2021-03-09 18:14:53.080622 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:14:53.101765 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:14:53.107888 (MainThread): Parsing macros/etc.sql
2021-03-09 18:14:53.110005 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:14:53.115016 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:14:53.128443 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:14:53.131217 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:14:53.133234 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:14:53.143800 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:14:53.148563 (MainThread): Parsing macros/core.sql
2021-03-09 18:14:53.152744 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:14:53.198440 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:14:53.207487 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:14:53.208433 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:14:53.210085 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:14:53.212111 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:14:53.213884 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:14:53.214951 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:14:53.224110 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:14:53.238515 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:14:53.240371 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:14:53.246884 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:14:53.268506 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:14:53.308334 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:14:53.310239 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:14:53.329164 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:14:53.336519 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:14:53.341887 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:14:53.348696 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:14:53.351751 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:14:53.353406 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:14:53.355316 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:14:53.363257 (MainThread): Partial parsing not enabled
2021-03-09 18:14:53.413570 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:14:53.437894 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:14:53.448017 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:14:53.458571 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:14:53.470212 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:14:53.478749 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:14:53.490043 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:14:53.540551 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:14:53.821817 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:14:53.829870 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '76620719-41a7-4764-b569-139b88ae326f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11068f400>]}
2021-03-09 18:14:53.899466 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:14:53.900599 (MainThread): 
2021-03-09 18:14:53.901037 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:14:53.902749 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:14:53.902940 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:14:54.307806 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:14:54.307993 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:14:54.312210 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:14:54.633079 (MainThread): 13:14:54 | Concurrency: 1 threads (target='prod')
2021-03-09 18:14:54.633290 (MainThread): 13:14:54 | 
2021-03-09 18:14:54.635264 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:14:54.636527 (Thread-1): 13:14:54 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:14:54.636872 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:14:54.637014 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:14:54.639086 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51849), raddr=('172.217.12.138', 443)>
2021-03-09 18:14:54.639313 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51850), raddr=('172.217.9.234', 443)>
2021-03-09 18:14:54.639477 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51852), raddr=('172.217.9.234', 443)>
2021-03-09 18:14:54.639641 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51851), raddr=('172.217.12.138', 443)>
2021-03-09 18:14:54.660467 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:14:54.660847 (Thread-1): finished collecting timing info
2021-03-09 18:14:54.691881 (Thread-1): finished collecting timing info
2021-03-09 18:14:54.692352 (Thread-1): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:14:54.694049 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '76620719-41a7-4764-b569-139b88ae326f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc90190>]}
2021-03-09 18:14:54.695116 (Thread-1): 13:14:54 | 1 of 1 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 0.06s]
2021-03-09 18:14:54.695252 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:14:54.696355 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:14:54.696627 (MainThread): 13:14:54 | 
2021-03-09 18:14:54.696740 (MainThread): 13:14:54 | Finished running 1 view model in 0.80s.
2021-03-09 18:14:54.696838 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:14:54.696965 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:14:54.756909 (MainThread): 
2021-03-09 18:14:54.757110 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:14:54.757264 (MainThread): 
2021-03-09 18:14:54.757404 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:14:54.757539 (MainThread):   Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-03-09 18:14:54.757725 (MainThread):   
2021-03-09 18:14:54.757938 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-03-09 18:14:54.758082 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:14:54.758212 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:14:54.758390 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-03-09 18:14:54.758541 (MainThread):   > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:14:54.758680 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-03-09 18:14:54.758990 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110598340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105a19d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11063d460>]}
2021-03-09 18:14:54.759198 (MainThread): Flushing usage events
2021-03-09 18:16:31.386882 (MainThread): Running with dbt=0.19.0
2021-03-09 18:16:31.855767 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:16:31.856928 (MainThread): Tracking: tracking
2021-03-09 18:16:31.864991 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3ca4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f643a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f643910>]}
2021-03-09 18:16:31.891661 (MainThread): Partial parsing not enabled
2021-03-09 18:16:31.892944 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:16:31.914156 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:16:31.920318 (MainThread): Parsing macros/etc.sql
2021-03-09 18:16:31.922325 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:16:31.927077 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:16:31.940445 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:16:31.943237 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:16:31.945067 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:16:31.956049 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:16:31.962519 (MainThread): Parsing macros/core.sql
2021-03-09 18:16:31.967641 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:16:32.012601 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:16:32.021645 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:16:32.022602 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:16:32.024780 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:16:32.026764 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:16:32.028387 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:16:32.029568 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:16:32.039518 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:16:32.054729 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:16:32.056783 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:16:32.064481 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:16:32.088613 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:16:32.131584 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:16:32.133895 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:16:32.154383 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:16:32.161734 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:16:32.167541 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:16:32.174636 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:16:32.177519 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:16:32.179134 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:16:32.181753 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:16:32.189208 (MainThread): Partial parsing not enabled
2021-03-09 18:16:32.239088 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:16:32.262616 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:16:32.272507 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:16:32.285106 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:16:32.296597 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:16:32.305177 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:16:32.319341 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:16:32.370810 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:16:32.639123 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:16:32.647576 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '71c65111-e50b-424e-bc44-837d7884d07a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f944670>]}
2021-03-09 18:16:32.716977 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:16:32.718229 (MainThread): 
2021-03-09 18:16:32.718717 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:16:32.720511 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:16:32.720687 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:16:33.162208 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:16:33.162385 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:16:33.166485 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:16:33.533794 (MainThread): 13:16:33 | Concurrency: 1 threads (target='prod')
2021-03-09 18:16:33.534000 (MainThread): 13:16:33 | 
2021-03-09 18:16:33.535879 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:16:33.536961 (Thread-1): 13:16:33 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:16:33.537255 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:16:33.537386 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:16:33.539110 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51871), raddr=('172.217.7.10', 443)>
2021-03-09 18:16:33.539283 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51872), raddr=('172.217.9.234', 443)>
2021-03-09 18:16:33.539411 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51874), raddr=('172.217.9.234', 443)>
2021-03-09 18:16:33.539545 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51873), raddr=('172.217.7.10', 443)>
2021-03-09 18:16:33.557630 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:16:33.557945 (Thread-1): finished collecting timing info
2021-03-09 18:16:33.590271 (Thread-1): finished collecting timing info
2021-03-09 18:16:33.590902 (Thread-1): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 50, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 29, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1008, in inner
    raise exc
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 1005, in inner
    return func(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 669, in relation_wrong_type
    raise_compiler_error(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
  
  > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
  > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
  > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
  > called by macro materialization_view_bigquery (macros/materializations/view.sql)
  > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:16:33.593048 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '71c65111-e50b-424e-bc44-837d7884d07a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8eba30>]}
2021-03-09 18:16:33.594385 (Thread-1): 13:16:33 | 1 of 1 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 0.06s]
2021-03-09 18:16:33.594561 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:16:33.595760 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:16:33.596071 (MainThread): 13:16:33 | 
2021-03-09 18:16:33.596208 (MainThread): 13:16:33 | Finished running 1 view model in 0.88s.
2021-03-09 18:16:33.596366 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:16:33.596451 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:16:33.655055 (MainThread): 
2021-03-09 18:16:33.655271 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:16:33.655608 (MainThread): 
2021-03-09 18:16:33.655785 (MainThread): Compilation Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:16:33.655992 (MainThread):   Trying to create view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`, but it currently exists as a table. Either drop `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics` manually, or run dbt with `--full-refresh` and dbt will drop it for you.
2021-03-09 18:16:33.656241 (MainThread):   
2021-03-09 18:16:33.656426 (MainThread):   > in macro bigquery__handle_existing_table (macros/materializations/view.sql)
2021-03-09 18:16:33.656523 (MainThread):   > called by macro handle_existing_table (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:16:33.656691 (MainThread):   > called by macro create_or_replace_view (macros/materializations/view/create_or_replace_view.sql)
2021-03-09 18:16:33.656876 (MainThread):   > called by macro materialization_view_bigquery (macros/materializations/view.sql)
2021-03-09 18:16:33.657098 (MainThread):   > called by model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:16:33.657419 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-03-09 18:16:33.657703 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8cbc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f856970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7e7880>]}
2021-03-09 18:16:33.657915 (MainThread): Flushing usage events
2021-03-09 18:16:53.268729 (MainThread): Running with dbt=0.19.0
2021-03-09 18:16:53.720634 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:16:53.721740 (MainThread): Tracking: tracking
2021-03-09 18:16:53.729852 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f4a400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1c3f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b1c3e50>]}
2021-03-09 18:16:53.757228 (MainThread): Partial parsing not enabled
2021-03-09 18:16:53.758470 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:16:53.780948 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:16:53.788421 (MainThread): Parsing macros/etc.sql
2021-03-09 18:16:53.790615 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:16:53.795517 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:16:53.809617 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:16:53.812415 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:16:53.814222 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:16:53.824893 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:16:53.828936 (MainThread): Parsing macros/core.sql
2021-03-09 18:16:53.832872 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:16:53.878190 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:16:53.887676 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:16:53.888630 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:16:53.890295 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:16:53.892750 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:16:53.894443 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:16:53.895519 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:16:53.904904 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:16:53.920362 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:16:53.923478 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:16:53.931583 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:16:53.958779 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:16:53.996376 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:16:53.999436 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:16:54.020453 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:16:54.029293 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:16:54.035432 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:16:54.042577 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:16:54.045566 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:16:54.047318 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:16:54.049341 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:16:54.057054 (MainThread): Partial parsing not enabled
2021-03-09 18:16:54.105390 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:16:54.127219 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:16:54.138050 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:16:54.150115 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:16:54.161555 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:16:54.170158 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:16:54.181940 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:16:54.238695 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:16:54.517264 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:16:54.525390 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49e92313-ef81-4779-9369-34a3e1424d2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4d52b0>]}
2021-03-09 18:16:54.592180 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:16:54.593333 (MainThread): 
2021-03-09 18:16:54.593660 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:16:54.595402 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:16:54.595567 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:16:54.948449 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:16:54.948791 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:16:54.953873 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:16:55.300174 (MainThread): 13:16:55 | Concurrency: 1 threads (target='prod')
2021-03-09 18:16:55.300378 (MainThread): 13:16:55 | 
2021-03-09 18:16:55.302373 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:16:55.303571 (Thread-1): 13:16:55 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:16:55.303906 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:16:55.304048 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:16:55.305983 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51879), raddr=('172.217.7.10', 443)>
2021-03-09 18:16:55.306169 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51880), raddr=('172.217.9.234', 443)>
2021-03-09 18:16:55.306313 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51882), raddr=('172.217.9.234', 443)>
2021-03-09 18:16:55.306470 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51881), raddr=('172.217.7.10', 443)>
2021-03-09 18:16:55.326528 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:16:55.326889 (Thread-1): finished collecting timing info
2021-03-09 18:16:55.361460 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:16:55.366163 (Thread-1): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:16:55.787829 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:16:55.788261 (Thread-1): On model.hashpath_demo.unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics`
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:16:57.208384 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/2fb97428-2d30-4e0e-bdfe-09b8ef10ecf9?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected ")" but got keyword SELECT at [18:1]')
2021-03-09 18:16:58.294250 (Thread-1): finished collecting timing info
2021-03-09 18:16:58.295186 (Thread-1): Database Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Syntax error: Expected ")" but got keyword SELECT at [18:1]
  compiled SQL at target/run/hashpath_demo/models/twitter/unique_public_metrics.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/b2b4a140-9a9b-4382-853d-db46f2bcbdd1?maxResults=0&location=US&prettyPrint=false: Syntax error: Expected ")" but got keyword SELECT at [18:1]

(job ID: b2b4a140-9a9b-4382-853d-db46f2bcbdd1)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.unique_public_metrics"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`
   5:  OPTIONS()
   6:  as with unique_tweets as 
   7:  (SELECT * FROM (SELECT
   8:  created_at as created_at,
   9:  id,
  10:  text, 
  11:  like_count,
  12:  retweet_count,
  13:  url,
  14:  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  15:  FROM `hashpath-demo-data`.`twitter`.`public_metrics`
  16:  WHERE rank = 1
  17:  )
  18:SELECT
  19:  id,
  20:  text,
  21:  like_count,
  22:  retweet_count,
  23:  created_at,
  24:  url
  25:FROM unique_tweets
  26:ORDER BY 3 DESC;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Syntax error: Expected ")" but got keyword SELECT at [18:1]
  compiled SQL at target/run/hashpath_demo/models/twitter/unique_public_metrics.sql
2021-03-09 18:16:58.317172 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '49e92313-ef81-4779-9369-34a3e1424d2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b507ee0>]}
2021-03-09 18:16:58.318968 (Thread-1): 13:16:58 | 1 of 1 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 3.01s]
2021-03-09 18:16:58.319274 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:16:58.320854 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:16:58.321186 (MainThread): 13:16:58 | 
2021-03-09 18:16:58.321328 (MainThread): 13:16:58 | Finished running 1 view model in 3.73s.
2021-03-09 18:16:58.321450 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:16:58.321540 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:16:58.389538 (MainThread): 
2021-03-09 18:16:58.389715 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:16:58.389828 (MainThread): 
2021-03-09 18:16:58.389937 (MainThread): Database Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:16:58.390035 (MainThread):   Syntax error: Expected ")" but got keyword SELECT at [18:1]
2021-03-09 18:16:58.390126 (MainThread):   compiled SQL at target/run/hashpath_demo/models/twitter/unique_public_metrics.sql
2021-03-09 18:16:58.390223 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-03-09 18:16:58.390445 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3ea460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b252340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b29c340>]}
2021-03-09 18:16:58.390653 (MainThread): Flushing usage events
2021-03-09 18:17:26.035086 (MainThread): Running with dbt=0.19.0
2021-03-09 18:17:26.503147 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:17:26.504465 (MainThread): Tracking: tracking
2021-03-09 18:17:26.512843 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d820430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea97be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea97ac0>]}
2021-03-09 18:17:26.541902 (MainThread): Partial parsing not enabled
2021-03-09 18:17:26.544023 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:17:26.575364 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:17:26.582898 (MainThread): Parsing macros/etc.sql
2021-03-09 18:17:26.585335 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:17:26.592501 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:17:26.609165 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:17:26.612658 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:17:26.615130 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:17:26.626994 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:17:26.631236 (MainThread): Parsing macros/core.sql
2021-03-09 18:17:26.636798 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:17:26.691219 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:17:26.700940 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:17:26.702039 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:17:26.703888 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:17:26.706084 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:17:26.707884 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:17:26.709050 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:17:26.718562 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:17:26.733052 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:17:26.734984 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:17:26.741941 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:17:26.766300 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:17:26.801426 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:17:26.803248 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:17:26.822644 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:17:26.830063 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:17:26.837096 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:17:26.844965 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:17:26.848101 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:17:26.849842 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:17:26.851978 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:17:26.859847 (MainThread): Partial parsing not enabled
2021-03-09 18:17:26.909112 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:17:26.932094 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:17:26.943898 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:17:26.955318 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:17:26.968388 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:17:26.977122 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:17:26.989632 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:17:27.049640 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:17:27.329965 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:17:27.338957 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '15e9d0cd-8964-45fc-80f9-d61f302606f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed3f460>]}
2021-03-09 18:17:27.412177 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:17:27.413545 (MainThread): 
2021-03-09 18:17:27.413943 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:17:27.415546 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:17:27.415722 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:17:27.826249 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:17:27.826431 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:17:27.830744 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:17:28.211537 (MainThread): 13:17:28 | Concurrency: 1 threads (target='prod')
2021-03-09 18:17:28.211749 (MainThread): 13:17:28 | 
2021-03-09 18:17:28.213888 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:17:28.215205 (Thread-1): 13:17:28 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:17:28.215552 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:17:28.215698 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:17:28.218333 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51891), raddr=('172.217.7.10', 443)>
2021-03-09 18:17:28.218539 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51892), raddr=('172.217.9.234', 443)>
2021-03-09 18:17:28.218697 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51894), raddr=('172.217.9.234', 443)>
2021-03-09 18:17:28.218857 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51893), raddr=('172.217.7.10', 443)>
2021-03-09 18:17:28.239077 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:17:28.239391 (Thread-1): finished collecting timing info
2021-03-09 18:17:28.279021 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:17:28.279415 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:17:28.283320 (Thread-1): On model.hashpath_demo.unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics`
  WHERE rank = 1
  ))
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:17:29.194824 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/807ddd87-390f-43b6-8cb4-db1fc41dd15a?maxResults=0&location=US&prettyPrint=false: Unrecognized name: rank at [16:9]')
2021-03-09 18:17:30.467589 (Thread-1): finished collecting timing info
2021-03-09 18:17:30.468478 (Thread-1): Database Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Unrecognized name: rank at [16:9]
  compiled SQL at target/run/hashpath_demo/models/twitter/unique_public_metrics.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/88f1a617-f816-4eed-bc86-20e3db0f44e3?maxResults=0&location=US&prettyPrint=false: Unrecognized name: rank at [16:9]

(job ID: 88f1a617-f816-4eed-bc86-20e3db0f44e3)

                                                              -----Query Job SQL Follows-----                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.unique_public_metrics"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`
   5:  OPTIONS()
   6:  as with unique_tweets as 
   7:  (SELECT * FROM (SELECT
   8:  created_at as created_at,
   9:  id,
  10:  text, 
  11:  like_count,
  12:  retweet_count,
  13:  url,
  14:  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  15:  FROM `hashpath-demo-data`.`twitter`.`public_metrics`
  16:  WHERE rank = 1
  17:  ))
  18:SELECT
  19:  id,
  20:  text,
  21:  like_count,
  22:  retweet_count,
  23:  created_at,
  24:  url
  25:FROM unique_tweets
  26:ORDER BY 3 DESC;
  27:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
  Unrecognized name: rank at [16:9]
  compiled SQL at target/run/hashpath_demo/models/twitter/unique_public_metrics.sql
2021-03-09 18:17:30.474108 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '15e9d0cd-8964-45fc-80f9-d61f302606f6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ecffd60>]}
2021-03-09 18:17:30.475558 (Thread-1): 13:17:30 | 1 of 1 ERROR creating view model dbt_demo_production.unique_public_metrics [ERROR in 2.26s]
2021-03-09 18:17:30.475730 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:17:30.477084 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:17:30.477430 (MainThread): 13:17:30 | 
2021-03-09 18:17:30.477578 (MainThread): 13:17:30 | Finished running 1 view model in 3.06s.
2021-03-09 18:17:30.477701 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:17:30.477788 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:17:30.541252 (MainThread): 
2021-03-09 18:17:30.541419 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:17:30.541528 (MainThread): 
2021-03-09 18:17:30.541699 (MainThread): Database Error in model unique_public_metrics (models/twitter/unique_public_metrics.sql)
2021-03-09 18:17:30.541809 (MainThread):   Unrecognized name: rank at [16:9]
2021-03-09 18:17:30.541989 (MainThread):   compiled SQL at target/run/hashpath_demo/models/twitter/unique_public_metrics.sql
2021-03-09 18:17:30.542131 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2021-03-09 18:17:30.542484 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eca32e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb7fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eab00d0>]}
2021-03-09 18:17:30.542668 (MainThread): Flushing usage events
2021-03-09 18:18:05.473134 (MainThread): Running with dbt=0.19.0
2021-03-09 18:18:05.953209 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:18:05.954373 (MainThread): Tracking: tracking
2021-03-09 18:18:05.962639 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132460a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113261880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113261760>]}
2021-03-09 18:18:05.990724 (MainThread): Partial parsing not enabled
2021-03-09 18:18:05.992486 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:18:06.014529 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:18:06.021174 (MainThread): Parsing macros/etc.sql
2021-03-09 18:18:06.023296 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:18:06.028201 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:18:06.042472 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:18:06.045351 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:18:06.047459 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:18:06.058027 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:18:06.062162 (MainThread): Parsing macros/core.sql
2021-03-09 18:18:06.066172 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:18:06.110273 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:18:06.119212 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:18:06.120147 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:18:06.121794 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:18:06.123837 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:18:06.125612 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:18:06.126680 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:18:06.137487 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:18:06.153192 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:18:06.155176 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:18:06.162209 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:18:06.185239 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:18:06.220293 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:18:06.222217 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:18:06.244980 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:18:06.252439 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:18:06.257940 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:18:06.264562 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:18:06.267441 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:18:06.269158 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:18:06.271161 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:18:06.278757 (MainThread): Partial parsing not enabled
2021-03-09 18:18:06.324392 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:18:06.348661 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:18:06.358891 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:18:06.369943 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:18:06.381024 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:18:06.389536 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:18:06.400605 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:18:06.459136 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:18:06.743017 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:18:06.753409 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4c7c4538-9681-4890-b0c5-83aacbeb15f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11356c340>]}
2021-03-09 18:18:06.828589 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:18:06.829659 (MainThread): 
2021-03-09 18:18:06.830014 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:18:06.831728 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:18:06.831926 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:18:07.204186 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:18:07.204363 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:18:07.208706 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:18:07.580147 (MainThread): 13:18:07 | Concurrency: 1 threads (target='prod')
2021-03-09 18:18:07.580386 (MainThread): 13:18:07 | 
2021-03-09 18:18:07.582535 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:18:07.583830 (Thread-1): 13:18:07 | 1 of 1 START view model dbt_demo_production.unique_public_metrics.... [RUN]
2021-03-09 18:18:07.584175 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:18:07.584330 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:18:07.587044 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51902), raddr=('172.217.7.10', 443)>
2021-03-09 18:18:07.587247 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51903), raddr=('172.217.9.234', 443)>
2021-03-09 18:18:07.587402 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51905), raddr=('172.217.9.234', 443)>
2021-03-09 18:18:07.587579 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51904), raddr=('172.217.7.10', 443)>
2021-03-09 18:18:07.608356 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:18:07.608719 (Thread-1): finished collecting timing info
2021-03-09 18:18:07.650286 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:18:07.650767 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:18:07.655347 (Thread-1): On model.hashpath_demo.unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:18:09.592467 (Thread-1): finished collecting timing info
2021-03-09 18:18:09.593295 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c7c4538-9681-4890-b0c5-83aacbeb15f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a0c670>]}
2021-03-09 18:18:09.594568 (Thread-1): 13:18:09 | 1 of 1 OK created view model dbt_demo_production.unique_public_metrics [OK in 2.01s]
2021-03-09 18:18:09.594730 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:18:09.595899 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:18:09.596224 (MainThread): 13:18:09 | 
2021-03-09 18:18:09.596364 (MainThread): 13:18:09 | Finished running 1 view model in 2.77s.
2021-03-09 18:18:09.596484 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:18:09.596586 (MainThread): Connection 'model.hashpath_demo.unique_public_metrics' was properly closed.
2021-03-09 18:18:09.658762 (MainThread): 
2021-03-09 18:18:09.658943 (MainThread): Completed successfully
2021-03-09 18:18:09.659063 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2021-03-09 18:18:09.659360 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113507a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112029d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a0c670>]}
2021-03-09 18:18:09.659580 (MainThread): Flushing usage events
2021-03-09 18:18:23.128174 (MainThread): Running with dbt=0.19.0
2021-03-09 18:18:23.630313 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-09 18:18:23.631759 (MainThread): Tracking: tracking
2021-03-09 18:18:23.641888 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112eccfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ed5250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ed5130>]}
2021-03-09 18:18:23.668513 (MainThread): Partial parsing not enabled
2021-03-09 18:18:23.669710 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:18:23.695608 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:18:23.703433 (MainThread): Parsing macros/etc.sql
2021-03-09 18:18:23.705744 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:18:23.710871 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:18:23.726198 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:18:23.729409 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:18:23.731745 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:18:23.743359 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:18:23.747769 (MainThread): Parsing macros/core.sql
2021-03-09 18:18:23.753892 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:18:23.811799 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:18:23.822695 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:18:23.824685 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:18:23.826846 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:18:23.829284 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:18:23.831310 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:18:23.832742 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:18:23.846346 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:18:23.865065 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:18:23.867791 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:18:23.875917 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:18:23.903335 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:18:23.949761 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:18:23.953283 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:18:23.987090 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:18:23.997844 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:18:24.006154 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:18:24.014123 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:18:24.017413 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:18:24.019120 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:18:24.021259 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:18:24.032519 (MainThread): Partial parsing not enabled
2021-03-09 18:18:24.079502 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:18:24.101892 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:18:24.115708 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:18:24.129377 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:18:24.141438 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:18:24.150206 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:18:24.162968 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:18:24.227460 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:18:24.546304 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:18:24.555835 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '37ddbb8d-ddf4-4783-b0b3-e2e42591c252', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131792e0>]}
2021-03-09 18:18:24.633234 (MainThread): Found 8 models, 6 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 3 sources, 0 exposures
2021-03-09 18:18:24.634638 (MainThread): 
2021-03-09 18:18:24.634970 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:18:24.653047 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:18:24.653237 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:18:24.658090 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:18:25.056738 (MainThread): 13:18:25 | Concurrency: 1 threads (target='prod')
2021-03-09 18:18:25.056945 (MainThread): 13:18:25 | 
2021-03-09 18:18:25.059252 (Thread-1): Began running node model.hashpath_demo.new_model
2021-03-09 18:18:25.059615 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.new_model".
2021-03-09 18:18:25.059773 (Thread-1): Compiling model.hashpath_demo.new_model
2021-03-09 18:18:25.073192 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51911), raddr=('172.217.9.234', 443)>
2021-03-09 18:18:25.073392 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51910), raddr=('172.217.7.10', 443)>
2021-03-09 18:18:25.076805 (Thread-1): Writing injected SQL for node "model.hashpath_demo.new_model"
2021-03-09 18:18:25.077118 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.077377 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.077798 (Thread-1): Finished running node model.hashpath_demo.new_model
2021-03-09 18:18:25.077932 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:18:25.078177 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:18:25.078282 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:18:25.085226 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-09 18:18:25.085509 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.085740 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.086111 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:18:25.086236 (Thread-1): Began running node model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:18:25.086464 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.bigfoot_ephemeral".
2021-03-09 18:18:25.086564 (Thread-1): Compiling model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:18:25.094349 (Thread-1): Writing injected SQL for node "model.hashpath_demo.bigfoot_ephemeral"
2021-03-09 18:18:25.094822 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.095952 (Thread-1): Finished running node model.hashpath_demo.bigfoot_ephemeral
2021-03-09 18:18:25.096191 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:18:25.096584 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:18:25.096713 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:18:25.110361 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:18:25.110749 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.111023 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.111448 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:18:25.111592 (Thread-1): Began running node model.hashpath_demo.all_sightings
2021-03-09 18:18:25.111852 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.all_sightings".
2021-03-09 18:18:25.111972 (Thread-1): Compiling model.hashpath_demo.all_sightings
2021-03-09 18:18:25.124223 (Thread-1): Writing injected SQL for node "model.hashpath_demo.all_sightings"
2021-03-09 18:18:25.124720 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.124997 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.125431 (Thread-1): Finished running node model.hashpath_demo.all_sightings
2021-03-09 18:18:25.125571 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-09 18:18:25.125856 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:18:25.125964 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-09 18:18:25.134577 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-09 18:18:25.134930 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.135252 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.135671 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-09 18:18:25.135817 (Thread-1): Began running node test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-09 18:18:25.136066 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_unique_public_metrics_id".
2021-03-09 18:18:25.136175 (Thread-1): Compiling test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-09 18:18:25.152041 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_unique_public_metrics_id"
2021-03-09 18:18:25.152389 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.152636 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.153010 (Thread-1): Finished running node test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-09 18:18:25.153141 (Thread-1): Began running node test.hashpath_demo.unique_unique_public_metrics_id
2021-03-09 18:18:25.153374 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_unique_public_metrics_id".
2021-03-09 18:18:25.153737 (Thread-1): Compiling test.hashpath_demo.unique_unique_public_metrics_id
2021-03-09 18:18:25.163985 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_unique_public_metrics_id"
2021-03-09 18:18:25.164339 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.164608 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.164990 (Thread-1): Finished running node test.hashpath_demo.unique_unique_public_metrics_id
2021-03-09 18:18:25.165121 (Thread-1): Began running node model.hashpath_demo.demo_123
2021-03-09 18:18:25.165359 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.demo_123".
2021-03-09 18:18:25.165460 (Thread-1): Compiling model.hashpath_demo.demo_123
2021-03-09 18:18:25.174540 (Thread-1): Writing injected SQL for node "model.hashpath_demo.demo_123"
2021-03-09 18:18:25.174979 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.175226 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.175621 (Thread-1): Finished running node model.hashpath_demo.demo_123
2021-03-09 18:18:25.175752 (Thread-1): Began running node model.hashpath_demo.massachusetts_sightings
2021-03-09 18:18:25.175990 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.massachusetts_sightings".
2021-03-09 18:18:25.176092 (Thread-1): Compiling model.hashpath_demo.massachusetts_sightings
2021-03-09 18:18:25.186541 (Thread-1): Writing injected SQL for node "model.hashpath_demo.massachusetts_sightings"
2021-03-09 18:18:25.186903 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.187179 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.187598 (Thread-1): Finished running node model.hashpath_demo.massachusetts_sightings
2021-03-09 18:18:25.187733 (Thread-1): Began running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-09 18:18:25.187981 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_all_sightings_geohash".
2021-03-09 18:18:25.188093 (Thread-1): Compiling test.hashpath_demo.not_null_all_sightings_geohash
2021-03-09 18:18:25.198203 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_all_sightings_geohash"
2021-03-09 18:18:25.198884 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.199162 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.199558 (Thread-1): Finished running node test.hashpath_demo.not_null_all_sightings_geohash
2021-03-09 18:18:25.199688 (Thread-1): Began running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-09 18:18:25.199925 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_all_sightings_geohash".
2021-03-09 18:18:25.200029 (Thread-1): Compiling test.hashpath_demo.unique_all_sightings_geohash
2021-03-09 18:18:25.213464 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_all_sightings_geohash"
2021-03-09 18:18:25.214574 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.214999 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.215510 (Thread-1): Finished running node test.hashpath_demo.unique_all_sightings_geohash
2021-03-09 18:18:25.215675 (Thread-1): Began running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-09 18:18:25.215964 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_massachusetts_sightings_geohash".
2021-03-09 18:18:25.216089 (Thread-1): Compiling test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-09 18:18:25.235563 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_massachusetts_sightings_geohash"
2021-03-09 18:18:25.238099 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.239203 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.241664 (Thread-1): Finished running node test.hashpath_demo.not_null_massachusetts_sightings_geohash
2021-03-09 18:18:25.241952 (Thread-1): Began running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-09 18:18:25.242844 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_massachusetts_sightings_geohash".
2021-03-09 18:18:25.243107 (Thread-1): Compiling test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-09 18:18:25.256318 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_massachusetts_sightings_geohash"
2021-03-09 18:18:25.256842 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.257316 (Thread-1): finished collecting timing info
2021-03-09 18:18:25.258185 (Thread-1): Finished running node test.hashpath_demo.unique_massachusetts_sightings_geohash
2021-03-09 18:18:25.259349 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:18:25.259499 (MainThread): Connection 'test.hashpath_demo.unique_massachusetts_sightings_geohash' was properly closed.
2021-03-09 18:18:25.335662 (MainThread): 13:18:25 | Done.
2021-03-09 18:18:25.339154 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-09 18:18:25.339314 (MainThread): 13:18:25 | Building catalog
2021-03-09 18:18:25.384742 (MainThread): Opening a new connection, currently in state init
2021-03-09 18:18:25.730503 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:18:25.748080 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-09 18:18:25.752466 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_demo_production`.__TABLES__
        where (upper(dataset_id) = upper('dbt_demo_production'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:18:29.062410 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:18:29.065877 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:18:29.070746 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`hashpath_dataset`.__TABLES__
        where (upper(dataset_id) = upper('hashpath_dataset'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`hashpath_dataset`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`hashpath_dataset`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:18:32.817278 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:18:32.825978 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:18:32.830158 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`twitter`.__TABLES__
        where (upper(dataset_id) = upper('twitter'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:18:36.596293 (MainThread): 13:18:36 | Catalog written to /Users/sethrosen/Documents/GitHub/dbt_topcoat_demo/target/catalog.json
2021-03-09 18:18:36.597468 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112eccfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ff9f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131670d0>]}
2021-03-09 18:18:36.597815 (MainThread): Flushing usage events
2021-03-09 18:18:36.730605 (MainThread): Connection 'generate_catalog' was properly closed.
2021-03-09 18:18:36.730801 (MainThread): Connection 'hashpath-demo-data.information_schema' was properly closed.
2021-03-09 18:19:28.245929 (MainThread): Running with dbt=0.19.0
2021-03-09 18:19:28.754099 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-09 18:19:28.755254 (MainThread): Tracking: tracking
2021-03-09 18:19:28.764920 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11104a400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122c21f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122c20d0>]}
2021-03-09 18:19:28.793015 (MainThread): Partial parsing not enabled
2021-03-09 18:19:28.794434 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:19:28.816791 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:19:28.823930 (MainThread): Parsing macros/etc.sql
2021-03-09 18:19:28.826427 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:19:28.834576 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:19:28.851035 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:19:28.854213 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:19:28.856771 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:19:28.868881 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:19:28.873779 (MainThread): Parsing macros/core.sql
2021-03-09 18:19:28.880155 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:19:28.933559 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:19:28.944553 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:19:28.945704 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:19:28.947669 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:19:28.949931 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:19:28.951714 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:19:28.952860 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:19:28.962961 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:19:28.978774 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:19:28.980831 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:19:28.988035 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:19:29.015567 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:19:29.052131 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:19:29.054163 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:19:29.074709 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:19:29.082486 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:19:29.087986 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:19:29.095231 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:19:29.098241 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:19:29.099949 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:19:29.102043 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:19:29.110376 (MainThread): Partial parsing not enabled
2021-03-09 18:19:29.158623 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:19:29.184249 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:19:29.196761 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:19:29.495843 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:19:29.500429 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6118c7f9-434f-488c-8a42-f5f4b10ac01a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1125b09a0>]}
2021-03-09 18:19:29.547921 (MainThread): Found 3 models, 2 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:19:29.549075 (MainThread): 
2021-03-09 18:19:29.549541 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:19:29.557144 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:19:29.557340 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:19:29.562205 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:19:29.912812 (MainThread): 13:19:29 | Concurrency: 1 threads (target='prod')
2021-03-09 18:19:29.913017 (MainThread): 13:19:29 | 
2021-03-09 18:19:29.915164 (Thread-1): Began running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:19:29.915540 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day_by_state".
2021-03-09 18:19:29.915699 (Thread-1): Compiling model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:19:29.934708 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day_by_state"
2021-03-09 18:19:29.935080 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.935351 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.935761 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day_by_state
2021-03-09 18:19:29.935897 (Thread-1): Began running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:19:29.936137 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.unique_public_metrics".
2021-03-09 18:19:29.936246 (Thread-1): Compiling model.hashpath_demo.unique_public_metrics
2021-03-09 18:19:29.937003 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51932), raddr=('172.217.7.10', 443)>
2021-03-09 18:19:29.937312 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51933), raddr=('172.217.9.234', 443)>
2021-03-09 18:19:29.949028 (Thread-1): Writing injected SQL for node "model.hashpath_demo.unique_public_metrics"
2021-03-09 18:19:29.949472 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.949776 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.950253 (Thread-1): Finished running node model.hashpath_demo.unique_public_metrics
2021-03-09 18:19:29.950412 (Thread-1): Began running node model.hashpath_demo.sightings_by_day
2021-03-09 18:19:29.950713 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.sightings_by_day".
2021-03-09 18:19:29.950836 (Thread-1): Compiling model.hashpath_demo.sightings_by_day
2021-03-09 18:19:29.961694 (Thread-1): Writing injected SQL for node "model.hashpath_demo.sightings_by_day"
2021-03-09 18:19:29.962427 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.962811 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.963423 (Thread-1): Finished running node model.hashpath_demo.sightings_by_day
2021-03-09 18:19:29.963686 (Thread-1): Began running node test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-09 18:19:29.964021 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.not_null_unique_public_metrics_id".
2021-03-09 18:19:29.964260 (Thread-1): Compiling test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-09 18:19:29.979584 (Thread-1): Writing injected SQL for node "test.hashpath_demo.not_null_unique_public_metrics_id"
2021-03-09 18:19:29.979923 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.980171 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.980664 (Thread-1): Finished running node test.hashpath_demo.not_null_unique_public_metrics_id
2021-03-09 18:19:29.980802 (Thread-1): Began running node test.hashpath_demo.unique_unique_public_metrics_id
2021-03-09 18:19:29.981042 (Thread-1): Acquiring new bigquery connection "test.hashpath_demo.unique_unique_public_metrics_id".
2021-03-09 18:19:29.981148 (Thread-1): Compiling test.hashpath_demo.unique_unique_public_metrics_id
2021-03-09 18:19:29.989471 (Thread-1): Writing injected SQL for node "test.hashpath_demo.unique_unique_public_metrics_id"
2021-03-09 18:19:29.989825 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.990371 (Thread-1): finished collecting timing info
2021-03-09 18:19:29.991190 (Thread-1): Finished running node test.hashpath_demo.unique_unique_public_metrics_id
2021-03-09 18:19:29.992368 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:19:29.992561 (MainThread): Connection 'test.hashpath_demo.unique_unique_public_metrics_id' was properly closed.
2021-03-09 18:19:30.031460 (MainThread): 13:19:30 | Done.
2021-03-09 18:19:30.035125 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-09 18:19:30.035296 (MainThread): 13:19:30 | Building catalog
2021-03-09 18:19:30.050461 (MainThread): Opening a new connection, currently in state init
2021-03-09 18:19:30.438172 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:19:30.457809 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-09 18:19:30.463446 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_demo_production`.__TABLES__
        where (upper(dataset_id) = upper('dbt_demo_production'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:19:34.323479 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:19:34.326566 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:19:34.331179 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`twitter`.__TABLES__
        where (upper(dataset_id) = upper('twitter'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:19:39.071110 (MainThread): 13:19:39 | Catalog written to /Users/sethrosen/Documents/GitHub/dbt_topcoat_demo/target/catalog.json
2021-03-09 18:19:39.071554 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11104a400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112511df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126f3a90>]}
2021-03-09 18:19:39.071796 (MainThread): Flushing usage events
2021-03-09 18:19:39.275548 (MainThread): Connection 'generate_catalog' was properly closed.
2021-03-09 18:19:39.275742 (MainThread): Connection 'hashpath-demo-data.information_schema' was properly closed.
2021-03-09 18:23:46.793768 (MainThread): Running with dbt=0.19.0
2021-03-09 18:23:47.502327 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:23:47.504081 (MainThread): Tracking: tracking
2021-03-09 18:23:47.516999 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11345ca60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11346b490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11346b370>]}
2021-03-09 18:23:47.545798 (MainThread): Partial parsing not enabled
2021-03-09 18:23:47.548316 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:23:47.572362 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:23:47.582770 (MainThread): Parsing macros/etc.sql
2021-03-09 18:23:47.585944 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:23:47.592066 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:23:47.608755 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:23:47.612454 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:23:47.614790 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:23:47.629719 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:23:47.635292 (MainThread): Parsing macros/core.sql
2021-03-09 18:23:47.641040 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:23:47.689142 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:23:47.699419 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:23:47.701295 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:23:47.703950 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:23:47.707123 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:23:47.709870 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:23:47.711872 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:23:47.722802 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:23:47.738840 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:23:47.741425 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:23:47.748864 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:23:47.773222 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:23:47.814429 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:23:47.819260 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:23:47.842165 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:23:47.852621 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:23:47.860878 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:23:47.870198 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:23:47.874067 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:23:47.876250 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:23:47.879669 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:23:47.889052 (MainThread): Partial parsing not enabled
2021-03-09 18:23:47.940047 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:23:47.962185 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:23:48.185790 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:23:48.186093 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:23:48.186256 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:23:48.239304 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:23:48.242714 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3f321427-5c60-4f76-8bc5-c7d9a212330c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136b48e0>]}
2021-03-09 18:23:48.279760 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:23:48.281936 (MainThread): 
2021-03-09 18:23:48.282361 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:23:48.285247 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:23:48.285415 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:23:48.743149 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:23:48.743349 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:23:48.747785 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:23:49.115654 (MainThread): 13:23:49 | Concurrency: 1 threads (target='prod')
2021-03-09 18:23:49.115831 (MainThread): 13:23:49 | 
2021-03-09 18:23:49.123874 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:23:49.125183 (Thread-1): 13:23:49 | 1 of 2 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:23:49.125776 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:23:49.126262 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:23:49.148663 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:23:49.149185 (Thread-1): finished collecting timing info
2021-03-09 18:23:49.150226 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51986), raddr=('172.217.9.234', 443)>
2021-03-09 18:23:49.150473 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51985), raddr=('172.217.11.10', 443)>
2021-03-09 18:23:49.150661 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51987), raddr=('172.217.11.10', 443)>
2021-03-09 18:23:49.150906 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 51988), raddr=('172.217.9.234', 443)>
2021-03-09 18:23:49.193927 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:23:49.194595 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:23:49.199742 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_organic_metrics,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`private_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_organic_metrics,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:23:50.125713 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_organic_metrics,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`private_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_organic_metrics,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:23:50.125965 (Thread-1): 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6?maxResults=0&location=US&prettyPrint=false: Not found: Table hashpath-demo-data:twitter.private_metrics was not found in location US

(job ID: 3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6)

                                                                 -----Query Job SQL Follows-----                                                                 

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
   5:  OPTIONS()
   6:  as with unique_tweets as 
   7:  (SELECT * FROM (SELECT
   8:  created_at as created_at,
   9:  id,
  10:  text, 
  11:  non_public_organic_metrics,
  12:  non_public_metrics_user_profile_clicks, 
  13:  organic_metrics_impression_count,
  14:  url,
  15:  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  16:  FROM `hashpath-demo-data`.`twitter`.`private_metrics` )
  17:  WHERE rank = 1
  18:  )
  19:SELECT
  20:  id,
  21:  text,
  22:  non_public_organic_metrics,
  23:  non_public_metrics_user_profile_clicks, 
  24:  organic_metrics_impression_count,
  25:  created_at,
  26:  url
  27:FROM unique_tweets
  28:ORDER BY 3 DESC;
  29:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
2021-03-09 18:23:50.126313 (Thread-1): finished collecting timing info
2021-03-09 18:23:50.126991 (Thread-1): Runtime Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6?maxResults=0&location=US&prettyPrint=false: Not found: Table hashpath-demo-data:twitter.private_metrics was not found in location US
  
  (job ID: 3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6)
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.NotFound: 404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6?maxResults=0&location=US&prettyPrint=false: Not found: Table hashpath-demo-data:twitter.private_metrics was not found in location US

(job ID: 3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6)

                                                                 -----Query Job SQL Follows-----                                                                 

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
   5:  OPTIONS()
   6:  as with unique_tweets as 
   7:  (SELECT * FROM (SELECT
   8:  created_at as created_at,
   9:  id,
  10:  text, 
  11:  non_public_organic_metrics,
  12:  non_public_metrics_user_profile_clicks, 
  13:  organic_metrics_impression_count,
  14:  url,
  15:  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  16:  FROM `hashpath-demo-data`.`twitter`.`private_metrics` )
  17:  WHERE rank = 1
  18:  )
  19:SELECT
  20:  id,
  21:  text,
  22:  non_public_organic_metrics,
  23:  non_public_metrics_user_profile_clicks, 
  24:  organic_metrics_impression_count,
  25:  created_at,
  26:  url
  27:FROM unique_tweets
  28:ORDER BY 3 DESC;
  29:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 181, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
  404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6?maxResults=0&location=US&prettyPrint=false: Not found: Table hashpath-demo-data:twitter.private_metrics was not found in location US
  
  (job ID: 3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6)
2021-03-09 18:23:50.146372 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f321427-5c60-4f76-8bc5-c7d9a212330c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11365fdf0>]}
2021-03-09 18:23:50.147873 (Thread-1): 13:23:50 | 1 of 2 ERROR creating view model dbt_demo_production.stg_unique_private_metrics [ERROR in 1.02s]
2021-03-09 18:23:50.148042 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:23:50.148213 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:23:50.149371 (Thread-1): 13:23:50 | 2 of 2 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:23:50.149917 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:23:50.150061 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:23:50.159047 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:23:50.159500 (Thread-1): finished collecting timing info
2021-03-09 18:23:50.164489 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:23:50.164951 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:23:50.169476 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:23:51.383419 (Thread-1): finished collecting timing info
2021-03-09 18:23:51.384245 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3f321427-5c60-4f76-8bc5-c7d9a212330c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113690e20>]}
2021-03-09 18:23:51.385846 (Thread-1): 13:23:51 | 2 of 2 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.23s]
2021-03-09 18:23:51.386211 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:23:51.388328 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:23:51.388822 (MainThread): 13:23:51 | 
2021-03-09 18:23:51.389009 (MainThread): 13:23:51 | Finished running 2 view models in 3.11s.
2021-03-09 18:23:51.389154 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:23:51.389256 (MainThread): Connection 'model.hashpath_demo.stg_unique_public_metrics' was properly closed.
2021-03-09 18:23:51.430882 (MainThread): 
2021-03-09 18:23:51.431104 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:23:51.431247 (MainThread): 
2021-03-09 18:23:51.431390 (MainThread): Runtime Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
2021-03-09 18:23:51.431521 (MainThread):   404 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6?maxResults=0&location=US&prettyPrint=false: Not found: Table hashpath-demo-data:twitter.private_metrics was not found in location US
2021-03-09 18:23:51.431643 (MainThread):   
2021-03-09 18:23:51.431742 (MainThread):   (job ID: 3c953bdb-4af3-4f96-8c9e-e0f3bd7e7fc6)
2021-03-09 18:23:51.431851 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2021-03-09 18:23:51.432078 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11365b160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135a02e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113694a00>]}
2021-03-09 18:23:51.432389 (MainThread): Flushing usage events
2021-03-09 18:24:06.446041 (MainThread): Running with dbt=0.19.0
2021-03-09 18:24:06.900898 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:24:06.902014 (MainThread): Tracking: tracking
2021-03-09 18:24:06.910355 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112037340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132b5130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132b5040>]}
2021-03-09 18:24:06.936931 (MainThread): Partial parsing not enabled
2021-03-09 18:24:06.938120 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:24:06.959917 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:24:06.967204 (MainThread): Parsing macros/etc.sql
2021-03-09 18:24:06.969372 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:24:06.974252 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:24:06.988134 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:24:06.991071 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:24:06.993021 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:24:07.003480 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:24:07.007453 (MainThread): Parsing macros/core.sql
2021-03-09 18:24:07.011494 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:24:07.058696 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:24:07.068069 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:24:07.069048 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:24:07.070946 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:24:07.072993 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:24:07.074754 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:24:07.075901 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:24:07.086720 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:24:07.103450 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:24:07.105585 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:24:07.112822 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:24:07.140450 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:24:07.177133 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:24:07.179077 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:24:07.198509 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:24:07.206910 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:24:07.213217 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:24:07.222912 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:24:07.226304 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:24:07.228023 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:24:07.230121 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:24:07.238021 (MainThread): Partial parsing not enabled
2021-03-09 18:24:07.284662 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:24:07.305455 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:24:07.518411 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:24:07.518668 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:24:07.518807 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:24:07.569970 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:24:07.573437 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cf5144a0-c2b6-40dc-881c-7cae85bfddca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134f9c10>]}
2021-03-09 18:24:07.616687 (MainThread): Found 2 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:24:07.617567 (MainThread): 
2021-03-09 18:24:07.617918 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:24:07.620830 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:24:07.621014 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:24:07.991864 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:24:07.992057 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:24:07.996815 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:24:08.352302 (MainThread): 13:24:08 | Concurrency: 1 threads (target='prod')
2021-03-09 18:24:08.352520 (MainThread): 13:24:08 | 
2021-03-09 18:24:08.354880 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:24:08.356146 (Thread-1): 13:24:08 | 1 of 2 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:24:08.356536 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:24:08.356698 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:24:08.374988 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:24:08.375516 (Thread-1): finished collecting timing info
2021-03-09 18:24:08.376391 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52005), raddr=('172.217.9.234', 443)>
2021-03-09 18:24:08.376551 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52003), raddr=('172.217.11.10', 443)>
2021-03-09 18:24:08.376672 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52006), raddr=('172.217.11.10', 443)>
2021-03-09 18:24:08.376800 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52007), raddr=('172.217.9.234', 443)>
2021-03-09 18:24:08.414630 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:24:08.415107 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:24:08.419483 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:24:09.340048 (Thread-1): finished collecting timing info
2021-03-09 18:24:09.340858 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf5144a0-c2b6-40dc-881c-7cae85bfddca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134a6a00>]}
2021-03-09 18:24:09.342358 (Thread-1): 13:24:09 | 1 of 2 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.98s]
2021-03-09 18:24:09.342531 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:24:09.342703 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:24:09.343867 (Thread-1): 13:24:09 | 2 of 2 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:24:09.344248 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:24:09.344396 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:24:09.353550 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:24:09.353927 (Thread-1): finished collecting timing info
2021-03-09 18:24:09.359919 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:24:09.360307 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:24:09.364779 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:24:10.213214 (Thread-1): finished collecting timing info
2021-03-09 18:24:10.213974 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf5144a0-c2b6-40dc-881c-7cae85bfddca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11340bf10>]}
2021-03-09 18:24:10.215210 (Thread-1): 13:24:10 | 2 of 2 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 0.87s]
2021-03-09 18:24:10.215372 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:24:10.216568 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:24:10.216915 (MainThread): 13:24:10 | 
2021-03-09 18:24:10.217058 (MainThread): 13:24:10 | Finished running 2 view models in 2.60s.
2021-03-09 18:24:10.217197 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:24:10.217285 (MainThread): Connection 'model.hashpath_demo.stg_unique_public_metrics' was properly closed.
2021-03-09 18:24:10.231470 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52010), raddr=('172.217.11.10', 443)>
2021-03-09 18:24:10.231661 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52011), raddr=('172.217.9.234', 443)>
2021-03-09 18:24:10.255203 (MainThread): 
2021-03-09 18:24:10.255373 (MainThread): Completed successfully
2021-03-09 18:24:10.255511 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2021-03-09 18:24:10.255741 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134c8f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1135090a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134d9d30>]}
2021-03-09 18:24:10.255921 (MainThread): Flushing usage events
2021-03-09 18:26:47.596057 (MainThread): Running with dbt=0.19.0
2021-03-09 18:26:48.306855 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:26:48.308405 (MainThread): Tracking: tracking
2021-03-09 18:26:48.322564 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095a43a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a81ea60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a81e940>]}
2021-03-09 18:26:48.350723 (MainThread): Partial parsing not enabled
2021-03-09 18:26:48.352532 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:26:48.377805 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:26:48.387479 (MainThread): Parsing macros/etc.sql
2021-03-09 18:26:48.390341 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:26:48.396108 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:26:48.412014 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:26:48.418010 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:26:48.421372 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:26:48.434230 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:26:48.438915 (MainThread): Parsing macros/core.sql
2021-03-09 18:26:48.443761 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:26:48.491599 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:26:48.505818 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:26:48.508728 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:26:48.512202 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:26:48.516282 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:26:48.520379 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:26:48.523037 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:26:48.535404 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:26:48.551480 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:26:48.555732 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:26:48.565201 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:26:48.592206 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:26:48.631902 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:26:48.635870 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:26:48.658240 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:26:48.669914 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:26:48.677870 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:26:48.686267 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:26:48.690192 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:26:48.694004 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:26:48.697656 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:26:48.706854 (MainThread): Partial parsing not enabled
2021-03-09 18:26:48.755565 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:26:48.782650 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:26:48.793857 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:26:49.018508 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:26:49.018823 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:26:49.018964 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:26:49.073722 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:26:49.077379 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6796c6aa-7403-49aa-ab01-773912d7b1da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa79b20>]}
2021-03-09 18:26:49.121041 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:26:49.121876 (MainThread): 
2021-03-09 18:26:49.122187 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:26:49.126143 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:26:49.126307 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:26:49.596989 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:26:49.597193 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:26:49.601392 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:26:49.957275 (MainThread): 13:26:49 | Concurrency: 1 threads (target='prod')
2021-03-09 18:26:49.957485 (MainThread): 13:26:49 | 
2021-03-09 18:26:49.965919 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:26:49.967510 (Thread-1): 13:26:49 | 1 of 3 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:26:49.967955 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:26:49.968111 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:26:49.977726 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52072), raddr=('172.217.11.10', 443)>
2021-03-09 18:26:49.977930 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52074), raddr=('172.217.11.10', 443)>
2021-03-09 18:26:49.978108 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52073), raddr=('172.217.9.234', 443)>
2021-03-09 18:26:49.978247 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52075), raddr=('172.217.9.234', 443)>
2021-03-09 18:26:49.988952 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:26:49.989275 (Thread-1): finished collecting timing info
2021-03-09 18:26:50.027273 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:26:50.027676 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:26:50.031478 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:26:50.856832 (Thread-1): finished collecting timing info
2021-03-09 18:26:50.857648 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6796c6aa-7403-49aa-ab01-773912d7b1da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aaa5910>]}
2021-03-09 18:26:50.859101 (Thread-1): 13:26:50 | 1 of 3 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.89s]
2021-03-09 18:26:50.859264 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:26:50.859430 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:26:50.860568 (Thread-1): 13:26:50 | 2 of 3 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:26:50.861006 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:26:50.861147 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:26:50.869587 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:26:50.869917 (Thread-1): finished collecting timing info
2021-03-09 18:26:50.874519 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:26:50.874811 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:26:50.878748 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:26:51.785305 (Thread-1): finished collecting timing info
2021-03-09 18:26:51.786131 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6796c6aa-7403-49aa-ab01-773912d7b1da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bc40880>]}
2021-03-09 18:26:51.787790 (Thread-1): 13:26:51 | 2 of 3 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 0.92s]
2021-03-09 18:26:51.787984 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:26:51.788700 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:26:51.789922 (Thread-1): 13:26:51 | 3 of 3 START view model dbt_demo_production.mrt_twitter_metrics...... [RUN]
2021-03-09 18:26:51.790268 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:26:51.790403 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:26:51.792459 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52079), raddr=('172.217.11.10', 443)>
2021-03-09 18:26:51.792649 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52080), raddr=('172.217.9.234', 443)>
2021-03-09 18:26:51.801210 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:26:51.807555 (Thread-1): finished collecting timing info
2021-03-09 18:26:51.815086 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:26:51.815551 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:26:51.820332 (Thread-1): On model.hashpath_demo.mrt_twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
  OPTIONS()
  as SELECT
id
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu
LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-09 18:26:52.512645 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/e5032ce3-cb0e-48fb-a23e-0602bef9d598?maxResults=0&location=US&prettyPrint=false: Column name id is ambiguous at [7:1]')
2021-03-09 18:26:54.078085 (Thread-1): finished collecting timing info
2021-03-09 18:26:54.078966 (Thread-1): Database Error in model mrt_twitter_metrics (models/twitter/mrt_twitter_metrics.sql)
  Column name id is ambiguous at [7:1]
  compiled SQL at target/run/hashpath_demo/models/twitter/mrt_twitter_metrics.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/988cb10f-293d-4a0c-9127-0b4e36ce2223?maxResults=0&location=US&prettyPrint=false: Column name id is ambiguous at [7:1]

(job ID: 988cb10f-293d-4a0c-9127-0b4e36ce2223)

                                                             -----Query Job SQL Follows-----                                                              

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
   5:  OPTIONS()
   6:  as SELECT
   7:id
   8:FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu
   9:LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
  10:ON pu.id = pr.id;
  11:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model mrt_twitter_metrics (models/twitter/mrt_twitter_metrics.sql)
  Column name id is ambiguous at [7:1]
  compiled SQL at target/run/hashpath_demo/models/twitter/mrt_twitter_metrics.sql
2021-03-09 18:26:54.101872 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6796c6aa-7403-49aa-ab01-773912d7b1da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bcc9c40>]}
2021-03-09 18:26:54.103531 (Thread-1): 13:26:54 | 3 of 3 ERROR creating view model dbt_demo_production.mrt_twitter_metrics [ERROR in 2.31s]
2021-03-09 18:26:54.103746 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:26:54.105168 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:26:54.105524 (MainThread): 13:26:54 | 
2021-03-09 18:26:54.105667 (MainThread): 13:26:54 | Finished running 3 view models in 4.98s.
2021-03-09 18:26:54.105792 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:26:54.105885 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:26:54.143931 (MainThread): 
2021-03-09 18:26:54.144178 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:26:54.144349 (MainThread): 
2021-03-09 18:26:54.144509 (MainThread): Database Error in model mrt_twitter_metrics (models/twitter/mrt_twitter_metrics.sql)
2021-03-09 18:26:54.144640 (MainThread):   Column name id is ambiguous at [7:1]
2021-03-09 18:26:54.144763 (MainThread):   compiled SQL at target/run/hashpath_demo/models/twitter/mrt_twitter_metrics.sql
2021-03-09 18:26:54.144897 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2021-03-09 18:26:54.145119 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9c6cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a9f58b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a88dca0>]}
2021-03-09 18:26:54.145310 (MainThread): Flushing usage events
2021-03-09 18:27:04.733877 (MainThread): Running with dbt=0.19.0
2021-03-09 18:27:05.269539 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:27:05.270799 (MainThread): Tracking: tracking
2021-03-09 18:27:05.278983 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e26430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a8190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140a8040>]}
2021-03-09 18:27:05.306135 (MainThread): Partial parsing not enabled
2021-03-09 18:27:05.307353 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:27:05.329274 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:27:05.335749 (MainThread): Parsing macros/etc.sql
2021-03-09 18:27:05.337844 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:27:05.342561 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:27:05.356493 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:27:05.360081 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:27:05.362049 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:27:05.373007 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:27:05.376967 (MainThread): Parsing macros/core.sql
2021-03-09 18:27:05.382215 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:27:05.428888 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:27:05.438131 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:27:05.439185 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:27:05.440860 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:27:05.442934 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:27:05.444573 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:27:05.445645 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:27:05.454917 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:27:05.469622 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:27:05.471612 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:27:05.478454 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:27:05.500294 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:27:05.533958 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:27:05.535847 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:27:05.554540 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:27:05.561669 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:27:05.566894 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:27:05.573300 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:27:05.576106 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:27:05.577756 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:27:05.579651 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:27:05.587226 (MainThread): Partial parsing not enabled
2021-03-09 18:27:05.633343 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:27:05.655288 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:27:05.665822 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:27:05.876101 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:27:05.876653 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:27:05.876915 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:27:05.929513 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:27:05.933653 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f578ba72-142b-4231-8661-f791a9b8d397', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114304820>]}
2021-03-09 18:27:05.976003 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:27:05.976949 (MainThread): 
2021-03-09 18:27:05.977445 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:27:05.981718 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:27:05.981896 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:27:06.360686 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:27:06.360980 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:27:06.365949 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:27:06.713820 (MainThread): 13:27:06 | Concurrency: 1 threads (target='prod')
2021-03-09 18:27:06.714044 (MainThread): 13:27:06 | 
2021-03-09 18:27:06.716342 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:27:06.717699 (Thread-1): 13:27:06 | 1 of 3 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:27:06.718074 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:27:06.718225 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:27:06.727697 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52087), raddr=('172.217.11.10', 443)>
2021-03-09 18:27:06.727875 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52089), raddr=('172.217.11.10', 443)>
2021-03-09 18:27:06.728023 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52088), raddr=('172.217.9.234', 443)>
2021-03-09 18:27:06.728150 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52090), raddr=('172.217.9.234', 443)>
2021-03-09 18:27:06.738545 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:27:06.738868 (Thread-1): finished collecting timing info
2021-03-09 18:27:06.779561 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:27:06.779984 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:27:06.783900 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:27:07.908255 (Thread-1): finished collecting timing info
2021-03-09 18:27:07.909137 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f578ba72-142b-4231-8661-f791a9b8d397', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11432bd60>]}
2021-03-09 18:27:07.910869 (Thread-1): 13:27:07 | 1 of 3 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 1.19s]
2021-03-09 18:27:07.911081 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:27:07.911339 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:27:07.912591 (Thread-1): 13:27:07 | 2 of 3 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:27:07.913201 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:27:07.913348 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:27:07.923165 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:27:07.923599 (Thread-1): finished collecting timing info
2021-03-09 18:27:07.929225 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:27:07.929665 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:27:07.934693 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:27:08.928483 (Thread-1): finished collecting timing info
2021-03-09 18:27:08.929270 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f578ba72-142b-4231-8661-f791a9b8d397', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1144a3d00>]}
2021-03-09 18:27:08.930537 (Thread-1): 13:27:08 | 2 of 3 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.02s]
2021-03-09 18:27:08.930704 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:27:08.931306 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:27:08.932597 (Thread-1): 13:27:08 | 3 of 3 START view model dbt_demo_production.mrt_twitter_metrics...... [RUN]
2021-03-09 18:27:08.932975 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:27:08.933111 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:27:08.935172 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52093), raddr=('172.217.11.10', 443)>
2021-03-09 18:27:08.935358 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52094), raddr=('172.217.9.234', 443)>
2021-03-09 18:27:08.943484 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:27:08.943808 (Thread-1): finished collecting timing info
2021-03-09 18:27:08.948529 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:27:08.948836 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:27:08.952860 (Thread-1): On model.hashpath_demo.mrt_twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
  OPTIONS()
  as SELECT
pu.id
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu
LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-09 18:27:09.863022 (Thread-1): finished collecting timing info
2021-03-09 18:27:09.863818 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f578ba72-142b-4231-8661-f791a9b8d397', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142d7fd0>]}
2021-03-09 18:27:09.865325 (Thread-1): 13:27:09 | 3 of 3 OK created view model dbt_demo_production.mrt_twitter_metrics. [OK in 0.93s]
2021-03-09 18:27:09.865524 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:27:09.866811 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:27:09.867182 (MainThread): 13:27:09 | 
2021-03-09 18:27:09.867330 (MainThread): 13:27:09 | Finished running 3 view models in 3.89s.
2021-03-09 18:27:09.867462 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:27:09.867571 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:27:09.884752 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52095), raddr=('172.217.11.10', 443)>
2021-03-09 18:27:09.884972 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52096), raddr=('172.217.9.234', 443)>
2021-03-09 18:27:09.910148 (MainThread): 
2021-03-09 18:27:09.910330 (MainThread): Completed successfully
2021-03-09 18:27:09.910452 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-03-09 18:27:09.910643 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114277f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e99a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142f10d0>]}
2021-03-09 18:27:09.910841 (MainThread): Flushing usage events
2021-03-09 18:31:19.778058 (MainThread): Running with dbt=0.19.0
2021-03-09 18:31:20.240273 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:31:20.241347 (MainThread): Tracking: tracking
2021-03-09 18:31:20.252010 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a58fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a61250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a61130>]}
2021-03-09 18:31:20.280058 (MainThread): Partial parsing not enabled
2021-03-09 18:31:20.281368 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:31:20.303363 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:31:20.309812 (MainThread): Parsing macros/etc.sql
2021-03-09 18:31:20.312041 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:31:20.316960 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:31:20.331280 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:31:20.334191 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:31:20.336099 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:31:20.346590 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:31:20.350553 (MainThread): Parsing macros/core.sql
2021-03-09 18:31:20.354610 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:31:20.403706 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:31:20.415326 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:31:20.416501 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:31:20.418416 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:31:20.420729 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:31:20.422621 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:31:20.423817 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:31:20.433432 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:31:20.450731 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:31:20.453148 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:31:20.460709 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:31:20.485315 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:31:20.519595 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:31:20.521411 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:31:20.543317 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:31:20.550668 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:31:20.556206 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:31:20.562836 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:31:20.565717 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:31:20.567537 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:31:20.570527 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:31:20.578282 (MainThread): Partial parsing not enabled
2021-03-09 18:31:20.627248 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:31:20.650729 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:31:20.661394 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:31:20.879121 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:31:20.879441 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:31:20.879580 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:31:20.929859 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:31:20.933590 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e506972a-aca0-45ba-b89e-4bef36be92c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d4e3a0>]}
2021-03-09 18:31:20.978243 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:31:20.979109 (MainThread): 
2021-03-09 18:31:20.979442 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:31:20.983741 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:31:20.983918 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:31:21.391204 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:31:21.391461 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:31:21.396426 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:31:21.778519 (MainThread): 13:31:21 | Concurrency: 1 threads (target='prod')
2021-03-09 18:31:21.778721 (MainThread): 13:31:21 | 
2021-03-09 18:31:21.780920 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:31:21.782212 (Thread-1): 13:31:21 | 1 of 3 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:31:21.782546 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:31:21.782684 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:31:21.790705 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52128), raddr=('172.217.10.42', 443)>
2021-03-09 18:31:21.790943 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52130), raddr=('172.217.10.42', 443)>
2021-03-09 18:31:21.791103 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52129), raddr=('172.217.9.234', 443)>
2021-03-09 18:31:21.791231 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52131), raddr=('172.217.9.234', 443)>
2021-03-09 18:31:21.801929 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:31:21.802242 (Thread-1): finished collecting timing info
2021-03-09 18:31:21.839111 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:31:21.839691 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:31:21.844328 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:31:23.105973 (Thread-1): finished collecting timing info
2021-03-09 18:31:23.106756 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e506972a-aca0-45ba-b89e-4bef36be92c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c1b370>]}
2021-03-09 18:31:23.108735 (Thread-1): 13:31:23 | 1 of 3 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 1.32s]
2021-03-09 18:31:23.108936 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:31:23.109122 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:31:23.110331 (Thread-1): 13:31:23 | 2 of 3 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:31:23.110743 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:31:23.110899 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:31:23.119810 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:31:23.120155 (Thread-1): finished collecting timing info
2021-03-09 18:31:23.124718 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:31:23.125009 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:31:23.128834 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:31:23.978567 (Thread-1): finished collecting timing info
2021-03-09 18:31:23.980075 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e506972a-aca0-45ba-b89e-4bef36be92c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cb2880>]}
2021-03-09 18:31:23.983003 (Thread-1): 13:31:23 | 2 of 3 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 0.87s]
2021-03-09 18:31:23.983457 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:31:23.984213 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:31:23.985531 (Thread-1): 13:31:23 | 3 of 3 START view model dbt_demo_production.mrt_twitter_metrics...... [RUN]
2021-03-09 18:31:23.985942 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:31:23.986089 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:31:23.988164 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52135), raddr=('172.217.10.42', 443)>
2021-03-09 18:31:23.988356 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52136), raddr=('172.217.9.234', 443)>
2021-03-09 18:31:23.997477 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:31:23.998313 (Thread-1): finished collecting timing info
2021-03-09 18:31:24.003409 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:31:24.003753 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:31:24.008014 (Thread-1): On model.hashpath_demo.mrt_twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-09 18:31:24.983941 (Thread-1): finished collecting timing info
2021-03-09 18:31:24.984973 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e506972a-aca0-45ba-b89e-4bef36be92c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ce1790>]}
2021-03-09 18:31:24.986640 (Thread-1): 13:31:24 | 3 of 3 OK created view model dbt_demo_production.mrt_twitter_metrics. [OK in 1.00s]
2021-03-09 18:31:24.986851 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:31:24.988154 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:31:24.988546 (MainThread): 13:31:24 | 
2021-03-09 18:31:24.988696 (MainThread): 13:31:24 | Finished running 3 view models in 4.01s.
2021-03-09 18:31:24.988819 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:31:24.988989 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:31:25.006240 (MainThread): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52137), raddr=('172.217.10.42', 443)>
2021-03-09 18:31:25.006485 (MainThread): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52138), raddr=('172.217.9.234', 443)>
2021-03-09 18:31:25.032832 (MainThread): 
2021-03-09 18:31:25.033002 (MainThread): Completed successfully
2021-03-09 18:31:25.033123 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2021-03-09 18:31:25.033361 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ca7220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c9bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c9bd90>]}
2021-03-09 18:31:25.033619 (MainThread): Flushing usage events
2021-03-09 18:31:40.569979 (MainThread): Running with dbt=0.19.0
2021-03-09 18:31:41.072964 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-09 18:31:41.073963 (MainThread): Tracking: tracking
2021-03-09 18:31:41.082510 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b033d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d7ca00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111d7c8e0>]}
2021-03-09 18:31:41.113724 (MainThread): Partial parsing not enabled
2021-03-09 18:31:41.114957 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:31:41.140611 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:31:41.148063 (MainThread): Parsing macros/etc.sql
2021-03-09 18:31:41.151022 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:31:41.156333 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:31:41.172794 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:31:41.176543 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:31:41.178709 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:31:41.191700 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:31:41.196189 (MainThread): Parsing macros/core.sql
2021-03-09 18:31:41.200716 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:31:41.256858 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:31:41.268505 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:31:41.269644 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:31:41.271565 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:31:41.273835 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:31:41.275951 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:31:41.277251 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:31:41.287635 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:31:41.304247 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:31:41.306561 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:31:41.314097 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:31:41.339929 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:31:41.397659 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:31:41.400869 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:31:41.438998 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:31:41.449284 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:31:41.455096 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:31:41.464372 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:31:41.468801 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:31:41.471015 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:31:41.475174 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:31:41.489578 (MainThread): Partial parsing not enabled
2021-03-09 18:31:41.570373 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:31:41.616143 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:31:41.634922 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:31:41.891214 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:31:41.891582 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:31:41.891742 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:31:41.948542 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:31:41.952806 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e9e6480-3a4d-457e-b93f-a9cd0c370497', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112088130>]}
2021-03-09 18:31:42.001589 (MainThread): Found 3 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:31:42.002479 (MainThread): 
2021-03-09 18:31:42.002795 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:31:42.010466 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:31:42.010666 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:31:42.015700 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:31:42.370123 (MainThread): 13:31:42 | Concurrency: 1 threads (target='prod')
2021-03-09 18:31:42.370312 (MainThread): 13:31:42 | 
2021-03-09 18:31:42.372407 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:31:42.372821 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:31:42.373030 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:31:42.388850 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52142), raddr=('172.217.10.42', 443)>
2021-03-09 18:31:42.389056 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52143), raddr=('172.217.9.234', 443)>
2021-03-09 18:31:42.394245 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:31:42.394644 (Thread-1): finished collecting timing info
2021-03-09 18:31:42.394917 (Thread-1): finished collecting timing info
2021-03-09 18:31:42.395371 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:31:42.395518 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:31:42.395840 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:31:42.396096 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:31:42.403766 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:31:42.404088 (Thread-1): finished collecting timing info
2021-03-09 18:31:42.404333 (Thread-1): finished collecting timing info
2021-03-09 18:31:42.404729 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:31:42.405393 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:31:42.405855 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:31:42.406050 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:31:42.418148 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:31:42.418662 (Thread-1): finished collecting timing info
2021-03-09 18:31:42.419113 (Thread-1): finished collecting timing info
2021-03-09 18:31:42.419820 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:31:42.420764 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:31:42.420879 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:31:42.465278 (MainThread): 13:31:42 | Done.
2021-03-09 18:31:42.471340 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-09 18:31:42.471511 (MainThread): 13:31:42 | Building catalog
2021-03-09 18:31:42.489647 (MainThread): Opening a new connection, currently in state init
2021-03-09 18:31:42.993250 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:31:43.021151 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-09 18:31:43.026102 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_demo_production`.__TABLES__
        where (upper(dataset_id) = upper('dbt_demo_production'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:31:46.407124 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:31:46.409237 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:31:46.413326 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`twitter`.__TABLES__
        where (upper(dataset_id) = upper('twitter'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:31:50.299066 (MainThread): 13:31:50 | Catalog written to /Users/sethrosen/Documents/GitHub/dbt_topcoat_demo/target/catalog.json
2021-03-09 18:31:50.299507 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b033d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120040d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121a9160>]}
2021-03-09 18:31:50.299701 (MainThread): Flushing usage events
2021-03-09 18:31:50.501879 (MainThread): Connection 'generate_catalog' was properly closed.
2021-03-09 18:31:50.502068 (MainThread): Connection 'hashpath-demo-data.information_schema' was properly closed.
2021-03-09 18:37:44.412960 (MainThread): Running with dbt=0.19.0
2021-03-09 18:37:44.946946 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:37:44.948177 (MainThread): Tracking: tracking
2021-03-09 18:37:44.957699 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b424640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4322e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4321c0>]}
2021-03-09 18:37:44.985097 (MainThread): Partial parsing not enabled
2021-03-09 18:37:44.986333 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:37:45.009729 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:37:45.016377 (MainThread): Parsing macros/etc.sql
2021-03-09 18:37:45.018616 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:37:45.023797 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:37:45.038276 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:37:45.042213 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:37:45.044242 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:37:45.055761 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:37:45.060027 (MainThread): Parsing macros/core.sql
2021-03-09 18:37:45.064189 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:37:45.111241 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:37:45.120661 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:37:45.121881 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:37:45.123617 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:37:45.125654 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:37:45.127292 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:37:45.128507 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:37:45.138273 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:37:45.153099 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:37:45.155394 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:37:45.162080 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:37:45.184947 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:37:45.224413 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:37:45.226395 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:37:45.246100 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:37:45.253678 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:37:45.259229 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:37:45.265937 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:37:45.268952 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:37:45.270489 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:37:45.272894 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:37:45.280639 (MainThread): Partial parsing not enabled
2021-03-09 18:37:45.326231 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:37:45.346902 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:37:45.358468 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:37:45.369236 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:37:45.586741 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:37:45.587087 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:37:45.587312 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:37:45.643401 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:37:45.648911 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6073f17e-37e5-4c08-b465-a26d5b59f4f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b729c70>]}
2021-03-09 18:37:45.694906 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:37:45.696264 (MainThread): 
2021-03-09 18:37:45.696994 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:37:45.703621 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:37:45.704016 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:37:46.244046 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:37:46.244230 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:37:46.248425 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:37:46.705643 (MainThread): 13:37:46 | Concurrency: 1 threads (target='prod')
2021-03-09 18:37:46.705856 (MainThread): 13:37:46 | 
2021-03-09 18:37:46.707281 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52203), raddr=('172.217.165.138', 443)>
2021-03-09 18:37:46.707505 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52204), raddr=('172.217.9.234', 443)>
2021-03-09 18:37:46.708891 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:37:46.710210 (Thread-1): 13:37:46 | 1 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:37:46.710565 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:37:46.710703 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:37:46.730487 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:37:46.730833 (Thread-1): finished collecting timing info
2021-03-09 18:37:46.771858 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:37:46.772288 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:37:46.776357 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  SPLIT(text,' ') as words,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:37:48.130644 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/2618de37-c9ed-46bf-9a2c-060d808070c4?maxResults=0&location=US&prettyPrint=false: ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]')
2021-03-09 18:37:48.945028 (Thread-1): finished collecting timing info
2021-03-09 18:37:48.945782 (Thread-1): Database Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
  ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]
  compiled SQL at target/run/hashpath_demo/models/twitter/stg_unique_private_metrics.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/962b315c-4d0e-41b1-b2ca-c149384c99f1?maxResults=0&location=US&prettyPrint=false: ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]

(job ID: 962b315c-4d0e-41b1-b2ca-c149384c99f1)

                                                                 -----Query Job SQL Follows-----                                                                 

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
   5:  OPTIONS()
   6:  as with unique_tweets as 
   7:  (SELECT * FROM (SELECT
   8:  created_at as created_at,
   9:  id,
  10:  text, 
  11:  non_public_metrics_user_profile_clicks, 
  12:  organic_metrics_impression_count,
  13:  url,
  14:  SPLIT(text,' ') as words,
  15:  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  16:  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  17:  WHERE rank = 1
  18:  )
  19:SELECT
  20:  id,
  21:  text,
  22:  words,
  23:  non_public_metrics_user_profile_clicks, 
  24:  organic_metrics_impression_count,
  25:  created_at,
  26:  url
  27:FROM unique_tweets
  28:ORDER BY 3 DESC;
  29:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
  ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]
  compiled SQL at target/run/hashpath_demo/models/twitter/stg_unique_private_metrics.sql
2021-03-09 18:37:48.976011 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6073f17e-37e5-4c08-b465-a26d5b59f4f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c867220>]}
2021-03-09 18:37:48.977797 (Thread-1): 13:37:48 | 1 of 4 ERROR creating view model dbt_demo_production.stg_unique_private_metrics [ERROR in 2.27s]
2021-03-09 18:37:48.977998 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:37:48.978213 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:37:48.979537 (Thread-1): 13:37:48 | 2 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:37:48.980204 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:37:48.980346 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:37:48.980891 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52207), raddr=('172.217.165.138', 443)>
2021-03-09 18:37:48.981069 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52208), raddr=('172.217.9.234', 443)>
2021-03-09 18:37:48.989478 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:37:48.989819 (Thread-1): finished collecting timing info
2021-03-09 18:37:48.994397 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:37:48.994704 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:37:48.998487 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:37:50.107289 (Thread-1): finished collecting timing info
2021-03-09 18:37:50.108096 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6073f17e-37e5-4c08-b465-a26d5b59f4f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c841070>]}
2021-03-09 18:37:50.109196 (Thread-1): 13:37:50 | 2 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.13s]
2021-03-09 18:37:50.109333 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:37:50.109470 (Thread-1): Began running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:37:50.109603 (Thread-1): 13:37:50 | 3 of 4 SKIP relation dbt_demo_production.mrt_tweet_words............. [SKIP]
2021-03-09 18:37:50.109721 (Thread-1): Finished running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:37:50.110265 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:37:50.110403 (Thread-1): 13:37:50 | 4 of 4 SKIP relation dbt_demo_production.mrt_twitter_metrics......... [SKIP]
2021-03-09 18:37:50.110521 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:37:50.111456 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:37:50.111749 (MainThread): 13:37:50 | 
2021-03-09 18:37:50.111868 (MainThread): 13:37:50 | Finished running 4 view models in 4.42s.
2021-03-09 18:37:50.111971 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:37:50.112047 (MainThread): Connection 'model.hashpath_demo.stg_unique_public_metrics' was properly closed.
2021-03-09 18:37:50.151984 (MainThread): 
2021-03-09 18:37:50.152451 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:37:50.152689 (MainThread): 
2021-03-09 18:37:50.152914 (MainThread): Database Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
2021-03-09 18:37:50.153121 (MainThread):   ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]
2021-03-09 18:37:50.153358 (MainThread):   compiled SQL at target/run/hashpath_demo/models/twitter/stg_unique_private_metrics.sql
2021-03-09 18:37:50.153552 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=2 TOTAL=4
2021-03-09 18:37:50.153883 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4975b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b578820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b72d0d0>]}
2021-03-09 18:37:50.154137 (MainThread): Flushing usage events
2021-03-09 18:38:42.447382 (MainThread): Running with dbt=0.19.0
2021-03-09 18:38:42.907557 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:38:42.908657 (MainThread): Tracking: tracking
2021-03-09 18:38:42.916934 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a18b100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a19c850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a19c730>]}
2021-03-09 18:38:42.943413 (MainThread): Partial parsing not enabled
2021-03-09 18:38:42.944667 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:38:42.970640 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:38:42.978458 (MainThread): Parsing macros/etc.sql
2021-03-09 18:38:42.981615 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:38:42.987555 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:38:43.004113 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:38:43.007790 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:38:43.010153 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:38:43.021707 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:38:43.026248 (MainThread): Parsing macros/core.sql
2021-03-09 18:38:43.030774 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:38:43.078970 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:38:43.088512 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:38:43.089532 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:38:43.091309 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:38:43.093443 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:38:43.095117 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:38:43.096263 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:38:43.105365 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:38:43.120037 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:38:43.121949 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:38:43.128609 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:38:43.156191 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:38:43.196077 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:38:43.198056 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:38:43.218203 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:38:43.226084 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:38:43.231648 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:38:43.238662 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:38:43.241645 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:38:43.243240 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:38:43.245161 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:38:43.253059 (MainThread): Partial parsing not enabled
2021-03-09 18:38:43.305735 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:38:43.328190 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:38:43.342848 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:38:43.353860 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:38:43.567904 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:38:43.568292 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:38:43.568536 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:38:43.623823 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:38:43.628718 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a196d16-b1eb-43eb-94f5-2962c29b14a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3e4370>]}
2021-03-09 18:38:43.673740 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:38:43.674689 (MainThread): 
2021-03-09 18:38:43.675057 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:38:43.682258 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:38:43.682526 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:38:44.054495 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:38:44.054803 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:38:44.059875 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:38:44.436297 (MainThread): 13:38:44 | Concurrency: 1 threads (target='prod')
2021-03-09 18:38:44.436512 (MainThread): 13:38:44 | 
2021-03-09 18:38:44.437908 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52221), raddr=('172.217.165.138', 443)>
2021-03-09 18:38:44.438122 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52222), raddr=('172.217.9.234', 443)>
2021-03-09 18:38:44.439533 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:38:44.440811 (Thread-1): 13:38:44 | 1 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:38:44.441181 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:38:44.441329 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:38:44.462383 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:38:44.462855 (Thread-1): finished collecting timing info
2021-03-09 18:38:44.504116 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:38:44.504541 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:38:44.508571 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  SPLIT(text,' ') as words,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:38:45.445224 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/60f422f9-e60a-4edd-8f1a-e5a36fde5ca6?maxResults=0&location=US&prettyPrint=false: ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]')
2021-03-09 18:38:47.012018 (Thread-1): finished collecting timing info
2021-03-09 18:38:47.012873 (Thread-1): Database Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
  ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]
  compiled SQL at target/run/hashpath_demo/models/twitter/stg_unique_private_metrics.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/0034286e-31c0-432c-bfe2-5e514389cffd?maxResults=0&location=US&prettyPrint=false: ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]

(job ID: 0034286e-31c0-432c-bfe2-5e514389cffd)

                                                                 -----Query Job SQL Follows-----                                                                 

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
   5:  OPTIONS()
   6:  as with unique_tweets as 
   7:  (SELECT * FROM (SELECT
   8:  created_at as created_at,
   9:  id,
  10:  text, 
  11:  non_public_metrics_user_profile_clicks, 
  12:  organic_metrics_impression_count,
  13:  url,
  14:  SPLIT(text,' ') as words,
  15:  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  16:  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  17:  WHERE rank = 1
  18:  )
  19:SELECT
  20:  id,
  21:  text,
  22:  words,
  23:  non_public_metrics_user_profile_clicks, 
  24:  organic_metrics_impression_count,
  25:  created_at,
  26:  url
  27:FROM unique_tweets
  28:ORDER BY 3 DESC;
  29:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
  ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]
  compiled SQL at target/run/hashpath_demo/models/twitter/stg_unique_private_metrics.sql
2021-03-09 18:38:47.018062 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a196d16-b1eb-43eb-94f5-2962c29b14a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5a0b80>]}
2021-03-09 18:38:47.019466 (Thread-1): 13:38:47 | 1 of 4 ERROR creating view model dbt_demo_production.stg_unique_private_metrics [ERROR in 2.58s]
2021-03-09 18:38:47.019638 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:38:47.019810 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:38:47.020988 (Thread-1): 13:38:47 | 2 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:38:47.021388 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:38:47.021538 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:38:47.022097 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52225), raddr=('172.217.165.138', 443)>
2021-03-09 18:38:47.022574 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52226), raddr=('172.217.9.234', 443)>
2021-03-09 18:38:47.032036 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:38:47.032415 (Thread-1): finished collecting timing info
2021-03-09 18:38:47.038012 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:38:47.038459 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:38:47.043220 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets
ORDER BY 3 DESC;


2021-03-09 18:38:48.288945 (Thread-1): finished collecting timing info
2021-03-09 18:38:48.289681 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a196d16-b1eb-43eb-94f5-2962c29b14a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5a0160>]}
2021-03-09 18:38:48.290792 (Thread-1): 13:38:48 | 2 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.27s]
2021-03-09 18:38:48.290942 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:38:48.291090 (Thread-1): Began running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:38:48.291232 (Thread-1): 13:38:48 | 3 of 4 SKIP relation dbt_demo_production.mrt_tweet_words............. [SKIP]
2021-03-09 18:38:48.291481 (Thread-1): Finished running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:38:48.291935 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:38:48.292180 (Thread-1): 13:38:48 | 4 of 4 SKIP relation dbt_demo_production.mrt_twitter_metrics......... [SKIP]
2021-03-09 18:38:48.292427 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:38:48.293574 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:38:48.293901 (MainThread): 13:38:48 | 
2021-03-09 18:38:48.294030 (MainThread): 13:38:48 | Finished running 4 view models in 4.62s.
2021-03-09 18:38:48.294141 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:38:48.294222 (MainThread): Connection 'model.hashpath_demo.stg_unique_public_metrics' was properly closed.
2021-03-09 18:38:48.337990 (MainThread): 
2021-03-09 18:38:48.338162 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:38:48.338272 (MainThread): 
2021-03-09 18:38:48.338405 (MainThread): Database Error in model stg_unique_private_metrics (models/twitter/stg_unique_private_metrics.sql)
2021-03-09 18:38:48.338543 (MainThread):   ORDER BY does not support expressions of type ARRAY<STRING> at [28:10]
2021-03-09 18:38:48.338675 (MainThread):   compiled SQL at target/run/hashpath_demo/models/twitter/stg_unique_private_metrics.sql
2021-03-09 18:38:48.338893 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=2 TOTAL=4
2021-03-09 18:38:48.339256 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2e2400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5a01c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a36feb0>]}
2021-03-09 18:38:48.339454 (MainThread): Flushing usage events
2021-03-09 18:39:08.244414 (MainThread): Running with dbt=0.19.0
2021-03-09 18:39:08.694839 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:39:08.696087 (MainThread): Tracking: tracking
2021-03-09 18:39:08.704356 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb66520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dde69d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dde68b0>]}
2021-03-09 18:39:08.731233 (MainThread): Partial parsing not enabled
2021-03-09 18:39:08.732440 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:39:08.754785 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:39:08.761417 (MainThread): Parsing macros/etc.sql
2021-03-09 18:39:08.763669 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:39:08.768599 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:39:08.783886 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:39:08.786852 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:39:08.788838 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:39:08.800798 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:39:08.805618 (MainThread): Parsing macros/core.sql
2021-03-09 18:39:08.810429 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:39:08.863326 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:39:08.873059 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:39:08.874084 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:39:08.875951 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:39:08.878243 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:39:08.879983 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:39:08.882383 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:39:08.894718 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:39:08.913259 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:39:08.915697 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:39:08.923169 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:39:08.946500 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:39:08.982485 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:39:08.984489 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:39:09.005725 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:39:09.013123 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:39:09.018509 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:39:09.025264 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:39:09.030369 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:39:09.033043 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:39:09.035860 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:39:09.044547 (MainThread): Partial parsing not enabled
2021-03-09 18:39:09.090088 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:39:09.111451 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:39:09.122726 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:39:09.132838 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:39:09.348552 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:39:09.348935 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:39:09.349117 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:39:09.400589 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:39:09.405085 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f3ac1d3-1111-454c-ace6-53cc0e512c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e03b970>]}
2021-03-09 18:39:09.451350 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:39:09.452236 (MainThread): 
2021-03-09 18:39:09.452572 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:39:09.459606 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:39:09.459853 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:39:09.841798 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:39:09.842014 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:39:09.847116 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:39:10.223413 (MainThread): 13:39:10 | Concurrency: 1 threads (target='prod')
2021-03-09 18:39:10.223619 (MainThread): 13:39:10 | 
2021-03-09 18:39:10.224974 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52245), raddr=('172.217.165.138', 443)>
2021-03-09 18:39:10.225195 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52246), raddr=('172.217.9.234', 443)>
2021-03-09 18:39:10.226693 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:39:10.227972 (Thread-1): 13:39:10 | 1 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:39:10.228341 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:39:10.228490 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:39:10.247584 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:39:10.247906 (Thread-1): finished collecting timing info
2021-03-09 18:39:10.285991 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:39:10.286399 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:39:10.290241 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  SPLIT(text,' ') as words,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:39:11.291420 (Thread-1): finished collecting timing info
2021-03-09 18:39:11.292243 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f3ac1d3-1111-454c-ace6-53cc0e512c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e02e580>]}
2021-03-09 18:39:11.293754 (Thread-1): 13:39:11 | 1 of 4 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 1.06s]
2021-03-09 18:39:11.293928 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:39:11.294207 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:39:11.295727 (Thread-1): 13:39:11 | 2 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:39:11.296094 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:39:11.296234 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:39:11.305379 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:39:11.305757 (Thread-1): finished collecting timing info
2021-03-09 18:39:11.310907 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:39:11.311289 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:39:11.315787 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:39:12.367455 (Thread-1): finished collecting timing info
2021-03-09 18:39:12.368254 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f3ac1d3-1111-454c-ace6-53cc0e512c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1c7f70>]}
2021-03-09 18:39:12.369525 (Thread-1): 13:39:12 | 2 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.07s]
2021-03-09 18:39:12.369709 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:39:12.369888 (Thread-1): Began running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:39:12.371065 (Thread-1): 13:39:12 | 3 of 4 START view model dbt_demo_production.mrt_tweet_words.......... [RUN]
2021-03-09 18:39:12.371463 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:39:12.371623 (Thread-1): Compiling model.hashpath_demo.mrt_tweet_words
2021-03-09 18:39:12.373582 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52251), raddr=('172.217.165.138', 443)>
2021-03-09 18:39:12.374026 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52252), raddr=('172.217.9.234', 443)>
2021-03-09 18:39:12.381031 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:39:12.387503 (Thread-1): finished collecting timing info
2021-03-09 18:39:12.394053 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:39:12.394933 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:39:12.399817 (Thread-1): On model.hashpath_demo.mrt_tweet_words: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_tweet_words"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_tweet_words`
  OPTIONS()
  as SELECT
  w,
  count(*)
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` r, UNNEST(r.words) as w
WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
GROUP BY w;


2021-03-09 18:39:13.186121 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/76ff3551-e3bb-4420-88f7-a041ffde804d?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 2 has no name at [6:6]')
2021-03-09 18:39:14.600664 (Thread-1): finished collecting timing info
2021-03-09 18:39:14.601539 (Thread-1): Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
  CREATE VIEW columns must be named, but column 2 has no name at [6:6]
  compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/d5197bae-774f-44da-8f0e-c4d004ae8eb0?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 2 has no name at [6:6]

(job ID: d5197bae-774f-44da-8f0e-c4d004ae8eb0)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_tweet_words"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_tweet_words`
   5:  OPTIONS()
   6:  as SELECT
   7:  w,
   8:  count(*)
   9:FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` r, UNNEST(r.words) as w
  10:WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
  11:GROUP BY w;
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
  CREATE VIEW columns must be named, but column 2 has no name at [6:6]
  compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
2021-03-09 18:39:14.606949 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f3ac1d3-1111-454c-ace6-53cc0e512c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f271760>]}
2021-03-09 18:39:14.608281 (Thread-1): 13:39:14 | 3 of 4 ERROR creating view model dbt_demo_production.mrt_tweet_words. [ERROR in 2.24s]
2021-03-09 18:39:14.608442 (Thread-1): Finished running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:39:14.608614 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:39:14.609734 (Thread-1): 13:39:14 | 4 of 4 START view model dbt_demo_production.mrt_twitter_metrics...... [RUN]
2021-03-09 18:39:14.610120 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:39:14.610265 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:39:14.612332 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52253), raddr=('172.217.165.138', 443)>
2021-03-09 18:39:14.612638 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52254), raddr=('172.217.9.234', 443)>
2021-03-09 18:39:14.619822 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52250), raddr=('172.217.9.234', 443)>
2021-03-09 18:39:14.620046 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52249), raddr=('172.217.165.138', 443)>
2021-03-09 18:39:14.627094 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:39:14.627438 (Thread-1): finished collecting timing info
2021-03-09 18:39:14.631958 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:39:14.632257 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:39:14.638467 (Thread-1): On model.hashpath_demo.mrt_twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-09 18:39:15.477991 (Thread-1): finished collecting timing info
2021-03-09 18:39:15.478800 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f3ac1d3-1111-454c-ace6-53cc0e512c19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f27ea60>]}
2021-03-09 18:39:15.480069 (Thread-1): 13:39:15 | 4 of 4 OK created view model dbt_demo_production.mrt_twitter_metrics. [OK in 0.87s]
2021-03-09 18:39:15.480236 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:39:15.481620 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:39:15.482011 (MainThread): 13:39:15 | 
2021-03-09 18:39:15.482164 (MainThread): 13:39:15 | Finished running 4 view models in 6.03s.
2021-03-09 18:39:15.482296 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:39:15.482406 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:39:15.526578 (MainThread): 
2021-03-09 18:39:15.526772 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:39:15.526914 (MainThread): 
2021-03-09 18:39:15.527174 (MainThread): Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
2021-03-09 18:39:15.527423 (MainThread):   CREATE VIEW columns must be named, but column 2 has no name at [6:6]
2021-03-09 18:39:15.527613 (MainThread):   compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
2021-03-09 18:39:15.527744 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-03-09 18:39:15.528014 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e00ef40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1c7ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df02160>]}
2021-03-09 18:39:15.528382 (MainThread): Flushing usage events
2021-03-09 18:40:11.792097 (MainThread): Running with dbt=0.19.0
2021-03-09 18:40:12.245241 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:40:12.246310 (MainThread): Tracking: tracking
2021-03-09 18:40:12.254630 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b2bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b3d520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b3d400>]}
2021-03-09 18:40:12.281065 (MainThread): Partial parsing not enabled
2021-03-09 18:40:12.282265 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:40:12.304477 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:40:12.311417 (MainThread): Parsing macros/etc.sql
2021-03-09 18:40:12.313496 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:40:12.318165 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:40:12.331760 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:40:12.334652 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:40:12.336534 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:40:12.347936 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:40:12.352226 (MainThread): Parsing macros/core.sql
2021-03-09 18:40:12.356787 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:40:12.403548 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:40:12.413476 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:40:12.414545 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:40:12.416231 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:40:12.418322 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:40:12.420097 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:40:12.421311 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:40:12.433236 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:40:12.452232 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:40:12.454482 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:40:12.461452 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:40:12.483196 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:40:12.518961 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:40:12.521149 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:40:12.542486 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:40:12.550771 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:40:12.556521 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:40:12.563344 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:40:12.566956 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:40:12.569709 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:40:12.572859 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:40:12.582226 (MainThread): Partial parsing not enabled
2021-03-09 18:40:12.631858 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:40:12.652145 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:40:12.663190 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:40:12.673447 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:40:12.885411 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:40:12.885936 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:40:12.886299 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:40:12.943612 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:40:12.948101 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '56327be5-26fe-4f83-a584-e06fc1e87b58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e33c70>]}
2021-03-09 18:40:12.990212 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:40:12.991090 (MainThread): 
2021-03-09 18:40:12.991411 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:40:12.996827 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:40:12.997010 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:40:13.361743 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:40:13.361919 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:40:13.366378 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:40:13.716898 (MainThread): 13:40:13 | Concurrency: 1 threads (target='prod')
2021-03-09 18:40:13.717110 (MainThread): 13:40:13 | 
2021-03-09 18:40:13.718554 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52299), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:13.718765 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52300), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:13.720199 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:40:13.721525 (Thread-1): 13:40:13 | 1 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:40:13.721876 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:40:13.722014 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:40:13.740545 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:40:13.740883 (Thread-1): finished collecting timing info
2021-03-09 18:40:13.780491 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:40:13.780916 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:40:13.784774 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  SPLIT(text,' ') as words,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:40:15.130903 (Thread-1): finished collecting timing info
2021-03-09 18:40:15.131592 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56327be5-26fe-4f83-a584-e06fc1e87b58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106da2700>]}
2021-03-09 18:40:15.132837 (Thread-1): 13:40:15 | 1 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.41s]
2021-03-09 18:40:15.132978 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:40:15.133118 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:40:15.134073 (Thread-1): 13:40:15 | 2 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:40:15.134339 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:40:15.134449 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:40:15.142316 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:40:15.142635 (Thread-1): finished collecting timing info
2021-03-09 18:40:15.147829 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:40:15.148191 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:40:15.152271 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:40:15.995261 (Thread-1): finished collecting timing info
2021-03-09 18:40:15.996155 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56327be5-26fe-4f83-a584-e06fc1e87b58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f21c40>]}
2021-03-09 18:40:15.997689 (Thread-1): 13:40:15 | 2 of 4 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.86s]
2021-03-09 18:40:15.997938 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:40:15.998148 (Thread-1): Began running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:40:15.999388 (Thread-1): 13:40:15 | 3 of 4 START view model dbt_demo_production.mrt_tweet_words.......... [RUN]
2021-03-09 18:40:15.999765 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:40:15.999901 (Thread-1): Compiling model.hashpath_demo.mrt_tweet_words
2021-03-09 18:40:16.002046 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52305), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:16.002240 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52306), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:16.009639 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:40:16.009997 (Thread-1): finished collecting timing info
2021-03-09 18:40:16.015098 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:40:16.015433 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:40:16.019733 (Thread-1): On model.hashpath_demo.mrt_tweet_words: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_tweet_words"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_tweet_words`
  OPTIONS()
  as SELECT
  w,
  count(*)
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
GROUP BY w;


2021-03-09 18:40:16.837853 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/1211b505-1fcf-4642-bcb5-34527d75e318?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 2 has no name at [6:6]')
2021-03-09 18:40:18.440492 (Thread-1): finished collecting timing info
2021-03-09 18:40:18.441331 (Thread-1): Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
  CREATE VIEW columns must be named, but column 2 has no name at [6:6]
  compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/fc8c9b02-54c1-4609-8c2f-ea67f5922395?maxResults=0&location=US&prettyPrint=false: CREATE VIEW columns must be named, but column 2 has no name at [6:6]

(job ID: fc8c9b02-54c1-4609-8c2f-ea67f5922395)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_tweet_words"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_tweet_words`
   5:  OPTIONS()
   6:  as SELECT
   7:  w,
   8:  count(*)
   9:FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
  10:WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
  11:GROUP BY w;
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
  CREATE VIEW columns must be named, but column 2 has no name at [6:6]
  compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
2021-03-09 18:40:18.446859 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56327be5-26fe-4f83-a584-e06fc1e87b58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fab790>]}
2021-03-09 18:40:18.448173 (Thread-1): 13:40:18 | 3 of 4 ERROR creating view model dbt_demo_production.mrt_tweet_words. [ERROR in 2.45s]
2021-03-09 18:40:18.448333 (Thread-1): Finished running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:40:18.448501 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:40:18.449853 (Thread-1): 13:40:18 | 4 of 4 START view model dbt_demo_production.mrt_twitter_metrics...... [RUN]
2021-03-09 18:40:18.450504 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:40:18.450659 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:40:18.452727 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52307), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:18.452913 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52308), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:18.459993 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52304), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:18.460275 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52303), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:18.467345 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:40:18.467684 (Thread-1): finished collecting timing info
2021-03-09 18:40:18.472263 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:40:18.472584 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:40:18.476471 (Thread-1): On model.hashpath_demo.mrt_twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-09 18:40:19.313555 (Thread-1): finished collecting timing info
2021-03-09 18:40:19.314370 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '56327be5-26fe-4f83-a584-e06fc1e87b58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f7ed30>]}
2021-03-09 18:40:19.315629 (Thread-1): 13:40:19 | 4 of 4 OK created view model dbt_demo_production.mrt_twitter_metrics. [OK in 0.86s]
2021-03-09 18:40:19.315795 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:40:19.316986 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:40:19.317344 (MainThread): 13:40:19 | 
2021-03-09 18:40:19.317497 (MainThread): 13:40:19 | Finished running 4 view models in 6.33s.
2021-03-09 18:40:19.317625 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:40:19.317719 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:40:19.361496 (MainThread): 
2021-03-09 18:40:19.361687 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:40:19.361824 (MainThread): 
2021-03-09 18:40:19.362005 (MainThread): Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
2021-03-09 18:40:19.362214 (MainThread):   CREATE VIEW columns must be named, but column 2 has no name at [6:6]
2021-03-09 18:40:19.362317 (MainThread):   compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
2021-03-09 18:40:19.362537 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-03-09 18:40:19.362855 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f3d280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bb2070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f69cd0>]}
2021-03-09 18:40:19.363037 (MainThread): Flushing usage events
2021-03-09 18:40:32.595555 (MainThread): Running with dbt=0.19.0
2021-03-09 18:40:33.038826 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:40:33.040094 (MainThread): Tracking: tracking
2021-03-09 18:40:33.048479 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091c8550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091e18e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091e17c0>]}
2021-03-09 18:40:33.075069 (MainThread): Partial parsing not enabled
2021-03-09 18:40:33.076268 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:40:33.098399 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:40:33.104851 (MainThread): Parsing macros/etc.sql
2021-03-09 18:40:33.106880 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:40:33.111493 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:40:33.125334 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:40:33.128195 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:40:33.130081 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:40:33.140571 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:40:33.144499 (MainThread): Parsing macros/core.sql
2021-03-09 18:40:33.148761 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:40:33.193874 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:40:33.209500 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:40:33.211129 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:40:33.213563 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:40:33.216277 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:40:33.218270 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:40:33.219491 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:40:33.229722 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:40:33.244916 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:40:33.246919 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:40:33.253982 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:40:33.278987 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:40:33.315564 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:40:33.317501 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:40:33.336814 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:40:33.343846 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:40:33.349086 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:40:33.355438 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:40:33.358351 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:40:33.359887 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:40:33.361867 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:40:33.369394 (MainThread): Partial parsing not enabled
2021-03-09 18:40:33.417293 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:40:33.437623 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:40:33.448703 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:40:33.459065 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:40:33.672233 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:40:33.672504 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:40:33.672641 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:40:33.728610 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:40:33.733661 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7570cd2a-898d-4ac0-9e30-107d3fd93a90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109440580>]}
2021-03-09 18:40:33.779708 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:40:33.781288 (MainThread): 
2021-03-09 18:40:33.781881 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:40:33.788090 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:40:33.788297 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:40:34.151317 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:40:34.151512 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:40:34.156434 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:40:34.514921 (MainThread): 13:40:34 | Concurrency: 1 threads (target='prod')
2021-03-09 18:40:34.515127 (MainThread): 13:40:34 | 
2021-03-09 18:40:34.516508 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52315), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:34.516723 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52316), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:34.518162 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:40:34.519413 (Thread-1): 13:40:34 | 1 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:40:34.519778 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:40:34.519918 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:40:34.540189 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:40:34.540546 (Thread-1): finished collecting timing info
2021-03-09 18:40:34.578941 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:40:34.579356 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:40:34.583388 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  SPLIT(text,' ') as words,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:40:35.568217 (Thread-1): finished collecting timing info
2021-03-09 18:40:35.569253 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7570cd2a-898d-4ac0-9e30-107d3fd93a90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10946c2e0>]}
2021-03-09 18:40:35.571107 (Thread-1): 13:40:35 | 1 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.05s]
2021-03-09 18:40:35.571331 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:40:35.571511 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:40:35.572759 (Thread-1): 13:40:35 | 2 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:40:35.573424 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:40:35.573629 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:40:35.582970 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:40:35.583384 (Thread-1): finished collecting timing info
2021-03-09 18:40:35.588657 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:40:35.589069 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:40:35.593457 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:40:36.506529 (Thread-1): finished collecting timing info
2021-03-09 18:40:36.507367 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7570cd2a-898d-4ac0-9e30-107d3fd93a90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10959eca0>]}
2021-03-09 18:40:36.508680 (Thread-1): 13:40:36 | 2 of 4 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.93s]
2021-03-09 18:40:36.508850 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:40:36.509018 (Thread-1): Began running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:40:36.510173 (Thread-1): 13:40:36 | 3 of 4 START view model dbt_demo_production.mrt_tweet_words.......... [RUN]
2021-03-09 18:40:36.510550 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:40:36.510698 (Thread-1): Compiling model.hashpath_demo.mrt_tweet_words
2021-03-09 18:40:36.512619 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52321), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:36.512972 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52322), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:36.520632 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:40:36.520999 (Thread-1): finished collecting timing info
2021-03-09 18:40:36.526068 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:40:36.526497 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:40:36.532832 (Thread-1): On model.hashpath_demo.mrt_tweet_words: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_tweet_words"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_tweet_words`
  OPTIONS()
  as SELECT
  w,
  count(*) as total
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
GROUP BY w;


2021-03-09 18:40:37.398836 (Thread-1): finished collecting timing info
2021-03-09 18:40:37.399660 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7570cd2a-898d-4ac0-9e30-107d3fd93a90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a606df0>]}
2021-03-09 18:40:37.400990 (Thread-1): 13:40:37 | 3 of 4 OK created view model dbt_demo_production.mrt_tweet_words..... [OK in 0.89s]
2021-03-09 18:40:37.401164 (Thread-1): Finished running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:40:37.401341 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:40:37.402557 (Thread-1): 13:40:37 | 4 of 4 START view model dbt_demo_production.mrt_twitter_metrics...... [RUN]
2021-03-09 18:40:37.403017 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:40:37.403172 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:40:37.405859 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52323), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:37.406055 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52324), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:37.413847 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52320), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:37.414077 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52319), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:37.421525 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:40:37.421899 (Thread-1): finished collecting timing info
2021-03-09 18:40:37.426852 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:40:37.427162 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:40:37.431274 (Thread-1): On model.hashpath_demo.mrt_twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-09 18:40:38.216828 (Thread-1): finished collecting timing info
2021-03-09 18:40:38.217687 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7570cd2a-898d-4ac0-9e30-107d3fd93a90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10959eca0>]}
2021-03-09 18:40:38.219016 (Thread-1): 13:40:38 | 4 of 4 OK created view model dbt_demo_production.mrt_twitter_metrics. [OK in 0.81s]
2021-03-09 18:40:38.219183 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:40:38.220381 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:40:38.220836 (MainThread): 13:40:38 | 
2021-03-09 18:40:38.220995 (MainThread): 13:40:38 | Finished running 4 view models in 4.44s.
2021-03-09 18:40:38.221123 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:40:38.221218 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:40:38.239666 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52325), raddr=('172.217.165.138', 443)>
2021-03-09 18:40:38.239849 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52326), raddr=('172.217.9.234', 443)>
2021-03-09 18:40:38.265647 (MainThread): 
2021-03-09 18:40:38.265810 (MainThread): Completed successfully
2021-03-09 18:40:38.265927 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-03-09 18:40:38.266218 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a669e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109457280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093d71f0>]}
2021-03-09 18:40:38.266393 (MainThread): Flushing usage events
2021-03-09 18:41:32.191255 (MainThread): Running with dbt=0.19.0
2021-03-09 18:41:32.653012 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:41:32.654106 (MainThread): Tracking: tracking
2021-03-09 18:41:32.662611 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124ed580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113763af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137639d0>]}
2021-03-09 18:41:32.689522 (MainThread): Partial parsing not enabled
2021-03-09 18:41:32.690739 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:41:32.712955 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:41:32.719367 (MainThread): Parsing macros/etc.sql
2021-03-09 18:41:32.721419 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:41:32.726142 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:41:32.740236 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:41:32.743165 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:41:32.745141 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:41:32.756350 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:41:32.760568 (MainThread): Parsing macros/core.sql
2021-03-09 18:41:32.765009 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:41:32.814110 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:41:32.823768 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:41:32.824776 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:41:32.826538 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:41:32.828773 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:41:32.830528 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:41:32.831653 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:41:32.841321 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:41:32.855988 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:41:32.857974 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:41:32.865132 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:41:32.888076 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:41:32.927143 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:41:32.929096 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:41:32.947645 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:41:32.954574 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:41:32.959770 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:41:32.966308 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:41:32.969181 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:41:32.970732 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:41:32.972639 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:41:32.980710 (MainThread): Partial parsing not enabled
2021-03-09 18:41:33.032730 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:41:33.054511 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:41:33.066049 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:41:33.076081 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:41:33.291907 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:41:33.292168 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:41:33.292325 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:41:33.349628 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:41:33.355111 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a9d3fd5-b332-4aba-8f1a-4a5acf7c0c0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139c3fd0>]}
2021-03-09 18:41:33.401973 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:41:33.403019 (MainThread): 
2021-03-09 18:41:33.403433 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:41:33.409280 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:41:33.409488 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:41:33.805275 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:41:33.805583 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:41:33.810922 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:41:34.191167 (MainThread): 13:41:34 | Concurrency: 1 threads (target='prod')
2021-03-09 18:41:34.191370 (MainThread): 13:41:34 | 
2021-03-09 18:41:34.192647 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52337), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:34.192846 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52338), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:34.194288 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:41:34.195539 (Thread-1): 13:41:34 | 1 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:41:34.195902 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:41:34.196046 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:41:34.214762 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:41:34.215098 (Thread-1): finished collecting timing info
2021-03-09 18:41:34.251885 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:41:34.252399 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:41:34.257079 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  SPLIT(text,' ') as words,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:41:35.406403 (Thread-1): finished collecting timing info
2021-03-09 18:41:35.407231 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a9d3fd5-b332-4aba-8f1a-4a5acf7c0c0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a79100>]}
2021-03-09 18:41:35.408780 (Thread-1): 13:41:35 | 1 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.21s]
2021-03-09 18:41:35.408954 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:41:35.409120 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:41:35.410326 (Thread-1): 13:41:35 | 2 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:41:35.410879 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:41:35.411072 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:41:35.420259 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:41:35.420625 (Thread-1): finished collecting timing info
2021-03-09 18:41:35.425116 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:41:35.425477 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:41:35.429846 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:41:36.397481 (Thread-1): finished collecting timing info
2021-03-09 18:41:36.398333 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a9d3fd5-b332-4aba-8f1a-4a5acf7c0c0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139c5400>]}
2021-03-09 18:41:36.399611 (Thread-1): 13:41:36 | 2 of 4 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.99s]
2021-03-09 18:41:36.399789 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:41:36.399953 (Thread-1): Began running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:41:36.401067 (Thread-1): 13:41:36 | 3 of 4 START view model dbt_demo_production.mrt_tweet_words.......... [RUN]
2021-03-09 18:41:36.401401 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:41:36.401536 (Thread-1): Compiling model.hashpath_demo.mrt_tweet_words
2021-03-09 18:41:36.403383 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52343), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:36.403854 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52344), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:36.410606 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:41:36.410922 (Thread-1): finished collecting timing info
2021-03-09 18:41:36.415894 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:41:36.416342 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:41:36.420573 (Thread-1): On model.hashpath_demo.mrt_tweet_words: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_tweet_words"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_tweet_words`
  OPTIONS()
  as SELECT
  w,
  created_date,
  count(*) as total
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
GROUP BY 1,2;


2021-03-09 18:41:37.256292 (Thread-1): Retry attempt 1 of 1 after error: BadRequest('GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/d8e83dc7-8fbb-49c0-99e8-4ebfbb8bbf92?maxResults=0&location=US&prettyPrint=false: Unrecognized name: created_date; Did you mean created_at? at [8:3]')
2021-03-09 18:41:38.007549 (Thread-1): finished collecting timing info
2021-03-09 18:41:38.008444 (Thread-1): Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
  Unrecognized name: created_date; Did you mean created_at? at [8:3]
  compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 149, in exception_handler
    yield
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 327, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 520, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1146, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/base.py", line 631, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 129, in result
    self._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1042, in _blocking_poll
    super(QueryJob, self)._blocking_poll(timeout=timeout, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 107, in _blocking_poll
    retry_(self._done_or_raise)(**kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/future/polling.py", line 85, in _done_or_raise
    if not self.done(**kwargs):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py", line 1022, in done
    self._query_results = self._client._get_query_results(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 1557, in _get_query_results
    resource = self._call_api(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/bigquery/client.py", line 636, in _call_api
    return call()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 281, in retry_wrapped_func
    return retry_target(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/google/cloud/_http.py", line 438, in api_request
    raise exceptions.from_http_response(response)
google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/hashpath-demo-data/queries/aca6c3a2-0299-499a-bab5-0ffdee5eb3f9?maxResults=0&location=US&prettyPrint=false: Unrecognized name: created_date; Did you mean created_at? at [8:3]

(job ID: aca6c3a2-0299-499a-bab5-0ffdee5eb3f9)

                                                           -----Query Job SQL Follows-----                                                            

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_tweet_words"} */
   2:
   3:
   4:  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_tweet_words`
   5:  OPTIONS()
   6:  as SELECT
   7:  w,
   8:  created_date,
   9:  count(*) as total
  10:FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
  11:WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
  12:GROUP BY 1,2;
  13:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 344, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 287, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/base.py", line 389, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/run.py", line 247, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 22, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 65, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 327, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/base/impl.py", line 227, in execute
    return self.connections.execute(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 338, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 329, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 534, in _retry_and_handle
    return retry.retry_target(
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 153, in exception_handler
    self.handle_error(e, message)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/adapters/bigquery/connections.py", line 141, in handle_error
    raise DatabaseException(error_msg)
dbt.exceptions.DatabaseException: Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
  Unrecognized name: created_date; Did you mean created_at? at [8:3]
  compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
2021-03-09 18:41:38.014185 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a9d3fd5-b332-4aba-8f1a-4a5acf7c0c0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113be0fd0>]}
2021-03-09 18:41:38.015683 (Thread-1): 13:41:38 | 3 of 4 ERROR creating view model dbt_demo_production.mrt_tweet_words. [ERROR in 1.61s]
2021-03-09 18:41:38.015878 (Thread-1): Finished running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:41:38.016069 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:41:38.017653 (Thread-1): 13:41:38 | 4 of 4 START view model dbt_demo_production.mrt_twitter_metrics...... [RUN]
2021-03-09 18:41:38.018153 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:41:38.018311 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:41:38.020606 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52345), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:38.020944 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52346), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:38.029101 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52342), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:38.029350 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52341), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:38.037770 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:41:38.038125 (Thread-1): finished collecting timing info
2021-03-09 18:41:38.043174 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:41:38.043524 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:41:38.048089 (Thread-1): On model.hashpath_demo.mrt_twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-09 18:41:38.918646 (Thread-1): finished collecting timing info
2021-03-09 18:41:38.919477 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a9d3fd5-b332-4aba-8f1a-4a5acf7c0c0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113be42e0>]}
2021-03-09 18:41:38.920773 (Thread-1): 13:41:38 | 4 of 4 OK created view model dbt_demo_production.mrt_twitter_metrics. [OK in 0.90s]
2021-03-09 18:41:38.920939 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:41:38.922126 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:41:38.922482 (MainThread): 13:41:38 | 
2021-03-09 18:41:38.922635 (MainThread): 13:41:38 | Finished running 4 view models in 5.52s.
2021-03-09 18:41:38.922729 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:41:38.922920 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:41:38.965409 (MainThread): 
2021-03-09 18:41:38.965577 (MainThread): Completed with 1 error and 0 warnings:
2021-03-09 18:41:38.965685 (MainThread): 
2021-03-09 18:41:38.965823 (MainThread): Database Error in model mrt_tweet_words (models/twitter/mrt_tweet_words.sql)
2021-03-09 18:41:38.965950 (MainThread):   Unrecognized name: created_date; Did you mean created_at? at [8:3]
2021-03-09 18:41:38.966144 (MainThread):   compiled SQL at target/run/hashpath_demo/models/twitter/mrt_tweet_words.sql
2021-03-09 18:41:38.966334 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2021-03-09 18:41:38.966594 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11398c670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1138cf040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113baa520>]}
2021-03-09 18:41:38.966770 (MainThread): Flushing usage events
2021-03-09 18:41:48.232680 (MainThread): Running with dbt=0.19.0
2021-03-09 18:41:48.684448 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-09 18:41:48.685959 (MainThread): Tracking: tracking
2021-03-09 18:41:48.694052 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10538c520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053a58e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053a57c0>]}
2021-03-09 18:41:48.721559 (MainThread): Partial parsing not enabled
2021-03-09 18:41:48.722804 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:41:48.746461 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:41:48.753077 (MainThread): Parsing macros/etc.sql
2021-03-09 18:41:48.755365 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:41:48.760277 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:41:48.774482 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:41:48.777240 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:41:48.779085 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:41:48.789952 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:41:48.793786 (MainThread): Parsing macros/core.sql
2021-03-09 18:41:48.798262 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:41:48.842324 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:41:48.851351 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:41:48.852299 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:41:48.853953 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:41:48.856477 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:41:48.858166 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:41:48.859278 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:41:48.868806 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:41:48.885853 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:41:48.889615 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:41:48.898919 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:41:48.922576 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:41:48.961332 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:41:48.963367 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:41:48.985738 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:41:48.993452 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:41:48.999103 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:41:49.005858 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:41:49.008890 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:41:49.010430 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:41:49.012580 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:41:49.022177 (MainThread): Partial parsing not enabled
2021-03-09 18:41:49.066875 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:41:49.086355 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:41:49.097802 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:41:49.108255 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:41:49.325181 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:41:49.325677 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:41:49.325872 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:41:49.380605 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:41:49.385711 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dfb88350-0d62-4a48-bc28-cb8a0179642c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105613430>]}
2021-03-09 18:41:49.429268 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:41:49.430183 (MainThread): 
2021-03-09 18:41:49.430516 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:41:49.436033 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-09 18:41:49.436419 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:41:49.829769 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:41:49.829978 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:41:49.835166 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:41:50.223211 (MainThread): 13:41:50 | Concurrency: 1 threads (target='prod')
2021-03-09 18:41:50.223452 (MainThread): 13:41:50 | 
2021-03-09 18:41:50.224798 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52351), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:50.225002 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52352), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:50.226474 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:41:50.227767 (Thread-1): 13:41:50 | 1 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-09 18:41:50.228130 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:41:50.228282 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:41:50.249684 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:41:50.250043 (Thread-1): finished collecting timing info
2021-03-09 18:41:50.287055 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:41:50.287460 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:41:50.291275 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  SPLIT(text,' ') as words,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:41:51.015810 (Thread-1): finished collecting timing info
2021-03-09 18:41:51.016701 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfb88350-0d62-4a48-bc28-cb8a0179642c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105798fd0>]}
2021-03-09 18:41:51.018192 (Thread-1): 13:41:51 | 1 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 0.79s]
2021-03-09 18:41:51.018355 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:41:51.018510 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:41:51.019564 (Thread-1): 13:41:51 | 2 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-09 18:41:51.019938 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:41:51.020071 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:41:51.028204 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:41:51.028612 (Thread-1): finished collecting timing info
2021-03-09 18:41:51.033126 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:41:51.033420 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:41:51.037279 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets;


2021-03-09 18:41:51.755249 (Thread-1): finished collecting timing info
2021-03-09 18:41:51.756017 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfb88350-0d62-4a48-bc28-cb8a0179642c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105797100>]}
2021-03-09 18:41:51.757227 (Thread-1): 13:41:51 | 2 of 4 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.74s]
2021-03-09 18:41:51.757396 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:41:51.757601 (Thread-1): Began running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:41:51.758781 (Thread-1): 13:41:51 | 3 of 4 START view model dbt_demo_production.mrt_tweet_words.......... [RUN]
2021-03-09 18:41:51.759243 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:41:51.759389 (Thread-1): Compiling model.hashpath_demo.mrt_tweet_words
2021-03-09 18:41:51.761084 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52357), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:51.761354 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52358), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:51.767615 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:41:51.767933 (Thread-1): finished collecting timing info
2021-03-09 18:41:51.772310 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:41:51.772609 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:41:51.776403 (Thread-1): On model.hashpath_demo.mrt_tweet_words: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_tweet_words"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_tweet_words`
  OPTIONS()
  as SELECT
  w,
  created_at,
  count(*) as total
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
GROUP BY 1,2;


2021-03-09 18:41:52.572667 (Thread-1): finished collecting timing info
2021-03-09 18:41:52.573482 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfb88350-0d62-4a48-bc28-cb8a0179642c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106804d90>]}
2021-03-09 18:41:52.574776 (Thread-1): 13:41:52 | 3 of 4 OK created view model dbt_demo_production.mrt_tweet_words..... [OK in 0.81s]
2021-03-09 18:41:52.574949 (Thread-1): Finished running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:41:52.575123 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:41:52.576264 (Thread-1): 13:41:52 | 4 of 4 START view model dbt_demo_production.mrt_twitter_metrics...... [RUN]
2021-03-09 18:41:52.576725 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:41:52.576873 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:41:52.579352 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52359), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:52.579530 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52360), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:52.586537 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52356), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:52.586741 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52355), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:52.594511 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:41:52.594852 (Thread-1): finished collecting timing info
2021-03-09 18:41:52.599436 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:41:52.599728 (Thread-1): Opening a new connection, currently in state closed
2021-03-09 18:41:52.603711 (Thread-1): On model.hashpath_demo.mrt_twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.mrt_twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`mrt_twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-09 18:41:53.476908 (Thread-1): finished collecting timing info
2021-03-09 18:41:53.477760 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dfb88350-0d62-4a48-bc28-cb8a0179642c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106843d00>]}
2021-03-09 18:41:53.479153 (Thread-1): 13:41:53 | 4 of 4 OK created view model dbt_demo_production.mrt_twitter_metrics. [OK in 0.90s]
2021-03-09 18:41:53.479334 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:41:53.480655 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:41:53.481024 (MainThread): 13:41:53 | 
2021-03-09 18:41:53.481174 (MainThread): 13:41:53 | Finished running 4 view models in 4.05s.
2021-03-09 18:41:53.481338 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:41:53.481483 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:41:53.499038 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52361), raddr=('172.217.3.106', 443)>
2021-03-09 18:41:53.499255 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52362), raddr=('172.217.9.234', 443)>
2021-03-09 18:41:53.526005 (MainThread): 
2021-03-09 18:41:53.526168 (MainThread): Completed successfully
2021-03-09 18:41:53.526286 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-03-09 18:41:53.526535 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105586490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055d1310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106875700>]}
2021-03-09 18:41:53.526712 (MainThread): Flushing usage events
2021-03-09 18:42:07.764684 (MainThread): Running with dbt=0.19.0
2021-03-09 18:42:08.213211 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-09 18:42:08.214183 (MainThread): Tracking: tracking
2021-03-09 18:42:08.222143 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10782c460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108aaea30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108aae910>]}
2021-03-09 18:42:08.248537 (MainThread): Partial parsing not enabled
2021-03-09 18:42:08.249736 (MainThread): Parsing macros/adapters.sql
2021-03-09 18:42:08.272377 (MainThread): Parsing macros/catalog.sql
2021-03-09 18:42:08.278903 (MainThread): Parsing macros/etc.sql
2021-03-09 18:42:08.281142 (MainThread): Parsing macros/materializations/copy.sql
2021-03-09 18:42:08.285768 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-09 18:42:08.299170 (MainThread): Parsing macros/materializations/seed.sql
2021-03-09 18:42:08.302039 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-09 18:42:08.303840 (MainThread): Parsing macros/materializations/table.sql
2021-03-09 18:42:08.314423 (MainThread): Parsing macros/materializations/view.sql
2021-03-09 18:42:08.318393 (MainThread): Parsing macros/core.sql
2021-03-09 18:42:08.322548 (MainThread): Parsing macros/adapters/common.sql
2021-03-09 18:42:08.368732 (MainThread): Parsing macros/etc/datetime.sql
2021-03-09 18:42:08.377770 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-09 18:42:08.378712 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-09 18:42:08.380412 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-09 18:42:08.382560 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-09 18:42:08.384191 (MainThread): Parsing macros/etc/query.sql
2021-03-09 18:42:08.385262 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-09 18:42:08.394432 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-09 18:42:08.410512 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-09 18:42:08.412555 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-09 18:42:08.420047 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-09 18:42:08.443101 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-09 18:42:08.478257 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-09 18:42:08.480111 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-09 18:42:08.499044 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-09 18:42:08.505979 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-09 18:42:08.511202 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-09 18:42:08.520316 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-09 18:42:08.524869 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-09 18:42:08.526995 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-09 18:42:08.529282 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-09 18:42:08.537533 (MainThread): Partial parsing not enabled
2021-03-09 18:42:08.583482 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:42:08.603698 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:42:08.614612 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:42:08.627776 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:42:08.844277 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-09 18:42:08.844543 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:42:08.844679 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-09 18:42:08.896726 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-09 18:42:08.901425 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '879476b1-eceb-427c-a17c-013af87a0d58', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d2edc0>]}
2021-03-09 18:42:08.945278 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-09 18:42:08.946433 (MainThread): 
2021-03-09 18:42:08.946845 (MainThread): Acquiring new bigquery connection "master".
2021-03-09 18:42:08.956885 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-09 18:42:08.957153 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-09 18:42:08.961476 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-09 18:42:09.357498 (MainThread): 13:42:09 | Concurrency: 1 threads (target='prod')
2021-03-09 18:42:09.357700 (MainThread): 13:42:09 | 
2021-03-09 18:42:09.359696 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:42:09.360067 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-09 18:42:09.360209 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:42:09.362447 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52367), raddr=('172.217.3.106', 443)>
2021-03-09 18:42:09.362667 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 52368), raddr=('172.217.9.234', 443)>
2021-03-09 18:42:09.379365 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-09 18:42:09.379792 (Thread-1): finished collecting timing info
2021-03-09 18:42:09.380110 (Thread-1): finished collecting timing info
2021-03-09 18:42:09.380555 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-09 18:42:09.380687 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:42:09.380917 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-09 18:42:09.381021 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:42:09.390096 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-09 18:42:09.390621 (Thread-1): finished collecting timing info
2021-03-09 18:42:09.390929 (Thread-1): finished collecting timing info
2021-03-09 18:42:09.391401 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-09 18:42:09.391557 (Thread-1): Began running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:42:09.391889 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_tweet_words".
2021-03-09 18:42:09.392297 (Thread-1): Compiling model.hashpath_demo.mrt_tweet_words
2021-03-09 18:42:09.402363 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_tweet_words"
2021-03-09 18:42:09.402704 (Thread-1): finished collecting timing info
2021-03-09 18:42:09.402955 (Thread-1): finished collecting timing info
2021-03-09 18:42:09.403388 (Thread-1): Finished running node model.hashpath_demo.mrt_tweet_words
2021-03-09 18:42:09.403525 (Thread-1): Began running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:42:09.403766 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.mrt_twitter_metrics".
2021-03-09 18:42:09.403873 (Thread-1): Compiling model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:42:09.413920 (Thread-1): Writing injected SQL for node "model.hashpath_demo.mrt_twitter_metrics"
2021-03-09 18:42:09.414434 (Thread-1): finished collecting timing info
2021-03-09 18:42:09.414890 (Thread-1): finished collecting timing info
2021-03-09 18:42:09.415596 (Thread-1): Finished running node model.hashpath_demo.mrt_twitter_metrics
2021-03-09 18:42:09.416840 (MainThread): Connection 'master' was properly closed.
2021-03-09 18:42:09.416992 (MainThread): Connection 'model.hashpath_demo.mrt_twitter_metrics' was properly closed.
2021-03-09 18:42:09.457594 (MainThread): 13:42:09 | Done.
2021-03-09 18:42:09.461432 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-09 18:42:09.461652 (MainThread): 13:42:09 | Building catalog
2021-03-09 18:42:09.477519 (MainThread): Opening a new connection, currently in state init
2021-03-09 18:42:09.823657 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:42:09.846166 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-09 18:42:09.851378 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_demo_production`.__TABLES__
        where (upper(dataset_id) = upper('dbt_demo_production'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:42:13.851639 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-09 18:42:13.853856 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-09 18:42:13.857766 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`twitter`.__TABLES__
        where (upper(dataset_id) = upper('twitter'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-09 18:42:18.153723 (MainThread): 13:42:18 | Catalog written to /Users/sethrosen/Documents/GitHub/dbt_topcoat_demo/target/catalog.json
2021-03-09 18:42:18.154241 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10782c460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108eb3b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108eb33d0>]}
2021-03-09 18:42:18.154499 (MainThread): Flushing usage events
2021-03-09 18:42:18.297738 (MainThread): Connection 'generate_catalog' was properly closed.
2021-03-09 18:42:18.297931 (MainThread): Connection 'hashpath-demo-data.information_schema' was properly closed.
2021-03-10 00:05:21.974609 (MainThread): Running with dbt=0.19.0
2021-03-10 00:05:22.801395 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-10 00:05:22.803057 (MainThread): Tracking: tracking
2021-03-10 00:05:22.827766 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107edd4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109155bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109155a90>]}
2021-03-10 00:05:22.873712 (MainThread): Partial parsing not enabled
2021-03-10 00:05:22.876824 (MainThread): Parsing macros/adapters.sql
2021-03-10 00:05:22.917395 (MainThread): Parsing macros/catalog.sql
2021-03-10 00:05:22.928495 (MainThread): Parsing macros/etc.sql
2021-03-10 00:05:22.932709 (MainThread): Parsing macros/materializations/copy.sql
2021-03-10 00:05:22.942251 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-10 00:05:22.967082 (MainThread): Parsing macros/materializations/seed.sql
2021-03-10 00:05:22.972704 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-10 00:05:22.976581 (MainThread): Parsing macros/materializations/table.sql
2021-03-10 00:05:22.994168 (MainThread): Parsing macros/materializations/view.sql
2021-03-10 00:05:23.003654 (MainThread): Parsing macros/core.sql
2021-03-10 00:05:23.010948 (MainThread): Parsing macros/adapters/common.sql
2021-03-10 00:05:23.088634 (MainThread): Parsing macros/etc/datetime.sql
2021-03-10 00:05:23.105580 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-10 00:05:23.107703 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-10 00:05:23.111389 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-10 00:05:23.116207 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-10 00:05:23.119047 (MainThread): Parsing macros/etc/query.sql
2021-03-10 00:05:23.121136 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-10 00:05:23.136834 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-10 00:05:23.165464 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-10 00:05:23.169381 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-10 00:05:23.184530 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-10 00:05:23.219831 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-10 00:05:23.280774 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-10 00:05:23.285127 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-10 00:05:23.318702 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-10 00:05:23.332557 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-10 00:05:23.342484 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-10 00:05:23.354677 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-10 00:05:23.360810 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-10 00:05:23.364093 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-10 00:05:23.369107 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-10 00:05:23.385792 (MainThread): Partial parsing not enabled
2021-03-10 00:05:23.467587 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-10 00:05:23.505483 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-10 00:05:23.527642 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-10 00:05:23.547742 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-10 00:05:23.912007 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-10 00:05:23.912513 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:05:23.912738 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:05:24.044414 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-10 00:05:24.051780 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b52ab5e1-f959-4c94-9acc-c88702eab965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109452100>]}
2021-03-10 00:05:24.129949 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-10 00:05:24.131622 (MainThread): 
2021-03-10 00:05:24.132565 (MainThread): Acquiring new bigquery connection "master".
2021-03-10 00:05:24.143700 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-10 00:05:24.144210 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-10 00:05:24.956600 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-10 00:05:24.956816 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-10 00:05:24.961501 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-10 00:05:25.380188 (MainThread): 19:05:25 | Concurrency: 1 threads (target='prod')
2021-03-10 00:05:25.380387 (MainThread): 19:05:25 | 
2021-03-10 00:05:25.382168 (MainThread): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56020), raddr=('172.217.10.106', 443)>
2021-03-10 00:05:25.382382 (MainThread): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56021), raddr=('172.217.9.234', 443)>
2021-03-10 00:05:25.383839 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:05:25.385613 (Thread-1): 19:05:25 | 1 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-10 00:05:25.386026 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-10 00:05:25.386175 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:05:25.406490 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-10 00:05:25.406827 (Thread-1): finished collecting timing info
2021-03-10 00:05:25.447355 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-10 00:05:25.447768 (Thread-1): Opening a new connection, currently in state closed
2021-03-10 00:05:25.451723 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  SPLIT(text,' ') as words,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets;


2021-03-10 00:05:26.499645 (Thread-1): finished collecting timing info
2021-03-10 00:05:26.500475 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b52ab5e1-f959-4c94-9acc-c88702eab965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093949a0>]}
2021-03-10 00:05:26.502053 (Thread-1): 19:05:26 | 1 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.11s]
2021-03-10 00:05:26.502242 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:05:26.502415 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:05:26.503587 (Thread-1): 19:05:26 | 2 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-10 00:05:26.504207 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-10 00:05:26.504353 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:05:26.513173 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-10 00:05:26.513522 (Thread-1): finished collecting timing info
2021-03-10 00:05:26.519110 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-10 00:05:26.519520 (Thread-1): Opening a new connection, currently in state closed
2021-03-10 00:05:26.523707 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets;


2021-03-10 00:05:27.364751 (Thread-1): finished collecting timing info
2021-03-10 00:05:27.365951 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b52ab5e1-f959-4c94-9acc-c88702eab965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093cfd00>]}
2021-03-10 00:05:27.367350 (Thread-1): 19:05:27 | 2 of 4 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.86s]
2021-03-10 00:05:27.367539 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:05:27.367712 (Thread-1): Began running node model.hashpath_demo.tweet_words
2021-03-10 00:05:27.368918 (Thread-1): 19:05:27 | 3 of 4 START view model dbt_demo_production.tweet_words.............. [RUN]
2021-03-10 00:05:27.369377 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-10 00:05:27.369507 (Thread-1): Compiling model.hashpath_demo.tweet_words
2021-03-10 00:05:27.371368 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56027), raddr=('172.217.10.106', 443)>
2021-03-10 00:05:27.371530 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56028), raddr=('172.217.9.234', 443)>
2021-03-10 00:05:27.378149 (Thread-1): Writing injected SQL for node "model.hashpath_demo.tweet_words"
2021-03-10 00:05:27.378600 (Thread-1): finished collecting timing info
2021-03-10 00:05:27.383785 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.tweet_words"
2021-03-10 00:05:27.384322 (Thread-1): Opening a new connection, currently in state closed
2021-03-10 00:05:27.388132 (Thread-1): On model.hashpath_demo.tweet_words: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.tweet_words"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`tweet_words`
  OPTIONS()
  as SELECT
  w,
  created_at,
  count(*) as total
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
WHERE w LIKE '%@%' AND w <> '@tayloramurphy'
GROUP BY 1,2;


2021-03-10 00:05:28.346291 (Thread-1): finished collecting timing info
2021-03-10 00:05:28.347124 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b52ab5e1-f959-4c94-9acc-c88702eab965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109590460>]}
2021-03-10 00:05:28.348626 (Thread-1): 19:05:28 | 3 of 4 OK created view model dbt_demo_production.tweet_words......... [OK in 0.98s]
2021-03-10 00:05:28.348801 (Thread-1): Finished running node model.hashpath_demo.tweet_words
2021-03-10 00:05:28.348978 (Thread-1): Began running node model.hashpath_demo.twitter_metrics
2021-03-10 00:05:28.350183 (Thread-1): 19:05:28 | 4 of 4 START view model dbt_demo_production.twitter_metrics.......... [RUN]
2021-03-10 00:05:28.350571 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-10 00:05:28.350721 (Thread-1): Compiling model.hashpath_demo.twitter_metrics
2021-03-10 00:05:28.353219 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56029), raddr=('172.217.10.106', 443)>
2021-03-10 00:05:28.353513 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56030), raddr=('172.217.9.234', 443)>
2021-03-10 00:05:28.361569 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56026), raddr=('172.217.9.234', 443)>
2021-03-10 00:05:28.361801 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56025), raddr=('172.217.10.106', 443)>
2021-03-10 00:05:28.369570 (Thread-1): Writing injected SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-10 00:05:28.370066 (Thread-1): finished collecting timing info
2021-03-10 00:05:28.375080 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-10 00:05:28.375794 (Thread-1): Opening a new connection, currently in state closed
2021-03-10 00:05:28.381089 (Thread-1): On model.hashpath_demo.twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-10 00:05:29.680120 (Thread-1): finished collecting timing info
2021-03-10 00:05:29.680930 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b52ab5e1-f959-4c94-9acc-c88702eab965', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093c5dc0>]}
2021-03-10 00:05:29.682234 (Thread-1): 19:05:29 | 4 of 4 OK created view model dbt_demo_production.twitter_metrics..... [OK in 1.33s]
2021-03-10 00:05:29.682400 (Thread-1): Finished running node model.hashpath_demo.twitter_metrics
2021-03-10 00:05:29.683685 (MainThread): Acquiring new bigquery connection "master".
2021-03-10 00:05:29.684337 (MainThread): 19:05:29 | 
2021-03-10 00:05:29.684583 (MainThread): 19:05:29 | Finished running 4 view models in 5.55s.
2021-03-10 00:05:29.684769 (MainThread): Connection 'master' was properly closed.
2021-03-10 00:05:29.684899 (MainThread): Connection 'model.hashpath_demo.twitter_metrics' was properly closed.
2021-03-10 00:05:29.704130 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56031), raddr=('172.217.10.106', 443)>
2021-03-10 00:05:29.704351 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56032), raddr=('172.217.9.234', 443)>
2021-03-10 00:05:29.733563 (MainThread): 
2021-03-10 00:05:29.733759 (MainThread): Completed successfully
2021-03-10 00:05:29.733895 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-03-10 00:05:29.734180 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10959b190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109394520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109590460>]}
2021-03-10 00:05:29.734470 (MainThread): Flushing usage events
2021-03-10 00:49:01.153605 (MainThread): Running with dbt=0.19.0
2021-03-10 00:49:01.925449 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-10 00:49:01.927103 (MainThread): Tracking: tracking
2021-03-10 00:49:01.941436 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047574f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059da100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059da040>]}
2021-03-10 00:49:01.975144 (MainThread): Partial parsing not enabled
2021-03-10 00:49:01.978170 (MainThread): Parsing macros/adapters.sql
2021-03-10 00:49:02.006442 (MainThread): Parsing macros/catalog.sql
2021-03-10 00:49:02.014321 (MainThread): Parsing macros/etc.sql
2021-03-10 00:49:02.017482 (MainThread): Parsing macros/materializations/copy.sql
2021-03-10 00:49:02.024138 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-10 00:49:02.041733 (MainThread): Parsing macros/materializations/seed.sql
2021-03-10 00:49:02.045670 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-10 00:49:02.048598 (MainThread): Parsing macros/materializations/table.sql
2021-03-10 00:49:02.061031 (MainThread): Parsing macros/materializations/view.sql
2021-03-10 00:49:02.065899 (MainThread): Parsing macros/core.sql
2021-03-10 00:49:02.073047 (MainThread): Parsing macros/adapters/common.sql
2021-03-10 00:49:02.136154 (MainThread): Parsing macros/etc/datetime.sql
2021-03-10 00:49:02.150507 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-10 00:49:02.152954 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-10 00:49:02.156674 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-10 00:49:02.160215 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-10 00:49:02.163074 (MainThread): Parsing macros/etc/query.sql
2021-03-10 00:49:02.165262 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-10 00:49:02.177142 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-10 00:49:02.193785 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-10 00:49:02.196968 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-10 00:49:02.205458 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-10 00:49:02.231582 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-10 00:49:02.274630 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-10 00:49:02.277198 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-10 00:49:02.299274 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-10 00:49:02.309531 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-10 00:49:02.315831 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-10 00:49:02.323957 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-10 00:49:02.327962 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-10 00:49:02.330198 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-10 00:49:02.333274 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-10 00:49:02.344488 (MainThread): Partial parsing not enabled
2021-03-10 00:49:02.399558 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-10 00:49:02.428197 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-10 00:49:02.439891 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-10 00:49:02.452528 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-10 00:49:02.693238 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-10 00:49:02.693563 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:49:02.693706 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:49:02.753550 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-10 00:49:02.757590 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2d53180c-3c42-49f8-b7f7-c521e47c3f72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c02d00>]}
2021-03-10 00:49:02.804941 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 0 exposures
2021-03-10 00:49:02.806136 (MainThread): 
2021-03-10 00:49:02.806650 (MainThread): Acquiring new bigquery connection "master".
2021-03-10 00:49:02.812955 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-10 00:49:02.813169 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-10 00:49:03.338390 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-10 00:49:03.338805 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-10 00:49:03.344450 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-10 00:49:03.748391 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56817), raddr=('172.217.6.202', 443)>
2021-03-10 00:49:03.748699 (ThreadPoolExecutor-1_0): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56818), raddr=('172.217.9.234', 443)>
2021-03-10 00:49:03.751486 (MainThread): 19:49:03 | Concurrency: 1 threads (target='prod')
2021-03-10 00:49:03.751679 (MainThread): 19:49:03 | 
2021-03-10 00:49:03.759869 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:49:03.761286 (Thread-1): 19:49:03 | 1 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-10 00:49:03.761661 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-10 00:49:03.761805 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:49:03.783019 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-10 00:49:03.784128 (Thread-1): finished collecting timing info
2021-03-10 00:49:03.833282 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-10 00:49:03.833716 (Thread-1): Opening a new connection, currently in state closed
2021-03-10 00:49:03.838218 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  SPLIT(text,' ') as words,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets;


2021-03-10 00:49:04.901933 (Thread-1): finished collecting timing info
2021-03-10 00:49:04.903020 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d53180c-3c42-49f8-b7f7-c521e47c3f72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c4bf10>]}
2021-03-10 00:49:04.904882 (Thread-1): 19:49:04 | 1 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.14s]
2021-03-10 00:49:04.905235 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:49:04.905585 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:49:04.907334 (Thread-1): 19:49:04 | 2 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-10 00:49:04.907867 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-10 00:49:04.908239 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:49:04.921864 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-10 00:49:04.922334 (Thread-1): finished collecting timing info
2021-03-10 00:49:04.931009 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-10 00:49:04.931647 (Thread-1): Opening a new connection, currently in state closed
2021-03-10 00:49:04.936937 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets;


2021-03-10 00:49:05.879797 (Thread-1): finished collecting timing info
2021-03-10 00:49:05.880878 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d53180c-3c42-49f8-b7f7-c521e47c3f72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dc8b20>]}
2021-03-10 00:49:05.882214 (Thread-1): 19:49:05 | 2 of 4 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.97s]
2021-03-10 00:49:05.882387 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:49:05.882555 (Thread-1): Began running node model.hashpath_demo.tweet_words
2021-03-10 00:49:05.883972 (Thread-1): 19:49:05 | 3 of 4 START view model dbt_demo_production.tweet_words.............. [RUN]
2021-03-10 00:49:05.884472 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-10 00:49:05.884784 (Thread-1): Compiling model.hashpath_demo.tweet_words
2021-03-10 00:49:05.893620 (Thread-1): Writing injected SQL for node "model.hashpath_demo.tweet_words"
2021-03-10 00:49:05.899525 (Thread-1): finished collecting timing info
2021-03-10 00:49:05.905307 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.tweet_words"
2021-03-10 00:49:05.905733 (Thread-1): Opening a new connection, currently in state closed
2021-03-10 00:49:05.910587 (Thread-1): On model.hashpath_demo.tweet_words: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.tweet_words"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`tweet_words`
  OPTIONS()
  as SELECT
  w,
  created_at,
  CASE WHEN w LIKE '%@%' THEN 'handle' ELSE 'word' END as type,
  count(*) as total
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
GROUP BY 1,2,3;


2021-03-10 00:49:06.961671 (Thread-1): finished collecting timing info
2021-03-10 00:49:06.962700 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d53180c-3c42-49f8-b7f7-c521e47c3f72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105dc8fa0>]}
2021-03-10 00:49:06.964075 (Thread-1): 19:49:06 | 3 of 4 OK created view model dbt_demo_production.tweet_words......... [OK in 1.08s]
2021-03-10 00:49:06.964240 (Thread-1): Finished running node model.hashpath_demo.tweet_words
2021-03-10 00:49:06.964406 (Thread-1): Began running node model.hashpath_demo.twitter_metrics
2021-03-10 00:49:06.965569 (Thread-1): 19:49:06 | 4 of 4 START view model dbt_demo_production.twitter_metrics.......... [RUN]
2021-03-10 00:49:06.965956 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-10 00:49:06.966100 (Thread-1): Compiling model.hashpath_demo.twitter_metrics
2021-03-10 00:49:06.969077 (Thread-1): unclosed <socket.socket fd=21, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56825), raddr=('172.217.6.202', 443)>
2021-03-10 00:49:06.969285 (Thread-1): unclosed <socket.socket fd=22, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56826), raddr=('172.217.9.234', 443)>
2021-03-10 00:49:06.977116 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56822), raddr=('172.217.9.234', 443)>
2021-03-10 00:49:06.977359 (Thread-1): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56821), raddr=('172.217.6.202', 443)>
2021-03-10 00:49:06.977516 (Thread-1): unclosed <socket.socket fd=20, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56824), raddr=('172.217.9.234', 443)>
2021-03-10 00:49:06.977708 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56823), raddr=('172.217.6.202', 443)>
2021-03-10 00:49:06.981731 (Thread-1): Writing injected SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-10 00:49:06.982078 (Thread-1): finished collecting timing info
2021-03-10 00:49:06.987190 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-10 00:49:06.987597 (Thread-1): Opening a new connection, currently in state closed
2021-03-10 00:49:06.992308 (Thread-1): On model.hashpath_demo.twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-10 00:49:07.771743 (Thread-1): finished collecting timing info
2021-03-10 00:49:07.772722 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d53180c-3c42-49f8-b7f7-c521e47c3f72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e5de50>]}
2021-03-10 00:49:07.774088 (Thread-1): 19:49:07 | 4 of 4 OK created view model dbt_demo_production.twitter_metrics..... [OK in 0.81s]
2021-03-10 00:49:07.774270 (Thread-1): Finished running node model.hashpath_demo.twitter_metrics
2021-03-10 00:49:07.776031 (MainThread): Acquiring new bigquery connection "master".
2021-03-10 00:49:07.776504 (MainThread): 19:49:07 | 
2021-03-10 00:49:07.776725 (MainThread): 19:49:07 | Finished running 4 view models in 4.97s.
2021-03-10 00:49:07.776897 (MainThread): Connection 'master' was properly closed.
2021-03-10 00:49:07.777021 (MainThread): Connection 'model.hashpath_demo.twitter_metrics' was properly closed.
2021-03-10 00:49:07.797886 (MainThread): unclosed <socket.socket fd=17, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56827), raddr=('172.217.6.202', 443)>
2021-03-10 00:49:07.798136 (MainThread): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56828), raddr=('172.217.9.234', 443)>
2021-03-10 00:49:07.828768 (MainThread): 
2021-03-10 00:49:07.829048 (MainThread): Completed successfully
2021-03-10 00:49:07.829235 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-03-10 00:49:07.829490 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ea6dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e5de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c9b580>]}
2021-03-10 00:49:07.829724 (MainThread): Flushing usage events
2021-03-10 00:56:18.875969 (MainThread): Running with dbt=0.19.0
2021-03-10 00:56:19.368897 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.deps.DepsTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='deps', single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='deps', write_json=True)
2021-03-10 00:56:19.369285 (MainThread): Tracking: tracking
2021-03-10 00:56:19.377173 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f27490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071aa850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071aa790>]}
2021-03-10 00:56:19.384806 (MainThread): Set downloads directory='/var/folders/3w/7rcz_nss6x5d0tlp0s41dt2m0000gn/T/dbt-downloads-wghhiqa_'
2021-03-10 00:56:19.386626 (MainThread): Executing "git clone --depth 1 git@github.com:Hashpath/topcoat_demo.git f22f38b6a498ea8816f762e9d7d25c21"
2021-03-10 00:56:20.430345 (MainThread): STDOUT: "b''"
2021-03-10 00:56:20.431045 (MainThread): STDERR: "b"Cloning into 'f22f38b6a498ea8816f762e9d7d25c21'...\n""
2021-03-10 00:56:20.431612 (MainThread): Pulling new dependency f22f38b6a498ea8816f762e9d7d25c21.
2021-03-10 00:56:20.431749 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:56:20.445714 (MainThread): STDOUT: "b'7ae0a5355b6c25cc84b98be628f6e1bb1975abae\n'"
2021-03-10 00:56:20.446255 (MainThread): STDERR: "b''"
2021-03-10 00:56:20.446473 (MainThread):   Checking out branch seth_demo.
2021-03-10 00:56:20.446579 (MainThread): Executing "git remote set-branches origin seth_demo"
2021-03-10 00:56:20.459002 (MainThread): STDOUT: "b''"
2021-03-10 00:56:20.459425 (MainThread): STDERR: "b''"
2021-03-10 00:56:20.459574 (MainThread): Executing "git fetch --tags --depth 1 origin seth_demo"
2021-03-10 00:56:21.184927 (MainThread): STDOUT: "b''"
2021-03-10 00:56:21.185284 (MainThread): STDERR: "b'From github.com:Hashpath/topcoat_demo\n * branch            seth_demo  -> FETCH_HEAD\n * [new branch]      seth_demo  -> origin/seth_demo\n'"
2021-03-10 00:56:21.185467 (MainThread): Executing "git tag --list"
2021-03-10 00:56:21.196595 (MainThread): STDOUT: "b''"
2021-03-10 00:56:21.197014 (MainThread): STDERR: "b''"
2021-03-10 00:56:21.197172 (MainThread): Executing "git reset --hard origin/seth_demo"
2021-03-10 00:56:21.222930 (MainThread): STDOUT: "b'HEAD is now at 661167e wip\n'"
2021-03-10 00:56:21.223284 (MainThread): STDERR: "b''"
2021-03-10 00:56:21.223438 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:56:21.233023 (MainThread): STDOUT: "b'661167ec7a2897e6d054ebb698b1d1d2a5a01651\n'"
2021-03-10 00:56:21.233386 (MainThread): STDERR: "b''"
2021-03-10 00:56:21.233574 (MainThread):   Checked out at 661167e.
2021-03-10 00:56:21.242272 (MainThread): Executing "git clone --depth 1 git@github.com:Hashpath/topcoat_demo.git f22f38b6a498ea8816f762e9d7d25c21"
2021-03-10 00:56:21.254163 (MainThread): STDOUT: "b''"
2021-03-10 00:56:21.254724 (MainThread): STDERR: "b"fatal: destination path 'f22f38b6a498ea8816f762e9d7d25c21' already exists and is not an empty directory.\n""
2021-03-10 00:56:21.254929 (MainThread): command return code=128
2021-03-10 00:56:21.255841 (MainThread): Updating existing dependency f22f38b6a498ea8816f762e9d7d25c21.
2021-03-10 00:56:21.256110 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:56:21.267293 (MainThread): STDOUT: "b'661167ec7a2897e6d054ebb698b1d1d2a5a01651\n'"
2021-03-10 00:56:21.267680 (MainThread): STDERR: "b''"
2021-03-10 00:56:21.267850 (MainThread):   Checking out branch seth_demo.
2021-03-10 00:56:21.267937 (MainThread): Executing "git remote set-branches origin seth_demo"
2021-03-10 00:56:21.281018 (MainThread): STDOUT: "b''"
2021-03-10 00:56:21.281419 (MainThread): STDERR: "b''"
2021-03-10 00:56:21.281559 (MainThread): Executing "git fetch --tags --depth 1 origin seth_demo"
2021-03-10 00:56:21.949205 (MainThread): STDOUT: "b''"
2021-03-10 00:56:21.949609 (MainThread): STDERR: "b'From github.com:Hashpath/topcoat_demo\n * branch            seth_demo  -> FETCH_HEAD\n'"
2021-03-10 00:56:21.949780 (MainThread): Executing "git tag --list"
2021-03-10 00:56:21.960724 (MainThread): STDOUT: "b''"
2021-03-10 00:56:21.961137 (MainThread): STDERR: "b''"
2021-03-10 00:56:21.961382 (MainThread): Executing "git reset --hard origin/seth_demo"
2021-03-10 00:56:21.978422 (MainThread): STDOUT: "b'HEAD is now at 661167e wip\n'"
2021-03-10 00:56:21.978806 (MainThread): STDERR: "b''"
2021-03-10 00:56:21.979003 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:56:21.988940 (MainThread): STDOUT: "b'661167ec7a2897e6d054ebb698b1d1d2a5a01651\n'"
2021-03-10 00:56:21.989293 (MainThread): STDERR: "b''"
2021-03-10 00:56:21.989493 (MainThread):   Already at 661167e, nothing to do.
2021-03-10 00:56:21.999610 (MainThread): Installing git@github.com:Hashpath/topcoat_demo.git@seth_demo
2021-03-10 00:56:21.999873 (MainThread): Executing "git clone --depth 1 git@github.com:Hashpath/topcoat_demo.git f22f38b6a498ea8816f762e9d7d25c21"
2021-03-10 00:56:22.009228 (MainThread): STDOUT: "b''"
2021-03-10 00:56:22.009679 (MainThread): STDERR: "b"fatal: destination path 'f22f38b6a498ea8816f762e9d7d25c21' already exists and is not an empty directory.\n""
2021-03-10 00:56:22.009789 (MainThread): command return code=128
2021-03-10 00:56:22.010061 (MainThread): Updating existing dependency f22f38b6a498ea8816f762e9d7d25c21.
2021-03-10 00:56:22.010221 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:56:22.020436 (MainThread): STDOUT: "b'661167ec7a2897e6d054ebb698b1d1d2a5a01651\n'"
2021-03-10 00:56:22.020814 (MainThread): STDERR: "b''"
2021-03-10 00:56:22.020997 (MainThread):   Checking out branch seth_demo.
2021-03-10 00:56:22.021080 (MainThread): Executing "git remote set-branches origin seth_demo"
2021-03-10 00:56:22.033392 (MainThread): STDOUT: "b''"
2021-03-10 00:56:22.033769 (MainThread): STDERR: "b''"
2021-03-10 00:56:22.033902 (MainThread): Executing "git fetch --tags --depth 1 origin seth_demo"
2021-03-10 00:56:22.711618 (MainThread): STDOUT: "b''"
2021-03-10 00:56:22.712029 (MainThread): STDERR: "b'From github.com:Hashpath/topcoat_demo\n * branch            seth_demo  -> FETCH_HEAD\n'"
2021-03-10 00:56:22.712171 (MainThread): Executing "git tag --list"
2021-03-10 00:56:22.723074 (MainThread): STDOUT: "b''"
2021-03-10 00:56:22.723467 (MainThread): STDERR: "b''"
2021-03-10 00:56:22.723667 (MainThread): Executing "git reset --hard origin/seth_demo"
2021-03-10 00:56:22.739844 (MainThread): STDOUT: "b'HEAD is now at 661167e wip\n'"
2021-03-10 00:56:22.740240 (MainThread): STDERR: "b''"
2021-03-10 00:56:22.740496 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:56:22.750917 (MainThread): STDOUT: "b'661167ec7a2897e6d054ebb698b1d1d2a5a01651\n'"
2021-03-10 00:56:22.751310 (MainThread): STDERR: "b''"
2021-03-10 00:56:22.751493 (MainThread):   Already at 661167e, nothing to do.
2021-03-10 00:56:22.753286 (MainThread):   Installed from revision seth_demo

2021-03-10 00:56:22.753741 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '84153e76-62ee-4ace-aaf1-8192d719fee6', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071bc5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071bca30>]}
2021-03-10 00:56:22.754602 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f27490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071bc040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071bcb80>]}
2021-03-10 00:56:22.754817 (MainThread): Flushing usage events
2021-03-10 00:56:29.547286 (MainThread): Running with dbt=0.19.0
2021-03-10 00:56:30.072139 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-10 00:56:30.074218 (MainThread): Tracking: tracking
2021-03-10 00:56:30.083806 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a118370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e95430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a118c70>]}
2021-03-10 00:56:30.131010 (MainThread): Partial parsing not enabled
2021-03-10 00:56:30.132472 (MainThread): Parsing macros/adapters.sql
2021-03-10 00:56:30.157276 (MainThread): Parsing macros/catalog.sql
2021-03-10 00:56:30.164972 (MainThread): Parsing macros/etc.sql
2021-03-10 00:56:30.167305 (MainThread): Parsing macros/materializations/copy.sql
2021-03-10 00:56:30.172894 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-10 00:56:30.188367 (MainThread): Parsing macros/materializations/seed.sql
2021-03-10 00:56:30.192005 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-10 00:56:30.195049 (MainThread): Parsing macros/materializations/table.sql
2021-03-10 00:56:30.207436 (MainThread): Parsing macros/materializations/view.sql
2021-03-10 00:56:30.211996 (MainThread): Parsing macros/core.sql
2021-03-10 00:56:30.216646 (MainThread): Parsing macros/adapters/common.sql
2021-03-10 00:56:30.271075 (MainThread): Parsing macros/etc/datetime.sql
2021-03-10 00:56:30.282184 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-10 00:56:30.283334 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-10 00:56:30.285279 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-10 00:56:30.287400 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-10 00:56:30.289153 (MainThread): Parsing macros/etc/query.sql
2021-03-10 00:56:30.290296 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-10 00:56:30.299990 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-10 00:56:30.314968 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-10 00:56:30.317000 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-10 00:56:30.323722 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-10 00:56:30.349742 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-10 00:56:30.389158 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-10 00:56:30.391123 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-10 00:56:30.409656 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-10 00:56:30.417249 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-10 00:56:30.422502 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-10 00:56:30.429347 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-10 00:56:30.432141 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-10 00:56:30.433833 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-10 00:56:30.436230 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-10 00:56:30.445020 (MainThread): Partial parsing not enabled
2021-03-10 00:56:30.492039 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-10 00:56:30.520144 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-10 00:56:30.532844 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-10 00:56:30.545404 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-10 00:56:30.837016 (MainThread): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-10 00:56:30.849117 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter".
2021-03-10 00:56:30.860150 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter_simple".
2021-03-10 00:56:30.871979 (MainThread): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-10 00:56:30.885201 (MainThread): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-10 00:56:30.897905 (MainThread): Acquiring new bigquery connection "model.topcoat.replies_toggle".
2021-03-10 00:56:30.909307 (MainThread): Acquiring new bigquery connection "model.topcoat.test_toggle".
2021-03-10 00:56:30.921117 (MainThread): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-10 00:56:30.935090 (MainThread): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-10 00:56:30.949284 (MainThread): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-10 00:56:30.962399 (MainThread): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-10 00:56:31.009412 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-10 00:56:31.009758 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:56:31.009904 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:56:31.010146 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4cef70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4ecdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5601c0>]}
2021-03-10 00:56:31.010344 (MainThread): Flushing usage events
2021-03-10 00:56:31.171838 (MainThread): Connection 'model.topcoat.your_network' was properly closed.
2021-03-10 00:56:31.172056 (MainThread): Encountered an error:
2021-03-10 00:56:31.172220 (MainThread): Compilation Error in model total_tweets (dbt_gen/twitter/total_tweets.sql)
  Model 'model.topcoat.total_tweets' (dbt_gen/twitter/total_tweets.sql) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:56:31.179371 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/generate.py", line 213, in run
    compile_results = CompileTask.run(self)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 406, in run
    self._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 122, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 79, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/runnable.py", line 66, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/perf_utils.py", line 28, in get_full_manifest
    return load_manifest(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 854, in load_manifest
    return ManifestLoader.load_all(config, macro_manifest, macro_hook)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 436, in load_all
    manifest = loader.create_manifest()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 414, in create_manifest
    self.process_manifest(manifest)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 380, in process_manifest
    process_refs(manifest, project_name)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 750, in process_refs
    _process_refs_for_node(manifest, current_project, node)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 732, in _process_refs_for_node
    invalid_ref_fail_unless_test(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/parser/manifest.py", line 475, in invalid_ref_fail_unless_test
    ref_target_not_found(
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 566, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/exceptions.py", line 435, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model total_tweets (dbt_gen/twitter/total_tweets.sql)
  Model 'model.topcoat.total_tweets' (dbt_gen/twitter/total_tweets.sql) depends on a node named 'unique_public_metrics' which was not found

2021-03-10 00:58:28.425913 (MainThread): Running with dbt=0.19.0
2021-03-10 00:58:28.892050 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.deps.DepsTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='deps', single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='deps', write_json=True)
2021-03-10 00:58:28.892423 (MainThread): Tracking: tracking
2021-03-10 00:58:28.900701 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d62a610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8ad8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8ad850>]}
2021-03-10 00:58:28.908588 (MainThread): Set downloads directory='/var/folders/3w/7rcz_nss6x5d0tlp0s41dt2m0000gn/T/dbt-downloads-qv6581ko'
2021-03-10 00:58:28.910702 (MainThread): Executing "git clone --depth 1 git@github.com:Hashpath/topcoat_demo.git f22f38b6a498ea8816f762e9d7d25c21"
2021-03-10 00:58:29.859881 (MainThread): STDOUT: "b''"
2021-03-10 00:58:29.860258 (MainThread): STDERR: "b"Cloning into 'f22f38b6a498ea8816f762e9d7d25c21'...\n""
2021-03-10 00:58:29.860702 (MainThread): Pulling new dependency f22f38b6a498ea8816f762e9d7d25c21.
2021-03-10 00:58:29.860825 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:58:29.871260 (MainThread): STDOUT: "b'7ae0a5355b6c25cc84b98be628f6e1bb1975abae\n'"
2021-03-10 00:58:29.871645 (MainThread): STDERR: "b''"
2021-03-10 00:58:29.871806 (MainThread):   Checking out branch seth_demo.
2021-03-10 00:58:29.871889 (MainThread): Executing "git remote set-branches origin seth_demo"
2021-03-10 00:58:29.882815 (MainThread): STDOUT: "b''"
2021-03-10 00:58:29.883234 (MainThread): STDERR: "b''"
2021-03-10 00:58:29.883365 (MainThread): Executing "git fetch --tags --depth 1 origin seth_demo"
2021-03-10 00:58:30.607768 (MainThread): STDOUT: "b''"
2021-03-10 00:58:30.608196 (MainThread): STDERR: "b'From github.com:Hashpath/topcoat_demo\n * branch            seth_demo  -> FETCH_HEAD\n * [new branch]      seth_demo  -> origin/seth_demo\n'"
2021-03-10 00:58:30.608332 (MainThread): Executing "git tag --list"
2021-03-10 00:58:30.618675 (MainThread): STDOUT: "b''"
2021-03-10 00:58:30.619082 (MainThread): STDERR: "b''"
2021-03-10 00:58:30.619303 (MainThread): Executing "git reset --hard origin/seth_demo"
2021-03-10 00:58:30.646341 (MainThread): STDOUT: "b'HEAD is now at b6d70c3 wip\n'"
2021-03-10 00:58:30.646743 (MainThread): STDERR: "b''"
2021-03-10 00:58:30.646928 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:58:30.656960 (MainThread): STDOUT: "b'b6d70c338fc4afb42f474096b722c859c6de17c3\n'"
2021-03-10 00:58:30.657471 (MainThread): STDERR: "b''"
2021-03-10 00:58:30.657931 (MainThread):   Checked out at b6d70c3.
2021-03-10 00:58:30.667403 (MainThread): Executing "git clone --depth 1 git@github.com:Hashpath/topcoat_demo.git f22f38b6a498ea8816f762e9d7d25c21"
2021-03-10 00:58:30.678656 (MainThread): STDOUT: "b''"
2021-03-10 00:58:30.679126 (MainThread): STDERR: "b"fatal: destination path 'f22f38b6a498ea8816f762e9d7d25c21' already exists and is not an empty directory.\n""
2021-03-10 00:58:30.679219 (MainThread): command return code=128
2021-03-10 00:58:30.679856 (MainThread): Updating existing dependency f22f38b6a498ea8816f762e9d7d25c21.
2021-03-10 00:58:30.679982 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:58:30.690457 (MainThread): STDOUT: "b'b6d70c338fc4afb42f474096b722c859c6de17c3\n'"
2021-03-10 00:58:30.690903 (MainThread): STDERR: "b''"
2021-03-10 00:58:30.691249 (MainThread):   Checking out branch seth_demo.
2021-03-10 00:58:30.691345 (MainThread): Executing "git remote set-branches origin seth_demo"
2021-03-10 00:58:30.704933 (MainThread): STDOUT: "b''"
2021-03-10 00:58:30.705432 (MainThread): STDERR: "b''"
2021-03-10 00:58:30.705564 (MainThread): Executing "git fetch --tags --depth 1 origin seth_demo"
2021-03-10 00:58:31.402397 (MainThread): STDOUT: "b''"
2021-03-10 00:58:31.402784 (MainThread): STDERR: "b'From github.com:Hashpath/topcoat_demo\n * branch            seth_demo  -> FETCH_HEAD\n'"
2021-03-10 00:58:31.402935 (MainThread): Executing "git tag --list"
2021-03-10 00:58:31.413470 (MainThread): STDOUT: "b''"
2021-03-10 00:58:31.413848 (MainThread): STDERR: "b''"
2021-03-10 00:58:31.414025 (MainThread): Executing "git reset --hard origin/seth_demo"
2021-03-10 00:58:31.429464 (MainThread): STDOUT: "b'HEAD is now at b6d70c3 wip\n'"
2021-03-10 00:58:31.429892 (MainThread): STDERR: "b''"
2021-03-10 00:58:31.430047 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:58:31.439686 (MainThread): STDOUT: "b'b6d70c338fc4afb42f474096b722c859c6de17c3\n'"
2021-03-10 00:58:31.440023 (MainThread): STDERR: "b''"
2021-03-10 00:58:31.440173 (MainThread):   Already at b6d70c3, nothing to do.
2021-03-10 00:58:31.450002 (MainThread): Installing git@github.com:Hashpath/topcoat_demo.git@seth_demo
2021-03-10 00:58:31.470080 (MainThread): Executing "git clone --depth 1 git@github.com:Hashpath/topcoat_demo.git f22f38b6a498ea8816f762e9d7d25c21"
2021-03-10 00:58:31.480711 (MainThread): STDOUT: "b''"
2021-03-10 00:58:31.481088 (MainThread): STDERR: "b"fatal: destination path 'f22f38b6a498ea8816f762e9d7d25c21' already exists and is not an empty directory.\n""
2021-03-10 00:58:31.481184 (MainThread): command return code=128
2021-03-10 00:58:31.481435 (MainThread): Updating existing dependency f22f38b6a498ea8816f762e9d7d25c21.
2021-03-10 00:58:31.481572 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:58:31.494893 (MainThread): STDOUT: "b'b6d70c338fc4afb42f474096b722c859c6de17c3\n'"
2021-03-10 00:58:31.495348 (MainThread): STDERR: "b''"
2021-03-10 00:58:31.495606 (MainThread):   Checking out branch seth_demo.
2021-03-10 00:58:31.495708 (MainThread): Executing "git remote set-branches origin seth_demo"
2021-03-10 00:58:31.508547 (MainThread): STDOUT: "b''"
2021-03-10 00:58:31.509709 (MainThread): STDERR: "b''"
2021-03-10 00:58:31.509980 (MainThread): Executing "git fetch --tags --depth 1 origin seth_demo"
2021-03-10 00:58:32.222444 (MainThread): STDOUT: "b''"
2021-03-10 00:58:32.222928 (MainThread): STDERR: "b'From github.com:Hashpath/topcoat_demo\n * branch            seth_demo  -> FETCH_HEAD\n'"
2021-03-10 00:58:32.223071 (MainThread): Executing "git tag --list"
2021-03-10 00:58:32.233371 (MainThread): STDOUT: "b''"
2021-03-10 00:58:32.233837 (MainThread): STDERR: "b''"
2021-03-10 00:58:32.234042 (MainThread): Executing "git reset --hard origin/seth_demo"
2021-03-10 00:58:32.248292 (MainThread): STDOUT: "b'HEAD is now at b6d70c3 wip\n'"
2021-03-10 00:58:32.248714 (MainThread): STDERR: "b''"
2021-03-10 00:58:32.248907 (MainThread): Executing "git rev-parse HEAD"
2021-03-10 00:58:32.259004 (MainThread): STDOUT: "b'b6d70c338fc4afb42f474096b722c859c6de17c3\n'"
2021-03-10 00:58:32.259455 (MainThread): STDERR: "b''"
2021-03-10 00:58:32.259645 (MainThread):   Already at b6d70c3, nothing to do.
2021-03-10 00:58:32.260012 (MainThread):   Installed from revision seth_demo

2021-03-10 00:58:32.260394 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '67f19529-e2f7-4996-8753-054c93226674', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e89aee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e89af40>]}
2021-03-10 00:58:32.261111 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d62a610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e89af40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e89a850>]}
2021-03-10 00:58:32.261301 (MainThread): Flushing usage events
2021-03-10 00:58:36.537031 (MainThread): Running with dbt=0.19.0
2021-03-10 00:58:37.023842 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-10 00:58:37.024793 (MainThread): Tracking: tracking
2021-03-10 00:58:37.034479 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2a83d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5179d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e517af0>]}
2021-03-10 00:58:37.076744 (MainThread): Partial parsing not enabled
2021-03-10 00:58:37.077975 (MainThread): Parsing macros/adapters.sql
2021-03-10 00:58:37.101750 (MainThread): Parsing macros/catalog.sql
2021-03-10 00:58:37.109106 (MainThread): Parsing macros/etc.sql
2021-03-10 00:58:37.111404 (MainThread): Parsing macros/materializations/copy.sql
2021-03-10 00:58:37.117391 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-10 00:58:37.135861 (MainThread): Parsing macros/materializations/seed.sql
2021-03-10 00:58:37.139868 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-10 00:58:37.142476 (MainThread): Parsing macros/materializations/table.sql
2021-03-10 00:58:37.154331 (MainThread): Parsing macros/materializations/view.sql
2021-03-10 00:58:37.159212 (MainThread): Parsing macros/core.sql
2021-03-10 00:58:37.164366 (MainThread): Parsing macros/adapters/common.sql
2021-03-10 00:58:37.218364 (MainThread): Parsing macros/etc/datetime.sql
2021-03-10 00:58:37.228813 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-10 00:58:37.229882 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-10 00:58:37.231702 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-10 00:58:37.233848 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-10 00:58:37.235895 (MainThread): Parsing macros/etc/query.sql
2021-03-10 00:58:37.237026 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-10 00:58:37.247604 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-10 00:58:37.263810 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-10 00:58:37.265852 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-10 00:58:37.272895 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-10 00:58:37.303104 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-10 00:58:37.344560 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-10 00:58:37.346688 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-10 00:58:37.370538 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-10 00:58:37.378205 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-10 00:58:37.383706 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-10 00:58:37.391416 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-10 00:58:37.394904 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-10 00:58:37.396983 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-10 00:58:37.399417 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-10 00:58:37.408257 (MainThread): Partial parsing not enabled
2021-03-10 00:58:37.459970 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-10 00:58:37.484847 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-10 00:58:37.498491 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-10 00:58:37.510467 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-10 00:58:37.762431 (MainThread): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-10 00:58:37.773658 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter".
2021-03-10 00:58:37.784536 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter_simple".
2021-03-10 00:58:37.795658 (MainThread): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-10 00:58:37.809156 (MainThread): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-10 00:58:37.822765 (MainThread): Acquiring new bigquery connection "model.topcoat.replies_toggle".
2021-03-10 00:58:37.835520 (MainThread): Acquiring new bigquery connection "model.topcoat.test_toggle".
2021-03-10 00:58:37.846510 (MainThread): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-10 00:58:37.861705 (MainThread): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-10 00:58:37.873580 (MainThread): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-10 00:58:37.888561 (MainThread): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-10 00:58:37.930051 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-10 00:58:37.930363 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:58:37.930498 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-10 00:58:38.003729 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-10 00:58:38.012690 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29be7fd4-5ef9-4f34-baac-7da78102b43a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8d8760>]}
2021-03-10 00:58:38.090954 (MainThread): Found 15 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 4 exposures
2021-03-10 00:58:38.092959 (MainThread): 
2021-03-10 00:58:38.093302 (MainThread): Acquiring new bigquery connection "master".
2021-03-10 00:58:38.101119 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-10 00:58:38.101278 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-10 00:58:38.105443 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-10 00:58:38.614456 (MainThread): 19:58:38 | Concurrency: 1 threads (target='prod')
2021-03-10 00:58:38.614634 (MainThread): 19:58:38 | 
2021-03-10 00:58:38.616441 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:58:38.616946 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-10 00:58:38.617080 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:58:38.635495 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-10 00:58:38.635828 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.636080 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.636506 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-10 00:58:38.636694 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:58:38.636931 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-10 00:58:38.637035 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:58:38.647554 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-10 00:58:38.648321 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.648938 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.650267 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-10 00:58:38.650690 (Thread-1): Began running node model.topcoat.sparklinesql
2021-03-10 00:58:38.651514 (Thread-1): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-10 00:58:38.651927 (Thread-1): Compiling model.topcoat.sparklinesql
2021-03-10 00:58:38.661236 (Thread-1): Writing injected SQL for node "model.topcoat.sparklinesql"
2021-03-10 00:58:38.661990 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.663092 (Thread-1): Finished running node model.topcoat.sparklinesql
2021-03-10 00:58:38.663481 (Thread-1): Began running node model.hashpath_demo.tweet_words
2021-03-10 00:58:38.664113 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-10 00:58:38.664284 (Thread-1): Compiling model.hashpath_demo.tweet_words
2021-03-10 00:58:38.676133 (Thread-1): Writing injected SQL for node "model.hashpath_demo.tweet_words"
2021-03-10 00:58:38.676662 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.677561 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.679161 (Thread-1): Finished running node model.hashpath_demo.tweet_words
2021-03-10 00:58:38.679838 (Thread-1): Began running node model.hashpath_demo.twitter_metrics
2021-03-10 00:58:38.681390 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-10 00:58:38.681840 (Thread-1): Compiling model.hashpath_demo.twitter_metrics
2021-03-10 00:58:38.697706 (Thread-1): Writing injected SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-10 00:58:38.698425 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.698853 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.699405 (Thread-1): Finished running node model.hashpath_demo.twitter_metrics
2021-03-10 00:58:38.699670 (Thread-1): Began running node model.topcoat.an_tweet_words
2021-03-10 00:58:38.700171 (Thread-1): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-10 00:58:38.700564 (Thread-1): Compiling model.topcoat.an_tweet_words
2021-03-10 00:58:38.704986 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56923), raddr=('172.217.12.170', 443)>
2021-03-10 00:58:38.705257 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 56924), raddr=('172.217.9.234', 443)>
2021-03-10 00:58:38.714853 (Thread-1): Writing injected SQL for node "model.topcoat.an_tweet_words"
2021-03-10 00:58:38.715610 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.716531 (Thread-1): Finished running node model.topcoat.an_tweet_words
2021-03-10 00:58:38.716838 (Thread-1): Began running node model.topcoat.your_network
2021-03-10 00:58:38.717544 (Thread-1): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-10 00:58:38.717781 (Thread-1): Compiling model.topcoat.your_network
2021-03-10 00:58:38.727430 (Thread-1): Writing injected SQL for node "model.topcoat.your_network"
2021-03-10 00:58:38.727942 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.728834 (Thread-1): Finished running node model.topcoat.your_network
2021-03-10 00:58:38.729045 (Thread-1): Began running node model.topcoat.all_tweets
2021-03-10 00:58:38.729356 (Thread-1): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-10 00:58:38.729604 (Thread-1): Compiling model.topcoat.all_tweets
2021-03-10 00:58:38.737835 (Thread-1): Writing injected SQL for node "model.topcoat.all_tweets"
2021-03-10 00:58:38.738337 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.738953 (Thread-1): Finished running node model.topcoat.all_tweets
2021-03-10 00:58:38.739689 (Thread-1): Began running node model.topcoat.top_tweets
2021-03-10 00:58:38.740326 (Thread-1): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-10 00:58:38.740542 (Thread-1): Compiling model.topcoat.top_tweets
2021-03-10 00:58:38.750430 (Thread-1): Writing injected SQL for node "model.topcoat.top_tweets"
2021-03-10 00:58:38.750872 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.751377 (Thread-1): Finished running node model.topcoat.top_tweets
2021-03-10 00:58:38.751526 (Thread-1): Began running node model.topcoat.total_tweets
2021-03-10 00:58:38.751782 (Thread-1): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-10 00:58:38.751904 (Thread-1): Compiling model.topcoat.total_tweets
2021-03-10 00:58:38.759840 (Thread-1): Writing injected SQL for node "model.topcoat.total_tweets"
2021-03-10 00:58:38.760261 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.760749 (Thread-1): Finished running node model.topcoat.total_tweets
2021-03-10 00:58:38.760909 (Thread-1): Began running node model.topcoat.tweets_by_day
2021-03-10 00:58:38.761243 (Thread-1): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-10 00:58:38.761361 (Thread-1): Compiling model.topcoat.tweets_by_day
2021-03-10 00:58:38.769545 (Thread-1): Writing injected SQL for node "model.topcoat.tweets_by_day"
2021-03-10 00:58:38.769934 (Thread-1): finished collecting timing info
2021-03-10 00:58:38.770389 (Thread-1): Finished running node model.topcoat.tweets_by_day
2021-03-10 00:58:38.771175 (MainThread): Connection 'master' was properly closed.
2021-03-10 00:58:38.771275 (MainThread): Connection 'model.topcoat.tweets_by_day' was properly closed.
2021-03-10 00:58:38.842979 (MainThread): 19:58:38 | Done.
2021-03-10 00:58:38.848340 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-10 00:58:38.848509 (MainThread): 19:58:38 | Building catalog
2021-03-10 00:58:38.891420 (MainThread): Opening a new connection, currently in state init
2021-03-10 00:58:39.249851 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-10 00:58:39.266619 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-10 00:58:39.272320 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_demo_production`.__TABLES__
        where (upper(dataset_id) = upper('dbt_demo_production'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-10 00:58:42.832791 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-10 00:58:42.835686 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-10 00:58:42.839858 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`twitter`.__TABLES__
        where (upper(dataset_id) = upper('twitter'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-10 00:58:46.472874 (MainThread): 19:58:46 | Catalog written to /Users/sethrosen/Documents/GitHub/dbt_topcoat_demo/target/catalog.json
2021-03-10 00:58:46.473341 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d2a83d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fab0f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8551c0>]}
2021-03-10 00:58:46.473564 (MainThread): Flushing usage events
2021-03-10 00:58:46.614636 (MainThread): Connection 'generate_catalog' was properly closed.
2021-03-10 00:58:46.614836 (MainThread): Connection 'hashpath-demo-data.information_schema' was properly closed.
2021-03-11 00:48:34.366706 (MainThread): Running with dbt=0.19.0
2021-03-11 00:48:35.172004 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', open_browser=True, partial_parse=None, port=8080, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='serve', write_json=True)
2021-03-11 00:48:35.173699 (MainThread): Tracking: tracking
2021-03-11 00:48:35.187563 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f82c2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f83d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f83d550>]}
2021-03-11 00:48:35.191509 (MainThread): Serving docs at 0.0.0.0:8080
2021-03-11 00:48:35.192027 (MainThread): To access from your browser, navigate to:  http://localhost:8080
2021-03-11 00:48:35.192182 (MainThread): Press Ctrl+C to exit.


2021-03-11 00:48:35.192817 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f83d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f83d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f83d790>]}
2021-03-11 00:48:35.193151 (MainThread): Flushing usage events
2021-03-11 00:48:35.434051 (MainThread): Encountered an error:
2021-03-11 00:48:35.434288 (MainThread): [Errno 48] Address already in use
2021-03-11 00:48:35.441300 (MainThread): Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 125, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 203, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/main.py", line 256, in run_from_args
    results = task.run()
  File "/usr/local/Cellar/dbt/0.19.0_1/libexec/lib/python3.8/site-packages/dbt/task/serve.py", line 29, in run
    httpd = TCPServer(  # type: ignore
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/socketserver.py", line 452, in __init__
    self.server_bind()
  File "/usr/local/Cellar/python@3.8/3.8.8_1/Frameworks/Python.framework/Versions/3.8/lib/python3.8/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2021-03-11 00:48:43.174097 (MainThread): Running with dbt=0.19.0
2021-03-11 00:48:43.629700 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-11 00:48:43.631459 (MainThread): Tracking: tracking
2021-03-11 00:48:43.639543 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928f700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a507f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a507df0>]}
2021-03-11 00:48:43.684524 (MainThread): Partial parsing not enabled
2021-03-11 00:48:43.687824 (MainThread): Parsing macros/adapters.sql
2021-03-11 00:48:43.714156 (MainThread): Parsing macros/catalog.sql
2021-03-11 00:48:43.724191 (MainThread): Parsing macros/etc.sql
2021-03-11 00:48:43.727586 (MainThread): Parsing macros/materializations/copy.sql
2021-03-11 00:48:43.734398 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-11 00:48:43.750321 (MainThread): Parsing macros/materializations/seed.sql
2021-03-11 00:48:43.756226 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-11 00:48:43.759451 (MainThread): Parsing macros/materializations/table.sql
2021-03-11 00:48:43.773157 (MainThread): Parsing macros/materializations/view.sql
2021-03-11 00:48:43.778499 (MainThread): Parsing macros/core.sql
2021-03-11 00:48:43.783805 (MainThread): Parsing macros/adapters/common.sql
2021-03-11 00:48:43.840641 (MainThread): Parsing macros/etc/datetime.sql
2021-03-11 00:48:43.854202 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-11 00:48:43.856114 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-11 00:48:43.858850 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-11 00:48:43.861963 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-11 00:48:43.864738 (MainThread): Parsing macros/etc/query.sql
2021-03-11 00:48:43.866712 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-11 00:48:43.877877 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-11 00:48:43.896733 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-11 00:48:43.900768 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-11 00:48:43.910211 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-11 00:48:43.937989 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-11 00:48:43.975039 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-11 00:48:43.977465 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-11 00:48:43.998109 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-11 00:48:44.006166 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-11 00:48:44.012640 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-11 00:48:44.020606 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-11 00:48:44.024122 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-11 00:48:44.026622 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-11 00:48:44.029243 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-11 00:48:44.037755 (MainThread): Partial parsing not enabled
2021-03-11 00:48:44.086604 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:48:44.108819 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:48:44.121368 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:48:44.133357 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:48:44.393395 (MainThread): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:48:44.404696 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter".
2021-03-11 00:48:44.416844 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter_simple".
2021-03-11 00:48:44.428992 (MainThread): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:48:44.442676 (MainThread): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:48:44.454526 (MainThread): Acquiring new bigquery connection "model.topcoat.replies_toggle".
2021-03-11 00:48:44.464654 (MainThread): Acquiring new bigquery connection "model.topcoat.test_toggle".
2021-03-11 00:48:44.477374 (MainThread): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:48:44.491468 (MainThread): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:48:44.503933 (MainThread): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:48:44.516570 (MainThread): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:48:44.562405 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-11 00:48:44.562699 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:48:44.562841 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:48:44.635942 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-11 00:48:44.645559 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6d599381-eb4e-4ab3-b2d3-4ea318221654', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a968130>]}
2021-03-11 00:48:44.721934 (MainThread): Found 15 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 4 exposures
2021-03-11 00:48:44.723991 (MainThread): 
2021-03-11 00:48:44.724341 (MainThread): Acquiring new bigquery connection "master".
2021-03-11 00:48:44.731833 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-11 00:48:44.731975 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-11 00:48:44.738888 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-11 00:48:45.283881 (MainThread): 19:48:45 | Concurrency: 1 threads (target='prod')
2021-03-11 00:48:45.284072 (MainThread): 19:48:45 | 
2021-03-11 00:48:45.292910 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:48:45.293708 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:48:45.293898 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:48:45.313519 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-11 00:48:45.313998 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.314278 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.314791 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:48:45.314923 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:48:45.315160 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:48:45.315262 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:48:45.323953 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-11 00:48:45.324297 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.324545 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.325188 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:48:45.325350 (Thread-1): Began running node model.topcoat.sparklinesql
2021-03-11 00:48:45.326839 (Thread-1): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:48:45.327093 (Thread-1): Compiling model.topcoat.sparklinesql
2021-03-11 00:48:45.332406 (Thread-1): Writing injected SQL for node "model.topcoat.sparklinesql"
2021-03-11 00:48:45.332914 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.333378 (Thread-1): Finished running node model.topcoat.sparklinesql
2021-03-11 00:48:45.333514 (Thread-1): Began running node model.hashpath_demo.tweet_words
2021-03-11 00:48:45.333780 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:48:45.333892 (Thread-1): Compiling model.hashpath_demo.tweet_words
2021-03-11 00:48:45.342848 (Thread-1): Writing injected SQL for node "model.hashpath_demo.tweet_words"
2021-03-11 00:48:45.343195 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.343456 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.343849 (Thread-1): Finished running node model.hashpath_demo.tweet_words
2021-03-11 00:48:45.343980 (Thread-1): Began running node model.hashpath_demo.twitter_metrics
2021-03-11 00:48:45.344227 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:48:45.344330 (Thread-1): Compiling model.hashpath_demo.twitter_metrics
2021-03-11 00:48:45.353287 (Thread-1): Writing injected SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-11 00:48:45.353667 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.354331 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.355148 (Thread-1): Finished running node model.hashpath_demo.twitter_metrics
2021-03-11 00:48:45.355305 (Thread-1): Began running node model.topcoat.an_tweet_words
2021-03-11 00:48:45.355571 (Thread-1): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:48:45.355684 (Thread-1): Compiling model.topcoat.an_tweet_words
2021-03-11 00:48:45.359222 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54115), raddr=('172.217.12.170', 443)>
2021-03-11 00:48:45.359688 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54116), raddr=('142.250.80.10', 443)>
2021-03-11 00:48:45.364000 (Thread-1): Writing injected SQL for node "model.topcoat.an_tweet_words"
2021-03-11 00:48:45.364337 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.364808 (Thread-1): Finished running node model.topcoat.an_tweet_words
2021-03-11 00:48:45.364945 (Thread-1): Began running node model.topcoat.your_network
2021-03-11 00:48:45.365192 (Thread-1): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:48:45.365303 (Thread-1): Compiling model.topcoat.your_network
2021-03-11 00:48:45.372132 (Thread-1): Writing injected SQL for node "model.topcoat.your_network"
2021-03-11 00:48:45.372462 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.372911 (Thread-1): Finished running node model.topcoat.your_network
2021-03-11 00:48:45.373040 (Thread-1): Began running node model.topcoat.all_tweets
2021-03-11 00:48:45.373272 (Thread-1): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:48:45.373375 (Thread-1): Compiling model.topcoat.all_tweets
2021-03-11 00:48:45.380562 (Thread-1): Writing injected SQL for node "model.topcoat.all_tweets"
2021-03-11 00:48:45.380891 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.381317 (Thread-1): Finished running node model.topcoat.all_tweets
2021-03-11 00:48:45.381833 (Thread-1): Began running node model.topcoat.top_tweets
2021-03-11 00:48:45.382076 (Thread-1): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:48:45.382177 (Thread-1): Compiling model.topcoat.top_tweets
2021-03-11 00:48:45.390095 (Thread-1): Writing injected SQL for node "model.topcoat.top_tweets"
2021-03-11 00:48:45.390415 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.390839 (Thread-1): Finished running node model.topcoat.top_tweets
2021-03-11 00:48:45.390972 (Thread-1): Began running node model.topcoat.total_tweets
2021-03-11 00:48:45.391209 (Thread-1): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:48:45.391311 (Thread-1): Compiling model.topcoat.total_tweets
2021-03-11 00:48:45.400228 (Thread-1): Writing injected SQL for node "model.topcoat.total_tweets"
2021-03-11 00:48:45.400561 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.400971 (Thread-1): Finished running node model.topcoat.total_tweets
2021-03-11 00:48:45.401099 (Thread-1): Began running node model.topcoat.tweets_by_day
2021-03-11 00:48:45.401344 (Thread-1): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:48:45.401446 (Thread-1): Compiling model.topcoat.tweets_by_day
2021-03-11 00:48:45.409513 (Thread-1): Writing injected SQL for node "model.topcoat.tweets_by_day"
2021-03-11 00:48:45.409873 (Thread-1): finished collecting timing info
2021-03-11 00:48:45.410639 (Thread-1): Finished running node model.topcoat.tweets_by_day
2021-03-11 00:48:45.411584 (MainThread): Connection 'master' was properly closed.
2021-03-11 00:48:45.411692 (MainThread): Connection 'model.topcoat.tweets_by_day' was properly closed.
2021-03-11 00:48:45.482734 (MainThread): 19:48:45 | Done.
2021-03-11 00:48:45.485855 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-11 00:48:45.486009 (MainThread): 19:48:45 | Building catalog
2021-03-11 00:48:45.526558 (MainThread): Opening a new connection, currently in state init
2021-03-11 00:48:45.877275 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-11 00:48:45.898566 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-11 00:48:45.902872 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_demo_production`.__TABLES__
        where (upper(dataset_id) = upper('dbt_demo_production'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-11 00:48:50.711235 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-11 00:48:50.713401 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-11 00:48:50.717632 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`twitter`.__TABLES__
        where (upper(dataset_id) = upper('twitter'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-11 00:48:55.064444 (MainThread): 19:48:55 | Catalog written to /Users/sethrosen/Documents/GitHub/dbt_topcoat_demo/target/catalog.json
2021-03-11 00:48:55.065015 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928f700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aaa6b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aaab220>]}
2021-03-11 00:48:55.065249 (MainThread): Flushing usage events
2021-03-11 00:48:55.205300 (MainThread): Connection 'generate_catalog' was properly closed.
2021-03-11 00:48:55.205490 (MainThread): Connection 'hashpath-demo-data.information_schema' was properly closed.
2021-03-11 00:57:40.335829 (MainThread): Running with dbt=0.19.0
2021-03-11 00:57:40.795866 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.deps.DepsTask'>, debug=False, defer=None, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='deps', single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, use_cache=True, use_colors=None, vars='{}', warn_error=False, which='deps', write_json=True)
2021-03-11 00:57:40.796227 (MainThread): Tracking: tracking
2021-03-11 00:57:40.804091 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e99a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107506310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075061f0>]}
2021-03-11 00:57:40.804881 (MainThread): Warning: No packages were found in packages.yml
2021-03-11 00:57:40.805177 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e99a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107506310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075061f0>]}
2021-03-11 00:57:40.805352 (MainThread): Flushing usage events
2021-03-11 00:57:44.293310 (MainThread): Running with dbt=0.19.0
2021-03-11 00:57:44.753380 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-11 00:57:44.754404 (MainThread): Tracking: tracking
2021-03-11 00:57:44.762759 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a30bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a4a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a4a3a0>]}
2021-03-11 00:57:44.802300 (MainThread): Partial parsing not enabled
2021-03-11 00:57:44.803673 (MainThread): Parsing macros/adapters.sql
2021-03-11 00:57:44.827222 (MainThread): Parsing macros/catalog.sql
2021-03-11 00:57:44.833880 (MainThread): Parsing macros/etc.sql
2021-03-11 00:57:44.836160 (MainThread): Parsing macros/materializations/copy.sql
2021-03-11 00:57:44.841064 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-11 00:57:44.856681 (MainThread): Parsing macros/materializations/seed.sql
2021-03-11 00:57:44.859961 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-11 00:57:44.861961 (MainThread): Parsing macros/materializations/table.sql
2021-03-11 00:57:44.872816 (MainThread): Parsing macros/materializations/view.sql
2021-03-11 00:57:44.877232 (MainThread): Parsing macros/core.sql
2021-03-11 00:57:44.881486 (MainThread): Parsing macros/adapters/common.sql
2021-03-11 00:57:44.929397 (MainThread): Parsing macros/etc/datetime.sql
2021-03-11 00:57:44.941192 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-11 00:57:44.942298 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-11 00:57:44.944241 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-11 00:57:44.946465 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-11 00:57:44.948403 (MainThread): Parsing macros/etc/query.sql
2021-03-11 00:57:44.949542 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-11 00:57:44.959738 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-11 00:57:44.979007 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-11 00:57:44.981179 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-11 00:57:44.988304 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-11 00:57:45.015834 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-11 00:57:45.053369 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-11 00:57:45.055380 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-11 00:57:45.075030 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-11 00:57:45.082890 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-11 00:57:45.088205 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-11 00:57:45.095465 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-11 00:57:45.098359 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-11 00:57:45.099984 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-11 00:57:45.102336 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-11 00:57:45.110716 (MainThread): Partial parsing not enabled
2021-03-11 00:57:45.156849 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:57:45.182864 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:57:45.193597 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:57:45.205896 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:57:45.446735 (MainThread): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:57:45.457101 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter".
2021-03-11 00:57:45.467458 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter_simple".
2021-03-11 00:57:45.481669 (MainThread): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:57:45.494715 (MainThread): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:57:45.507126 (MainThread): Acquiring new bigquery connection "model.topcoat.replies_toggle".
2021-03-11 00:57:45.517251 (MainThread): Acquiring new bigquery connection "model.topcoat.test_toggle".
2021-03-11 00:57:45.527919 (MainThread): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:57:45.540315 (MainThread): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:57:45.553220 (MainThread): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:57:45.567494 (MainThread): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:57:45.613767 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-11 00:57:45.614224 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:57:45.614366 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:57:45.695334 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-11 00:57:45.706483 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f33cfc9-ed1c-4d54-b4b1-b7ee33f5288f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ea4f10>]}
2021-03-11 00:57:45.791477 (MainThread): Found 15 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 4 exposures
2021-03-11 00:57:45.793675 (MainThread): 
2021-03-11 00:57:45.794243 (MainThread): Acquiring new bigquery connection "master".
2021-03-11 00:57:45.803366 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-11 00:57:45.803599 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-11 00:57:45.807807 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-11 00:57:46.315016 (MainThread): 19:57:46 | Concurrency: 1 threads (target='prod')
2021-03-11 00:57:46.315207 (MainThread): 19:57:46 | 
2021-03-11 00:57:46.317091 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:57:46.317635 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:57:46.317769 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:57:46.335142 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-11 00:57:46.335460 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.335711 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.336095 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:57:46.336229 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:57:46.336468 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:57:46.336573 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:57:46.344393 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-11 00:57:46.344842 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.345104 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.345514 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:57:46.345647 (Thread-1): Began running node model.topcoat.sparklinesql
2021-03-11 00:57:46.346306 (Thread-1): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:57:46.346431 (Thread-1): Compiling model.topcoat.sparklinesql
2021-03-11 00:57:46.353210 (Thread-1): Writing injected SQL for node "model.topcoat.sparklinesql"
2021-03-11 00:57:46.353571 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.354016 (Thread-1): Finished running node model.topcoat.sparklinesql
2021-03-11 00:57:46.354189 (Thread-1): Began running node model.hashpath_demo.tweet_words
2021-03-11 00:57:46.354707 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:57:46.354967 (Thread-1): Compiling model.hashpath_demo.tweet_words
2021-03-11 00:57:46.364306 (Thread-1): Writing injected SQL for node "model.hashpath_demo.tweet_words"
2021-03-11 00:57:46.364640 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.364894 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.365318 (Thread-1): Finished running node model.hashpath_demo.tweet_words
2021-03-11 00:57:46.365456 (Thread-1): Began running node model.hashpath_demo.twitter_metrics
2021-03-11 00:57:46.365716 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:57:46.365826 (Thread-1): Compiling model.hashpath_demo.twitter_metrics
2021-03-11 00:57:46.376787 (Thread-1): Writing injected SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-11 00:57:46.377308 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.377563 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.377975 (Thread-1): Finished running node model.hashpath_demo.twitter_metrics
2021-03-11 00:57:46.378103 (Thread-1): Began running node model.topcoat.an_tweet_words
2021-03-11 00:57:46.378346 (Thread-1): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:57:46.378719 (Thread-1): Compiling model.topcoat.an_tweet_words
2021-03-11 00:57:46.382324 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54808), raddr=('172.217.10.42', 443)>
2021-03-11 00:57:46.382521 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54809), raddr=('142.250.80.10', 443)>
2021-03-11 00:57:46.386493 (Thread-1): Writing injected SQL for node "model.topcoat.an_tweet_words"
2021-03-11 00:57:46.386815 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.387255 (Thread-1): Finished running node model.topcoat.an_tweet_words
2021-03-11 00:57:46.387388 (Thread-1): Began running node model.topcoat.your_network
2021-03-11 00:57:46.387631 (Thread-1): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:57:46.387747 (Thread-1): Compiling model.topcoat.your_network
2021-03-11 00:57:46.394729 (Thread-1): Writing injected SQL for node "model.topcoat.your_network"
2021-03-11 00:57:46.395056 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.395593 (Thread-1): Finished running node model.topcoat.your_network
2021-03-11 00:57:46.395748 (Thread-1): Began running node model.topcoat.all_tweets
2021-03-11 00:57:46.396014 (Thread-1): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:57:46.396125 (Thread-1): Compiling model.topcoat.all_tweets
2021-03-11 00:57:46.402911 (Thread-1): Writing injected SQL for node "model.topcoat.all_tweets"
2021-03-11 00:57:46.403254 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.403714 (Thread-1): Finished running node model.topcoat.all_tweets
2021-03-11 00:57:46.404274 (Thread-1): Began running node model.topcoat.top_tweets
2021-03-11 00:57:46.404552 (Thread-1): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:57:46.404661 (Thread-1): Compiling model.topcoat.top_tweets
2021-03-11 00:57:46.412983 (Thread-1): Writing injected SQL for node "model.topcoat.top_tweets"
2021-03-11 00:57:46.413332 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.413798 (Thread-1): Finished running node model.topcoat.top_tweets
2021-03-11 00:57:46.413930 (Thread-1): Began running node model.topcoat.total_tweets
2021-03-11 00:57:46.414167 (Thread-1): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:57:46.414270 (Thread-1): Compiling model.topcoat.total_tweets
2021-03-11 00:57:46.422242 (Thread-1): Writing injected SQL for node "model.topcoat.total_tweets"
2021-03-11 00:57:46.422564 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.422988 (Thread-1): Finished running node model.topcoat.total_tweets
2021-03-11 00:57:46.423118 (Thread-1): Began running node model.topcoat.tweets_by_day
2021-03-11 00:57:46.423353 (Thread-1): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:57:46.423456 (Thread-1): Compiling model.topcoat.tweets_by_day
2021-03-11 00:57:46.432133 (Thread-1): Writing injected SQL for node "model.topcoat.tweets_by_day"
2021-03-11 00:57:46.432468 (Thread-1): finished collecting timing info
2021-03-11 00:57:46.432949 (Thread-1): Finished running node model.topcoat.tweets_by_day
2021-03-11 00:57:46.434299 (MainThread): Connection 'master' was properly closed.
2021-03-11 00:57:46.434455 (MainThread): Connection 'model.topcoat.tweets_by_day' was properly closed.
2021-03-11 00:57:46.505562 (MainThread): 19:57:46 | Done.
2021-03-11 00:57:46.507659 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-11 00:57:46.507853 (MainThread): 19:57:46 | Building catalog
2021-03-11 00:57:46.551067 (MainThread): Opening a new connection, currently in state init
2021-03-11 00:57:46.933101 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-11 00:57:46.953536 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-11 00:57:46.957793 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_demo_production`.__TABLES__
        where (upper(dataset_id) = upper('dbt_demo_production'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-11 00:57:49.890965 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-11 00:57:49.893707 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-11 00:57:49.897641 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`twitter`.__TABLES__
        where (upper(dataset_id) = upper('twitter'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-11 00:57:53.395613 (MainThread): 19:57:53 | Catalog written to /Users/sethrosen/Documents/GitHub/dbt_topcoat_demo/target/catalog.json
2021-03-11 00:57:53.396171 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a30bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1150659a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fdab50>]}
2021-03-11 00:57:53.396465 (MainThread): Flushing usage events
2021-03-11 00:57:53.528739 (MainThread): Connection 'generate_catalog' was properly closed.
2021-03-11 00:57:53.528994 (MainThread): Connection 'hashpath-demo-data.information_schema' was properly closed.
2021-03-11 00:58:17.225015 (MainThread): Running with dbt=0.19.0
2021-03-11 00:58:17.687558 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, defer=None, exclude=None, fail_fast=False, full_refresh=True, log_cache_events=False, log_format='default', models=['twitter'], partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-03-11 00:58:17.688507 (MainThread): Tracking: tracking
2021-03-11 00:58:17.696929 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aac1820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aad02e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aad01c0>]}
2021-03-11 00:58:17.734948 (MainThread): Partial parsing not enabled
2021-03-11 00:58:17.736173 (MainThread): Parsing macros/adapters.sql
2021-03-11 00:58:17.759206 (MainThread): Parsing macros/catalog.sql
2021-03-11 00:58:17.768734 (MainThread): Parsing macros/etc.sql
2021-03-11 00:58:17.771355 (MainThread): Parsing macros/materializations/copy.sql
2021-03-11 00:58:17.776599 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-11 00:58:17.791368 (MainThread): Parsing macros/materializations/seed.sql
2021-03-11 00:58:17.794662 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-11 00:58:17.796628 (MainThread): Parsing macros/materializations/table.sql
2021-03-11 00:58:17.808042 (MainThread): Parsing macros/materializations/view.sql
2021-03-11 00:58:17.812318 (MainThread): Parsing macros/core.sql
2021-03-11 00:58:17.816629 (MainThread): Parsing macros/adapters/common.sql
2021-03-11 00:58:17.863774 (MainThread): Parsing macros/etc/datetime.sql
2021-03-11 00:58:17.873697 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-11 00:58:17.874696 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-11 00:58:17.876541 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-11 00:58:17.878648 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-11 00:58:17.880382 (MainThread): Parsing macros/etc/query.sql
2021-03-11 00:58:17.881511 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-11 00:58:17.891519 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-11 00:58:17.906782 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-11 00:58:17.909046 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-11 00:58:17.915602 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-11 00:58:17.942911 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-11 00:58:17.984401 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-11 00:58:17.986340 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-11 00:58:18.005945 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-11 00:58:18.017253 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-11 00:58:18.023352 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-11 00:58:18.030794 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-11 00:58:18.033785 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-11 00:58:18.035768 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-11 00:58:18.037824 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-11 00:58:18.046436 (MainThread): Partial parsing not enabled
2021-03-11 00:58:18.093644 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:58:18.118169 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:58:18.130505 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:58:18.142361 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:58:18.393688 (MainThread): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:58:18.404910 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter".
2021-03-11 00:58:18.417988 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter_simple".
2021-03-11 00:58:18.429156 (MainThread): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:58:18.441374 (MainThread): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:58:18.456724 (MainThread): Acquiring new bigquery connection "model.topcoat.replies_toggle".
2021-03-11 00:58:18.467154 (MainThread): Acquiring new bigquery connection "model.topcoat.test_toggle".
2021-03-11 00:58:18.478247 (MainThread): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:58:18.490496 (MainThread): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:58:18.502315 (MainThread): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:58:18.514221 (MainThread): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:58:18.557557 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-11 00:58:18.557887 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:58:18.558031 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:58:18.629183 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-11 00:58:18.639301 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c0cd6d1-5a2a-4a98-a2fb-9fee210c94ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af2ac40>]}
2021-03-11 00:58:18.714623 (MainThread): Found 15 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 4 exposures
2021-03-11 00:58:18.716678 (MainThread): 
2021-03-11 00:58:18.717121 (MainThread): Acquiring new bigquery connection "master".
2021-03-11 00:58:18.722394 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data".
2021-03-11 00:58:18.722590 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-11 00:58:19.099723 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-11 00:58:19.100025 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-11 00:58:19.104741 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-11 00:58:19.468470 (MainThread): 19:58:19 | Concurrency: 1 threads (target='prod')
2021-03-11 00:58:19.468682 (MainThread): 19:58:19 | 
2021-03-11 00:58:19.470703 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:19.471986 (Thread-1): 19:58:19 | 1 of 4 START view model dbt_demo_production.stg_unique_public_metrics [RUN]
2021-03-11 00:58:19.472349 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:58:19.472505 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:19.490888 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-11 00:58:19.491220 (Thread-1): finished collecting timing info
2021-03-11 00:58:19.531147 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-11 00:58:19.531708 (Thread-1): Opening a new connection, currently in state closed
2021-03-11 00:58:19.535994 (Thread-1): On model.hashpath_demo.stg_unique_public_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_public_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  like_count,
  retweet_count,
  SPLIT(text,' ') as words,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`public_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  words,
  like_count,
  retweet_count,
  created_at,
  url
FROM unique_tweets;


2021-03-11 00:58:20.477410 (Thread-1): finished collecting timing info
2021-03-11 00:58:20.478209 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c0cd6d1-5a2a-4a98-a2fb-9fee210c94ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae9d100>]}
2021-03-11 00:58:20.479743 (Thread-1): 19:58:20 | 1 of 4 OK created view model dbt_demo_production.stg_unique_public_metrics [OK in 1.01s]
2021-03-11 00:58:20.479913 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:20.480088 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:20.481249 (Thread-1): 19:58:20 | 2 of 4 START view model dbt_demo_production.stg_unique_private_metrics [RUN]
2021-03-11 00:58:20.481608 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:58:20.481757 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:20.488227 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54835), raddr=('172.217.10.42', 443)>
2021-03-11 00:58:20.488449 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54836), raddr=('142.250.80.10', 443)>
2021-03-11 00:58:20.488594 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54837), raddr=('172.217.10.42', 443)>
2021-03-11 00:58:20.488730 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54838), raddr=('142.250.80.10', 443)>
2021-03-11 00:58:20.488887 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54840), raddr=('142.250.80.10', 443)>
2021-03-11 00:58:20.489032 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54839), raddr=('172.217.10.42', 443)>
2021-03-11 00:58:20.492204 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-11 00:58:20.492532 (Thread-1): finished collecting timing info
2021-03-11 00:58:20.497458 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-11 00:58:20.497820 (Thread-1): Opening a new connection, currently in state closed
2021-03-11 00:58:20.501936 (Thread-1): On model.hashpath_demo.stg_unique_private_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.stg_unique_private_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics`
  OPTIONS()
  as with unique_tweets as 
  (SELECT * FROM (SELECT
  created_at as created_at,
  id,
  text, 
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  url,
  rank() OVER(PARTITION BY id ORDER BY fetch_date DESC) as rank
  FROM `hashpath-demo-data`.`twitter`.`non_public_organic_metrics` )
  WHERE rank = 1
  )
SELECT
  id,
  text,
  non_public_metrics_user_profile_clicks, 
  organic_metrics_impression_count,
  created_at,
  url
FROM unique_tweets;


2021-03-11 00:58:21.419752 (Thread-1): finished collecting timing info
2021-03-11 00:58:21.420541 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c0cd6d1-5a2a-4a98-a2fb-9fee210c94ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aea0af0>]}
2021-03-11 00:58:21.421833 (Thread-1): 19:58:21 | 2 of 4 OK created view model dbt_demo_production.stg_unique_private_metrics [OK in 0.94s]
2021-03-11 00:58:21.422008 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:21.422334 (Thread-1): Began running node model.hashpath_demo.tweet_words
2021-03-11 00:58:21.423588 (Thread-1): 19:58:21 | 3 of 4 START view model dbt_demo_production.tweet_words.............. [RUN]
2021-03-11 00:58:21.424003 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:58:21.424152 (Thread-1): Compiling model.hashpath_demo.tweet_words
2021-03-11 00:58:21.433527 (Thread-1): Writing injected SQL for node "model.hashpath_demo.tweet_words"
2021-03-11 00:58:21.434033 (Thread-1): finished collecting timing info
2021-03-11 00:58:21.439857 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.tweet_words"
2021-03-11 00:58:21.440303 (Thread-1): Opening a new connection, currently in state closed
2021-03-11 00:58:21.444636 (Thread-1): On model.hashpath_demo.tweet_words: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.tweet_words"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`tweet_words`
  OPTIONS()
  as SELECT
  w,
  created_at,
  CASE WHEN w LIKE '%@%' THEN 'handle' ELSE 'word' END as type,
  count(*) as total
FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` r, UNNEST(r.words) as w
GROUP BY 1,2,3;


2021-03-11 00:58:22.472010 (Thread-1): finished collecting timing info
2021-03-11 00:58:22.473053 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c0cd6d1-5a2a-4a98-a2fb-9fee210c94ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0d5f40>]}
2021-03-11 00:58:22.474346 (Thread-1): 19:58:22 | 3 of 4 OK created view model dbt_demo_production.tweet_words......... [OK in 1.05s]
2021-03-11 00:58:22.474535 (Thread-1): Finished running node model.hashpath_demo.tweet_words
2021-03-11 00:58:22.474767 (Thread-1): Began running node model.hashpath_demo.twitter_metrics
2021-03-11 00:58:22.476135 (Thread-1): 19:58:22 | 4 of 4 START view model dbt_demo_production.twitter_metrics.......... [RUN]
2021-03-11 00:58:22.476536 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:58:22.476678 (Thread-1): Compiling model.hashpath_demo.twitter_metrics
2021-03-11 00:58:22.486679 (Thread-1): Writing injected SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-11 00:58:22.487044 (Thread-1): finished collecting timing info
2021-03-11 00:58:22.491944 (Thread-1): Writing runtime SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-11 00:58:22.492301 (Thread-1): Opening a new connection, currently in state closed
2021-03-11 00:58:22.496368 (Thread-1): On model.hashpath_demo.twitter_metrics: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "node_id": "model.hashpath_demo.twitter_metrics"} */


  create or replace view `hashpath-demo-data`.`dbt_demo_production`.`twitter_metrics`
  OPTIONS()
  as SELECT
pu.id,
pu.text,
pu.like_count,
pu.retweet_count,
pr.non_public_metrics_user_profile_clicks, 
pr.organic_metrics_impression_count,
pu.created_at,
pu.url

FROM `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_public_metrics` pu

LEFT JOIN `hashpath-demo-data`.`dbt_demo_production`.`stg_unique_private_metrics` pr
ON pu.id = pr.id;


2021-03-11 00:58:23.492505 (Thread-1): finished collecting timing info
2021-03-11 00:58:23.493315 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c0cd6d1-5a2a-4a98-a2fb-9fee210c94ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0db6d0>]}
2021-03-11 00:58:23.494564 (Thread-1): 19:58:23 | 4 of 4 OK created view model dbt_demo_production.twitter_metrics..... [OK in 1.02s]
2021-03-11 00:58:23.494732 (Thread-1): Finished running node model.hashpath_demo.twitter_metrics
2021-03-11 00:58:23.494902 (Thread-1): Began running node model.topcoat.an_tweet_words
2021-03-11 00:58:23.495235 (Thread-1): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:58:23.495370 (Thread-1): Compiling model.topcoat.an_tweet_words
2021-03-11 00:58:23.496653 (Thread-1): unclosed <socket.socket fd=18, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54845), raddr=('172.217.10.42', 443)>
2021-03-11 00:58:23.497113 (Thread-1): unclosed <socket.socket fd=19, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54846), raddr=('142.250.80.10', 443)>
2021-03-11 00:58:23.504435 (Thread-1): Writing injected SQL for node "model.topcoat.an_tweet_words"
2021-03-11 00:58:23.504792 (Thread-1): finished collecting timing info
2021-03-11 00:58:23.505283 (Thread-1): Finished running node model.topcoat.an_tweet_words
2021-03-11 00:58:23.505459 (Thread-1): Began running node model.topcoat.your_network
2021-03-11 00:58:23.505736 (Thread-1): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:58:23.505862 (Thread-1): Compiling model.topcoat.your_network
2021-03-11 00:58:23.513273 (Thread-1): Writing injected SQL for node "model.topcoat.your_network"
2021-03-11 00:58:23.513606 (Thread-1): finished collecting timing info
2021-03-11 00:58:23.514053 (Thread-1): Finished running node model.topcoat.your_network
2021-03-11 00:58:23.514196 (Thread-1): Began running node model.topcoat.all_tweets
2021-03-11 00:58:23.514448 (Thread-1): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:58:23.514561 (Thread-1): Compiling model.topcoat.all_tweets
2021-03-11 00:58:23.522357 (Thread-1): Writing injected SQL for node "model.topcoat.all_tweets"
2021-03-11 00:58:23.522713 (Thread-1): finished collecting timing info
2021-03-11 00:58:23.523186 (Thread-1): Finished running node model.topcoat.all_tweets
2021-03-11 00:58:23.523780 (Thread-1): Began running node model.topcoat.top_tweets
2021-03-11 00:58:23.524075 (Thread-1): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:58:23.524198 (Thread-1): Compiling model.topcoat.top_tweets
2021-03-11 00:58:23.530589 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54842), raddr=('142.250.80.10', 443)>
2021-03-11 00:58:23.530853 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54841), raddr=('172.217.10.42', 443)>
2021-03-11 00:58:23.531006 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54844), raddr=('142.250.80.10', 443)>
2021-03-11 00:58:23.531139 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54843), raddr=('172.217.10.42', 443)>
2021-03-11 00:58:23.538634 (Thread-1): Writing injected SQL for node "model.topcoat.top_tweets"
2021-03-11 00:58:23.539008 (Thread-1): finished collecting timing info
2021-03-11 00:58:23.539511 (Thread-1): Finished running node model.topcoat.top_tweets
2021-03-11 00:58:23.539663 (Thread-1): Began running node model.topcoat.total_tweets
2021-03-11 00:58:23.539925 (Thread-1): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:58:23.540044 (Thread-1): Compiling model.topcoat.total_tweets
2021-03-11 00:58:23.548298 (Thread-1): Writing injected SQL for node "model.topcoat.total_tweets"
2021-03-11 00:58:23.548638 (Thread-1): finished collecting timing info
2021-03-11 00:58:23.549329 (Thread-1): Finished running node model.topcoat.total_tweets
2021-03-11 00:58:23.549510 (Thread-1): Began running node model.topcoat.tweets_by_day
2021-03-11 00:58:23.549821 (Thread-1): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:58:23.550095 (Thread-1): Compiling model.topcoat.tweets_by_day
2021-03-11 00:58:23.560349 (Thread-1): Writing injected SQL for node "model.topcoat.tweets_by_day"
2021-03-11 00:58:23.560723 (Thread-1): finished collecting timing info
2021-03-11 00:58:23.561211 (Thread-1): Finished running node model.topcoat.tweets_by_day
2021-03-11 00:58:23.562126 (MainThread): Acquiring new bigquery connection "master".
2021-03-11 00:58:23.562426 (MainThread): 19:58:23 | 
2021-03-11 00:58:23.562551 (MainThread): 19:58:23 | Finished running 4 view models in 4.85s.
2021-03-11 00:58:23.562656 (MainThread): Connection 'master' was properly closed.
2021-03-11 00:58:23.562731 (MainThread): Connection 'model.topcoat.tweets_by_day' was properly closed.
2021-03-11 00:58:23.636348 (MainThread): 
2021-03-11 00:58:23.636512 (MainThread): Completed successfully
2021-03-11 00:58:23.636626 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2021-03-11 00:58:23.636894 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adf5fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af052e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab41130>]}
2021-03-11 00:58:23.637075 (MainThread): Flushing usage events
2021-03-11 00:58:35.222794 (MainThread): Running with dbt=0.19.0
2021-03-11 00:58:35.690017 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.compile.CompileTask'>, debug=False, defer=None, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, parse_only=False, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='compile', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='compile', write_json=True)
2021-03-11 00:58:35.690816 (MainThread): Tracking: tracking
2021-03-11 00:58:35.699276 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c27c460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4fea00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4fe8e0>]}
2021-03-11 00:58:35.737885 (MainThread): Partial parsing not enabled
2021-03-11 00:58:35.739123 (MainThread): Parsing macros/adapters.sql
2021-03-11 00:58:35.761633 (MainThread): Parsing macros/catalog.sql
2021-03-11 00:58:35.768479 (MainThread): Parsing macros/etc.sql
2021-03-11 00:58:35.770709 (MainThread): Parsing macros/materializations/copy.sql
2021-03-11 00:58:35.775667 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-11 00:58:35.790155 (MainThread): Parsing macros/materializations/seed.sql
2021-03-11 00:58:35.793390 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-11 00:58:35.795324 (MainThread): Parsing macros/materializations/table.sql
2021-03-11 00:58:35.806760 (MainThread): Parsing macros/materializations/view.sql
2021-03-11 00:58:35.810853 (MainThread): Parsing macros/core.sql
2021-03-11 00:58:35.815124 (MainThread): Parsing macros/adapters/common.sql
2021-03-11 00:58:35.865210 (MainThread): Parsing macros/etc/datetime.sql
2021-03-11 00:58:35.876322 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-11 00:58:35.877481 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-11 00:58:35.879410 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-11 00:58:35.881578 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-11 00:58:35.884060 (MainThread): Parsing macros/etc/query.sql
2021-03-11 00:58:35.885290 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-11 00:58:35.896848 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-11 00:58:35.914122 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-11 00:58:35.916990 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-11 00:58:35.924260 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-11 00:58:35.951028 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-11 00:58:35.992218 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-11 00:58:35.994737 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-11 00:58:36.019158 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-11 00:58:36.027184 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-11 00:58:36.033060 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-11 00:58:36.040563 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-11 00:58:36.043776 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-11 00:58:36.045680 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-11 00:58:36.047770 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-11 00:58:36.056386 (MainThread): Partial parsing not enabled
2021-03-11 00:58:36.107596 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:58:36.133251 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:58:36.144553 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:58:36.157353 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:58:36.439482 (MainThread): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:58:36.452829 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter".
2021-03-11 00:58:36.463486 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter_simple".
2021-03-11 00:58:36.474261 (MainThread): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:58:36.487832 (MainThread): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:58:36.500807 (MainThread): Acquiring new bigquery connection "model.topcoat.replies_toggle".
2021-03-11 00:58:36.511183 (MainThread): Acquiring new bigquery connection "model.topcoat.test_toggle".
2021-03-11 00:58:36.521538 (MainThread): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:58:36.533881 (MainThread): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:58:36.545841 (MainThread): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:58:36.557843 (MainThread): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:58:36.603108 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-11 00:58:36.603423 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:58:36.603562 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:58:36.674734 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-11 00:58:36.684863 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a188c88-d541-40e2-a45f-ded4632e671a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d89d880>]}
2021-03-11 00:58:36.765133 (MainThread): Found 15 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 4 exposures
2021-03-11 00:58:36.767525 (MainThread): 
2021-03-11 00:58:36.767917 (MainThread): Acquiring new bigquery connection "master".
2021-03-11 00:58:36.776271 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-11 00:58:36.776463 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-11 00:58:36.780948 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-11 00:58:37.107876 (MainThread): 19:58:37 | Concurrency: 1 threads (target='prod')
2021-03-11 00:58:37.108065 (MainThread): 19:58:37 | 
2021-03-11 00:58:37.110041 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:37.110562 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:58:37.110700 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:37.128430 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-11 00:58:37.128767 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.129021 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.129406 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:37.129536 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:37.129766 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:58:37.129866 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:37.137849 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-11 00:58:37.138168 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.138401 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.138773 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:37.138900 (Thread-1): Began running node model.topcoat.sparklinesql
2021-03-11 00:58:37.139129 (Thread-1): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:58:37.139236 (Thread-1): Compiling model.topcoat.sparklinesql
2021-03-11 00:58:37.145502 (Thread-1): Writing injected SQL for node "model.topcoat.sparklinesql"
2021-03-11 00:58:37.146160 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.146665 (Thread-1): Finished running node model.topcoat.sparklinesql
2021-03-11 00:58:37.146797 (Thread-1): Began running node model.hashpath_demo.tweet_words
2021-03-11 00:58:37.147043 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:58:37.147295 (Thread-1): Compiling model.hashpath_demo.tweet_words
2021-03-11 00:58:37.157739 (Thread-1): Writing injected SQL for node "model.hashpath_demo.tweet_words"
2021-03-11 00:58:37.158093 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.158361 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.158774 (Thread-1): Finished running node model.hashpath_demo.tweet_words
2021-03-11 00:58:37.158912 (Thread-1): Began running node model.hashpath_demo.twitter_metrics
2021-03-11 00:58:37.159162 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:58:37.159269 (Thread-1): Compiling model.hashpath_demo.twitter_metrics
2021-03-11 00:58:37.169471 (Thread-1): Writing injected SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-11 00:58:37.170109 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.170506 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.170989 (Thread-1): Finished running node model.hashpath_demo.twitter_metrics
2021-03-11 00:58:37.171140 (Thread-1): Began running node model.topcoat.an_tweet_words
2021-03-11 00:58:37.171410 (Thread-1): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:58:37.171655 (Thread-1): Compiling model.topcoat.an_tweet_words
2021-03-11 00:58:37.176193 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54854), raddr=('172.217.10.42', 443)>
2021-03-11 00:58:37.176527 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54855), raddr=('142.250.80.10', 443)>
2021-03-11 00:58:37.180392 (Thread-1): Writing injected SQL for node "model.topcoat.an_tweet_words"
2021-03-11 00:58:37.180709 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.181594 (Thread-1): Finished running node model.topcoat.an_tweet_words
2021-03-11 00:58:37.181805 (Thread-1): Began running node model.topcoat.your_network
2021-03-11 00:58:37.182184 (Thread-1): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:58:37.182560 (Thread-1): Compiling model.topcoat.your_network
2021-03-11 00:58:37.190385 (Thread-1): Writing injected SQL for node "model.topcoat.your_network"
2021-03-11 00:58:37.190897 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.191409 (Thread-1): Finished running node model.topcoat.your_network
2021-03-11 00:58:37.191544 (Thread-1): Began running node model.topcoat.all_tweets
2021-03-11 00:58:37.191798 (Thread-1): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:58:37.191908 (Thread-1): Compiling model.topcoat.all_tweets
2021-03-11 00:58:37.199286 (Thread-1): Writing injected SQL for node "model.topcoat.all_tweets"
2021-03-11 00:58:37.199635 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.200071 (Thread-1): Finished running node model.topcoat.all_tweets
2021-03-11 00:58:37.200610 (Thread-1): Began running node model.topcoat.top_tweets
2021-03-11 00:58:37.200860 (Thread-1): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:58:37.200962 (Thread-1): Compiling model.topcoat.top_tweets
2021-03-11 00:58:37.211036 (Thread-1): Writing injected SQL for node "model.topcoat.top_tweets"
2021-03-11 00:58:37.211419 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.211897 (Thread-1): Finished running node model.topcoat.top_tweets
2021-03-11 00:58:37.212042 (Thread-1): Began running node model.topcoat.total_tweets
2021-03-11 00:58:37.212357 (Thread-1): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:58:37.212480 (Thread-1): Compiling model.topcoat.total_tweets
2021-03-11 00:58:37.221774 (Thread-1): Writing injected SQL for node "model.topcoat.total_tweets"
2021-03-11 00:58:37.222135 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.222689 (Thread-1): Finished running node model.topcoat.total_tweets
2021-03-11 00:58:37.222853 (Thread-1): Began running node model.topcoat.tweets_by_day
2021-03-11 00:58:37.223115 (Thread-1): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:58:37.223228 (Thread-1): Compiling model.topcoat.tweets_by_day
2021-03-11 00:58:37.231236 (Thread-1): Writing injected SQL for node "model.topcoat.tweets_by_day"
2021-03-11 00:58:37.231560 (Thread-1): finished collecting timing info
2021-03-11 00:58:37.231979 (Thread-1): Finished running node model.topcoat.tweets_by_day
2021-03-11 00:58:37.233152 (MainThread): Connection 'master' was properly closed.
2021-03-11 00:58:37.233253 (MainThread): Connection 'model.topcoat.tweets_by_day' was properly closed.
2021-03-11 00:58:37.306189 (MainThread): 19:58:37 | Done.
2021-03-11 00:58:37.306438 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d76fa00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d7dfca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d75ad60>]}
2021-03-11 00:58:37.306652 (MainThread): Flushing usage events
2021-03-11 00:58:45.136130 (MainThread): Running with dbt=0.19.0
2021-03-11 00:58:45.625274 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, defer=None, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sethrosen/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', selector_name=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2021-03-11 00:58:45.626155 (MainThread): Tracking: tracking
2021-03-11 00:58:45.636147 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10528b940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10529d3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10529d280>]}
2021-03-11 00:58:45.681731 (MainThread): Partial parsing not enabled
2021-03-11 00:58:45.683065 (MainThread): Parsing macros/adapters.sql
2021-03-11 00:58:45.708979 (MainThread): Parsing macros/catalog.sql
2021-03-11 00:58:45.717277 (MainThread): Parsing macros/etc.sql
2021-03-11 00:58:45.720110 (MainThread): Parsing macros/materializations/copy.sql
2021-03-11 00:58:45.725625 (MainThread): Parsing macros/materializations/incremental.sql
2021-03-11 00:58:45.742128 (MainThread): Parsing macros/materializations/seed.sql
2021-03-11 00:58:45.745470 (MainThread): Parsing macros/materializations/snapshot.sql
2021-03-11 00:58:45.748868 (MainThread): Parsing macros/materializations/table.sql
2021-03-11 00:58:45.761397 (MainThread): Parsing macros/materializations/view.sql
2021-03-11 00:58:45.766570 (MainThread): Parsing macros/core.sql
2021-03-11 00:58:45.771215 (MainThread): Parsing macros/adapters/common.sql
2021-03-11 00:58:45.823471 (MainThread): Parsing macros/etc/datetime.sql
2021-03-11 00:58:45.834886 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-03-11 00:58:45.836152 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-03-11 00:58:45.837991 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-03-11 00:58:45.840175 (MainThread): Parsing macros/etc/is_incremental.sql
2021-03-11 00:58:45.843469 (MainThread): Parsing macros/etc/query.sql
2021-03-11 00:58:45.844737 (MainThread): Parsing macros/materializations/helpers.sql
2021-03-11 00:58:45.855025 (MainThread): Parsing macros/materializations/common/merge.sql
2021-03-11 00:58:45.873167 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-03-11 00:58:45.876053 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-03-11 00:58:45.884357 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-03-11 00:58:45.911941 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-03-11 00:58:45.952532 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-03-11 00:58:45.954568 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-03-11 00:58:45.977680 (MainThread): Parsing macros/materializations/table/table.sql
2021-03-11 00:58:45.986145 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-03-11 00:58:45.992384 (MainThread): Parsing macros/materializations/view/view.sql
2021-03-11 00:58:46.000292 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-03-11 00:58:46.004347 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-03-11 00:58:46.006311 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-03-11 00:58:46.008395 (MainThread): Parsing macros/schema_tests/unique.sql
2021-03-11 00:58:46.017483 (MainThread): Partial parsing not enabled
2021-03-11 00:58:46.071134 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:58:46.095131 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:58:46.108048 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:58:46.119339 (MainThread): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:58:46.378161 (MainThread): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:58:46.388887 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter".
2021-03-11 00:58:46.399669 (MainThread): Acquiring new bigquery connection "model.topcoat.date_filter_simple".
2021-03-11 00:58:46.409865 (MainThread): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:58:46.421821 (MainThread): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:58:46.436043 (MainThread): Acquiring new bigquery connection "model.topcoat.replies_toggle".
2021-03-11 00:58:46.448505 (MainThread): Acquiring new bigquery connection "model.topcoat.test_toggle".
2021-03-11 00:58:46.461829 (MainThread): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:58:46.485765 (MainThread): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:58:46.498142 (MainThread): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:58:46.510539 (MainThread): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:58:46.559352 (MainThread): WARNING: Found documentation for resource "unique_public_metrics" which was not found or is disabled
2021-03-11 00:58:46.559710 (MainThread): [WARNING]: Test 'test.hashpath_demo.unique_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:58:46.559860 (MainThread): [WARNING]: Test 'test.hashpath_demo.not_null_unique_public_metrics_id' (models/twitter/schema.yml) depends on a node named 'unique_public_metrics' which was not found
2021-03-11 00:58:46.631345 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.twitter

2021-03-11 00:58:46.642491 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96fe3125-ab6f-44c0-a312-30fe99736015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056f3c10>]}
2021-03-11 00:58:46.725037 (MainThread): Found 15 models, 0 tests, 0 snapshots, 0 analyses, 156 macros, 0 operations, 0 seed files, 2 sources, 4 exposures
2021-03-11 00:58:46.727241 (MainThread): 
2021-03-11 00:58:46.727608 (MainThread): Acquiring new bigquery connection "master".
2021-03-11 00:58:46.736932 (ThreadPoolExecutor-0_0): Acquiring new bigquery connection "list_hashpath-demo-data_dbt_demo_production".
2021-03-11 00:58:46.737115 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-03-11 00:58:46.741500 (ThreadPoolExecutor-0_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2021-03-11 00:58:47.107953 (MainThread): 19:58:47 | Concurrency: 1 threads (target='prod')
2021-03-11 00:58:47.108169 (MainThread): 19:58:47 | 
2021-03-11 00:58:47.110541 (Thread-1): Began running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:47.111445 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_public_metrics".
2021-03-11 00:58:47.111966 (Thread-1): Compiling model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:47.133255 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_public_metrics"
2021-03-11 00:58:47.133664 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.133988 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.134499 (Thread-1): Finished running node model.hashpath_demo.stg_unique_public_metrics
2021-03-11 00:58:47.134677 (Thread-1): Began running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:47.135079 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.stg_unique_private_metrics".
2021-03-11 00:58:47.135263 (Thread-1): Compiling model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:47.143549 (Thread-1): Writing injected SQL for node "model.hashpath_demo.stg_unique_private_metrics"
2021-03-11 00:58:47.144074 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.144604 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.145090 (Thread-1): Finished running node model.hashpath_demo.stg_unique_private_metrics
2021-03-11 00:58:47.145239 (Thread-1): Began running node model.topcoat.sparklinesql
2021-03-11 00:58:47.145495 (Thread-1): Acquiring new bigquery connection "model.topcoat.sparklinesql".
2021-03-11 00:58:47.145615 (Thread-1): Compiling model.topcoat.sparklinesql
2021-03-11 00:58:47.152519 (Thread-1): Writing injected SQL for node "model.topcoat.sparklinesql"
2021-03-11 00:58:47.152878 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.153355 (Thread-1): Finished running node model.topcoat.sparklinesql
2021-03-11 00:58:47.153498 (Thread-1): Began running node model.hashpath_demo.tweet_words
2021-03-11 00:58:47.153759 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.tweet_words".
2021-03-11 00:58:47.153872 (Thread-1): Compiling model.hashpath_demo.tweet_words
2021-03-11 00:58:47.166090 (Thread-1): Writing injected SQL for node "model.hashpath_demo.tweet_words"
2021-03-11 00:58:47.166959 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.167550 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.168184 (Thread-1): Finished running node model.hashpath_demo.tweet_words
2021-03-11 00:58:47.168375 (Thread-1): Began running node model.hashpath_demo.twitter_metrics
2021-03-11 00:58:47.168709 (Thread-1): Acquiring new bigquery connection "model.hashpath_demo.twitter_metrics".
2021-03-11 00:58:47.168861 (Thread-1): Compiling model.hashpath_demo.twitter_metrics
2021-03-11 00:58:47.180024 (Thread-1): Writing injected SQL for node "model.hashpath_demo.twitter_metrics"
2021-03-11 00:58:47.180603 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.181003 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.181496 (Thread-1): Finished running node model.hashpath_demo.twitter_metrics
2021-03-11 00:58:47.181660 (Thread-1): Began running node model.topcoat.an_tweet_words
2021-03-11 00:58:47.181942 (Thread-1): Acquiring new bigquery connection "model.topcoat.an_tweet_words".
2021-03-11 00:58:47.182062 (Thread-1): Compiling model.topcoat.an_tweet_words
2021-03-11 00:58:47.186054 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54862), raddr=('172.217.10.42', 443)>
2021-03-11 00:58:47.186495 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.86.91', 54863), raddr=('142.250.80.10', 443)>
2021-03-11 00:58:47.191201 (Thread-1): Writing injected SQL for node "model.topcoat.an_tweet_words"
2021-03-11 00:58:47.191540 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.192001 (Thread-1): Finished running node model.topcoat.an_tweet_words
2021-03-11 00:58:47.192144 (Thread-1): Began running node model.topcoat.your_network
2021-03-11 00:58:47.192400 (Thread-1): Acquiring new bigquery connection "model.topcoat.your_network".
2021-03-11 00:58:47.192512 (Thread-1): Compiling model.topcoat.your_network
2021-03-11 00:58:47.199993 (Thread-1): Writing injected SQL for node "model.topcoat.your_network"
2021-03-11 00:58:47.200331 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.200783 (Thread-1): Finished running node model.topcoat.your_network
2021-03-11 00:58:47.200923 (Thread-1): Began running node model.topcoat.all_tweets
2021-03-11 00:58:47.201177 (Thread-1): Acquiring new bigquery connection "model.topcoat.all_tweets".
2021-03-11 00:58:47.201287 (Thread-1): Compiling model.topcoat.all_tweets
2021-03-11 00:58:47.208364 (Thread-1): Writing injected SQL for node "model.topcoat.all_tweets"
2021-03-11 00:58:47.208690 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.209127 (Thread-1): Finished running node model.topcoat.all_tweets
2021-03-11 00:58:47.209684 (Thread-1): Began running node model.topcoat.top_tweets
2021-03-11 00:58:47.209967 (Thread-1): Acquiring new bigquery connection "model.topcoat.top_tweets".
2021-03-11 00:58:47.210077 (Thread-1): Compiling model.topcoat.top_tweets
2021-03-11 00:58:47.218324 (Thread-1): Writing injected SQL for node "model.topcoat.top_tweets"
2021-03-11 00:58:47.218665 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.219212 (Thread-1): Finished running node model.topcoat.top_tweets
2021-03-11 00:58:47.219362 (Thread-1): Began running node model.topcoat.total_tweets
2021-03-11 00:58:47.219627 (Thread-1): Acquiring new bigquery connection "model.topcoat.total_tweets".
2021-03-11 00:58:47.219739 (Thread-1): Compiling model.topcoat.total_tweets
2021-03-11 00:58:47.227464 (Thread-1): Writing injected SQL for node "model.topcoat.total_tweets"
2021-03-11 00:58:47.227769 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.228192 (Thread-1): Finished running node model.topcoat.total_tweets
2021-03-11 00:58:47.228330 (Thread-1): Began running node model.topcoat.tweets_by_day
2021-03-11 00:58:47.228653 (Thread-1): Acquiring new bigquery connection "model.topcoat.tweets_by_day".
2021-03-11 00:58:47.228772 (Thread-1): Compiling model.topcoat.tweets_by_day
2021-03-11 00:58:47.236478 (Thread-1): Writing injected SQL for node "model.topcoat.tweets_by_day"
2021-03-11 00:58:47.236832 (Thread-1): finished collecting timing info
2021-03-11 00:58:47.237392 (Thread-1): Finished running node model.topcoat.tweets_by_day
2021-03-11 00:58:47.238329 (MainThread): Connection 'master' was properly closed.
2021-03-11 00:58:47.238437 (MainThread): Connection 'model.topcoat.tweets_by_day' was properly closed.
2021-03-11 00:58:47.311126 (MainThread): 19:58:47 | Done.
2021-03-11 00:58:47.313329 (MainThread): Acquiring new bigquery connection "generate_catalog".
2021-03-11 00:58:47.313589 (MainThread): 19:58:47 | Building catalog
2021-03-11 00:58:47.353348 (MainThread): Opening a new connection, currently in state init
2021-03-11 00:58:47.696094 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-11 00:58:47.715832 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2021-03-11 00:58:47.720092 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`dbt_demo_production`.__TABLES__
        where (upper(dataset_id) = upper('dbt_demo_production'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`dbt_demo_production`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-11 00:58:51.875590 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "hashpath-demo-data.information_schema".
2021-03-11 00:58:51.878968 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2021-03-11 00:58:51.884392 (ThreadPoolExecutor-1_0): On hashpath-demo-data.information_schema: /* {"app": "dbt", "dbt_version": "0.19.0", "profile_name": "default", "target_name": "prod", "connection_name": "hashpath-demo-data.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `hashpath-demo-data`.`twitter`.__TABLES__
        where (upper(dataset_id) = upper('twitter'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `hashpath-demo-data`.`twitter`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
2021-03-11 00:58:55.561963 (MainThread): 19:58:55 | Catalog written to /Users/sethrosen/Documents/GitHub/dbt_topcoat_demo/target/catalog.json
2021-03-11 00:58:55.562529 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10528b940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e2b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10558b430>]}
2021-03-11 00:58:55.562728 (MainThread): Flushing usage events
2021-03-11 00:58:55.803795 (MainThread): Connection 'generate_catalog' was properly closed.
2021-03-11 00:58:55.803973 (MainThread): Connection 'hashpath-demo-data.information_schema' was properly closed.
